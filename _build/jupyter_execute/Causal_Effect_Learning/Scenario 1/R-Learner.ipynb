{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32szzPY4RyWO",
   "metadata": {
    "id": "32szzPY4RyWO"
   },
   "source": [
    "### **4. R learner**\n",
    "The idea of classical R-learner came from Robinson 1988 [3] and was formalized by Nie and Wager in 2020 [2]. The main idea of R learner starts from the partially linear model setup, in which we assume that\n",
    "\\begin{equation}\n",
    "  \\begin{aligned}\n",
    "    R&=A\\tau(S)+g_0(S)+U,\\\\\n",
    "    A&=m_0(S)+V,\n",
    "  \\end{aligned}\n",
    "\\end{equation}\n",
    "where $U$ and $V$ satisfies $\\mathbb{E}[U|D,X]=0$, $\\mathbb{E}[V|X]=0$.\n",
    "\n",
    "After several manipulations, it’s easy to get\n",
    "\\begin{equation}\n",
    "\tR-\\mathbb{E}[R|S]=\\tau(S)\\cdot(A-\\mathbb{E}[A|S])+\\epsilon.\n",
    "\\end{equation}\n",
    "Define $m_0(X)=\\mathbb{E}[A|S]$ and $l_0(X)=\\mathbb{E}[R|S]$. A natural way to estimate $\\tau(X)$ is given below, which is also the main idea of R-learner:\n",
    "\n",
    "**Step 1**: Regress $R$ on $S$ to obtain model $\\hat{\\eta}(S)=\\hat{\\mathbb{E}}[R|S]$; and regress $A$ on $S$ to obtain model $\\hat{m}(S)=\\hat{\\mathbb{E}}[A|S]$.\n",
    "\n",
    "**Step 2**: Regress outcome residual $R-\\hat{l}(S)$ on propensity score residual $A-\\hat{m}(S)$.\n",
    "\n",
    "That is,\n",
    "\\begin{equation}\n",
    "\t\\hat{\\tau}(S)=\\arg\\min_{\\tau}\\left\\{\\mathbb{E}_n\\left[\\left(\\{R_i-\\hat{\\eta}(S_i)\\}-\\{A_i-\\hat{m}(S_i)\\}\\cdot\\tau(S_i)\\right)^2\\right]\\right\\}\t\n",
    "\\end{equation}\n",
    "\n",
    "The easiest way to do so is to specify $\\hat{\\tau}(S)$ to the linear function class. In this case, $\\tau(S)=S\\beta$, and the problem becomes to estimate $\\beta$ by solving the following linear regression:\n",
    "\\begin{equation}\n",
    "\t\\hat{\\beta}=\\arg\\min_{\\beta}\\left\\{\\mathbb{E}_n\\left[\\left(\\{R_i-\\hat{\\eta}(S_i)\\}-\\{A_i-\\hat{m}(S_i)\\} S_i\\cdot \\beta\\right)^2\\right]\\right\\}.\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "oJd6A5hgXmGZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4287,
     "status": "ok",
     "timestamp": 1676134075357,
     "user": {
      "displayName": "Yang Xu",
      "userId": "12270366590264264299"
     },
     "user_tz": 300
    },
    "id": "oJd6A5hgXmGZ",
    "outputId": "9e32343f-1b89-4ab6-eca3-8a02680d80af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-uplift in c:\\faked\\anaconda\\lib\\site-packages (0.5.1)\n",
      "Requirement already satisfied: requests in c:\\faked\\anaconda\\lib\\site-packages (from scikit-uplift) (2.22.0)\n",
      "Requirement already satisfied: tqdm in c:\\faked\\anaconda\\lib\\site-packages (from scikit-uplift) (4.36.1)\n",
      "Requirement already satisfied: numpy>=1.16 in c:\\faked\\anaconda\\lib\\site-packages (from scikit-uplift) (1.16.5)\n",
      "Requirement already satisfied: pandas in c:\\faked\\anaconda\\lib\\site-packages (from scikit-uplift) (0.25.1)\n",
      "Requirement already satisfied: scikit-learn>=0.21.0 in c:\\faked\\anaconda\\lib\\site-packages (from scikit-uplift) (0.21.3)\n",
      "Requirement already satisfied: matplotlib in c:\\faked\\anaconda\\lib\\site-packages (from scikit-uplift) (3.1.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\faked\\anaconda\\lib\\site-packages (from scikit-learn>=0.21.0->scikit-uplift) (1.3.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\faked\\anaconda\\lib\\site-packages (from scikit-learn>=0.21.0->scikit-uplift) (0.13.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\faked\\anaconda\\lib\\site-packages (from matplotlib->scikit-uplift) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\faked\\anaconda\\lib\\site-packages (from matplotlib->scikit-uplift) (1.1.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\faked\\anaconda\\lib\\site-packages (from matplotlib->scikit-uplift) (2.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\yang xu\\appdata\\roaming\\python\\python37\\site-packages (from matplotlib->scikit-uplift) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\faked\\anaconda\\lib\\site-packages (from pandas->scikit-uplift) (2019.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\faked\\anaconda\\lib\\site-packages (from requests->scikit-uplift) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\faked\\anaconda\\lib\\site-packages (from requests->scikit-uplift) (2019.9.11)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\faked\\anaconda\\lib\\site-packages (from requests->scikit-uplift) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\faked\\anaconda\\lib\\site-packages (from requests->scikit-uplift) (1.24.2)\n",
      "Requirement already satisfied: six in c:\\faked\\anaconda\\lib\\site-packages (from cycler>=0.10->matplotlib->scikit-uplift) (1.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\faked\\anaconda\\lib\\site-packages (from kiwisolver>=1.0.1->matplotlib->scikit-uplift) (41.4.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install scikit-uplift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eRpP5k9MBtzO",
   "metadata": {
    "id": "eRpP5k9MBtzO"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'causaldm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-275f33df0573>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mcausaldm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_util_causaldm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcausaldm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearners\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCausal_Effect_Learning\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSingle_Stage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRlearner\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRlearner\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'causaldm'"
     ]
    }
   ],
   "source": [
    "# import related packages\n",
    "from matplotlib import pyplot as plt\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from causaldm._util_causaldm import *\n",
    "from causaldm.learners.Causal_Effect_Learning.Single_Stage.Rlearner import Rlearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovM_twTxuOj",
   "metadata": {
    "id": "lovM_twTxuOj"
   },
   "outputs": [],
   "source": [
    "n = 10**3  # sample size in observed data\n",
    "n0 = 10**5 # the number of samples used to estimate the true reward distribution by MC\n",
    "seed=223"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AnRQO0viX3D1",
   "metadata": {
    "id": "AnRQO0viX3D1"
   },
   "outputs": [],
   "source": [
    "# Get data\n",
    "data_behavior = get_data_simulation(n, seed, policy=\"behavior\")\n",
    "#data_target = get_data_simulation(n0, seed, policy=\"target\")\n",
    "\n",
    "# The true expected heterogeneous treatment effect\n",
    "HTE_true = get_data_simulation(n, seed, policy=\"1\")['R']-get_data_simulation(n, seed, policy=\"0\")['R']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jYIe491FKQAs",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 687,
     "status": "ok",
     "timestamp": 1676134159221,
     "user": {
      "displayName": "Yang Xu",
      "userId": "12270366590264264299"
     },
     "user_tz": 300
    },
    "id": "jYIe491FKQAs",
    "outputId": "26de837c-daa2-4402-d668-c71439246014"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimate with R-learner\n",
      "fold 1,testing r2 y_learner: 0.942, ps_learner: 0.943\n",
      "fold 2,testing r2 y_learner: 0.958, ps_learner: 0.966\n",
      "fold 3,testing r2 y_learner: 0.951, ps_learner: 0.948\n",
      "fold 4,testing r2 y_learner: 0.957, ps_learner: 0.932\n",
      "fold 5,testing r2 y_learner: 0.950, ps_learner: 0.944\n",
      "fold 1, training r2 R-learner: 0.683, testing r2 R-learner: 0.584\n",
      "fold 2, training r2 R-learner: 0.659, testing r2 R-learner: 0.705\n",
      "fold 3, training r2 R-learner: 0.677, testing r2 R-learner: 0.536\n",
      "fold 4, training r2 R-learner: 0.667, testing r2 R-learner: 0.642\n",
      "fold 5, training r2 R-learner: 0.669, testing r2 R-learner: 0.551\n"
     ]
    }
   ],
   "source": [
    "# R-learner for HTE estimation\n",
    "outcome = 'R'\n",
    "treatment = 'A'\n",
    "controls = ['S1','S2']\n",
    "n_folds = 5\n",
    "y_model = LGBMRegressor(max_depth=2)\n",
    "ps_model = LogisticRegression()\n",
    "Rlearner_model = LGBMRegressor(max_depth=2)\n",
    "\n",
    "HTE_R_learner = Rlearner(data_behavior, outcome, treatment, controls, n_folds, y_model, ps_model, Rlearner_model)\n",
    "HTE_R_learner = HTE_R_learner.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "D_B2JzoeEVkM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 176,
     "status": "ok",
     "timestamp": 1676134159939,
     "user": {
      "displayName": "Yang Xu",
      "userId": "12270366590264264299"
     },
     "user_tz": 300
    },
    "id": "D_B2JzoeEVkM",
    "outputId": "d1c29b6e-2994-44d5-f2d9-07331faa6f5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-learner:   [-0.5085 -0.1427 -1.1424 -0.0139 -1.1341 -1.1424 -1.4466 -1.5688]\n",
      "true value:  [ 1.2961 -0.4475  0.731   0.2863  0.4471 -0.1839 -3.3869 -1.238 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"R-learner:  \",HTE_R_learner[0:8])\n",
    "print(\"true value: \",HTE_true[0:8].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2FvnH_FtEVkj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 142,
     "status": "ok",
     "timestamp": 1676134160896,
     "user": {
      "displayName": "Yang Xu",
      "userId": "12270366590264264299"
     },
     "user_tz": 300
    },
    "id": "2FvnH_FtEVkj",
    "outputId": "bd4d43cf-5fd2-4263-aeb8-449ac7ad7d37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall estimation bias of R-learner is :      -0.02930508052654023 , \n",
      " The overall estimation variance of R-learner is : 3.1359997242638173 . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Bias_R_learner = np.sum(HTE_R_learner-HTE_true)/n\n",
    "Variance_R_learner = np.sum((HTE_R_learner-HTE_true)**2)/n\n",
    "print(\"The overall estimation bias of R-learner is :     \", Bias_R_learner, \", \\n\", \"The overall estimation variance of R-learner is :\",Variance_R_learner,\". \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EWhausRhExr5",
   "metadata": {
    "id": "EWhausRhExr5"
   },
   "source": [
    "**Conclusion:** It's amazing to see that the bias of R-learner is significantly smaller than all other approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1098b550",
   "metadata": {
    "id": "1098b550"
   },
   "source": [
    "## References\n",
    "\n",
    "2. Xinkun Nie and Stefan Wager. Quasi-oracle estimation of heterogeneous treatment effects. Biometrika, 108(2):299–319, 2021.\n",
    "\n",
    "3. Peter M Robinson. Root-n-consistent semiparametric regression. Econometrica: Journal of the Econometric Society, pages 931–954, 1988.\n",
    "\n",
    "4. Edward H Kennedy. Optimal doubly robust estimation of heterogeneous causal effects. arXiv preprint arXiv:2004.14497, 2020\n",
    "\n",
    "5. M. J. van der Laan. Statistical inference for variable importance. The International Journal of Biostatistics, 2(1), 2006.\n",
    "\n",
    "6. S. Lee, R. Okui, and Y.-J. Whang. Doubly robust uniform confidence band for the conditional average treatment effect function. Journal of Applied Econometrics, 32(7):1207–1225, 2017.\n",
    "\n",
    "7. D. J. Foster and V. Syrgkanis. Orthogonal statistical learning. arXiv preprint arXiv:1901.09036, 2019."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "1098b550"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}