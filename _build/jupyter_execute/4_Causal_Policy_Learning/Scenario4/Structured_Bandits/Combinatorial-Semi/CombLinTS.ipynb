{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c50dd25",
   "metadata": {},
   "source": [
    "# CombLinTS\n",
    "\n",
    "## Overview\n",
    "- **Advantage**: It is scalable when the features are used. It outperforms algorithms based on other frameworks, such as UCB, in practice.\n",
    "- **Disadvantage**: It is susceptible to model misspecification.\n",
    "- **Application Situation**: Useful when presenting a list of items, each of which will generate a partial outcome (reward). The outcome is continuous.\n",
    "\n",
    "## Main Idea\n",
    "Noticing that feature information are common in practice, Wen et al. (2015) considers a generalization across items to reach a lower regret bound independent of $N$, by assuming a linear generalization model for $\\boldsymbol{\\theta}$. Specifically, we assume that\n",
    "\\begin{equation}\n",
    "\\theta_{i} = \\boldsymbol{s}_{i,t}^{T}\\boldsymbol{\\gamma}.\n",
    "\\end{equation}\n",
    "At each round $t$, **CombLinTS** samples $\\tilde{\\boldsymbol{\\gamma}}_{t}$ from the updated posterior distribution $N(\\hat{\\boldsymbol{\\gamma}}_{t},\\hat{\\boldsymbol{\\Sigma}}_{t})$ and get the $\\tilde{\\theta}_{i}^{t}$ as $\\boldsymbol{s}_{i,t}^{T}\\tilde{\\boldsymbol{\\gamma}}_{t}$, where $\\hat{\\boldsymbol{\\gamma}}_{t}$ and $\\hat{\\boldsymbol{\\Sigma}}_{t}$ are updated by the Kalman Filtering algorithm[1]. Note that when the outcome distribution $\\mathcal{P}$ is Gaussian, the updated posterior distribution is the exact posterior distribution of $\\boldsymbol{\\gamma}$ as **CombLinTS** assumes a Gaussian Prior. \n",
    "\n",
    "It's also important to note that, if necessary, the posterior updating stepÂ can be simply changed to accommodate various prior/reward distribution specifications. Further, for simplicity, we consider the most basic size constraint such that the action space includes all the possible subsets with size $K$. Therefore, the optimization process to find the optimal subset $A_{t}$ is equal to selecting a list of $K$ items with the highest attractiveness factors. Of course, users are welcome to modify the **optimization** function to satisfy more complex constraints.\n",
    "\n",
    "## Key Steps\n",
    "For round $t = 1,2,\\cdots$:\n",
    "1. Approximate $P(\\boldsymbol{\\gamma}|\\mathcal{H}_{t})$ with a Gaussian prior;\n",
    "2. Sample $\\tilde{\\boldsymbol{\\gamma}} \\sim P(\\boldsymbol{\\gamma}|\\mathcal{H}_{t})$;\n",
    "3. Update $\\tilde{\\boldsymbol{\\theta}}$ as $\\boldsymbol{s}_{i,t}^T \\tilde{\\boldsymbol{\\gamma}}$;\n",
    "5. Take the action $A_{t}$ w.r.t $\\tilde{\\boldsymbol{\\theta}}$ such that $A_t = arg max_{a \\in \\mathcal{A}} E(R_t(a) \\mid \\tilde{\\boldsymbol{\\theta}})$;\n",
    "6. Receive reward $R_{t}$.\n",
    "\n",
    "*Notations can be found in either the inroduction of the chapter \"Structured Bandits\" or the introduction of the combinatorial Semi-Bandit problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa0d14b",
   "metadata": {},
   "source": [
    "## Demo Code"
   ]
  },
  {
<<<<<<< Updated upstream
   "cell_type": "code",
   "execution_count": 1,
   "id": "728a9324",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\GitHub\\\\CausalDM'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m os\u001b[38;5;241m.\u001b[39mgetcwd()\n\u001b[0;32m----> 3\u001b[0m os\u001b[38;5;241m.\u001b[39mchdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mGitHub\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCausalDM\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\GitHub\\\\CausalDM'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()\n",
    "os.chdir('D:\\GitHub\\CausalDM')"
   ]
  },
  {
=======
>>>>>>> Stashed changes
   "cell_type": "markdown",
   "id": "f9dd94b4-81a0-4171-9a37-e62add6fd99d",
   "metadata": {},
   "source": [
    "### Import the learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "074a9ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from causaldm.learners.CPL4.Structured_Bandits.Combinatorial_Semi import CombLinTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef70e64c-c506-42bd-97e3-fe0950c6e928",
   "metadata": {},
   "source": [
    "### Generate the Environment\n",
    "\n",
    "Here, we imitate an environment based on the Adult dataset. The length of horizon, $T$, is specified as $500$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b194b43-6741-481a-96c9-f73b81693c55",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\anaconda3\\\\lib\\\\site-packages\\\\causaldm\\\\learners\\\\CPL4\\\\Structured_Bandits\\\\Combinatorial_Semi\\\\data\\\\Semi_realdata_d_4_X_transform_origin_with_intercept_0_L_3000'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcausaldm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlearners\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCPL4\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mStructured_Bandits\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCombinatorial_Semi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _env_realComb \u001b[38;5;28;01mas\u001b[39;00m _env\n\u001b[1;32m----> 2\u001b[0m env \u001b[38;5;241m=\u001b[39m \u001b[43m_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCombSemi_env\u001b[49m\u001b[43m(\u001b[49m\u001b[43mT\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\causaldm\\learners\\CPL4\\_util_online.py:223\u001b[0m, in \u001b[0;36mautoargs.<locals>._autoargs.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m sieve(attr):\n\u001b[0;32m    222\u001b[0m             \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, attr, val)\n\u001b[1;32m--> 223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\causaldm\\learners\\CPL4\\Structured_Bandits\\Combinatorial_Semi\\_env_realComb.py:17\u001b[0m, in \u001b[0;36mCombSemi_env.__init__\u001b[1;34m(self, T, seed)\u001b[0m\n\u001b[0;32m     14\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed)\n\u001b[0;32m     15\u001b[0m random\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed)\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mPhi, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mp, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwith_intercept, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mL, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtheta \u001b[38;5;241m=\u001b[39m \u001b[43mget_Adult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigma_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors \u001b[38;5;241m=\u001b[39m randn(T, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mL) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msigma_2\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\causaldm\\learners\\CPL4\\Structured_Bandits\\Combinatorial_Semi\\_env_realComb.py:31\u001b[0m, in \u001b[0;36mget_Adult\u001b[1;34m()\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_Adult\u001b[39m():\n\u001b[0;32m     30\u001b[0m     dataset_path \u001b[38;5;241m=\u001b[39m pkg_resources\u001b[38;5;241m.\u001b[39mresource_filename(\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/Semi_realdata_d_4_X_transform_origin_with_intercept_0_L_3000\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[0;32m     32\u001b[0m         Adult \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(fp) \n\u001b[0;32m     33\u001b[0m     with_intercept \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\anaconda3\\\\lib\\\\site-packages\\\\causaldm\\\\learners\\\\CPL4\\\\Structured_Bandits\\\\Combinatorial_Semi\\\\data\\\\Semi_realdata_d_4_X_transform_origin_with_intercept_0_L_3000'"
     ]
    }
   ],
   "source": [
    "from causaldm.learners.CPL4.Structured_Bandits.Combinatorial_Semi import _env_realComb as _env\n",
    "env = _env.CombSemi_env(T = 500, seed = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328596a2-5deb-47ac-ae63-5acfaa0e3960",
   "metadata": {},
   "source": [
    "### Specify Hyperparameters\n",
    "- K: number of itmes to be recommended at each round\n",
    "- L: total number of candidate items\n",
    "- p: number of features (If the intercept is considerd,Â p includes the intercept as well.)\n",
    "- sigma: standard deviation of reward distribution (Note: we assume that the observed reward's random noise comes from the same distribution for all items.)\n",
    "- prior_gamma_mu: mean of the Gaussian prior of the $\\boldsymbol{\\gamma}$\n",
    "- prior_gamma_cov: the covariance matrix of the Gaussian prior of $\\boldsymbol{\\gamma}$\n",
    "- seed: random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14c2ed83",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = env.L\n",
    "K = 10\n",
    "p = env.p\n",
    "sigma = 1\n",
    "prior_gamma_mu = np.zeros(p)\n",
    "prior_gamma_cov = np.identity(p)\n",
    "seed = 0\n",
    "LinTS_agent = CombLinTS.LinTS_Semi(sigma = sigma, prior_gamma_mu = prior_gamma_mu, \n",
    "                                   prior_gamma_cov = prior_gamma_cov,L = L, K = K, \n",
    "                                   p = p, seed = seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fddb65c4-16c2-4eff-85c8-c503b95a6f40",
   "metadata": {},
   "source": [
    "### Recommendation and Interaction\n",
    "We fisrt observe the feature information $\\boldsymbol{S}$ by\n",
    "<code> S = env.Phi </code>. (Note: if an intercept is considered, the X should include a column of ones).\n",
    "Starting from t = 0, for each step t, there are three steps:\n",
    "1. Recommend an action (a set of ordered restaturants)\n",
    "<code> A = LinTS_agent.take_action(S) </code>\n",
    "2. Get the reward of each item recommended from the environment\n",
    "<code> R, _, tot_R = env.get_reward(A, t) </code>\n",
    "3. Update the posterior distribution\n",
    "<code> LinTS_agent.receive_reward(t, A, R, S) </code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acf95af3-dc5e-4969-a7b9-2602f5d81ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " array([ 480, 1895, 1700, 2219, 2807, 1593, 2784,  172, 2831, 1523]),\n",
       " array([ 0.8214, -0.2055, -1.408 , -0.0487, -0.8551,  1.1778, -0.595 ,\n",
       "         0.9068,  0.6194,  1.9444]),\n",
       " 2.3574891974648375)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = env.Phi\n",
    "t = 0\n",
    "A = LinTS_agent.take_action(S)\n",
    "R, _, tot_R = env.get_reward(A, t)\n",
    "LinTS_agent.receive_reward(t, A, R, S)\n",
    "t, A, R, tot_R"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cf743e",
   "metadata": {},
   "source": [
    "**Interpretation**: For step 0, the agent decides to send the advertisement to 10 potential customers (480, 1895, 1700, 2219, 2807, 1593, 2784,  172, 2831, 1523), and then receives a total reward of $2.36$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7723d78",
   "metadata": {},
   "source": [
    "## References\n",
    "[1] Wen, Z., Kveton, B., & Ashkan, A. (2015, June). Efficient learning in large-scale combinatorial semi-bandits. In International Conference on Machine Learning (pp. 1113-1122). PMLR."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< Updated upstream
   "version": "3.11.3"
=======
   "version": "3.9.12"
>>>>>>> Stashed changes
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}