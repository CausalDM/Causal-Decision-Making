{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eded0d2c",
   "metadata": {},
   "source": [
    "# LinTS\n",
    "\n",
    "## Overview\n",
    "- **Advantage**: It is scalable by utilizing features. It outperforms algorithms based on other frameworks, such as UCB, in practice.\n",
    "- **Disadvantage**: It is susceptible to model misspecification.\n",
    "- **Application Situation**: discrete action space, binary/Gaussian reward space\n",
    "\n",
    "## Main Idea\n",
    "Supposed there are $K$ options, and the action space is $\\mathcal{A} = \\{0,1,\\cdots, K-1\\}$. Noticing that feature information are commonly avialable, the **LinTS**[1,2] algorithm consdiers modeling the expectation of the potential reward $R_t(i)$ with features of item $i$. As an example, considering the Gaussian reward, we assume that \n",
    "\\begin{align}\n",
    "R_t(i)\\sim \\mathcal{N}(\\boldsymbol{s}_i^T \\boldsymbol{\\gamma},\\sigma^2).\n",
    "\\end{align}\n",
    "As for the Bernoulli reward, we assume that \n",
    "\\begin{align}\n",
    "R_t(i) \\sim Bernoulli(logistic(\\boldsymbol{s}_i^T \\boldsymbol{\\gamma})).\n",
    "\\end{align}where $logistic(c) \\equiv 1 / (1 + exp^{-1}(c))$.\n",
    "Similar as the standard TS algorithm, the LinTS algorithm starts with specifying a prior distribution of the parameter $\\boldsymbol{\\gamma}$, and a variance of the reward, based on the domian knowledge. At each round $t$, the agent will samples a vector of $\\tilde{\\boldsymbol{\\gamma}}^{t}$ from thecorresponding posterior distribution, and the mean reward $\\tilde{\\boldsymbol{\\theta}}^{t}$ is then calculated accordingly. The action $a$ with the greatest $\\tilde{\\theta}_{a}^{t}$ is then selected. Finally, the posterior distribution would be updated after receiving the feedback at the end of each round. It should be noted that the posterior updating step differs for different pairs of the prior distribution of expected potential reward and reward distribution, and the code can be easily modified to different prior/reward distribution specifications if necessary.\n",
    "\n",
    "## Key Steps\n",
    "\n",
    "1. Specifying a prior distirbution of $\\boldsymbol{\\gamma}$, and the variance of the reward distribution.\n",
    "2. For t = $0, 1,\\cdots, T$:\n",
    "    - sample a $\\tilde{\\boldsymbol{\\gamma}}^{t}$ from the posterior distribution of $\\boldsymbol{\\gamma}$ or the prior distribution of it if in round $0$\n",
    "    - calculated the $\\tilde{\\boldsymbol{\\theta}}^{t}$ based on the assumed linear relationship\n",
    "    - select action $A_t$ which has the greatest $\\tilde{\\theta}_{a}$, i.e. $A_t = \\arg\\max_{a \\in \\mathcal{A}} \\tilde{\\theta}_{a}^{t}$\n",
    "    - receive the rewad $R$, and update the posterior distirbution of $\\boldsymbol{\\gamma}$ accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9224fe",
   "metadata": {},
   "source": [
    "## Demo Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75011c94-199f-4cb5-9e99-8c9e183ce60b",
   "metadata": {},
   "source": [
    "### Import the learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bc44c6d-fe2d-4bb2-928a-cf972fd74d30",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9j/vb5nb4rd5bx0gr1q5ytx9q600000gn/T/ipykernel_51274/3250134418.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcausaldm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearners\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCPL4\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCMAB\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinTS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/causaldm/learners/CPL4/CMAB/LinTS.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_online_learner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseOnlineLearner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_util_online\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSGDClassifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/causaldm/learners/CPL4/_base_online_learner.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_util_online\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mBaseOnlineLearner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mautoargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/causaldm/learners/CPL4/_util_online.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpymc3\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpymc3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInterpolated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pymc3/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__config__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblas_opt_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblas_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0m_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pymc3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/theano/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You have the theano directory in your Python path.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigdefaults\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeprecated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/theano/configdefaults.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   1838\u001b[0m \u001b[0madd_dnn_configvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1839\u001b[0m \u001b[0madd_magma_configvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1840\u001b[0;31m \u001b[0madd_compile_configvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1841\u001b[0m \u001b[0;31m# TODO: \"tensor\", \"gpuarray\" and compilation options are closely related.. Grouping is not great.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m \u001b[0madd_tensor_configvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/theano/configdefaults.py\u001b[0m in \u001b[0;36madd_compile_configvars\u001b[0;34m()\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0;31m# Test whether or not g++ is present: disable C code if it is not.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m         \u001b[0mrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_subprocess_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"g++\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"-v\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0mrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/theano/utils.py\u001b[0m in \u001b[0;36mcall_subprocess_Popen\u001b[0;34m(command, **params)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stderr\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnull\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubprocess_Popen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         \u001b[0mreturncode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/subprocess.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1187\u001b[0m             \u001b[0mendtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_time\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m             \u001b[0;31m# https://bugs.python.org/issue25942\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/subprocess.py\u001b[0m in \u001b[0;36m_wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1915\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m                             \u001b[0;32mbreak\u001b[0m  \u001b[0;31m# Another thread waited.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m                         \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m                         \u001b[0;31m# Check the pid and loop as waitpid has been known to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m                         \u001b[0;31m# return 0 even without WNOHANG in odd situations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/subprocess.py\u001b[0m in \u001b[0;36m_try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   1873\u001b[0m             \u001b[0;34m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1874\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1875\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msts\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait_flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1876\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mChildProcessError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1877\u001b[0m                 \u001b[0;31m# This happens if SIGCLD is set to be ignored or waiting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from causaldm.learners.CPL4.CMAB import LinTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02c4d22-cf51-4573-94d4-02915c06a1a8",
   "metadata": {},
   "source": [
    "### Generate the Environment\n",
    "\n",
    "Here, we imitate an environment based on the MovieLens data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a732bb5a-7421-4fc5-bece-1f4f40507ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from causaldm.learners.CPL4.CMAB import _env_realCMAB as _env\n",
    "env = _env.Single_Contextual_Env(seed = 0, Binary = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c03633-b729-4be5-81f0-d45ef5fff1e9",
   "metadata": {},
   "source": [
    "### Specify Hyperparameters\n",
    "\n",
    "- K: number of arms\n",
    "- p: number of features per arm\n",
    "- sigma: the standard deviation of the reward distributions\n",
    "- prior_theta_u: mean of the prior distribution of the coefficients\n",
    "- prior_theta_cov: Covaraince matrix of the prior distribution of the coefficients\n",
    "- seed: random seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8c5862f",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = env.K\n",
    "p = env.p\n",
    "seed = 42\n",
    "sigma = 1\n",
    "prior_theta_u = np.zeros(p)\n",
    "prior_theta_cov = np.identity(p)\n",
    "\n",
    "LinTS_Gaussian_agent = LinTS.LinTS_Gaussian(sigma = sigma, prior_theta_u = prior_theta_u, \n",
    "                                            prior_theta_cov = prior_theta_cov, \n",
    "                                            K = K, p = p,seed = seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bcb131-8021-4c50-b82f-8fda18f8f537",
   "metadata": {},
   "source": [
    "### Recommendation and Interaction\n",
    "\n",
    "Starting from t = 0, for each step t, there are three steps:\n",
    "1. Observe the feature information\n",
    "<code> X = env.get_Phi(t) </code>\n",
    "2. Recommend an action \n",
    "<code> A = LinTS_Gaussian_agent.take_action(X) </code>\n",
    "3. Get the reward from the environment \n",
    "<code> R = env.get_reward(t,A) </code>\n",
    "4. Update the posterior distribution\n",
    "<code> LinTS_Gaussian_agent.receive_reward(t,A,R,X) </code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "40943007-7550-43fa-9ec1-601e0de611d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 3, 2.0, (25.0, 1.0, 'college/grad student'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = 0\n",
    "X, feature_info = env.get_Phi(t)\n",
    "A = LinTS_Gaussian_agent.take_action(X)\n",
    "R = env.get_reward(t,A)\n",
    "LinTS_Gaussian_agent.receive_reward(t,A,R,X)\n",
    "t,A,R,feature_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8187b9-0c27-49af-9a88-53cd0c0a9d13",
   "metadata": {},
   "source": [
    "**Interpretation**: For step 0, the TS agent encounter a male user who is a 25-year-old college/grad student. Given the information, the agent recommend a Thriller (arm 3), and receive a rate of 2 from the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccb20a4-a69c-4c39-8c62-94606460bc0f",
   "metadata": {},
   "source": [
    "### Demo Code for Bernoulli Bandit\n",
    "The steps are similar to those previously performed with a Gaussian Bandit. Note that, when specifying the prior distribution of the expected reward, the mean-precision form of the Beta distribution is used here, i.e., Beta($\\mu$, $\\phi$), where $\\mu$ is the mean reward of each arm and $\\phi$ is the precision of the Beta distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86e61955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 3, 0, (25.0, 1.0, 'college/grad student'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = _env.Single_Contextual_Env(seed = 0, Binary = True)\n",
    "K = env.K\n",
    "p = env.p\n",
    "seed = 42\n",
    "alpha = 1 # exploration rate\n",
    "retrain_freq = 1 #frequency to train the GLM model\n",
    "\n",
    "LinTS_GLM_agent = LinTS.LinTS_GLM(K = K, p = p , alpha = alpha, retrain_freq = retrain_freq)\n",
    "t = 0\n",
    "X, feature_info = env.get_Phi(t)\n",
    "A = LinTS_GLM_agent.take_action(X)\n",
    "R = env.get_reward(t,A)\n",
    "LinTS_GLM_agent.receive_reward(t,A,R,X)\n",
    "t,A,R,feature_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47c85a5-8f39-42a9-9d0d-5d70a179c10a",
   "metadata": {},
   "source": [
    "**Interpretation**: For step 0, the TS agent encounter a male user who is a 25-year-old college/grad student. Given the information, the agent recommend a Thriller (arm 3), and receive a rate of 0 from the user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bad780",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Agrawal, S., & Goyal, N. (2013, May). Thompson sampling for contextual bandits with linear payoffs. In International conference on machine learning (pp. 127-135). PMLR.\n",
    "\n",
    "[2] Kveton, B., Zaheer, M., Szepesvari, C., Li, L., Ghavamzadeh, M., & Boutilier, C. (2020, June). Randomized exploration in generalized linear bandits. In International Conference on Artificial Intelligence and Statistics (pp. 2066-2076). PMLR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afc3c3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}