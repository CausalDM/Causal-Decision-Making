{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a0f865c-10e4-440e-a970-2a1bd566881c",
   "metadata": {},
   "source": [
    "# Dynamic Mediation Analysis in Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8a6f6e-0223-44ba-be1d-4f7d761aa3b3",
   "metadata": {},
   "source": [
    "While the majority of existing works concentrate on mediation analysis with a single exposure or a limited number of treatments, there are a growing number of applications (e.g., mobile health) in which treatments are sequentially assigned over time, resulting in a large number of decision times. To learn the mediation effects in such settings with an infinite horizon, [1] proposed to construct the mediation analysis withÂ a reinforcement learning framework. Based on a newly introduced Mediated MDP data structure as illustrated below, [1] devised a novel four-way decomposition of the average treatment effect, encompassing both long-term and short-term direct/indirect effects. A direct estimator, an IPW estimator, and a multiply-robust estimator are provided for each effect component, in accordance with the standard methodologies used in literature of off-policy evaluation (OPE).\n",
    "\n",
    "![Proposed_MDP.jpg](Proposed_MDP.jpg)\n",
    "\n",
    "## Main Idea\n",
    "The core of [1] is a **four-way effect decomposition** of the average treatment effect. Let $\\pi_e$ denote the treatment policy of interest, where $\\pi_e(a|S_t = s) = P^{\\pi_e}(A_t=a|S_t=s)$, and $\\pi_0$ denote the control policy. Let $E^{\\pi}[\\cdot]$ dentoe the expectation of a random variable under a policy $\\pi$. Then the average treatment effect can be defined as \n",
    "\\begin{align}\n",
    "\\textrm{ATE($\\pi_e,\\pi_0$)}=\\lim_{T\\to \\infty} \\frac{1}{T}\\sum_{t=0}^{T-1} \\textrm{TE$_t$($\\pi_e,\\pi_0$)},\n",
    "\\end{align}\n",
    "where $\\textrm{TE}_t(\\pi_e,\\pi_0) = E^{\\pi_e}[R_t] - E^{\\pi_0}[R_t]$. We first decompose the $\\textrm{TE}_t(\\pi_e,\\pi_0)$ into four effect components, such that\n",
    "$\\textrm{TE}_t(\\pi_e,\\pi_0) = \\textrm{IDE}_t(\\pi_e,\\pi_0)+\\textrm{IME}_t(\\pi_e,\\pi_0)+\\textrm{DDE}_t(\\pi_e,\\pi_0)+\\textrm{DME}_t(\\pi_e,\\pi_0),$\n",
    "where i) the $\\textrm{IDE}_t$ quantifies the direct treatment effect on the proximal outcome $R_t$; ii) the $\\textrm{IME}_t$ evaluates the indirect effect mediated by $M_t$; iii) the $\\textrm{DDE}_t$ quantifies how past actions directly impact the current outcome; and iv) the $\\textrm{DME}_t$ measures the indirect past treatment effects mediated by past mediators. \n",
    "\n",
    "Averaging over $t$, we obtain a four-way decomposition of ATE as \n",
    "$\\textrm{ATE}(\\pi_e,\\pi_0) = \\textrm{IDE}(\\pi_e,\\pi_0) + \\textrm{IME}(\\pi_e,\\pi_0) + \\textrm{DDE}(\\pi_e,\\pi_0) + \\textrm{DME}(\\pi_e,\\pi_0).$\n",
    "As an illustration, let's consider $t=1$. The complete causal graph from actions to $R_1$ is depicted as follows.\n",
    "![2-stage.png](2-stage.png)\n",
    "\n",
    "  - $\\textrm{IDE}_1$ measures the causal effect along the path $A_1\\to R_1$;\n",
    "  - $\\textrm{IME}_1$ corresponds to the effect along the path $A_1\\to M_1 \\to R_1$;\n",
    "  - $\\textrm{DDE}_1$ captures the causal effect along the path $A_0\\to S_1\\to\\{A_1, M_1\\}\\to R_1$;\n",
    "  - $\\textrm{DME}_1$ considers the path $A_0\\to M_0 \\to S_1 \\to \\{A_1, M_1\\} \\to R_1$.\n",
    "  \n",
    "Each effect component is identifiable under the three standard assumptions, including consistency, sequential randomization, and positivity. Following the standard methodology used in OPE and under the assumptions, Direct estimator, IPW estimator, and multiply robust estimator for each effect component are provided in [1] and also supported by our package. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705de882-5e40-41fa-aa5f-c0a5ec004113",
   "metadata": {},
   "source": [
    "## Demo Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "673bb407-a32c-4451-a2d6-9e731cca939f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('D:/GitHub/CausalDM')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666e8a73-f355-481a-9d58-331981024aed",
   "metadata": {},
   "source": [
    "### Load the observational data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71dbbccf-f1f4-4526-92f6-ad2e5f99cafc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icustayid</th>\n",
       "      <th>bloc</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>PaO2_FiO2</th>\n",
       "      <th>IV_Input</th>\n",
       "      <th>SOFA</th>\n",
       "      <th>next_Glucose</th>\n",
       "      <th>next_PaO2_FiO2</th>\n",
       "      <th>Died_within_48H</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>1006</td>\n",
       "      <td>1</td>\n",
       "      <td>91.0</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>91.0</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>1006</td>\n",
       "      <td>3</td>\n",
       "      <td>91.0</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>91.0</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>1006</td>\n",
       "      <td>6</td>\n",
       "      <td>175.0</td>\n",
       "      <td>100.173913</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>175.0</td>\n",
       "      <td>100.173913</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>1006</td>\n",
       "      <td>7</td>\n",
       "      <td>175.0</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>175.0</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>1006</td>\n",
       "      <td>8</td>\n",
       "      <td>175.0</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>175.0</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>1006</td>\n",
       "      <td>10</td>\n",
       "      <td>144.0</td>\n",
       "      <td>187.234036</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>144.0</td>\n",
       "      <td>187.234036</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     icustayid  bloc  Glucose   PaO2_FiO2  IV_Input  SOFA  next_Glucose  \\\n",
       "682       1006     1     91.0  206.000000         0     8          91.0   \n",
       "683       1006     3     91.0  206.000000         0     8          91.0   \n",
       "684       1006     6    175.0  100.173913         1     3         175.0   \n",
       "685       1006     7    175.0   96.000000         1    10         175.0   \n",
       "686       1006     8    175.0   96.000000         1     9         175.0   \n",
       "687       1006    10    144.0  187.234036         1    12         144.0   \n",
       "\n",
       "     next_PaO2_FiO2  Died_within_48H  \n",
       "682      206.000000                1  \n",
       "683      206.000000                1  \n",
       "684      100.173913                1  \n",
       "685       96.000000                1  \n",
       "686       96.000000                1  \n",
       "687      187.234036                0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open('./causaldm/MIMIC3/mimic3_MRL_data_dict_V2.pickle', 'rb')\n",
    "mimic3_MRL = pickle.load(file)\n",
    "mimic3_MRL['reward'] = [1 if r == 0 else r for r in mimic3_MRL['reward']]\n",
    "mimic3_MRL['reward'] = [0 if r == -1 else r for r in mimic3_MRL['reward']]\n",
    "MRL_df = pd.read_csv('./causaldm/MIMIC3/mimic3_MRL_df_V2.csv')\n",
    "MRL_df.iloc[np.where(MRL_df['Died_within_48H']==0)[0],-1]=1\n",
    "MRL_df.iloc[np.where(MRL_df['Died_within_48H']==-1)[0],-1]=0\n",
    "MRL_df[MRL_df.icustayid==1006]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0dee2fa-8735-4cbf-9686-e5de66ce0e57",
   "metadata": {},
   "source": [
    "### Import the learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c1b2734-70e4-4c78-a011-971b5f93c27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from causaldm.learners.CEL.MA import ME_MDP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbcbdc2-a851-4c41-85bf-30e0ad4f57dd",
   "metadata": {},
   "source": [
    "### Specify the control policy and the target policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f486c185-da52-44a9-af91-383dc84e74e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control Policy\n",
    "def control_policy(state = None, dim_state=None, action=None, get_a = False):\n",
    "    # fixed policy with fixed action 0\n",
    "    if get_a:\n",
    "        action_value = np.array([0])\n",
    "    else:\n",
    "        state = np.copy(state).reshape(-1,dim_state)\n",
    "        NT = state.shape[0]\n",
    "        if action is None:\n",
    "            action_value = np.array([0]*NT)\n",
    "        else:\n",
    "            action = np.copy(action).flatten()\n",
    "            if len(action) == 1 and NT>1:\n",
    "                action = action * np.ones(NT)\n",
    "            action_value = 1-action\n",
    "    return action_value\n",
    "def target_policy(state, dim_state = 1, action=None):\n",
    "    state = np.copy(state).reshape((-1, dim_state))\n",
    "    NT = state.shape[0]\n",
    "    pa = 1 * np.ones(NT)\n",
    "    if action is None:\n",
    "        if NT == 1:\n",
    "            pa = pa[0]\n",
    "            prob_arr = np.array([1-pa, pa])\n",
    "            action_value = np.random.choice([0, 1], 1, p=prob_arr)\n",
    "        else:\n",
    "            raise ValueError('No random for matrix input')\n",
    "    else:\n",
    "        action = np.copy(action).flatten()\n",
    "        action_value = pa * action + (1-pa) * (1-action)\n",
    "    return action_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19a2f22-33f7-48ef-8fc9-eed0ced54fbd",
   "metadata": {},
   "source": [
    "### Specify Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbff1643-c7f9-492f-bc17-358b6612f553",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_state=2\n",
    "dim_mediator = 1\n",
    "MCMC = 50\n",
    "truncate = 50\n",
    "problearner_parameters = {\"splitter\":[\"best\",\"random\"], \"max_depth\" : range(1,50)},\n",
    "ratio_ndim = 10\n",
    "scaler = 'Identity'\n",
    "method = \"Robust\"\n",
    "seed = 0\n",
    "r_model = \"OLS\"\n",
    "Q_settings = {'scaler': 'Identity','product_tensor': False, 'beta': 3/7, \n",
    "              'include_intercept': False, \n",
    "              'penalty': 10**(-4),'d': 2, 'min_L': 5, 't_dependent_Q': False}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ef46807-4b36-4c5a-9f8c-de51263f00e6",
   "metadata": {},
   "source": [
    "### Define the estimation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "686377e0-4c75-49b1-859d-8f9c632e104f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building 0-th basis spline (total 3 state-mediator dimemsion) which has 3 basis, in total 3 features \n",
      "Building 1-th basis spline (total 3 state-mediator dimemsion) which has 3 basis, in total 6 features \n",
      "Building 2-th basis spline (total 3 state-mediator dimemsion) which has 3 basis, in total 9 features \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m Robust_est \u001b[38;5;241m=\u001b[39m ME_MDP\u001b[38;5;241m.\u001b[39mevaluator(mimic3_MRL, r_model \u001b[38;5;241m=\u001b[39m r_model,\n\u001b[0;32m      2\u001b[0m                      problearner_parameters \u001b[38;5;241m=\u001b[39m problearner_parameters,\n\u001b[0;32m      3\u001b[0m                      ratio_ndim \u001b[38;5;241m=\u001b[39m ratio_ndim, truncate \u001b[38;5;241m=\u001b[39m truncate, l2penalty \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m                      MCMC \u001b[38;5;241m=\u001b[39m MCMC,\n\u001b[0;32m      8\u001b[0m                      seed \u001b[38;5;241m=\u001b[39m seed, nature_decomp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, method \u001b[38;5;241m=\u001b[39m method)\n\u001b[1;32m----> 9\u001b[0m \u001b[43mRobust_est\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimate_DE_ME\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\GitHub\\CausalDM\\causaldm\\learners\\CEL\\MA\\ME_MDP.py:114\u001b[0m, in \u001b[0;36mevaluator.estimate_DE_ME\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mIPW_est()\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRobust\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;66;03m# Baseline TR\u001b[39;00m\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRobust_est\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\GitHub\\CausalDM\\causaldm\\learners\\CEL\\MA\\ME_MDP.py:177\u001b[0m, in \u001b[0;36mevaluator.Robust_est\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mRobust_est\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    176\u001b[0m     data_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNT\n\u001b[1;32m--> 177\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Q_terms\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mEr_Sa0, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mEr_SA \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Er_Sa0_SA(data_num)\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrho_SAM \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrho_SAM(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmediator)\n",
      "File \u001b[1;32mD:\\GitHub\\CausalDM\\causaldm\\learners\\CEL\\MA\\ME_MDP.py:223\u001b[0m, in \u001b[0;36mevaluator._Q_terms\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    221\u001b[0m Q_est\u001b[38;5;241m.\u001b[39mest_Q4()\n\u001b[0;32m    222\u001b[0m Q_est\u001b[38;5;241m.\u001b[39mest_Q5()\n\u001b[1;32m--> 223\u001b[0m \u001b[43mQ_est\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mest_Qdiffs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mQ1_diff, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meta_pie \u001b[38;5;241m=\u001b[39m Q_est\u001b[38;5;241m.\u001b[39mQ1_diff, Q_est\u001b[38;5;241m.\u001b[39meta_pie\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mQ5_diff, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meta_a0 \u001b[38;5;241m=\u001b[39m Q_est\u001b[38;5;241m.\u001b[39mQ5_diff, Q_est\u001b[38;5;241m.\u001b[39meta_a0\n",
      "File \u001b[1;32mD:\\GitHub\\CausalDM\\causaldm\\learners\\CEL\\MA\\qLearner_Linear.py:109\u001b[0m, in \u001b[0;36mQLearner.est_Qdiffs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mest_Qdiffs\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mQ1_diff, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mQ2_diff, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mQ3_diff, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mQ4_diff_1, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mQ4_diff_2, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mQ5_diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Q_diff\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmediator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\GitHub\\CausalDM\\causaldm\\learners\\CEL\\MA\\qLearner_Linear.py:356\u001b[0m, in \u001b[0;36mQLearner._Q_diff\u001b[1;34m(self, state, mediator, action, next_state)\u001b[0m\n\u001b[0;32m    353\u001b[0m pi0_a_S \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol_policy(state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim_state, a)\n\u001b[0;32m    354\u001b[0m pie_a_S \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_policy(state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim_state, a)\n\u001b[1;32m--> 356\u001b[0m Q1_Snext_am_MC, Q2_Snext_am_MC, Q3_Snext_am_MC, Q4_Snext_am_MC, Q5_Snext_am_MC, Q4_S_am_MC \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcal_Q_am_MC\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    358\u001b[0m Q1_Snext_am \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m pie_a_Sprime \u001b[38;5;241m*\u001b[39m Q1_Snext_am_MC\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,))\n\u001b[0;32m    359\u001b[0m Q5_Snext_am \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m pi0_a_Sprime \u001b[38;5;241m*\u001b[39m Q5_Snext_am_MC\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,))\n",
      "File \u001b[1;32mD:\\GitHub\\CausalDM\\causaldm\\learners\\CEL\\MA\\qLearner_Linear.py:429\u001b[0m, in \u001b[0;36mQLearner.cal_Q_am_MC\u001b[1;34m(self, next_state, state, action, a)\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMCMC):\n\u001b[0;32m    426\u001b[0m     \u001b[38;5;66;03m#np.random.seed(rep)\u001b[39;00m\n\u001b[0;32m    427\u001b[0m     Q1_Snext_am_MC, Q2_Snext_am_MC, Q3_Snext_am_MC, Q5_Snext_am_MC \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_Q1235_Snext_am_MC(rep, next_state, a, Q1_Snext_am_MC, Q2_Snext_am_MC, Q3_Snext_am_MC, Q5_Snext_am_MC)\n\u001b[1;32m--> 429\u001b[0m     Q4_Snext_am_MC_astar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_Q4_Snext_am_MC_astar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQ4_Snext_am_MC_astar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    431\u001b[0m     Q4_S_am_MC \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_Q4_S_am_MC(rep, state, action, a, Q4_S_am_MC)\n\u001b[0;32m    433\u001b[0m Q4_Snext_am_MC \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNT, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m)\n",
      "File \u001b[1;32mD:\\GitHub\\CausalDM\\causaldm\\learners\\CEL\\MA\\qLearner_Linear.py:453\u001b[0m, in \u001b[0;36mQLearner.update_Q4_Snext_am_MC_astar\u001b[1;34m(self, rep, next_state, a, Q4_Snext_am_MC_astar)\u001b[0m\n\u001b[0;32m    451\u001b[0m     m_Snext_a_star \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpmlearner\u001b[38;5;241m.\u001b[39msample_m(next_state, np\u001b[38;5;241m.\u001b[39marray([a_star]), random \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    452\u001b[0m     action_list \u001b[38;5;241m=\u001b[39m [a]\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNT\n\u001b[1;32m--> 453\u001b[0m     out_Q4_a_star \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcal_newQ_4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm_Snext_a_star\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    454\u001b[0m     Q4_Snext_am_MC_astar[a_star] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_exp(rep, Q4_Snext_am_MC_astar[a_star], out_Q4_a_star)\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Q4_Snext_am_MC_astar\n",
      "File \u001b[1;32mD:\\GitHub\\CausalDM\\causaldm\\learners\\CEL\\MA\\qLearner_Linear.py:409\u001b[0m, in \u001b[0;36mQLearner.cal_newQ_4\u001b[1;34m(self, s, m, a, time_idx)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcal_newQ_4\u001b[39m(\u001b[38;5;28mself\u001b[39m, s,m,a, time_idx):\n\u001b[1;32m--> 409\u001b[0m     Qs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mQ_4(s[i], m[i], a[i], time_idx[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNT)]\n\u001b[0;32m    410\u001b[0m     Q4 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(Qs)\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,))\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Q4\n",
      "File \u001b[1;32mD:\\GitHub\\CausalDM\\causaldm\\learners\\CEL\\MA\\qLearner_Linear.py:409\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcal_newQ_4\u001b[39m(\u001b[38;5;28mself\u001b[39m, s,m,a, time_idx):\n\u001b[1;32m--> 409\u001b[0m     Qs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mQ_4\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_idx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNT)]\n\u001b[0;32m    410\u001b[0m     Q4 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(Qs)\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,))\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Q4\n",
      "File \u001b[1;32mD:\\GitHub\\CausalDM\\causaldm\\learners\\CEL\\MA\\qLearner_Linear.py:405\u001b[0m, in \u001b[0;36mQLearner.Q_4\u001b[1;34m(self, S, M, A, t)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mQ_4\u001b[39m(\u001b[38;5;28mself\u001b[39m, S, M, A, t):\n\u001b[0;32m    404\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_U(S, M, A, time_idx \u001b[38;5;241m=\u001b[39m t)[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m--> 405\u001b[0m     Q4 \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mQ4_est_beta\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Q4\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Robust_est = ME_MDP.evaluator(mimic3_MRL, r_model = r_model,\n",
    "                     problearner_parameters = problearner_parameters,\n",
    "                     ratio_ndim = ratio_ndim, truncate = truncate, l2penalty = 10**(-4),\n",
    "                     target_policy=target_policy, control_policy = control_policy, \n",
    "                     dim_state = dim_state, dim_mediator = dim_mediator, \n",
    "                     Q_settings = Q_settings,\n",
    "                     MCMC = MCMC,\n",
    "                     seed = seed, nature_decomp = True, method = method)\n",
    "Robust_est.estimate_DE_ME()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e49a34-e16e-47be-b88d-00db8fb89af6",
   "metadata": {},
   "source": [
    "### Obtain the estimation of each effect component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d51ec829-e482-43e4-9dc1-55cc829d1d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.018100205548084617,\n",
       " 0.006066387157097036,\n",
       " -0.00486632802292234,\n",
       " -0.0001815880750934009,\n",
       " -0.017081734489003318)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Robust_est.est_IDE, Robust_est.IME, Robust_est.DDE, Robust_est.DME, Robust_est.TE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2569aa7e-8e1a-41c6-8761-297ef9923859",
   "metadata": {},
   "source": [
    "### Obtain the standard error of each effect component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c7887c0-06a5-45c2-beca-60e6c88ebf06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.00586890111356167,\n",
       " 0.002110278954333155,\n",
       " 0.002770561709397491,\n",
       " 0.0010678186846428818,\n",
       " 0.005821662648170317)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Robust_est.IDE_se, Robust_est.IME_se, Robust_est.DDE_se, Robust_est.DME_se, Robust_est.TE_se"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8702a0d2-0776-4e0a-b033-a0d17f3e7f07",
   "metadata": {},
   "source": [
    "**Interpretation**: We analyze the average treatment effect (ATE) of a target policy that provides IV input all of the time compared to a control policy that provides no IV input at all. Using the multiply-robust estimator proposed in [1], we decomposed the ATE into four components, including immediate nature dierct effect (INDE), Immediate nature mediator effect (INME), delayed nature direct effect (DNDE), and delayed nature mediator effect (NDDNME), and estimated each of the effect component. The estimation results are summarized in the table below.\n",
    "\n",
    "| INDE           | INME | DNDE           | DNME           | ATE           |\n",
    "|---------------|-----|---------------|---------------|---------------|\n",
    "| -.0181(.0059) | .0061(.0021)   | -.0049(.0028) | -.0002(.0011) | -.0171(.0058) |\n",
    "\n",
    "Specifically, the ATE of the target policy is significantly negative, with an effect size of .0171. Diving deep, we find that the DNME and DNDE are insignificant, whereas the INDE and INME are all statistically significant. Further, taking the effect size into account, we can conclude that the majority of the average treatment effect is directly due to the actions derived from the target treatment policy, while the part of the effect that can be attributed to the mediators is negligible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec636bb-9385-48da-a18a-a8f731414750",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Ge, L., Wang, J., Shi, C., Wu, Z., & Song, R. (2023). A Reinforcement Learning Framework for Dynamic Mediation Analysis. arXiv preprint arXiv:2301.13348."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}