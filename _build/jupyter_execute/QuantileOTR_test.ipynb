{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mHcFPAA_l4xE"
   },
   "source": [
    "# **Quantile Optimal Treatment Regime**\n",
    "---\n",
    "\n",
    "*   **Basic Idea:**\n",
    "\n",
    "   The aim of this paper is to estimate the quantile-optimal treatment regime given a class of feasible treatment regimes $\\mathbb{D}=\\{I(X^T\\beta>0:\\beta\\in \\mathbb{B})\\}$. That is, the objective function is to maximize\n",
    "   $$\\arg\\max_{d\\in \\mathbb{D}}Q_{\\tau}(Y^*(d)),$$\n",
    "where $Q_{\\tau}$ denotes the quantile value at level $\\tau$. \\\\\n",
    "To estimate the quantile value at a given level $\\tau$, a doubly robust estimator was implemented:\n",
    "$$\n",
    "\\hat{Q}_{\\tau}(\\beta)=\\frac{1}{n}\\sum_{i=1}^n \\left[\\frac{C_i(\\beta)}{\\hat{\\pi}(X_i,\\beta)}\\rho_{\\tau}(Y_i-a)+\\left(1-\\frac{C_i(\\beta)}{\\hat{\\pi}}\\right)\\rho_{\\tau}(\\hat{Y}_i^{**}-a)\\right].\n",
    "$$\n",
    "\n",
    "*   Next, we will use an simulation data and a real dataset to illustrate the performance of Quantile Optimal Treatment Regime.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDntAIqKCuyv"
   },
   "source": [
    "## **Demo on Simulation data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "zptaK7DMpIoz"
   },
   "outputs": [],
   "source": [
    "# define some functions to generate the original data\n",
    "\n",
    "# definition of behavior policy (or original treatment function)\n",
    "def b(x1,x2):\n",
    "    if np.shape(x1) == ():\n",
    "      x1 = np.array([x1])\n",
    "    if np.shape(x2) == ():\n",
    "      x2 = np.array([x2])\n",
    "    n = len(x1)\n",
    "    epsilon = 0.25 * np.random.normal(size=n)\n",
    "    return ((x1+x2 + epsilon > 0) + 0)\n",
    "\n",
    "# definition of target policy (or the treatment of our interest)\n",
    "def pi(x1,x2):\n",
    "    if np.shape(x1) == ():\n",
    "      x1 = np.array([x1])\n",
    "    if np.shape(x2) == ():\n",
    "      x2 = np.array([x2])\n",
    "    n = len(x1)\n",
    "    return ((x1+x2 > 0) + 0)\n",
    "\n",
    "# definition of reward function r(x,a), where x denotes states and a denotes actions(treatments)\n",
    "def r(x1, x2, a):\n",
    "    if np.shape(x1) == ():\n",
    "      x1 = np.array([x1])\n",
    "    if np.shape(x2) == ():\n",
    "      x2 = np.array([x2])\n",
    "    if np.shape(a) == ():\n",
    "      a = np.array([a])\n",
    "    n = len(x1)\n",
    "    epsilon = 0.25 * np.random.normal(size=n)\n",
    "    return (np.ones(n) - x1 + 2*a*x1 +2*x2 +0.5*a*x2) * (np.ones(n) + epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1645677090213,
     "user": {
      "displayName": "Yang Xu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiwmFvGwaija8HCAZKtLkFQJjRWaWko5tV_i1Zd=s64",
      "userId": "12270366590264264299"
     },
     "user_tz": 300
    },
    "id": "3X-hR0Y8pIo0",
    "outputId": "757dc542-7d19-470d-bcd9-49c43f98edd7"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/lj/55rs1m_n5gv3_0cy812ml6lh0000gq/T/ipykernel_63730/478063769.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# the number of samples used to estimate the true reward distribution by MC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m223\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "n0 = (10**3)  # the number of samples used to estimate the true reward distribution by MC\n",
    "\n",
    "np.random.seed(seed=223)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "tau=0.5\n",
    "X_1=np.random.normal(loc=-0.5,size=n0)\n",
    "X_2=np.random.normal(loc=0.6,size=n0)\n",
    "A=b(X_1,X_2)\n",
    "Y=r(X_1, X_2, A) \n",
    "data={'X_1':X_1,'X_2':X_2,'A':A,'Y':Y}\n",
    "data=pd.DataFrame(data)\n",
    "(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y_Jn5v3Jr-Od"
   },
   "outputs": [],
   "source": [
    "# initialize the learner\n",
    "Quantile_OTR=QuantileOTR()\n",
    "\n",
    "# when a=1, Y ~ 1+x1+2.5*x2\n",
    "# when a=0, Y ~ 1-x1+2*x2\n",
    "moCondQuant_0 = ['X_1', 'X_2']\n",
    "moCondQuant_1 = ['X_1', 'X_2']\n",
    "\n",
    "coefficient, coef_original_scale, Q_est=Quantile_OTR.DR_Qopt(data=data, tau=0.5, moCondQuant_0=moCondQuant_0, moCondQuant_1=moCondQuant_1,moPropen = \"NotBinaryRandom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1645677571003,
     "user": {
      "displayName": "Yang Xu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiwmFvGwaija8HCAZKtLkFQJjRWaWko5tV_i1Zd=s64",
      "userId": "12270366590264264299"
     },
     "user_tz": 300
    },
    "id": "mbsVGvdVBtZP",
    "outputId": "ba4ed930-2610-471f-839d-2788361ec174"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1668, 0.1462, 2.0194])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the coefficient that maximize the quantile\n",
    "coef_original_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 374,
     "status": "ok",
     "timestamp": 1645677578256,
     "user": {
      "displayName": "Yang Xu",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiwmFvGwaija8HCAZKtLkFQJjRWaWko5tV_i1Zd=s64",
      "userId": "12270366590264264299"
     },
     "user_tz": 300
    },
    "id": "haB3XPvrBugS",
    "outputId": "ca0d9a92-b22a-4b7a-ae91-4404358c0860"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.8429162304108773"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the estimated quantile that corresponds to the optimized coefficient\n",
    "Q_est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Imj47BToIycE"
   },
   "source": [
    "##**Reference**\n",
    "\n",
    "\n",
    "*   Lan Wang, Yu Zhou, Rui Song and Ben Sherwood. \"Quantile-Optimal Treatment Regimes.\" Journal of the American Statistical Association 2018; 113(523): 1243â€“1254.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyN7Qxb2gYV83qehpCz48pxs",
   "collapsed_sections": [],
   "name": "QuantileOTR_test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}