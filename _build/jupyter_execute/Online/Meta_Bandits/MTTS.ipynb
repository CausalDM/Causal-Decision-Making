{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f17c8f1-4560-4d7a-90b3-86a9d9cc810d",
   "metadata": {},
   "source": [
    "# Multi-Task Thompson Sampling (MTTS)\n",
    "\n",
    "## Overview\n",
    "- **Advantage**: It is both scalable and robust. Furthermore, it also accounts for the iter-task heterogeneity.\n",
    "- **Disadvantage**:\n",
    "- **Application Situation**: Useful when there are a large number of tasks to learn, especially when new tasks are introduced on a regular basis. The outcome can be either binary or continuous. Static baseline information.\n",
    "\n",
    "## Main Idea\n",
    "The **MTTS**[1] utilize baseline information to share information among different tasks efficiently, by constructing a Bayesian hierarchical model. Specifically, it assumes that\n",
    "\\begin{equation}\n",
    "  \\begin{alignedat}{2}\n",
    "&\\text{(Prior)} \\quad\n",
    "\\quad\\quad\\quad    \\boldsymbol{\\gamma} &&\\sim Q(\\boldsymbol{\\gamma}), \\\\\n",
    "&\\text{(Inter-task)} \\quad\n",
    "\\;    \\boldsymbol{\\mu}_j | \\boldsymbol{s}_j, \\boldsymbol{\\gamma} &&\\sim g(\\boldsymbol{\\mu}_j | \\boldsymbol{s}_j, \\boldsymbol{\\gamma})=\\boldsymbol{s}_j^{T}\\boldsymbol{\\gamma} + \\boldsymbol{\\delta}_{j}, \\\\\n",
    "&\\text{(Intra-task)} \\quad\n",
    "\\;    R_{j,t}(a) = Y_{j,t}(a) &&= \\mu_{j,a} + \\epsilon_{j,t}, \n",
    "      \\end{alignedat}\n",
    "\\end{equation} where $\\boldsymbol{\\delta}_{j} \\stackrel{i.i.d.}{\\sim} \\mathcal{N}(\\boldsymbol{0}, \\boldsymbol{\\Sigma})$, and $\\epsilon_{j,t} \\stackrel{i.i.d.}{\\sim} \\mathcal{N}(\\boldsymbol{0}, \\sigma^{2})$. For simplicity, we assume a Normal prior, which resulted in a Normal posterior with explicit form. Note that, if we replace the inter-task layer to a deterministic model (i.e., $g(\\boldsymbol{\\mu}_j | \\boldsymbol{x}_j, \\boldsymbol{\\gamma})=\\boldsymbol{s}_j^{T}\\boldsymbol{\\gamma}$), **MTTS** is reduced to an algorithm similar to **AdaTS** with linear bandits and Gaussian rewards discussed in Section 3.2 [2]. In contrast to **MTSS**, the **AdaTS** fail to address the issue of heterogeneous tasks.\n",
    "\n",
    "Similarly, considering the Bernoulli bandit, it assumes that\n",
    "\\begin{equation}\\label{eqn:hierachical_model}\n",
    "  \\begin{alignedat}{2}\n",
    "&\\text{(Prior)} \\quad\n",
    "\\quad\\quad\\quad    \\boldsymbol{\\gamma} &&\\sim Q(\\boldsymbol{\\gamma}), \\\\\n",
    "&\\text{(Inter-task)} \\quad\n",
    "\\;    \\boldsymbol{\\mu}_j | \\boldsymbol{x}_j, \\boldsymbol{\\gamma} &&\\sim g(\\boldsymbol{\\mu}_j | \\boldsymbol{x}_j, \\boldsymbol{\\gamma})=\\text{Beta}\\big(logistic(\\boldsymbol{x}_j^T \\boldsymbol{\\gamma}), \\psi \\big), \\\\\n",
    "&\\text{(Intra-task)} \\quad\n",
    "\\;    R_{j,t}(a) = Y_{j,t}(a) &&\\sim  \\text{Bernoulli} \\big( \\mu_{j, a} \\big), \n",
    "      \\end{alignedat}\n",
    "\\end{equation}\n",
    "where  $logistic(s) \\equiv 1 / (1 + exp^{-1}(s))$, $\\psi$ is a known parameter, and  $\\text{Beta}(\\mu, \\psi)$ denotes a Beta distribution with mean $\\mu$ and precision $\\psi$. Still, we assume a Normal prior of $\\boldsymbol{\\gamma}$. As there is no explicit form of the corresponding posterior, we update the posterior distribution by **Pymc3**.\n",
    "\n",
    "Under the TS framework, at each round $t$ with task $j$, the agent will sample a $\\tilde{\\boldsymbol{\\mu}}_{j}$ from its posterior distribution updated according to the hierarchical model, then the action $a$ with the maximum sampled $\\tilde{\\mu}_{j,a}$ will be pulled. Mathmetically,\n",
    "\\begin{equation}\n",
    "    A_{j,t} = argmax_{a \\in \\mathcal{A}} \\hat{E}(R_{j,t}(a)) = argmax_{a \\in \\mathcal{A}} \\tilde\\mu_{j,a}.\n",
    "\\end{equation}\n",
    "\n",
    "Essentially, **MTTS** assumes that the mean reward $\\boldsymbol{\\mu}_{j}$ is sampled from model $g$ parameterized by unknown parameter $\\boldsymbol{\\gamma}$ and conditional on task feature $\\boldsymbol{s}_{j}$. Instead of assuming that $\\boldsymbol{\\mu}_j$ is fully determined by its features through a deterministic function, **MTTS** adds an item-specific noise term to account for the inter-task heterogeneity. Simultaneously modeling heterogeneity and sharing information across tasks via $g$, **MTTS** is able to provide an informative prior distribution to guide the exploration. Appropriately addressing the heterogeneity between tasks, the MTTS has been shown to have a superior performance in practice[1].\n",
    "\n",
    "## Key Steps\n",
    "For $(j,t) = (1,1),(1,2),\\cdots$:\n",
    "1. Approximate $P(\\boldsymbol{\\gamma}|\\mathcal{H})$ either by implementing **Pymc3** or by calculating the explicit form of the posterior distribution;\n",
    "2. Sample $\\tilde{\\boldsymbol{\\gamma}} \\sim P(\\boldsymbol{\\gamma}|\\mathcal{H})$;\n",
    "3. Update $P(\\boldsymbol{\\mu}|\\tilde{\\boldsymbol{\\gamma}},\\mathcal{H})$ and sample $\\tilde{\\boldsymbol{\\mu}} \\sim P(\\boldsymbol{\\mu}|\\tilde{\\boldsymbol{\\gamma}},\\mathcal{H})$;\n",
    "4. Take the action $A_{j,t}$ such that $A_{j,t} = argmax_{a \\in \\mathcal{A}} \\tilde\\mu_{j,a}$;\n",
    "6. Receive reward $R_{j,t}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f3eee1-f1f8-4cea-8759-3737e5397c97",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Wan, R., Ge, L., & Song, R. (2021). Metadata-based multi-task bandits with bayesian hierarchical models. Advances in Neural Information Processing Systems, 34, 29655-29668.\n",
    "\n",
    "[2] Basu, S., Kveton, B., Zaheer, M., & Szepesv√°ri, C. (2021). No regrets for learning the prior in bandits. Advances in Neural Information Processing Systems, 34, 28029-28041.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7b4fad-70bb-49de-bb28-61052b9a601d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}