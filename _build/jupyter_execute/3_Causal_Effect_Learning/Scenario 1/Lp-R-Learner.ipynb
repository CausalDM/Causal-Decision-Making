{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "YgKc3F0cR0Y4",
   "metadata": {
    "id": "YgKc3F0cR0Y4"
   },
   "source": [
    "### **6. Lp-R-learner**\n",
    "\n",
    "As an extension of R-learner, Lp-R-learner combined the idea of residual regression with local polynomial adaptation, and leveraged the idea of cross fitting to further relax the conditions needed to obtain the oracle convergence rate. For brevity of content, we will just introduce their main algorithm. For more details about its theory and real data performance please see the paper written by Kennedy [4]. \n",
    "\t\n",
    "Let $(I_{1a}^n, I_{1b}^n,I_{2}^n)$ denote three independent samples of $n$ observations of $Z_i = (S_i, A_i, R_i)$. Let $b:\\mathbb{R}^d\\rightarrow \\mathbb{R}^p$ denote the vector of basis functions consisting of all powers of each covariate, up to order $\\gamma$, and all interactions up to degree $\\gamma$ polynomials. Let $K_{hs}(S)=\\frac{1}{h^d}K\\left(\\frac{S-s}{h}\\right)$ for $k:\\mathbb{R}^d\\rightarrow \\mathbb{R}$ a bounded kernel function with support $[-1,1]^d$, and $h$ is a bandwidth parameter.\n",
    "\n",
    "**Step 1**: Nuisance training: \n",
    "\n",
    "(a)  Using $I_{1a}^n$ to construct estimates $\\hat{\\pi}_a$ of the propensity scores $\\pi$; \n",
    "\n",
    "(b)  Using $I_{1b}^n$ to construct estimates $\\hat{\\eta}$ of the regression function $\\eta=\\pi\\mu_1+(1-\\pi)\\mu_0$, and estimtes $\\hat{\\pi}_b$ of the propensity scores $\\pi$.\n",
    "\n",
    "**Step 2**: Localized double-residual regression: \n",
    "\n",
    "Define $\\hat{\\tau}_r(s)$ as the fitted value from a kernel-weighted least squares regression (in the test sample $I_2^n$) of outcome residual $(R-\\hat{\\eta})$ on basis terms $b$ scaled by the treatment residual $A-\\hat{\\pi}_b$, with weights $\\Big(\\frac{A-\\hat{\\pi}_a}{A-\\hat{\\pi}_b}\\Big)\\cdot K_{hs}$. Thus $\\hat{\\tau}_r(s)=b(0)^T\\hat{\\theta}$ for\n",
    "\\begin{equation}\n",
    "\t\t\\hat{\\theta}=\\arg\\min_{\\theta\\in\\mathbb{R}^p}\\mathbb{P}_n\\left(K_{hs}(S)\\Big\\{ \\frac{A-\\hat{\\pi}_a(S)}{A-\\hat{\\pi}_b(S)}\\Big\\} \\left[  \\big\\{R-\\hat{\\eta}(S)\\big\\}-\\theta^Tb(S-s_0)\\big\\{A-\\hat{\\pi}_b(S)\\big\\} \\right] \\right).\n",
    "\\end{equation}\n",
    "**Step 3**: Cross-fitting(optional): \n",
    "\n",
    "Repeat Step 1–2 twice, first using $(I^n_{1b} , I_2^n)$ for nuisance training and $I_{1a}^n$ as the test samplem and then using $(I^n_{1a} , I_2^n)$ for training and $I_{1b}^n$ as the test sample. Use the average of the resulting three estimators of $\\tau$ as the final estimator $\\hat{\\tau}_r$.\n",
    "\n",
    "In the theory section, Kennedy proved that Lp-R-learner, compared with traditional DR learner, can achieve the oracle convergence rate under milder conditions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eRpP5k9MBtzO",
   "metadata": {
    "id": "eRpP5k9MBtzO"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_env_getdata_CEL' from 'causaldm.learners.CEL.Single_Stage' (/Users/alinaxu/opt/anaconda3/lib/python3.9/site-packages/causaldm/learners/CEL/Single_Stage/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9j/vb5nb4rd5bx0gr1q5ytx9q600000gn/T/ipykernel_50788/3497684307.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcausaldm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearners\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSingle_Stage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_env_getdata_CEL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcausaldm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearners\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSingle_Stage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLpRlearner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLpRlearner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name '_env_getdata_CEL' from 'causaldm.learners.CEL.Single_Stage' (/Users/alinaxu/opt/anaconda3/lib/python3.9/site-packages/causaldm/learners/CEL/Single_Stage/__init__.py)"
     ]
    }
   ],
   "source": [
    "# import related packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt;\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from causaldm.learners.CEL.Single_Stage import _env_getdata_CEL\n",
    "from causaldm.learners.CEL.Single_Stage.LpRlearner import LpRlearner\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XUu695Qrf61-",
   "metadata": {
    "id": "XUu695Qrf61-"
   },
   "source": [
    "### MovieLens Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "JhfJntzcVVy2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 288,
     "status": "ok",
     "timestamp": 1676750101543,
     "user": {
      "displayName": "Yang Xu",
      "userId": "12270366590264264299"
     },
     "user_tz": 300
    },
    "id": "JhfJntzcVVy2",
    "outputId": "7fab8a7a-7cd9-445c-a005-9a6d1994a071"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>age</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>occupation_academic/educator</th>\n",
       "      <th>occupation_college/grad student</th>\n",
       "      <th>occupation_executive/managerial</th>\n",
       "      <th>occupation_other</th>\n",
       "      <th>occupation_technician/engineer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.0</td>\n",
       "      <td>919.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48.0</td>\n",
       "      <td>527.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>1721.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65637</th>\n",
       "      <td>5878.0</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65638</th>\n",
       "      <td>5878.0</td>\n",
       "      <td>1391.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65639</th>\n",
       "      <td>5878.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65640</th>\n",
       "      <td>5878.0</td>\n",
       "      <td>2232.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65641</th>\n",
       "      <td>5878.0</td>\n",
       "      <td>426.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65642 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  movie_id  rating   age  Drama  Sci-Fi  gender_M  \\\n",
       "0         48.0    1193.0     4.0  25.0    1.0     0.0       1.0   \n",
       "1         48.0     919.0     4.0  25.0    1.0     0.0       1.0   \n",
       "2         48.0     527.0     5.0  25.0    1.0     0.0       1.0   \n",
       "3         48.0    1721.0     4.0  25.0    1.0     0.0       1.0   \n",
       "4         48.0     150.0     4.0  25.0    1.0     0.0       1.0   \n",
       "...        ...       ...     ...   ...    ...     ...       ...   \n",
       "65637   5878.0    3300.0     2.0  25.0    0.0     1.0       0.0   \n",
       "65638   5878.0    1391.0     1.0  25.0    0.0     1.0       0.0   \n",
       "65639   5878.0     185.0     4.0  25.0    0.0     1.0       0.0   \n",
       "65640   5878.0    2232.0     1.0  25.0    0.0     1.0       0.0   \n",
       "65641   5878.0     426.0     3.0  25.0    0.0     1.0       0.0   \n",
       "\n",
       "       occupation_academic/educator  occupation_college/grad student  \\\n",
       "0                               0.0                              1.0   \n",
       "1                               0.0                              1.0   \n",
       "2                               0.0                              1.0   \n",
       "3                               0.0                              1.0   \n",
       "4                               0.0                              1.0   \n",
       "...                             ...                              ...   \n",
       "65637                           0.0                              0.0   \n",
       "65638                           0.0                              0.0   \n",
       "65639                           0.0                              0.0   \n",
       "65640                           0.0                              0.0   \n",
       "65641                           0.0                              0.0   \n",
       "\n",
       "       occupation_executive/managerial  occupation_other  \\\n",
       "0                                  0.0               0.0   \n",
       "1                                  0.0               0.0   \n",
       "2                                  0.0               0.0   \n",
       "3                                  0.0               0.0   \n",
       "4                                  0.0               0.0   \n",
       "...                                ...               ...   \n",
       "65637                              0.0               1.0   \n",
       "65638                              0.0               1.0   \n",
       "65639                              0.0               1.0   \n",
       "65640                              0.0               1.0   \n",
       "65641                              0.0               1.0   \n",
       "\n",
       "       occupation_technician/engineer  \n",
       "0                                 0.0  \n",
       "1                                 0.0  \n",
       "2                                 0.0  \n",
       "3                                 0.0  \n",
       "4                                 0.0  \n",
       "...                               ...  \n",
       "65637                             0.0  \n",
       "65638                             0.0  \n",
       "65639                             0.0  \n",
       "65640                             0.0  \n",
       "65641                             0.0  \n",
       "\n",
       "[65642 rows x 12 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the MovieLens data\n",
    "#import os\n",
    "#os.chdir('/Users/alinaxu/Documents/CDM/CausalDM')\n",
    "#MovieLens_CEL = pd.read_csv(\"./causaldm/data/MovieLens_CEL.csv\")\n",
    "MovieLens_CEL = get_movielens_CEL()\n",
    "MovieLens_CEL.pop(MovieLens_CEL.columns[0])\n",
    "MovieLens_CEL = MovieLens_CEL[MovieLens_CEL.columns.drop(['Comedy','Action', 'Thriller'])]\n",
    "MovieLens_CEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "J__3Ozs7Uxxs",
   "metadata": {
    "id": "J__3Ozs7Uxxs"
   },
   "outputs": [],
   "source": [
    "n = len(MovieLens_CEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "r703l-q0GeyE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 177694,
     "status": "ok",
     "timestamp": 1675480091797,
     "user": {
      "displayName": "Yang Xu",
      "userId": "12270366590264264299"
     },
     "user_tz": 300
    },
    "id": "r703l-q0GeyE",
    "outputId": "b04e7218-50f9-40d0-8105-eb5fc0193eab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimate with Lp-R-learner\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "np.random.seed(1)\n",
    "\n",
    "outcome = 'rating'\n",
    "treatment = 'Drama'\n",
    "controls = ['age', 'gender_M', 'occupation_academic/educator',\n",
    "       'occupation_college/grad student', 'occupation_executive/managerial',\n",
    "       'occupation_other', 'occupation_technician/engineer']\n",
    "n_folds = 5\n",
    "y_model = GradientBoostingRegressor(max_depth=3)\n",
    "ps_model_a = LogisticRegression()\n",
    "ps_model_b = LogisticRegression()\n",
    "s = 1\n",
    "LpRlearner_model = LinearRegression()\n",
    "\n",
    "sample_index = random.sample(np.arange(len(MovieLens_CEL)).tolist(),1000)\n",
    "MovieLens_CEL = MovieLens_CEL.iloc[sample_index,:]\n",
    "\n",
    "HTE_Lp_R_learner = LpRlearner(MovieLens_CEL, outcome, treatment, controls, y_model, ps_model_a, ps_model_b, s, LpRlearner_model, degree = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FA-F8Jc_T5Lz",
   "metadata": {
    "id": "FA-F8Jc_T5Lz"
   },
   "source": [
    "Let's focus on the estimated HTEs for three randomly chosen users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be166555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lp-R-learner:   [0.42175269 0.52461763 0.13400663]\n"
     ]
    }
   ],
   "source": [
    "print(\"Lp-R-learner:  \",HTE_Lp_R_learner[np.array([0,300,900])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "48136320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choosing Drama instead of Sci-Fi is expected to improve the rating of all users by 0.2182 out of 5 points.\n"
     ]
    }
   ],
   "source": [
    "ATE_Lp_R_learner = np.sum(HTE_Lp_R_learner)/1000\n",
    "print(\"Choosing Drama instead of Sci-Fi is expected to improve the rating of all users by\",round(ATE_Lp_R_learner,4), \"out of 5 points.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mVAZTZYTUKJ6",
   "metadata": {
    "id": "mVAZTZYTUKJ6"
   },
   "source": [
    "**Conclusion:** Choosing Drama instead of Sci-Fi is expected to improve the rating of all users by 0.2182 out of 5 points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1098b550",
   "metadata": {
    "id": "1098b550"
   },
   "source": [
    "## References\n",
    "\n",
    "2. Xinkun Nie and Stefan Wager. Quasi-oracle estimation of heterogeneous treatment effects. Biometrika, 108(2):299–319, 2021.\n",
    "\n",
    "3. Peter M Robinson. Root-n-consistent semiparametric regression. Econometrica: Journal of the Econometric Society, pages 931–954, 1988.\n",
    "\n",
    "4. Edward H Kennedy. Optimal doubly robust estimation of heterogeneous causal effects. arXiv preprint arXiv:2004.14497, 2020\n",
    "\n",
    "5. M. J. van der Laan. Statistical inference for variable importance. The International Journal of Biostatistics, 2(1), 2006.\n",
    "\n",
    "6. S. Lee, R. Okui, and Y.-J. Whang. Doubly robust uniform confidence band for the conditional average treatment effect function. Journal of Applied Econometrics, 32(7):1207–1225, 2017.\n",
    "\n",
    "7. D. J. Foster and V. Syrgkanis. Orthogonal statistical learning. arXiv preprint arXiv:1901.09036, 2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f776d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "1098b550"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}