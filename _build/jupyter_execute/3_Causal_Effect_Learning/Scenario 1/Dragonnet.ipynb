{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "XUdcqLkabYny",
   "metadata": {
    "id": "XUdcqLkabYny"
   },
   "source": [
    "### **8. Dragon Net**\n",
    "\n",
    "In previous sections, we reviewed quite a large amount of work utilizing machine learning or deep learning based approaches to estimate ATE and HTE. To guarantee the consistency and asymptotic convergence rate of the treatment effect estimator, the underlying models are often required to satisfy certain convergence rate. For example, in double machine learning (DML) [9], the treatment effect estimator is asymptotically normal when both the propensity score and outcome regression models satisfy a convergence rate $o(n^{-1/4})$. Most of the existing work can be summarized into a two-stage estimation structure: In stage 1, we fit the models for the propensity score and expected outcome; In stage 2, we plug in the estimated models to formalize the final estimator of interest, such as ATE, HTE, ATT (averaged treatment effect on the treated), etc.\n",
    "\n",
    "Despite the versatile choices of ML-based methods in both stages, there seems to be no targeted criteria about which model can serve for the best performance of the treatment effect estimation in stage 2. Therefore, Dragonnet [8] aims to answer this question: how can we adapt the design and training of the neural networks used in the first step in order to improve the quality of treatment effect estimation?\n",
    "\n",
    "The author addressed this problem from two angles:\n",
    "\n",
    "1. Based on the sufficiency of the propensity score for causal estimation, the author designed an innovative neural network structure, named as Dragonnet, so as to discard the irrelevant information in observational data and thus improve the quality of treatment effect estimation;\n",
    "\n",
    "2. Starting from the non-parametric theory, the author utilized targeted minimum loss estimation (TMLE) procedure to imporve the finite sample stability of the final estimator.\n",
    "\n",
    "In the rest of this section, we will introduce the above two innovations parts in details, and use a real data example to illustrate the estimation procedure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc3c270",
   "metadata": {},
   "source": [
    "#### Part 1: Dragonnet\n",
    "Define the conditional outcome as $Q(a,s)=E[R|a,s]$ amd propensity score $g(s)=P(A=1|S=s)$. Our goal is to estimate the effect of treatment $A=1$ versus $A=0$, i.e.\n",
    "\\begin{equation}\n",
    "    \\text{HTE}_{\\text{Dragonnet}}(s)=E[R(1)|S=s]-E[R(0)|S=s],\n",
    "\\end{equation}\n",
    "and the average treatment effect \n",
    "\\begin{equation}\n",
    "    \\text{ATE}_{\\text{Dragonnet}}=E\\Big[E[R(1)|S]-E[R(0)|S]\\Big].\n",
    "\\end{equation}\n",
    "\n",
    "Under certain identifiability assumptions, the HTE can be estimated by\n",
    "\\begin{equation}\n",
    "    \\widehat{\\text{HTE}}_{\\text{Dragonnet}}(s)=\\hat{E}[R|A=1,S=s]-\\hat{E}[R|A=0,S=s]=\\hat{Q}(1,s)-\\hat{Q}(1,s).\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "According to the sufficiency of propensity score (Theorem 2.1 in [8]), all of the information in $S$ that is useful in estimating ATE is contained in $g(S)$. In other words, we should train $\\hat{Q}(a,s)$ only through the information in $g(S)$, instead of the entire $S$. To achieve so, the author proposed a novel three-headed archetecture, which is shown in Figure 1 below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2e24f93",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 系统找不到指定的路径。: '/Users/alinaxu/Documents/CDM/CausalDM'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/Users/alinaxu/Documents/CDM/CausalDM\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m display\u001b[38;5;241m.\u001b[39mImage(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./images/CEL-SingleStage-Dragonnet.png\u001b[39m\u001b[38;5;124m\"\u001b[39m, width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 系统找不到指定的路径。: '/Users/alinaxu/Documents/CDM/CausalDM'"
     ]
    }
   ],
   "source": [
    "from IPython import display\n",
    "import os\n",
    "os.chdir('/Users/alinaxu/Documents/CDM/CausalDM')\n",
    "display.Image(\"./images/CEL-SingleStage-Dragonnet.png\", width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d00023f",
   "metadata": {},
   "source": [
    "By first training the propensity score model through several layers of neural network, we are able to capture the resourceful information of $g(S)$ in layer $Z$. The core idea of Dragonnet is to directly utilize the information in $Z$ to fit outcome regression models for $\\hat{Q}(1,s)$ and $\\hat{Q}(0,s)$.\n",
    "\n",
    "The objective function of Dragonnet is given by\n",
    "\\begin{equation}\n",
    "\\hat{\\theta}=\\arg\\min_{\\theta} \\frac{1}{n}\\sum_{i}\\Big[(Q^{\\text{nn}}(a_i,s_i;\\theta)-R_i)^2+\\alpha \\text{CrossEntropy}(g^{\\text{nn}}(s_i,\\theta),a_i)\\Big],\n",
    "\\end{equation}\n",
    "where $\\theta$ is the collection of all parameters, and $\\alpha$ is a weighting hyperparameter.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda3ea61",
   "metadata": {},
   "source": [
    "#### Part 2. Targeted Regularization\n",
    "\n",
    "\n",
    "In targeted regularization, the author modified the objective function to yield a better finite sample performance. Specifically, the author defined\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "& \\tilde{Q}(a_i,s_i;\\theta,\\epsilon) = {Q}^{\\text{nn}}(a_i,s_i;\\theta)+\\epsilon, \\bigg[\\frac{a_i}{g^{\\text{nn}}(s_i;\\theta)}-\\frac{1-a_i}{1-g^{\\text{nn}}(s_i;\\theta)}\\bigg]\\\\\n",
    "& \\gamma(R_i,a_i,s_i;\\theta,\\epsilon) = (R_i-\\tilde{Q}(a_i,s_i;\\theta,\\epsilon))^2,\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "and then train the model by minimizing a new objective function with an extra parameter $\\epsilon$ as below:\n",
    "\\begin{equation}\n",
    "\\hat{\\theta},\\hat{\\epsilon} = \\arg\\min_{\\theta,\\epsilon} \\Big[\\hat{R}(\\theta,S)+\\beta\\frac{1}{n}\\sum_{i} \\gamma(R_i,a_i,s_i;\\theta,\\epsilon)\\Big],\n",
    "\\end{equation}\n",
    "where $\\beta$ is another weighting hyperparameter.\n",
    "\n",
    "The final treatment effect estimator, after targeted regularization, is given by\n",
    "\\begin{equation}\n",
    "\\widehat{\\text{HTE}}_{\\text{Dragonnet}}(s)=\\tilde{Q}(1,s;\\hat\\theta,\\hat\\epsilon)-\\tilde{Q}(0,s;\\hat\\theta,\\hat\\epsilon),\n",
    "\\end{equation}\n",
    "where $(\\hat\\theta,\\hat\\epsilon)$ is the solution we obtained above.\n",
    "\n",
    "\n",
    "**Note**: The simulation code of Dragonnet is available at https://github.com/claudiashi57/dragonnet. To check its performance, we apply this method on MovieLens data for a primary illustration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eRpP5k9MBtzO",
   "metadata": {
    "id": "eRpP5k9MBtzO"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'causaldm.learners.CEL._util_online'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9j/vb5nb4rd5bx0gr1q5ytx9q600000gn/T/ipykernel_71135/1311581033.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGradientBoostingRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcausaldm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearners\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSingle_Stage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_env_getdata_CEL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcausaldm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearners\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSingle_Stage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDragonnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/CDM/CausalDM/causaldm/learners/CEL/Single_Stage/_env_getdata_CEL.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_util_online\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'causaldm.learners.CEL._util_online'"
     ]
    }
   ],
   "source": [
    "# The code is available at https://github.com/claudiashi57/dragonnet\n",
    "# import related packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt;\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from causaldm.learners.CEL.Single_Stage import _env_getdata_CEL\n",
    "from causaldm.learners.CEL.Single_Stage.Dragonnet import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XUu695Qrf61-",
   "metadata": {
    "id": "XUu695Qrf61-"
   },
   "source": [
    "### MovieLens Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "JhfJntzcVVy2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 288,
     "status": "ok",
     "timestamp": 1676750101543,
     "user": {
      "displayName": "Yang Xu",
      "userId": "12270366590264264299"
     },
     "user_tz": 300
    },
    "id": "JhfJntzcVVy2",
    "outputId": "7fab8a7a-7cd9-445c-a005-9a6d1994a071"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>age</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>occupation_academic/educator</th>\n",
       "      <th>occupation_college/grad student</th>\n",
       "      <th>occupation_executive/managerial</th>\n",
       "      <th>occupation_other</th>\n",
       "      <th>occupation_technician/engineer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.0</td>\n",
       "      <td>919.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48.0</td>\n",
       "      <td>527.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>1721.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65637</th>\n",
       "      <td>5878.0</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65638</th>\n",
       "      <td>5878.0</td>\n",
       "      <td>1391.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65639</th>\n",
       "      <td>5878.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65640</th>\n",
       "      <td>5878.0</td>\n",
       "      <td>2232.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65641</th>\n",
       "      <td>5878.0</td>\n",
       "      <td>426.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65642 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  movie_id  rating   age  Drama  Sci-Fi  gender_M  \\\n",
       "0         48.0    1193.0     4.0  25.0    1.0     0.0       1.0   \n",
       "1         48.0     919.0     4.0  25.0    1.0     0.0       1.0   \n",
       "2         48.0     527.0     5.0  25.0    1.0     0.0       1.0   \n",
       "3         48.0    1721.0     4.0  25.0    1.0     0.0       1.0   \n",
       "4         48.0     150.0     4.0  25.0    1.0     0.0       1.0   \n",
       "...        ...       ...     ...   ...    ...     ...       ...   \n",
       "65637   5878.0    3300.0     2.0  25.0    0.0     1.0       0.0   \n",
       "65638   5878.0    1391.0     1.0  25.0    0.0     1.0       0.0   \n",
       "65639   5878.0     185.0     4.0  25.0    0.0     1.0       0.0   \n",
       "65640   5878.0    2232.0     1.0  25.0    0.0     1.0       0.0   \n",
       "65641   5878.0     426.0     3.0  25.0    0.0     1.0       0.0   \n",
       "\n",
       "       occupation_academic/educator  occupation_college/grad student  \\\n",
       "0                               0.0                              1.0   \n",
       "1                               0.0                              1.0   \n",
       "2                               0.0                              1.0   \n",
       "3                               0.0                              1.0   \n",
       "4                               0.0                              1.0   \n",
       "...                             ...                              ...   \n",
       "65637                           0.0                              0.0   \n",
       "65638                           0.0                              0.0   \n",
       "65639                           0.0                              0.0   \n",
       "65640                           0.0                              0.0   \n",
       "65641                           0.0                              0.0   \n",
       "\n",
       "       occupation_executive/managerial  occupation_other  \\\n",
       "0                                  0.0               0.0   \n",
       "1                                  0.0               0.0   \n",
       "2                                  0.0               0.0   \n",
       "3                                  0.0               0.0   \n",
       "4                                  0.0               0.0   \n",
       "...                                ...               ...   \n",
       "65637                              0.0               1.0   \n",
       "65638                              0.0               1.0   \n",
       "65639                              0.0               1.0   \n",
       "65640                              0.0               1.0   \n",
       "65641                              0.0               1.0   \n",
       "\n",
       "       occupation_technician/engineer  \n",
       "0                                 0.0  \n",
       "1                                 0.0  \n",
       "2                                 0.0  \n",
       "3                                 0.0  \n",
       "4                                 0.0  \n",
       "...                               ...  \n",
       "65637                             0.0  \n",
       "65638                             0.0  \n",
       "65639                             0.0  \n",
       "65640                             0.0  \n",
       "65641                             0.0  \n",
       "\n",
       "[65642 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get data\n",
    "#MovieLens_CEL = pd.read_csv(\"./causaldm/data/MovieLens_CEL.csv\")\n",
    "MovieLens_CEL = get_movielens_CEL()\n",
    "MovieLens_CEL.pop(MovieLens_CEL.columns[0])\n",
    "MovieLens_CEL = MovieLens_CEL[MovieLens_CEL.columns.drop(['Comedy','Action', 'Thriller'])]\n",
    "MovieLens_CEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "J__3Ozs7Uxxs",
   "metadata": {
    "id": "J__3Ozs7Uxxs"
   },
   "outputs": [],
   "source": [
    "n = len(MovieLens_CEL)\n",
    "userinfo_index = np.array([3,6,7,8,9,10,11])\n",
    "S = MovieLens_CEL.iloc[:, userinfo_index]\n",
    "#SandA = MovieLens_CEL.iloc[:, np.array([3,4,5,6,7,8,9,10])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41e8a212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am here making dragonnet\n",
      "***************************** elapsed_time is:  285.40207719802856\n",
      "2031/2031 [==============================] - 2s 898us/step\n",
      "2031/2031 [==============================] - 2s 964us/step\n",
      "average propensity for treated: 0.7404845356941223 and untreated: 0.7264252305030823\n",
      "average propensity for treated: 0.7404845356941223 and untreated: 0.7264252305030823\n"
     ]
    }
   ],
   "source": [
    "test_outputs, train_output = train_and_predict_dragons(MovieLens_CEL['Drama'].to_numpy().reshape(-1,1),MovieLens_CEL['rating'].to_numpy().reshape(-1,1), S.to_numpy(),\n",
    "                                                       targeted_regularization=True,\n",
    "                                                       output_dir='/Users/alinaxu/Downloads/dragonnet-master/result',\n",
    "                                                       knob_loss=dragonnet_loss_binarycross, ratio=1., dragon='dragonnet',\n",
    "                                                       val_split=0.2, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e3baaf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['q_t0', 'q_t1', 'g', 't', 'y', 'x', 'index', 'eps'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the output keys\n",
    "train_output[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f4a32c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "HTE_Dragonnet = train_output[0]['q_t1'] - train_output[0]['q_t0']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FA-F8Jc_T5Lz",
   "metadata": {
    "id": "FA-F8Jc_T5Lz"
   },
   "source": [
    "Let's focus on the estimated HTEs for three randomly chosen users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "GvHnTOxmT5Lz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 318,
     "status": "ok",
     "timestamp": 1676750150517,
     "user": {
      "displayName": "Yang Xu",
      "userId": "12270366590264264299"
     },
     "user_tz": 300
    },
    "id": "GvHnTOxmT5Lz",
    "outputId": "7b0b76fd-f5ac-4ab8-a3c0-188e15484fe7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dragonnet:   [0.34005857 0.33967185 0.46262145]\n"
     ]
    }
   ],
   "source": [
    "print(\"Dragonnet:  \",HTE_Dragonnet[0][np.array([0,1000,5000])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48136320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choosing Drama instead of Sci-Fi is expected to improve the rating of all users by 0.3526 out of 5 points.\n"
     ]
    }
   ],
   "source": [
    "# Calculate the Aaverage Treatment Effect by Dragonnet\n",
    "ATE_Dragonnet = np.sum(HTE_Dragonnet)/n\n",
    "print(\"Choosing Drama instead of Sci-Fi is expected to improve the rating of all users by\",round(ATE_Dragonnet,4), \"out of 5 points.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mVAZTZYTUKJ6",
   "metadata": {
    "id": "mVAZTZYTUKJ6"
   },
   "source": [
    "**Conclusion:** Choosing Drama instead of Sci-Fi is expected to improve the rating of all users by 0.3526 out of 5 points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1098b550",
   "metadata": {
    "id": "1098b550"
   },
   "source": [
    "## References\n",
    "\n",
    "8. Claudia Shi, David M. Blei, and Victor Veitch. Adapting Neural Networks for the Estimation of\n",
    "Treatment Effects. 33rd Conference on Neural Information Processing Systems (NeurIPS 2019).\n",
    "\n",
    "9. Chernozhukov, V., D. Chetverikov, M. Demirer, E. Duflo, C. Hansen, W. Newey, and\n",
    "J. Robins (2018). Double/debiased machine learning for treatment and structural parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732a1c2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "1098b550"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}