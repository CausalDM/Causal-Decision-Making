{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8lwheJQ8RxAw",
   "metadata": {
    "id": "8lwheJQ8RxAw"
   },
   "source": [
    "### **3. X-learner**\n",
    "Next, let's introduce the X-learner. As a combination of S-learner and T-learner, the X-learner can use information from the control(treatment) group to derive better estimators for the treatment(control) group, which is provably more efficient than the above two.\n",
    "\n",
    "The basic\n",
    "\n",
    "\n",
    "**Step 1:**  Estimate $\\mu_0(s)$ and $\\mu_1(s)$ separately with any regression algorithms or supervised machine learning methods (same as T-learner);\n",
    "\n",
    "\n",
    "**Step 2:**  Obtain the imputed treatment effects for individuals\n",
    "\\begin{equation*}\n",
    "\\tilde{\\Delta}_i^1:=R_i^1-\\hat\\mu_0(S_i^1), \\quad \\tilde{\\Delta}_i^0:=\\hat\\mu_1(S_i^0)-R_i^0.\n",
    "\\end{equation*}\n",
    "\n",
    "**Step 3:**  Fit the imputed treatment effects to obtain $\\hat\\tau_1(s):=\\mathbb{E}[\\tilde{\\Delta}_i^1|S=s]$ and $\\hat\\tau_0(s):=\\mathbb{E}[\\tilde{\\Delta}_i^0|S=s]$;\n",
    "\n",
    "**Step 4:**  The final HTE estimator is given by\n",
    "\\begin{equation*}\n",
    "\\hat{\\tau}_{\\text{X-learner}}(s)=g(s)\\hat\\tau_0(s)+(1-g(s))\\hat\\tau_1(s),\n",
    "\\end{equation*}\n",
    "\n",
    "where $g(s)$ is a weight function between $[0,1]$. A possible way is to use the propensity score model as an estimate of $g(s)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "epBAzoVzVqTK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5036,
     "status": "ok",
     "timestamp": 1676133719672,
     "user": {
      "displayName": "Yang Xu",
      "userId": "12270366590264264299"
     },
     "user_tz": 300
    },
    "id": "epBAzoVzVqTK",
    "outputId": "2f3f929c-fbba-40a3-d9bf-b74ea77f3f7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-uplift in d:\\anaconda3\\lib\\site-packages (0.4.1)\n",
      "Requirement already satisfied: scikit-learn>=0.21.0 in d:\\anaconda3\\lib\\site-packages (from scikit-uplift) (1.0.2)\n",
      "Requirement already satisfied: numpy>=1.16 in d:\\anaconda3\\lib\\site-packages (from scikit-uplift) (1.21.5)\n",
      "Requirement already satisfied: matplotlib in d:\\anaconda3\\lib\\site-packages (from scikit-uplift) (3.5.1)\n",
      "Requirement already satisfied: tqdm in d:\\anaconda3\\lib\\site-packages (from scikit-uplift) (4.64.0)\n",
      "Requirement already satisfied: pandas in d:\\anaconda3\\lib\\site-packages (from scikit-uplift) (1.4.2)\n",
      "Requirement already satisfied: requests in d:\\anaconda3\\lib\\site-packages (from scikit-uplift) (2.27.1)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\anaconda3\\lib\\site-packages (from scikit-learn>=0.21.0->scikit-uplift) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\anaconda3\\lib\\site-packages (from scikit-learn>=0.21.0->scikit-uplift) (2.2.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in d:\\anaconda3\\lib\\site-packages (from scikit-learn>=0.21.0->scikit-uplift) (1.7.3)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda3\\lib\\site-packages (from matplotlib->scikit-uplift) (21.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\anaconda3\\lib\\site-packages (from matplotlib->scikit-uplift) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\anaconda3\\lib\\site-packages (from matplotlib->scikit-uplift) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\anaconda3\\lib\\site-packages (from matplotlib->scikit-uplift) (4.25.0)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\anaconda3\\lib\\site-packages (from matplotlib->scikit-uplift) (0.11.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in d:\\anaconda3\\lib\\site-packages (from matplotlib->scikit-uplift) (9.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in d:\\anaconda3\\lib\\site-packages (from matplotlib->scikit-uplift) (3.0.4)\n",
      "Requirement already satisfied: six>=1.5 in d:\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->scikit-uplift) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\anaconda3\\lib\\site-packages (from pandas->scikit-uplift) (2021.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda3\\lib\\site-packages (from requests->scikit-uplift) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda3\\lib\\site-packages (from requests->scikit-uplift) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\anaconda3\\lib\\site-packages (from requests->scikit-uplift) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda3\\lib\\site-packages (from requests->scikit-uplift) (2022.9.24)\n",
      "Requirement already satisfied: colorama in d:\\anaconda3\\lib\\site-packages (from tqdm->scikit-uplift) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install scikit-uplift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "kDtKXxNtVqTM",
   "metadata": {
    "id": "kDtKXxNtVqTM"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lightgbm'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# import related packages\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt;\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlightgbm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LGBMRegressor;\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearRegression\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcausaldm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_util_causaldm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lightgbm'"
     ]
    }
   ],
   "source": [
    "# import related packages\n",
    "from matplotlib import pyplot as plt;\n",
    "from lightgbm import LGBMRegressor;\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from causaldm._util_causaldm import *;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dMktSxiPVqTN",
   "metadata": {
    "id": "dMktSxiPVqTN"
   },
   "outputs": [],
   "source": [
    "n = 10**3  # sample size in observed data\n",
    "n0 = 10**5 # the number of samples used to estimate the true reward distribution by MC\n",
    "seed=223"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4rhP8UeSVqTN",
   "metadata": {
    "id": "4rhP8UeSVqTN"
   },
   "outputs": [],
   "source": [
    "# Get data\n",
    "data_behavior = get_data_simulation(n, seed, policy=\"behavior\")\n",
    "#data_target = get_data_simulation(n0, seed, policy=\"target\")\n",
    "\n",
    "# The true expected heterogeneous treatment effect\n",
    "HTE_true = get_data_simulation(n, seed, policy=\"1\")['R']-get_data_simulation(n, seed, policy=\"0\")['R']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sfb-mplOP9HJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 449,
     "status": "ok",
     "timestamp": 1676133738275,
     "user": {
      "displayName": "Yang Xu",
      "userId": "12270366590264264299"
     },
     "user_tz": 300
    },
    "id": "sfb-mplOP9HJ",
    "outputId": "8b2be802-5918-414b-de0f-8d26dd0930cf"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(max_depth=3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Fit two models under treatment and control separately, same as T-learner\n",
    "\n",
    "import numpy as np\n",
    "mu0 = LGBMRegressor(max_depth=3)\n",
    "mu1 = LGBMRegressor(max_depth=3)\n",
    "\n",
    "S_T0 = data_behavior.iloc[np.where(data_behavior['A']==0)[0],0:2]\n",
    "S_T1 = data_behavior.iloc[np.where(data_behavior['A']==1)[0],0:2]\n",
    "R_T0 = data_behavior.iloc[np.where(data_behavior['A']==0)[0],3] \n",
    "R_T1 = data_behavior.iloc[np.where(data_behavior['A']==1)[0],3] \n",
    "\n",
    "mu0.fit(S_T0, R_T0)\n",
    "mu1.fit(S_T1, R_T1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zb42ZMw3pkqm",
   "metadata": {
    "id": "zb42ZMw3pkqm"
   },
   "outputs": [],
   "source": [
    "# Step 2: impute the potential outcomes that are unobserved in original data\n",
    "\n",
    "n_T0 = len(R_T0)\n",
    "n_T1 = len(R_T1)\n",
    "\n",
    "Delta0 = mu1.predict(S_T0) - R_T0\n",
    "Delta1 = R_T1 - mu0.predict(S_T1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pxYLjE0Ar2_5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 194,
     "status": "ok",
     "timestamp": 1676133740928,
     "user": {
      "displayName": "Yang Xu",
      "userId": "12270366590264264299"
     },
     "user_tz": 300
    },
    "id": "pxYLjE0Ar2_5",
    "outputId": "539a9b7e-21ad-4c03-8a48-da65ec5d3a2e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(max_depth=2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Fit tau_1(s) and tau_0(s)\n",
    "\n",
    "tau0 = LGBMRegressor(max_depth=2)\n",
    "tau1 = LGBMRegressor(max_depth=2)\n",
    "\n",
    "tau0.fit(S_T0, Delta0)\n",
    "tau1.fit(S_T1, Delta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LRvEZ4uluT-U",
   "metadata": {
    "id": "LRvEZ4uluT-U"
   },
   "outputs": [],
   "source": [
    "# Step 4: fit the propensity score model $\\hat{g}(s)$ and obtain the final HTE estimator by taking weighted average of tau0 and tau1\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "g = LogisticRegression()\n",
    "g.fit(data_behavior.iloc[:,0:2],data_behavior['A'])\n",
    "\n",
    "HTE_X_learner = g.predict_proba(data_behavior.iloc[:,0:2])[:,0]*tau0.predict(data_behavior.iloc[:,0:2]) + g.predict_proba(data_behavior.iloc[:,0:2])[:,1]*tau1.predict(data_behavior.iloc[:,0:2])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Mz8I_J0h4N6B",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 172,
     "status": "ok",
     "timestamp": 1676133743287,
     "user": {
      "displayName": "Yang Xu",
      "userId": "12270366590264264299"
     },
     "user_tz": 300
    },
    "id": "Mz8I_J0h4N6B",
    "outputId": "a45b9739-0f4e-4934-dacd-e17420d86055"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-learner:   [ 1.9341  1.9235  0.2944  0.2013 -0.4147 -0.5626 -2.214  -1.5443]\n",
      "true value:  [ 1.2961 -0.4475  0.731   0.2863  0.4471 -0.1839 -3.3869 -1.238 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"X-learner:  \",HTE_X_learner[0:8])\n",
    "print(\"true value: \",HTE_true[0:8].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XyxjzDBy4N6k",
   "metadata": {
    "id": "XyxjzDBy4N6k"
   },
   "source": [
    "From the result above we can see that X-learner can roughly catch the trend of treatment effect w.r.t. the change of baseline information $S$. In this synthetic example, X-learner also performs slightly better than T-learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rlbacETd4N6l",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1676133743982,
     "user": {
      "displayName": "Yang Xu",
      "userId": "12270366590264264299"
     },
     "user_tz": 300
    },
    "id": "rlbacETd4N6l",
    "outputId": "b99bc160-95ce-4eee-8718-376a69ce0164"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall estimation bias of X-learner is :      0.2827518068171628 , \n",
      " The overall estimation variance of X-learner is : 1.7686646616779012 . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Bias_X_learner = np.sum(HTE_X_learner-HTE_true)/n\n",
    "Variance_X_learner = np.sum((HTE_X_learner-HTE_true)**2)/n\n",
    "print(\"The overall estimation bias of X-learner is :     \", Bias_X_learner, \", \\n\", \"The overall estimation variance of X-learner is :\",Variance_X_learner,\". \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EnxQ_Tkg4o_q",
   "metadata": {
    "id": "EnxQ_Tkg4o_q"
   },
   "source": [
    "**Conclusion:** In this toy example, the overall estimation variance of X-learner is the smallest, followed by T-learner, and the worst is given by S-learner.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zxpRscObJmbX",
   "metadata": {
    "id": "zxpRscObJmbX"
   },
   "source": [
    "**Note**: For more details about the meta learners, please refer to [1]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nyirbjS5JdGh",
   "metadata": {
    "id": "nyirbjS5JdGh"
   },
   "source": [
    "## References\n",
    "1. Kunzel, S. R., Sekhon, J. S., Bickel, P. J., and Yu, B. (2019). Metalearners for estimating heterogeneous treatment effects using machine learning. Proceedings of the national academy of sciences 116, 4156–4165.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}