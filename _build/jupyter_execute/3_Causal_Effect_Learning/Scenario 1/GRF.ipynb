{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "SgWh47pKR1XR",
   "metadata": {
    "id": "SgWh47pKR1XR"
   },
   "source": [
    "### **7. Generalized Random Forest**\n",
    "\n",
    "Developed by Susan Athey, Julie Tibshirani and Stefan Wager, Generalized Random Forest [8] aims to give the solution to a set of local moment equations:\n",
    "\\begin{equation}\n",
    "  \\mathbb{E}\\big[\\psi_{\\tau(s),\\nu(s)}(O_i)\\big| S_i=s\\big]=0,\n",
    "\\end{equation}\n",
    "where $\\tau(s)$ is the parameter we care about and $\\nu(s)$ is an optional nuisance parameter. In the problem of Heterogeneous Treatment Effect Evaluation, our parameter of interest $\\tau(s)=\\xi\\cdot \\beta(s)$ is identified by \n",
    "\\begin{equation}\n",
    "  \\psi_{\\beta(s),\\nu(s)}(R_i,A_i)=(R_i-\\beta(s)\\cdot A_i-c(s))(1 \\quad A_i^T)^T.\n",
    "\\end{equation}\n",
    "The induced estimator $\\hat{\\tau}(s)$ for $\\tau(s)$ can thus be solved by\n",
    "\\begin{equation}\n",
    "  \\hat{\\tau}(s)=\\xi^T\\left(\\sum_{i=1}^n \\alpha_i(s)\\big(A_i-\\bar{A}_\\alpha\\big)^{\\otimes 2}\\right)^{-1}\\sum_{i=1}^n \\alpha_i(s)\\big(A_i-\\bar{A}_\\alpha\\big)\\big(R_i-\\bar{R}_\\alpha\\big),\n",
    "\\end{equation}\n",
    "where $\\bar{A}_\\alpha=\\sum \\alpha_i(s)A_i$ and $\\bar{R}_\\alpha=\\sum \\alpha_i(s)R_i$, and we write $v^{\\otimes 2}=vv^T$.\n",
    "\n",
    "Notice that this formula is just a weighted version of R-learner introduced above. However, instead of using ordinary kernel weighting functions that are prone to a strong curse of dimensionality, GRF uses an adaptive weighting function $\\alpha_i(s)$ derived from a forest designed to express heterogeneity in the specified quantity of interest. \n",
    "    \n",
    "To be more specific, in order to obtain $\\alpha_i(s)$, GRF first grows a set of $B$ trees indexed by $1,\\dots,B$. Then for each such tree, define $L_b(s)$ as the set of training samples falling in the same ``leaf\" as x. The weights $\\alpha_i(s)$ then capture the frequency with which the $i$-th training example falls into the same leaf as $s$:\n",
    "\\begin{equation}\n",
    "  \\alpha_{bi}(s)=\\frac{\\boldsymbol{1}\\big(\\{S_i\\in L_b(s)\\}\\big)}{\\big|L_b(s)\\big|},\\quad \\alpha_i(s)=\\frac{1}{B}\\sum_{b=1}^B \\alpha_{bi}(s).\n",
    "\\end{equation}\n",
    "\n",
    "To sum up, GRF aims to leverage the splitting result of a series of trees to decide the ``localized” weight for HTE estimation at each point $x_0$. Compared with kernel functions, we may expect tree-based weights to be more flexible and better performed in real settings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eRpP5k9MBtzO",
   "metadata": {
    "id": "eRpP5k9MBtzO"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'causaldm.learners.Causal_Effect_Learning'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9j/vb5nb4rd5bx0gr1q5ytx9q600000gn/T/ipykernel_50768/1061371864.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLinearRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogisticRegression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcausaldm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearners\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCausal_Effect_Learning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSingle_Stage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLpRlearner\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLpRlearner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'causaldm.learners.Causal_Effect_Learning'"
     ]
    }
   ],
   "source": [
    "# import related packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt;\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from causaldm.learners.Causal_Effect_Learning.Single_Stage.LpRlearner import LpRlearner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XUu695Qrf61-",
   "metadata": {
    "id": "XUu695Qrf61-"
   },
   "source": [
    "### MovieLens Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "JhfJntzcVVy2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 288,
     "status": "ok",
     "timestamp": 1676750101543,
     "user": {
      "displayName": "Yang Xu",
      "userId": "12270366590264264299"
     },
     "user_tz": 300
    },
    "id": "JhfJntzcVVy2",
    "outputId": "7fab8a7a-7cd9-445c-a005-9a6d1994a071"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>age</th>\n",
       "      <th>Comedy</th>\n",
       "      <th>Drama</th>\n",
       "      <th>Action</th>\n",
       "      <th>Thriller</th>\n",
       "      <th>Sci-Fi</th>\n",
       "      <th>gender_M</th>\n",
       "      <th>occupation_academic/educator</th>\n",
       "      <th>occupation_college/grad student</th>\n",
       "      <th>occupation_executive/managerial</th>\n",
       "      <th>occupation_other</th>\n",
       "      <th>occupation_technician/engineer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48.0</td>\n",
       "      <td>1193.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48.0</td>\n",
       "      <td>919.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48.0</td>\n",
       "      <td>527.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48.0</td>\n",
       "      <td>1721.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65637</th>\n",
       "      <td>5878.0</td>\n",
       "      <td>3300.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65638</th>\n",
       "      <td>5878.0</td>\n",
       "      <td>1391.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65639</th>\n",
       "      <td>5878.0</td>\n",
       "      <td>185.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65640</th>\n",
       "      <td>5878.0</td>\n",
       "      <td>2232.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65641</th>\n",
       "      <td>5878.0</td>\n",
       "      <td>426.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65642 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id  movie_id  rating   age  Comedy  Drama  Action  Thriller  \\\n",
       "0         48.0    1193.0     4.0  25.0     0.0    1.0     0.0       0.0   \n",
       "1         48.0     919.0     4.0  25.0     0.0    1.0     0.0       0.0   \n",
       "2         48.0     527.0     5.0  25.0     0.0    1.0     0.0       0.0   \n",
       "3         48.0    1721.0     4.0  25.0     0.0    1.0     0.0       0.0   \n",
       "4         48.0     150.0     4.0  25.0     0.0    1.0     0.0       0.0   \n",
       "...        ...       ...     ...   ...     ...    ...     ...       ...   \n",
       "65637   5878.0    3300.0     2.0  25.0     0.0    0.0     0.0       0.0   \n",
       "65638   5878.0    1391.0     1.0  25.0     0.0    0.0     0.0       0.0   \n",
       "65639   5878.0     185.0     4.0  25.0     0.0    0.0     0.0       0.0   \n",
       "65640   5878.0    2232.0     1.0  25.0     0.0    0.0     0.0       0.0   \n",
       "65641   5878.0     426.0     3.0  25.0     0.0    0.0     0.0       0.0   \n",
       "\n",
       "       Sci-Fi  gender_M  occupation_academic/educator  \\\n",
       "0         0.0       1.0                           0.0   \n",
       "1         0.0       1.0                           0.0   \n",
       "2         0.0       1.0                           0.0   \n",
       "3         0.0       1.0                           0.0   \n",
       "4         0.0       1.0                           0.0   \n",
       "...       ...       ...                           ...   \n",
       "65637     1.0       0.0                           0.0   \n",
       "65638     1.0       0.0                           0.0   \n",
       "65639     1.0       0.0                           0.0   \n",
       "65640     1.0       0.0                           0.0   \n",
       "65641     1.0       0.0                           0.0   \n",
       "\n",
       "       occupation_college/grad student  occupation_executive/managerial  \\\n",
       "0                                  1.0                              0.0   \n",
       "1                                  1.0                              0.0   \n",
       "2                                  1.0                              0.0   \n",
       "3                                  1.0                              0.0   \n",
       "4                                  1.0                              0.0   \n",
       "...                                ...                              ...   \n",
       "65637                              0.0                              0.0   \n",
       "65638                              0.0                              0.0   \n",
       "65639                              0.0                              0.0   \n",
       "65640                              0.0                              0.0   \n",
       "65641                              0.0                              0.0   \n",
       "\n",
       "       occupation_other  occupation_technician/engineer  \n",
       "0                   0.0                             0.0  \n",
       "1                   0.0                             0.0  \n",
       "2                   0.0                             0.0  \n",
       "3                   0.0                             0.0  \n",
       "4                   0.0                             0.0  \n",
       "...                 ...                             ...  \n",
       "65637               1.0                             0.0  \n",
       "65638               1.0                             0.0  \n",
       "65639               1.0                             0.0  \n",
       "65640               1.0                             0.0  \n",
       "65641               1.0                             0.0  \n",
       "\n",
       "[65642 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the MovieLens data\n",
    "import os\n",
    "os.chdir('/Users/alinaxu/Documents/CDM/CausalDM')\n",
    "MovieLens_CEL = pd.read_csv(\"./causaldm/data/MovieLens_CEL.csv\")\n",
    "MovieLens_CEL.pop(MovieLens_CEL.columns[0])\n",
    "MovieLens_CEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "J__3Ozs7Uxxs",
   "metadata": {
    "id": "J__3Ozs7Uxxs"
   },
   "outputs": [],
   "source": [
    "n = len(MovieLens_CEL)\n",
    "userinfo_index = np.array([3,5,6,7,8,9,10])\n",
    "SandA = MovieLens_CEL.iloc[:, np.array([3,4,5,6,7,8,9,10])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcaeaff5",
   "metadata": {
    "id": "eRpP5k9MBtzO"
   },
   "outputs": [],
   "source": [
    "# import related packages\n",
    "from causaldm._util_causaldm import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cmjcDa7juPbB",
   "metadata": {
    "id": "cmjcDa7juPbB"
   },
   "source": [
    "The generalized random forest (GRF) approach has been implemented in package *grf* for R and C++, and *econml* in python. Here we implement the package of *econml* for a simple illustration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fZT7U8YnNLGo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4180,
     "status": "ok",
     "timestamp": 1675480054329,
     "user": {
      "displayName": "Yang Xu",
      "userId": "12270366590264264299"
     },
     "user_tz": 300
    },
    "id": "fZT7U8YnNLGo",
    "outputId": "b3d4a3ec-3680-4f86-906e-deeafd162109"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting econml\n",
      "  Downloading econml-0.14.0-cp39-cp39-macosx_10_9_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting shap<0.41.0,>=0.38.1\n",
      "  Downloading shap-0.40.0-cp39-cp39-macosx_10_9_x86_64.whl (433 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.3/433.3 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn<1.2,>0.22.0 in /Users/alinaxu/opt/anaconda3/lib/python3.9/site-packages (from econml) (1.0.2)\n",
      "Requirement already satisfied: scipy>1.4.0 in /Users/alinaxu/opt/anaconda3/lib/python3.9/site-packages (from econml) (1.7.3)\n",
      "Requirement already satisfied: numpy in /Users/alinaxu/opt/anaconda3/lib/python3.9/site-packages (from econml) (1.21.5)\n",
      "Requirement already satisfied: pandas in /Users/alinaxu/opt/anaconda3/lib/python3.9/site-packages (from econml) (1.4.4)\n",
      "Requirement already satisfied: statsmodels>=0.10 in /Users/alinaxu/opt/anaconda3/lib/python3.9/site-packages (from econml) (0.13.2)\n",
      "Requirement already satisfied: lightgbm in /Users/alinaxu/opt/anaconda3/lib/python3.9/site-packages (from econml) (3.3.5)\n",
      "Collecting sparse\n",
      "  Downloading sparse-0.14.0-py2.py3-none-any.whl (80 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.0/81.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.13.0 in /Users/alinaxu/opt/anaconda3/lib/python3.9/site-packages (from econml) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/alinaxu/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn<1.2,>0.22.0->econml) (2.2.0)\n",
      "Requirement already satisfied: numba in /Users/alinaxu/opt/anaconda3/lib/python3.9/site-packages (from shap<0.41.0,>=0.38.1->econml) (0.55.1)\n",
      "Collecting slicer==0.0.7\n",
      "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: tqdm>4.25.0 in /Users/alinaxu/opt/anaconda3/lib/python3.9/site-packages (from shap<0.41.0,>=0.38.1->econml) (4.64.1)\n",
      "Requirement already satisfied: packaging>20.9 in /Users/alinaxu/opt/anaconda3/lib/python3.9/site-packages (from shap<0.41.0,>=0.38.1->econml) (21.3)\n",
      "Requirement already satisfied: cloudpickle in /Users/alinaxu/opt/anaconda3/lib/python3.9/site-packages (from shap<0.41.0,>=0.38.1->econml) (2.0.0)\n",
      "Requirement already satisfied: patsy>=0.5.2 in /Users/alinaxu/opt/anaconda3/lib/python3.9/site-packages (from statsmodels>=0.10->econml) (0.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/alinaxu/opt/anaconda3/lib/python3.9/site-packages (from pandas->econml) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/alinaxu/opt/anaconda3/lib/python3.9/site-packages (from pandas->econml) (2022.1)\n",
      "Requirement already satisfied: wheel in /Users/alinaxu/opt/anaconda3/lib/python3.9/site-packages (from lightgbm->econml) (0.35.1)\n",
      "Requirement already satisfied: llvmlite<0.39,>=0.38.0rc1 in /Users/alinaxu/opt/anaconda3/lib/python3.9/site-packages (from numba->shap<0.41.0,>=0.38.1->econml) (0.38.0)\n",
      "Requirement already satisfied: setuptools in /Users/alinaxu/opt/anaconda3/lib/python3.9/site-packages (from numba->shap<0.41.0,>=0.38.1->econml) (63.4.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/alinaxu/opt/anaconda3/lib/python3.9/site-packages (from packaging>20.9->shap<0.41.0,>=0.38.1->econml) (3.0.9)\n",
      "Requirement already satisfied: six in /Users/alinaxu/opt/anaconda3/lib/python3.9/site-packages (from patsy>=0.5.2->statsmodels>=0.10->econml) (1.16.0)\n",
      "Installing collected packages: slicer, sparse, shap, econml\n",
      "Successfully installed econml-0.14.0 shap-0.40.0 slicer-0.0.7 sparse-0.14.0\n"
     ]
    }
   ],
   "source": [
    "# import the package for Causal Random Forest\n",
    "! pip install econml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "gk0nYH559XIL",
   "metadata": {
    "id": "gk0nYH559XIL"
   },
   "outputs": [],
   "source": [
    "# A demo code of Causal Random Forest\n",
    "from econml.grf import CausalForest, CausalIVForest, RegressionForest\n",
    "from econml.dml import CausalForestDML\n",
    "est = CausalForest(criterion='het', n_estimators=400, min_samples_leaf=5, max_depth=None,\n",
    "                    min_var_fraction_leaf=None, min_var_leaf_on_val=True,\n",
    "                    min_impurity_decrease = 0.0, max_samples=0.45, min_balancedness_tol=.45,\n",
    "                    warm_start=False, inference=True, fit_intercept=True, subforest_size=4,\n",
    "                    honest=True, verbose=0, n_jobs=-1, random_state=1235)\n",
    "\n",
    "\n",
    "est.fit(MovieLens_CEL.iloc[:,userinfo_index], MovieLens_CEL['Drama'], MovieLens_CEL['rating'])\n",
    "\n",
    "HTE_GRF = est.predict(MovieLens_CEL.iloc[:,userinfo_index], interval=False, alpha=0.05)\n",
    "HTE_GRF = HTE_GRF.flatten()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FA-F8Jc_T5Lz",
   "metadata": {
    "id": "FA-F8Jc_T5Lz"
   },
   "source": [
    "Let's focus on the estimated HTEs for three randomly chosen users:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "GvHnTOxmT5Lz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 318,
     "status": "ok",
     "timestamp": 1676750150517,
     "user": {
      "displayName": "Yang Xu",
      "userId": "12270366590264264299"
     },
     "user_tz": 300
    },
    "id": "GvHnTOxmT5Lz",
    "outputId": "7b0b76fd-f5ac-4ab8-a3c0-188e15484fe7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalized Random Forest:   [0.3605 0.3783 0.3646]\n"
     ]
    }
   ],
   "source": [
    "print(\"Generalized Random Forest:  \",HTE_GRF[np.array([0,300,900])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48136320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Choosing Drama instead of Sci-Fi is expected to improve the rating of all users by 0.358 out of 5 points.\n"
     ]
    }
   ],
   "source": [
    "ATE_GRF = np.sum(HTE_GRF)/n\n",
    "print(\"Choosing Drama instead of Sci-Fi is expected to improve the rating of all users by\",round(ATE_GRF,4), \"out of 5 points.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mVAZTZYTUKJ6",
   "metadata": {
    "id": "mVAZTZYTUKJ6"
   },
   "source": [
    "**Conclusion:** Choosing Drama instead of Sci-Fi is expected to improve the rating of all users by 0.358 out of 5 points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1098b550",
   "metadata": {
    "id": "1098b550"
   },
   "source": [
    "## References\n",
    "\n",
    "8. Susan Athey, Julie Tibshirani, and Stefan Wager. Generalized random forests. The Annals of Statistics, 47(2):1148–1178, 2019."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "1098b550"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}