{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "Z_pBCOWOruCh",
   "metadata": {
    "id": "Z_pBCOWOruCh"
   },
   "source": [
    "## **Meta Learners**\n",
    "\n",
    "In this section, we introduce three classical learners in HTE estimation. These meta learners are easy to implement, and can handle general data without additional assumptions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yfiI-lSZRuOP",
   "metadata": {
    "id": "yfiI-lSZRuOP"
   },
   "source": [
    "### **1. S-learner**\n",
    "\n",
    "\n",
    "The first estimator we would like to introduce is the S-learner, also known as a ``single learner\". This is one of the most foundamental learners in HTE esitmation, and is very easy to implement.\n",
    "\n",
    "Under three common assumptions in causal inference, i.e. (1) consistency, (2) no unmeasured confounders (NUC), (3) positivity assumption, the heterogeneous treatment effect can be identified by the observed data, where\n",
    "\\begin{equation*}\n",
    "\\tau(s)=\\mathbb{E}[R|S,A=1]-\\mathbb{E}[R|S,A=0].\n",
    "\\end{equation*}\n",
    "\n",
    "The basic idea of S-learner is to fit a model for $\\mathbb{E}[R|S,A]$, and then construct a plug-in estimator based on the expression above. Specifically, the algorithm can be summarized as below:\n",
    "\n",
    "**Step 1:**  Estimate the combined response function $\\mu(s,a):=\\mathbb{E}[R|S=s,A=a]$ with any regression algorithm or supervised machine learning methods;\n",
    "\n",
    "**Step 2:**  Estimate HTE by \n",
    "\\begin{equation*}\n",
    "\\hat{\\tau}_{\\text{S-learner}}(s)=\\hat\\mu(s,1)-\\hat\\mu(s,0).\n",
    "\\end{equation*}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eRpP5k9MBtzO",
   "metadata": {
    "id": "eRpP5k9MBtzO"
   },
   "outputs": [],
   "source": [
    "# import related packages\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from causaldm._util_causaldm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "lovM_twTxuOj",
   "metadata": {
    "id": "lovM_twTxuOj"
   },
   "outputs": [],
   "source": [
    "n = 10**3  # sample size in observed data\n",
    "n0 = 10**5 # the number of samples used to estimate the true reward distribution by MC\n",
    "seed=223"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "JhfJntzcVVy2",
   "metadata": {
    "id": "JhfJntzcVVy2"
   },
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'data' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/9j/vb5nb4rd5bx0gr1q5ytx9q600000gn/T/ipykernel_50825/2180662469.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# The true expected heterogeneous treatment effect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mHTE_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_simulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'R'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mget_data_simulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'R'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/causaldm/_util_causaldm.py\u001b[0m in \u001b[0;36mget_data_simulation\u001b[0;34m(n0, seed, policy)\u001b[0m\n\u001b[1;32m    227\u001b[0m         \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'data' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "data_behavior = get_data_simulation(n, seed, policy=\"behavior\")\n",
    "#data_target = get_data_simulation(n0, seed, policy=\"target\")\n",
    "\n",
    "# The true expected heterogeneous treatment effect\n",
    "HTE_true = get_data_simulation(n, seed, policy=\"1\")['R']-get_data_simulation(n, seed, policy=\"0\")['R']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "F4yvhP_yJ9DH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1675480604895,
     "user": {
      "displayName": "Yang Xu",
      "userId": "12270366590264264299"
     },
     "user_tz": 300
    },
    "id": "F4yvhP_yJ9DH",
    "outputId": "3a84de92-f342-44ba-fa92-b4094f9382b1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-c61c9893-973f-4fb6-a9fc-be419e504f49\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S1</th>\n",
       "      <th>S2</th>\n",
       "      <th>A</th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.034775</td>\n",
       "      <td>2.453145</td>\n",
       "      <td>1</td>\n",
       "      <td>7.167637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.084880</td>\n",
       "      <td>-1.234459</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.553798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.144626</td>\n",
       "      <td>2.040543</td>\n",
       "      <td>1</td>\n",
       "      <td>5.956732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.148426</td>\n",
       "      <td>-0.021139</td>\n",
       "      <td>1</td>\n",
       "      <td>1.095578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.120852</td>\n",
       "      <td>1.377594</td>\n",
       "      <td>1</td>\n",
       "      <td>4.323133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-2.022440</td>\n",
       "      <td>1.887551</td>\n",
       "      <td>0</td>\n",
       "      <td>6.797542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.411179</td>\n",
       "      <td>-1.655833</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.722846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.155706</td>\n",
       "      <td>-0.992197</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.140100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>-1.510241</td>\n",
       "      <td>0.828438</td>\n",
       "      <td>0</td>\n",
       "      <td>4.167118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-1.744187</td>\n",
       "      <td>0.857147</td>\n",
       "      <td>0</td>\n",
       "      <td>4.458481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c61c9893-973f-4fb6-a9fc-be419e504f49')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-c61c9893-973f-4fb6-a9fc-be419e504f49 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-c61c9893-973f-4fb6-a9fc-be419e504f49');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "           S1        S2  A         R\n",
       "0    0.034775  2.453145  1  7.167637\n",
       "1    0.084880 -1.234459  0 -1.553798\n",
       "2   -0.144626  2.040543  1  5.956732\n",
       "3    0.148426 -0.021139  1  1.095578\n",
       "4   -0.120852  1.377594  1  4.323133\n",
       "..        ...       ... ..       ...\n",
       "995 -2.022440  1.887551  0  6.797542\n",
       "996  0.411179 -1.655833  0 -2.722846\n",
       "997  0.155706 -0.992197  0 -1.140100\n",
       "998 -1.510241  0.828438  0  4.167118\n",
       "999 -1.744187  0.857147  0  4.458481\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Nxf-mXJmFrEl",
   "metadata": {
    "id": "Nxf-mXJmFrEl"
   },
   "outputs": [],
   "source": [
    "SandA = data_behavior.iloc[:,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "h5G8dAwM-PGO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1675480604897,
     "user": {
      "displayName": "Yang Xu",
      "userId": "12270366590264264299"
     },
     "user_tz": 300
    },
    "id": "h5G8dAwM-PGO",
    "outputId": "0ad1d5ef-f445-4246-a321-36f8ee9867ab"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(max_depth=5)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# S-learner\n",
    "S_learner = LGBMRegressor(max_depth=5)\n",
    "#S_learner = LinearRegression()\n",
    "#SandA = np.hstack((S.to_numpy(),A.to_numpy().reshape(-1,1)))\n",
    "S_learner.fit(SandA, data_behavior['R'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Vqsb5wLTaR0q",
   "metadata": {
    "id": "Vqsb5wLTaR0q"
   },
   "outputs": [],
   "source": [
    "HTE_S_learner = S_learner.predict(np.hstack(( data_behavior.iloc[:,0:2].to_numpy(),np.ones(n).reshape(-1,1)))) - S_learner.predict(np.hstack(( data_behavior.iloc[:,0:2].to_numpy(),np.zeros(n).reshape(-1,1))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FA-F8Jc_T5Lz",
   "metadata": {
    "id": "FA-F8Jc_T5Lz"
   },
   "source": [
    "To evaluate how well S-learner is in estimating heterogeneous treatment effect, we compare its estimates with the true value for the first 10 subjects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GvHnTOxmT5Lz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1675480604898,
     "user": {
      "displayName": "Yang Xu",
      "userId": "12270366590264264299"
     },
     "user_tz": 300
    },
    "id": "GvHnTOxmT5Lz",
    "outputId": "834ffc4a-bf31-429e-e030-888052a4b36e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S-learner:   [-0.1492  0.1687 -0.589  -0.0319 -0.8354 -0.5843 -0.4577 -2.0791]\n",
      "true value:  [ 1.2961 -0.4475  0.731   0.2863  0.4471 -0.1839 -3.3869 -1.238 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"S-learner:  \",HTE_S_learner[0:8])\n",
    "print(\"true value: \",HTE_true[0:8].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "g9NgyjQ7PqRf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 346,
     "status": "ok",
     "timestamp": 1675480605638,
     "user": {
      "displayName": "Yang Xu",
      "userId": "12270366590264264299"
     },
     "user_tz": 300
    },
    "id": "g9NgyjQ7PqRf",
    "outputId": "ee4a1419-12a6-4a2a-f27c-db3f9d6b8487"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall estimation bias of S-learner is :      0.2857192464627009 , \n",
      " The overall estimation variance of S-learner is : 4.079505077680185 . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Bias_S_learner = np.sum(HTE_S_learner-HTE_true)/n\n",
    "Variance_S_learner = np.sum((HTE_S_learner-HTE_true)**2)/n\n",
    "print(\"The overall estimation bias of S-learner is :     \", Bias_S_learner, \", \\n\", \"The overall estimation variance of S-learner is :\",Variance_S_learner,\". \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mVAZTZYTUKJ6",
   "metadata": {
    "id": "mVAZTZYTUKJ6"
   },
   "source": [
    "**Conclusion:** The performance of S-learner, at least in this toy example, is not very attractive. Although it is the easiest approach to implement, the over-simplicity tends to cover some information that can be better explored with some advanced approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cMny8Ri7RvqC",
   "metadata": {
    "id": "cMny8Ri7RvqC"
   },
   "source": [
    "\n",
    "### **2. T-learner**\n",
    "The second learner is called T-learner, which denotes ``two learners\". Instead of fitting a single model to estimate the potential outcomes under both treatment and control groups, T-learner aims to learn different models for $\\mathbb{E}[R(1)|S]$ and $\\mathbb{E}[R(0)|S]$ separately, and finally combines them to obtain a final HTE estimator.\n",
    "\n",
    "Define the control response function as $\\mu_0(s)=\\mathbb{E}[R(0)|S=s]$, and the treatment response function as $\\mu_1(s)=\\mathbb{E}[R(1)|S=s]$. The algorithm of T-learner is summarized below:\n",
    "\n",
    "**Step 1:**  Estimate $\\mu_0(s)$ and $\\mu_1(s)$ separately with any regression algorithms or supervised machine learning methods;\n",
    "\n",
    "**Step 2:**  Estimate HTE by \n",
    "\\begin{equation*}\n",
    "\\hat{\\tau}_{\\text{T-learner}}(s)=\\hat\\mu_1(s)-\\hat\\mu_0(s).\n",
    "\\end{equation*}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "X1VmlNjstdsN",
   "metadata": {
    "id": "X1VmlNjstdsN"
   },
   "outputs": [],
   "source": [
    "mu0 = LGBMRegressor(max_depth=3)\n",
    "mu1 = LGBMRegressor(max_depth=3)\n",
    "\n",
    "mu0.fit(data_behavior.iloc[np.where(data_behavior['A']==0)[0],0:2],data_behavior.iloc[np.where(data_behavior['A']==0)[0],3] )\n",
    "mu1.fit(data_behavior.iloc[np.where(data_behavior['A']==1)[0],0:2],data_behavior.iloc[np.where(data_behavior['A']==1)[0],3] )\n",
    "\n",
    "\n",
    "# estimate the HTE by T-learner\n",
    "HTE_T_learner = mu1.predict(data_behavior.iloc[:,0:2]) - mu0.predict(data_behavior.iloc[:,0:2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CUv_0SuBTi3e",
   "metadata": {
    "id": "CUv_0SuBTi3e"
   },
   "source": [
    "Now let's take a glance at the performance of T-learner by comparing it with the true value for the first 10 subjects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5OHVneDpTgMp",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1675480607174,
     "user": {
      "displayName": "Yang Xu",
      "userId": "12270366590264264299"
     },
     "user_tz": 300
    },
    "id": "5OHVneDpTgMp",
    "outputId": "0f987dc7-c5ba-49eb-94c9-58e4ab346da9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-learner:   [ 1.869   1.8733  0.6596  0.3087 -0.2298 -0.5598 -2.2745 -1.8211]\n",
      "true value:  [ 1.2961 -0.4475  0.731   0.2863  0.4471 -0.1839 -3.3869 -1.238 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"T-learner:  \",HTE_T_learner[0:8])\n",
    "print(\"true value: \",HTE_true[0:8].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Ux89PwJagR5_",
   "metadata": {
    "id": "Ux89PwJagR5_"
   },
   "source": [
    "This is quite good! T-learner captures the overall trend of the treatment effect w.r.t. the heterogeneity of different subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SW8ONIdFPpvM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1675480608079,
     "user": {
      "displayName": "Yang Xu",
      "userId": "12270366590264264299"
     },
     "user_tz": 300
    },
    "id": "SW8ONIdFPpvM",
    "outputId": "a9373651-5081-40ac-ef54-d713602f3976"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall estimation bias of T-learner is :      0.29138198450323705 , \n",
      " The overall estimation variance of T-learner is : 1.810391408711312 . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Bias_T_learner = np.sum(HTE_T_learner-HTE_true)/n\n",
    "Variance_T_learner = np.sum((HTE_T_learner-HTE_true)**2)/n\n",
    "print(\"The overall estimation bias of T-learner is :     \", Bias_T_learner, \", \\n\", \"The overall estimation variance of T-learner is :\",Variance_T_learner,\". \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vOsw-rfxU415",
   "metadata": {
    "id": "vOsw-rfxU415"
   },
   "source": [
    "**Conclusion:** In this toy example, the overall estimation variance of T-learner is smaller than that of S-learner. In some cases when the treatment effect is relatively complex, it's likely to yield better performance by fitting two models separately. \n",
    "\n",
    "However, in an extreme case when both $\\mu_0(s)$ and $\\mu_1(s)$ are nonlinear complicated function of state $s$ while their difference is just a constant, T-learner will overfit each model very easily, yielding a nonlinear treatment effect estimator. In this case, other estimators are often preferred."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8lwheJQ8RxAw",
   "metadata": {
    "id": "8lwheJQ8RxAw"
   },
   "source": [
    "### **3. X-learner**\n",
    "Next, let's introduce the X-learner. As a combination of S-learner and T-learner, the X-learner can use information from the control(treatment) group to derive better estimators for the treatment(control) group, which is provably more efficient than the above two.\n",
    "\n",
    "The basic\n",
    "\n",
    "\n",
    "**Step 1:**  Estimate $\\mu_0(s)$ and $\\mu_1(s)$ separately with any regression algorithms or supervised machine learning methods (same as T-learner);\n",
    "\n",
    "\n",
    "**Step 2:**  Obtain the imputed treatment effects for individuals\n",
    "\\begin{equation*}\n",
    "\\tilde{\\Delta}_i^1:=R_i^1-\\hat\\mu_0(S_i^1), \\quad \\tilde{\\Delta}_i^0:=\\hat\\mu_1(S_i^0)-R_i^0.\n",
    "\\end{equation*}\n",
    "\n",
    "**Step 3:**  Fit the imputed treatment effects to obtain $\\hat\\tau_1(s):=\\mathbb{E}[\\tilde{\\Delta}_i^1|S=s]$ and $\\hat\\tau_0(s):=\\mathbb{E}[\\tilde{\\Delta}_i^0|S=s]$;\n",
    "\n",
    "**Step 4:**  The final HTE estimator is given by\n",
    "\\begin{equation*}\n",
    "\\hat{\\tau}_{\\text{X-learner}}(s)=g(s)\\hat\\tau_0(s)+(1-g(s))\\hat\\tau_1(s),\n",
    "\\end{equation*}\n",
    "\n",
    "where $g(s)$ is a weight function between $[0,1]$. A possible way is to use the propensity score model as an estimate of $g(s)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sfb-mplOP9HJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1675480609180,
     "user": {
      "displayName": "Yang Xu",
      "userId": "12270366590264264299"
     },
     "user_tz": 300
    },
    "id": "sfb-mplOP9HJ",
    "outputId": "a225f7dc-6b60-4198-9db3-5cd4c73ce5e4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(max_depth=3)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Fit two models under treatment and control separately, same as T-learner\n",
    "\n",
    "import numpy as np\n",
    "mu0 = LGBMRegressor(max_depth=3)\n",
    "mu1 = LGBMRegressor(max_depth=3)\n",
    "\n",
    "S_T0 = data_behavior.iloc[np.where(data_behavior['A']==0)[0],0:2]\n",
    "S_T1 = data_behavior.iloc[np.where(data_behavior['A']==1)[0],0:2]\n",
    "R_T0 = data_behavior.iloc[np.where(data_behavior['A']==0)[0],3] \n",
    "R_T1 = data_behavior.iloc[np.where(data_behavior['A']==1)[0],3] \n",
    "\n",
    "mu0.fit(S_T0, R_T0)\n",
    "mu1.fit(S_T1, R_T1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zb42ZMw3pkqm",
   "metadata": {
    "id": "zb42ZMw3pkqm"
   },
   "outputs": [],
   "source": [
    "# Step 2: impute the potential outcomes that are unobserved in original data\n",
    "\n",
    "n_T0 = len(R_T0)\n",
    "n_T1 = len(R_T1)\n",
    "\n",
    "Delta0 = mu1.predict(S_T0) - R_T0\n",
    "Delta1 = R_T1 - mu0.predict(S_T1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pxYLjE0Ar2_5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1675480610349,
     "user": {
      "displayName": "Yang Xu",
      "userId": "12270366590264264299"
     },
     "user_tz": 300
    },
    "id": "pxYLjE0Ar2_5",
    "outputId": "561b87a3-e53a-4293-dfd1-55ccc98cf050"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(max_depth=2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Fit tau_1(s) and tau_0(s)\n",
    "\n",
    "tau0 = LGBMRegressor(max_depth=2)\n",
    "tau1 = LGBMRegressor(max_depth=2)\n",
    "\n",
    "tau0.fit(S_T0, Delta0)\n",
    "tau1.fit(S_T1, Delta1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "LRvEZ4uluT-U",
   "metadata": {
    "id": "LRvEZ4uluT-U"
   },
   "outputs": [],
   "source": [
    "# Step 4: fit the propensity score model $\\hat{g}(s)$ and obtain the final HTE estimator by taking weighted average of tau0 and tau1\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "\n",
    "g = LogisticRegression()\n",
    "g.fit(data_behavior.iloc[:,0:2],data_behavior['A'])\n",
    "\n",
    "HTE_X_learner = g.predict_proba(data_behavior.iloc[:,0:2])[:,0]*tau0.predict(data_behavior.iloc[:,0:2]) + g.predict_proba(data_behavior.iloc[:,0:2])[:,1]*tau1.predict(data_behavior.iloc[:,0:2])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Mz8I_J0h4N6B",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1675480611104,
     "user": {
      "displayName": "Yang Xu",
      "userId": "12270366590264264299"
     },
     "user_tz": 300
    },
    "id": "Mz8I_J0h4N6B",
    "outputId": "721754de-27bb-41d5-99b1-cb8f6e758381"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-learner:   [ 1.9341  1.9235  0.2944  0.2013 -0.4147 -0.5626 -2.214  -1.5443]\n",
      "true value:  [ 1.2961 -0.4475  0.731   0.2863  0.4471 -0.1839 -3.3869 -1.238 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"X-learner:  \",HTE_X_learner[0:8])\n",
    "print(\"true value: \",HTE_true[0:8].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "XyxjzDBy4N6k",
   "metadata": {
    "id": "XyxjzDBy4N6k"
   },
   "source": [
    "From the result above we can see that X-learner can roughly catch the trend of treatment effect w.r.t. the change of baseline information $S$. In this synthetic example, X-learner also performs slightly better than T-learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rlbacETd4N6l",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1675480612355,
     "user": {
      "displayName": "Yang Xu",
      "userId": "12270366590264264299"
     },
     "user_tz": 300
    },
    "id": "rlbacETd4N6l",
    "outputId": "a432821d-9f34-4701-9d56-e404179795cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overall estimation bias of X-learner is :      0.2827518068171628 , \n",
      " The overall estimation variance of X-learner is : 1.7686646616779012 . \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Bias_X_learner = np.sum(HTE_X_learner-HTE_true)/n\n",
    "Variance_X_learner = np.sum((HTE_X_learner-HTE_true)**2)/n\n",
    "print(\"The overall estimation bias of X-learner is :     \", Bias_X_learner, \", \\n\", \"The overall estimation variance of X-learner is :\",Variance_X_learner,\". \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "EnxQ_Tkg4o_q",
   "metadata": {
    "id": "EnxQ_Tkg4o_q"
   },
   "source": [
    "**Conclusion:** In this toy example, the overall estimation variance of X-learner is the smallest, followed by T-learner, and the worst is given by S-learner.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zxpRscObJmbX",
   "metadata": {
    "id": "zxpRscObJmbX"
   },
   "source": [
    "**Note**: For more details about the meta learners, please refer to [1]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nyirbjS5JdGh",
   "metadata": {
    "id": "nyirbjS5JdGh"
   },
   "source": [
    "## References\n",
    "1. Kunzel, S. R., Sekhon, J. S., Bickel, P. J., and Yu, B. (2019). Metalearners for estimating heterogeneous treatment effects using machine learning. Proceedings of the national academy of sciences 116, 4156–4165.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}