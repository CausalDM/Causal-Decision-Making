{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3f76509-3b83-49f3-9946-e24b92f6ee8c",
   "metadata": {},
   "source": [
    "# MIMIC III (Infinite Horizon)\n",
    "\n",
    "In this notebook, we conducted analysis on the MIMIC III data with infinite horizon. We first analyzed the mediation effect and then evaluate the policy of interest and calculated the optimal policy. As informed by the causal structure learning, here we consider Glucose and PaO2_FiO2 as confounders/states, IV_Input as the action, SOFA as the mediator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a53ca1bf-dae9-4a01-8457-cef602459750",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icustayid</th>\n",
       "      <th>bloc</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>PaO2_FiO2</th>\n",
       "      <th>IV_Input</th>\n",
       "      <th>SOFA</th>\n",
       "      <th>next_Glucose</th>\n",
       "      <th>next_PaO2_FiO2</th>\n",
       "      <th>Died_within_48H</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>682</th>\n",
       "      <td>1006</td>\n",
       "      <td>1</td>\n",
       "      <td>91.0</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>91.0</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>683</th>\n",
       "      <td>1006</td>\n",
       "      <td>3</td>\n",
       "      <td>91.0</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>91.0</td>\n",
       "      <td>206.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>1006</td>\n",
       "      <td>6</td>\n",
       "      <td>175.0</td>\n",
       "      <td>100.173913</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>175.0</td>\n",
       "      <td>100.173913</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>1006</td>\n",
       "      <td>7</td>\n",
       "      <td>175.0</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>175.0</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>1006</td>\n",
       "      <td>8</td>\n",
       "      <td>175.0</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>175.0</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>1006</td>\n",
       "      <td>10</td>\n",
       "      <td>144.0</td>\n",
       "      <td>187.234036</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>144.0</td>\n",
       "      <td>187.234036</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     icustayid  bloc  Glucose   PaO2_FiO2  IV_Input  SOFA  next_Glucose  \\\n",
       "682       1006     1     91.0  206.000000         0     8          91.0   \n",
       "683       1006     3     91.0  206.000000         0     8          91.0   \n",
       "684       1006     6    175.0  100.173913         1     3         175.0   \n",
       "685       1006     7    175.0   96.000000         1    10         175.0   \n",
       "686       1006     8    175.0   96.000000         1     9         175.0   \n",
       "687       1006    10    144.0  187.234036         1    12         144.0   \n",
       "\n",
       "     next_PaO2_FiO2  Died_within_48H  \n",
       "682      206.000000                1  \n",
       "683      206.000000                1  \n",
       "684      100.173913                1  \n",
       "685       96.000000                1  \n",
       "686       96.000000                1  \n",
       "687      187.234036                0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('D:/GitHub/CausalDM')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "file = open('./causaldm/MIMIC3/mimic3_MRL_data_dict_V2.pickle', 'rb')\n",
    "mimic3_MRL = pickle.load(file)\n",
    "mimic3_MRL['reward'] = [1 if r == 0 else r for r in mimic3_MRL['reward']]\n",
    "mimic3_MRL['reward'] = [0 if r == -1 else r for r in mimic3_MRL['reward']]\n",
    "MRL_df = pd.read_csv('./causaldm/MIMIC3/mimic3_MRL_df_V2.csv')\n",
    "MRL_df.iloc[np.where(MRL_df['Died_within_48H']==0)[0],-1]=1\n",
    "MRL_df.iloc[np.where(MRL_df['Died_within_48H']==-1)[0],-1]=0\n",
    "MRL_df[MRL_df.icustayid==1006]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdfd9ef-9bee-42bc-8649-f2cc20806ce3",
   "metadata": {},
   "source": [
    "## CEL: Mediation Analysis with Infinite Horizon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a161516-9900-4523-bf04-d6f6edd31c76",
   "metadata": {},
   "source": [
    "We processed the MIMIC III data similarly to literature on reinforcement learning by setting the reward of each stage prior to the final stage to 0, and the reward of the final stage to the observed value of Died within 48H. In this section, we analyze the average treatment effect (ATE) of a target policy that provides IV input all of the time compared to a control policy that provides no IV input at all. Using the multiply-robust estimator proposed in [1], we decomposed the ATE into four components, including immediate nature dierct effect (INDE), Immediate nature mediator effect (INME), delayed nature direct effect (DNDE), and delayed nature mediator effect (NDDNME), and estimated each of the effect component. The estimation results are summarized in the table below.\n",
    "\n",
    "| INDE           | INME | DNDE           | DNME           | ATE           |\n",
    "|---------------|-----|---------------|---------------|---------------|\n",
    "| -.0181(.0059) | .0061(.0021)   | -.0049(.0028) | -.0002(.0011) | -.0171(.0058) |\n",
    "\n",
    "Specifically, the ATE of the target policy is significantly negative, with an effect size of .0171. Diving deep, we find that the DNME and DNDE are insignificant, whereas the INDE and INME are all statistically significant. Further, taking the effect size into account, we can conclude that the majority of the average treatment effect is directly due to the actions derived from the target treatment policy, while the part of the effect that can be attributed to the mediators is negligible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "722a2e3b-d45c-4035-8033-ff410aef15f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from causaldm.learners.CEL.MA import ME_MDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e35283e0-6646-4f14-ab56-ab7afabc7740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control Policy\n",
    "def control_policy(state = None, dim_state=None, action=None, get_a = False):\n",
    "    # fixed policy with fixed action 0\n",
    "    if get_a:\n",
    "        action_value = np.array([0])\n",
    "    else:\n",
    "        state = np.copy(state).reshape(-1,dim_state)\n",
    "        NT = state.shape[0]\n",
    "        if action is None:\n",
    "            action_value = np.array([0]*NT)\n",
    "        else:\n",
    "            action = np.copy(action).flatten()\n",
    "            if len(action) == 1 and NT>1:\n",
    "                action = action * np.ones(NT)\n",
    "            action_value = 1-action\n",
    "    return action_value\n",
    "def target_policy(state, dim_state = 1, action=None):\n",
    "    state = np.copy(state).reshape((-1, dim_state))\n",
    "    NT = state.shape[0]\n",
    "    pa = 1 * np.ones(NT)\n",
    "    if action is None:\n",
    "        if NT == 1:\n",
    "            pa = pa[0]\n",
    "            prob_arr = np.array([1-pa, pa])\n",
    "            action_value = np.random.choice([0, 1], 1, p=prob_arr)\n",
    "        else:\n",
    "            raise ValueError('No random for matrix input')\n",
    "    else:\n",
    "        action = np.copy(action).flatten()\n",
    "        action_value = pa * action + (1-pa) * (1-action)\n",
    "    return action_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a88c374-41a3-4269-997f-c0e87ce586f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fixed hyper-parameter--no need to modify\n",
    "MCMC = 50\n",
    "truncate = 50\n",
    "problearner_parameters = {\"splitter\":[\"best\",\"random\"], \"max_depth\" : range(1,50)},\n",
    "dim_state=2; dim_mediator = 1\n",
    "ratio_ndim = 10\n",
    "d = 2\n",
    "L = 5\n",
    "scaler = 'Identity'\n",
    "method = \"Robust\"\n",
    "seed = 0\n",
    "r_model = \"OLS\"\n",
    "Q_settings = {'scaler': 'Identity','product_tensor': False, 'beta': 3/7, \n",
    "              'include_intercept': False, \n",
    "              'penalty': 10**(-4),'d': d, 'min_L': L, 't_dependent_Q': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0daebafc-3006-46e5-905d-1f2a3f1fd3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building 0-th basis spline (total 3 state-mediator dimemsion) which has 3 basis, in total 3 features \n",
      "Building 1-th basis spline (total 3 state-mediator dimemsion) which has 3 basis, in total 6 features \n",
      "Building 2-th basis spline (total 3 state-mediator dimemsion) which has 3 basis, in total 9 features \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 10>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m Robust_est \u001b[38;5;241m=\u001b[39m ME_MDP\u001b[38;5;241m.\u001b[39mevaluator(mimic3_MRL, r_model \u001b[38;5;241m=\u001b[39m r_model,\n\u001b[0;32m      2\u001b[0m                      problearner_parameters \u001b[38;5;241m=\u001b[39m problearner_parameters,\n\u001b[0;32m      3\u001b[0m                      ratio_ndim \u001b[38;5;241m=\u001b[39m ratio_ndim, truncate \u001b[38;5;241m=\u001b[39m truncate, l2penalty \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      7\u001b[0m                      MCMC \u001b[38;5;241m=\u001b[39m MCMC,\n\u001b[0;32m      8\u001b[0m                      seed \u001b[38;5;241m=\u001b[39m seed, nature_decomp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m, method \u001b[38;5;241m=\u001b[39m method)\n\u001b[1;32m---> 10\u001b[0m \u001b[43mRobust_est\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mestimate_DE_ME\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m Robust_est\u001b[38;5;241m.\u001b[39mest_IDE, Robust_est\u001b[38;5;241m.\u001b[39mIME, Robust_est\u001b[38;5;241m.\u001b[39mDDE, Robust_est\u001b[38;5;241m.\u001b[39mDME, Robust_est\u001b[38;5;241m.\u001b[39mTE\n",
      "File \u001b[1;32mD:\\GitHub\\CausalDM\\causaldm\\learners\\CEL\\MA\\ME_MDP.py:114\u001b[0m, in \u001b[0;36mevaluator.estimate_DE_ME\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mIPW_est()\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRobust\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;66;03m# Baseline TR\u001b[39;00m\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mRobust_est\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\GitHub\\CausalDM\\causaldm\\learners\\CEL\\MA\\ME_MDP.py:177\u001b[0m, in \u001b[0;36mevaluator.Robust_est\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mRobust_est\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    176\u001b[0m     data_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNT\n\u001b[1;32m--> 177\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Q_terms\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mEr_Sa0, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mEr_SA \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Er_Sa0_SA(data_num)\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrho_SAM \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrho_SAM(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmediator)\n",
      "File \u001b[1;32mD:\\GitHub\\CausalDM\\causaldm\\learners\\CEL\\MA\\ME_MDP.py:223\u001b[0m, in \u001b[0;36mevaluator._Q_terms\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    221\u001b[0m Q_est\u001b[38;5;241m.\u001b[39mest_Q4()\n\u001b[0;32m    222\u001b[0m Q_est\u001b[38;5;241m.\u001b[39mest_Q5()\n\u001b[1;32m--> 223\u001b[0m \u001b[43mQ_est\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mest_Qdiffs\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mQ1_diff, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meta_pie \u001b[38;5;241m=\u001b[39m Q_est\u001b[38;5;241m.\u001b[39mQ1_diff, Q_est\u001b[38;5;241m.\u001b[39meta_pie\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mQ5_diff, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meta_a0 \u001b[38;5;241m=\u001b[39m Q_est\u001b[38;5;241m.\u001b[39mQ5_diff, Q_est\u001b[38;5;241m.\u001b[39meta_a0\n",
      "File \u001b[1;32mD:\\GitHub\\CausalDM\\causaldm\\learners\\CEL\\MA\\qLearner_Linear.py:109\u001b[0m, in \u001b[0;36mQLearner.est_Qdiffs\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mest_Qdiffs\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 109\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mQ1_diff, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mQ2_diff, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mQ3_diff, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mQ4_diff_1, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mQ4_diff_2, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mQ5_diff \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_Q_diff\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmediator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\GitHub\\CausalDM\\causaldm\\learners\\CEL\\MA\\qLearner_Linear.py:356\u001b[0m, in \u001b[0;36mQLearner._Q_diff\u001b[1;34m(self, state, mediator, action, next_state)\u001b[0m\n\u001b[0;32m    353\u001b[0m pi0_a_S \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol_policy(state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim_state, a)\n\u001b[0;32m    354\u001b[0m pie_a_S \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_policy(state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim_state, a)\n\u001b[1;32m--> 356\u001b[0m Q1_Snext_am_MC, Q2_Snext_am_MC, Q3_Snext_am_MC, Q4_Snext_am_MC, Q5_Snext_am_MC, Q4_S_am_MC \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcal_Q_am_MC\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    358\u001b[0m Q1_Snext_am \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m pie_a_Sprime \u001b[38;5;241m*\u001b[39m Q1_Snext_am_MC\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,))\n\u001b[0;32m    359\u001b[0m Q5_Snext_am \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m pi0_a_Sprime \u001b[38;5;241m*\u001b[39m Q5_Snext_am_MC\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,))\n",
      "File \u001b[1;32mD:\\GitHub\\CausalDM\\causaldm\\learners\\CEL\\MA\\qLearner_Linear.py:427\u001b[0m, in \u001b[0;36mQLearner.cal_Q_am_MC\u001b[1;34m(self, next_state, state, action, a)\u001b[0m\n\u001b[0;32m    423\u001b[0m         pi_a_star[a_star] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_pa_next(next_state, a_star)\n\u001b[0;32m    425\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mMCMC):\n\u001b[0;32m    426\u001b[0m     \u001b[38;5;66;03m#np.random.seed(rep)\u001b[39;00m\n\u001b[1;32m--> 427\u001b[0m     Q1_Snext_am_MC, Q2_Snext_am_MC, Q3_Snext_am_MC, Q5_Snext_am_MC \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_Q1235_Snext_am_MC\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQ1_Snext_am_MC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQ2_Snext_am_MC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQ3_Snext_am_MC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mQ5_Snext_am_MC\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    429\u001b[0m     Q4_Snext_am_MC_astar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_Q4_Snext_am_MC_astar(rep, next_state, a, Q4_Snext_am_MC_astar)\n\u001b[0;32m    431\u001b[0m     Q4_S_am_MC \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_Q4_S_am_MC(rep, state, action, a, Q4_S_am_MC)\n",
      "File \u001b[1;32mD:\\GitHub\\CausalDM\\causaldm\\learners\\CEL\\MA\\qLearner_Linear.py:442\u001b[0m, in \u001b[0;36mQLearner.update_Q1235_Snext_am_MC\u001b[1;34m(self, rep, next_state, a, Q1_Snext_am_MC, Q2_Snext_am_MC, Q3_Snext_am_MC, Q5_Snext_am_MC)\u001b[0m\n\u001b[0;32m    440\u001b[0m m_Snext_a \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpmlearner\u001b[38;5;241m.\u001b[39msample_m(next_state, np\u001b[38;5;241m.\u001b[39marray([a]), random \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    441\u001b[0m action_list \u001b[38;5;241m=\u001b[39m [a]\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNT\n\u001b[1;32m--> 442\u001b[0m out_Q1, out_Q2, out_Q3, out_Q5 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcal_newQ_1235\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm_Snext_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtime_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    443\u001b[0m Q1_Snext_am_MC \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_exp(rep, Q1_Snext_am_MC, out_Q1)\n\u001b[0;32m    444\u001b[0m Q2_Snext_am_MC \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mupdate_exp(rep, Q2_Snext_am_MC, out_Q2)\n",
      "File \u001b[1;32mD:\\GitHub\\CausalDM\\causaldm\\learners\\CEL\\MA\\qLearner_Linear.py:396\u001b[0m, in \u001b[0;36mQLearner.cal_newQ_1235\u001b[1;34m(self, s, m, a, time_idx)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcal_newQ_1235\u001b[39m(\u001b[38;5;28mself\u001b[39m, s,m,a, time_idx):\n\u001b[1;32m--> 396\u001b[0m     Qs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mQ_1235(s[i], m[i], a[i], time_idx[i]) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNT)]\n\u001b[0;32m    397\u001b[0m     Q1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([q[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m Qs])\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,))\n\u001b[0;32m    398\u001b[0m     Q2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([q[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m Qs])\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,))\n",
      "File \u001b[1;32mD:\\GitHub\\CausalDM\\causaldm\\learners\\CEL\\MA\\qLearner_Linear.py:396\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcal_newQ_1235\u001b[39m(\u001b[38;5;28mself\u001b[39m, s,m,a, time_idx):\n\u001b[1;32m--> 396\u001b[0m     Qs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mQ_1235\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_idx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mNT)]\n\u001b[0;32m    397\u001b[0m     Q1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([q[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m Qs])\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,))\n\u001b[0;32m    398\u001b[0m     Q2 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([q[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m Qs])\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,))\n",
      "File \u001b[1;32mD:\\GitHub\\CausalDM\\causaldm\\learners\\CEL\\MA\\qLearner_Linear.py:328\u001b[0m, in \u001b[0;36mQLearner.Q_1235\u001b[1;34m(self, S, M, A, t)\u001b[0m\n\u001b[0;32m    326\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_U(S, M, A, time_idx \u001b[38;5;241m=\u001b[39m t)[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    327\u001b[0m Q1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(output\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mQ1_est_beta[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)))\n\u001b[1;32m--> 328\u001b[0m Q2 \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mQ2_est_beta\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    329\u001b[0m Q3 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(output\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mQ3_est_beta[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)))\n\u001b[0;32m    330\u001b[0m Q5 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(output\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mQ5_est_beta[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,)))\n",
      "File \u001b[1;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Robust_est = ME_MDP.evaluator(mimic3_MRL, r_model = r_model,\n",
    "                     problearner_parameters = problearner_parameters,\n",
    "                     ratio_ndim = ratio_ndim, truncate = truncate, l2penalty = 10**(-4),\n",
    "                     target_policy=target_policy, control_policy = control_policy, \n",
    "                     dim_state = dim_state, dim_mediator = dim_mediator, \n",
    "                     Q_settings = Q_settings,\n",
    "                     MCMC = MCMC,\n",
    "                     seed = seed, nature_decomp = True, method = method)\n",
    "\n",
    "Robust_est.estimate_DE_ME()\n",
    "Robust_est.est_IDE, Robust_est.IME, Robust_est.DDE, Robust_est.DME, Robust_est.TE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfff7a47-7449-4255-a121-e54b1dfc4a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.00586890111356167,\n",
       " 0.002110278954333155,\n",
       " 0.002770561709397491,\n",
       " 0.0010678186846428818,\n",
       " 0.005821662648170317)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Robust_est.IDE_se, Robust_est.IME_se, Robust_est.DDE_se, Robust_est.DME_se, Robust_est.TE_se"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dcd03a-13db-4924-8340-3df258236487",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "[1] Ge, L., Wang, J., Shi, C., Wu, Z., & Song, R. (2023). A Reinforcement Learning Framework for Dynamic Mediation Analysis. arXiv preprint arXiv:2301.13348."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}