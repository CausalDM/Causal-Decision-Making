{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99b219d1-2f7b-4ca3-8a20-1adeec8fab31",
   "metadata": {},
   "source": [
    "## MIMIC III (Single-Stage)\n",
    "\n",
    "In this notebook, we conducted analysis on the MIMIC III data with a single stage. We first analyzed the mediation effect and then evaluate the policy of interest and calculated the optimal policy. As informed by the causal structure learning, here we consider Glucose and PaO2_FiO2 as confounders/states, IV_Input as the action, SOFA as the mediator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51a5e576-f6f2-47c0-a96d-3935d0ee6ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icustayid</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>PaO2</th>\n",
       "      <th>PaO2_FiO2</th>\n",
       "      <th>IV Input</th>\n",
       "      <th>SOFA</th>\n",
       "      <th>Died within 48H</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1006</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>100.200000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1204</td>\n",
       "      <td>138.794872</td>\n",
       "      <td>127.782051</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.153846</td>\n",
       "      <td>6.153846</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4132</td>\n",
       "      <td>129.364286</td>\n",
       "      <td>123.956461</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4201</td>\n",
       "      <td>145.580087</td>\n",
       "      <td>118.083333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.363636</td>\n",
       "      <td>5.818182</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5170</td>\n",
       "      <td>174.525000</td>\n",
       "      <td>147.350198</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.437500</td>\n",
       "      <td>4.125000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6504</td>\n",
       "      <td>106.081169</td>\n",
       "      <td>88.836364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>5.090909</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   icustayid     Glucose        PaO2  PaO2_FiO2  IV Input      SOFA  \\\n",
       "0       1006  152.000000  100.200000        1.0  2.800000  0.000000   \n",
       "1       1204  138.794872  127.782051        1.0  1.153846  6.153846   \n",
       "2       4132  129.364286  123.956461        1.0  3.000000  0.000000   \n",
       "3       4201  145.580087  118.083333        1.0  1.363636  5.818182   \n",
       "4       5170  174.525000  147.350198        1.0  2.437500  4.125000   \n",
       "5       6504  106.081169   88.836364        0.0  0.363636  5.090909   \n",
       "\n",
       "   Died within 48H  \n",
       "0             -1.0  \n",
       "1              1.0  \n",
       "2             -1.0  \n",
       "3              1.0  \n",
       "4              1.0  \n",
       "5              1.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "single_data = pd.read_csv('mimic3_single_stage.csv')\n",
    "single_data.iloc[np.where(single_data['IV Input']<1)[0],3]=0 # change the discrete action to binary\n",
    "single_data.iloc[np.where(single_data['IV Input']>=1)[0],3]=1 # change the discrete action to binary\n",
    "single_data.iloc[np.where(single_data['Died within 48H']==-1)[0],5]=0 # change the discrete action to binary\n",
    "single_data.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d02f71b-f28b-459f-8029-6231ce90f7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = np.array(single_data[['Glucose','PaO2_FiO2']])\n",
    "action = np.array(single_data[['IV Input']])\n",
    "mediator = np.array(single_data[['SOFA']])\n",
    "reward = np.array(single_data[['Died within 48H']])\n",
    "single_dataset = {'state':state,'action':action,'mediator':mediator,'reward':reward}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b03650-db06-4e91-ac8b-bcc870187f00",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CEL: Single-Stage Mediation Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6de86b4-574a-4f15-a346-0a0122464ae7",
   "metadata": {},
   "source": [
    "Under the single-stage setting, we are interested in analyzing the treatment effect on the final outcome Died_within_48H observed at the end of the study by comparing the target treatment regime that provides IV input for all patients and the control treatment regime that does not provide any treatment. Using the direct estimator proposed in [1], IPW estimator proposed in [2], and robust estimator proposed in [3], we examine the natural direct and indirect effects of the target treatment regime based on observational data. With the code in the following blocks, the estimated effect components are summarized in the following:\n",
    "\n",
    "|                  |   NDE   | NIE     | TE     |\n",
    "|------------------|:------:|--------|--------|\n",
    "| Direct Estimator | -.2133 |  .0030 | -.2104 |\n",
    "| IPW              | -.2332 | 0      | -.2332 |\n",
    "| Robust           | -.2276 | -.0164 | -.2440 |\n",
    "\n",
    "Specifically, when compared to no treatment, always giving IV input has a negative impact on the survival rate, among which the effect directly from actions to the final outcome dominates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "681ab834-086a-438b-becc-0e101a17bde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from causaldm.learners.CEL.MA.ME_Single import ME_Single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6bafbfd-2dd6-47cc-8d76-a0100406fabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Control Policy\n",
    "def control_policy(state = None, dim_state=None, action=None, get_a = False):\n",
    "    if get_a:\n",
    "        action_value = np.array([0])\n",
    "    else:\n",
    "        state = np.copy(state).reshape(-1,dim_state)\n",
    "        NT = state.shape[0]\n",
    "        if action is None:\n",
    "            action_value = np.array([0]*NT)\n",
    "        else:\n",
    "            action = np.copy(action).flatten()\n",
    "            if len(action) == 1 and NT>1:\n",
    "                action = action * np.ones(NT)\n",
    "            action_value = 1-action\n",
    "    return action_value\n",
    "\n",
    "def target_policy(state, dim_state = 1, action=None):\n",
    "    state = np.copy(state).reshape((-1, dim_state))\n",
    "    NT = state.shape[0]\n",
    "    pa = 1 * np.ones(NT)\n",
    "    if action is None:\n",
    "        if NT == 1:\n",
    "            pa = pa[0]\n",
    "            prob_arr = np.array([1-pa, pa])\n",
    "            action_value = np.random.choice([0, 1], 1, p=prob_arr)\n",
    "        else:\n",
    "            raise ValueError('No random for matrix input')\n",
    "    else:\n",
    "        action = np.copy(action).flatten()\n",
    "        action_value = pa * action + (1-pa) * (1-action)\n",
    "    return action_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7113c82f-4488-4781-a62d-9eb23c216282",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "490 fits failed out of a total of 490.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "490 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 203, in fit\n",
      "    check_classification_targets(y)\n",
      "  File \"D:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py\", line 197, in check_classification_targets\n",
      "    raise ValueError(\"Unknown label type: %r\" % y_type)\n",
      "ValueError: Unknown label type: 'continuous'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "D:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan nan\n",
      " nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m problearner_parameters \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplitter\u001b[39m\u001b[38;5;124m\"\u001b[39m:[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrandom\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m50\u001b[39m)},\n\u001b[1;32m----> 2\u001b[0m Direct_est \u001b[38;5;241m=\u001b[39m \u001b[43mME_Single\u001b[49m\u001b[43m(\u001b[49m\u001b[43msingle_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mOLS\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mproblearner_parameters\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mproblearner_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mtruncate\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mtarget_policy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_policy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrol_policy\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcontrol_policy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mdim_state\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_mediator\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mMCMC\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mnature_decomp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDirect\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m Direct_est\u001b[38;5;241m.\u001b[39mestimate_DE_ME()\n\u001b[0;32m     13\u001b[0m Direct_est\u001b[38;5;241m.\u001b[39mest_DE, Direct_est\u001b[38;5;241m.\u001b[39mest_ME, Direct_est\u001b[38;5;241m.\u001b[39mest_TE,\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\causaldm\\learners\\CEL\\MA\\ME_Single.py:64\u001b[0m, in \u001b[0;36mME_Single.__init__\u001b[1;34m(self, dataset, r_model, problearner_parameters, truncate, target_policy, control_policy, dim_state, dim_mediator, MCMC, seed, nature_decomp, method)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewardlearner\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpalearner \u001b[38;5;241m=\u001b[39m PALearner(dataset, problearner_parameters, seed, dim_state \u001b[38;5;241m=\u001b[39m dim_state,\n\u001b[0;32m     63\u001b[0m                            dim_mediator \u001b[38;5;241m=\u001b[39m dim_mediator)\n\u001b[1;32m---> 64\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpalearner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpie_A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_policy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim_state, action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction)\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mI_A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol_policy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim_state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction)\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\causaldm\\learners\\CEL\\MA\\probLearner.py:182\u001b[0m, in \u001b[0;36mPALearner.train\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    179\u001b[0m y \u001b[38;5;241m=\u001b[39m action\n\u001b[0;32m    181\u001b[0m regressor \u001b[38;5;241m=\u001b[39m GridSearchCV(DecisionTreeClassifier(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparameters, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m--> 182\u001b[0m \u001b[43mregressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m best_params \u001b[38;5;241m=\u001b[39m regressor\u001b[38;5;241m.\u001b[39mbest_params_\n\u001b[0;32m    184\u001b[0m \u001b[38;5;66;03m#print('action', best_params)\u001b[39;00m\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:926\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    924\u001b[0m refit_start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    925\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 926\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m    927\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    928\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_estimator_\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:937\u001b[0m, in \u001b[0;36mDecisionTreeClassifier.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    899\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\n\u001b[0;32m    900\u001b[0m     \u001b[38;5;28mself\u001b[39m, X, y, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, X_idx_sorted\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    901\u001b[0m ):\n\u001b[0;32m    902\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Build a decision tree classifier from the training set (X, y).\u001b[39;00m\n\u001b[0;32m    903\u001b[0m \n\u001b[0;32m    904\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    934\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[0;32m    935\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 937\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheck_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_idx_sorted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_idx_sorted\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py:203\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_classification:\n\u001b[1;32m--> 203\u001b[0m     \u001b[43mcheck_classification_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcopy(y)\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_ \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mD:\\anaconda3\\lib\\site-packages\\sklearn\\utils\\multiclass.py:197\u001b[0m, in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    189\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y)\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    192\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel-sequences\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    196\u001b[0m ]:\n\u001b[1;32m--> 197\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown label type: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m y_type)\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "problearner_parameters = {\"splitter\":[\"best\",\"random\"], \"max_depth\" : range(1,50)},\n",
    "Direct_est = ME_Single(single_dataset, r_model = 'OLS',\n",
    "                     problearner_parameters = problearner_parameters,\n",
    "                     truncate = 50, \n",
    "                     target_policy=target_policy, control_policy = control_policy, \n",
    "                     dim_state = 2, dim_mediator = 1, \n",
    "                     MCMC = 50,\n",
    "                     nature_decomp = True,\n",
    "                     seed = 10,\n",
    "                     method = 'Direct')\n",
    "\n",
    "Direct_est.estimate_DE_ME()\n",
    "Direct_est.est_DE, Direct_est.est_ME, Direct_est.est_TE,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ffac3b7-30ec-4280-a4c0-0fbfdfdeb2b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.23320671819000469, 0.0, -0.23320671819000469)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IPW_est = ME_Single(single_dataset, r_model = 'OLS',\n",
    "                     problearner_parameters = problearner_parameters,\n",
    "                     truncate = 50, \n",
    "                     target_policy=target_policy, control_policy = control_policy, \n",
    "                     dim_state = 2, dim_mediator = 1, \n",
    "                     MCMC = 50,\n",
    "                     nature_decomp = True,\n",
    "                     seed = 10,\n",
    "                     method = 'IPW')\n",
    "\n",
    "IPW_est.estimate_DE_ME()\n",
    "IPW_est.est_DE, IPW_est.est_ME, IPW_est.est_TE,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a5b2ab6-5f8f-4f0a-9696-981b3f661cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.22762835456807218, -0.01638548320515956, -0.24401383777323174)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Robust_est = ME_Single(single_dataset, r_model = 'OLS',\n",
    "                     problearner_parameters = problearner_parameters,\n",
    "                     truncate = 50, \n",
    "                     target_policy=target_policy, control_policy = control_policy, \n",
    "                     dim_state = 2, dim_mediator = 1, \n",
    "                     MCMC = 50,\n",
    "                     nature_decomp = True,\n",
    "                     seed = 10,\n",
    "                     method = 'Robust')\n",
    "\n",
    "Robust_est.estimate_DE_ME()\n",
    "Robust_est.est_DE, Robust_est.est_ME, Robust_est.est_TE,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b3bb90-76b4-4005-b626-574ad2759383",
   "metadata": {},
   "source": [
    "## CPL: Single-Stage Policy Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92cc85ce-d2b7-445b-9950-e2a87ca7d2ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from causaldm.learners.CPL13.disc import QLearning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903e7f10-ce3d-4124-9d8f-4e1ab719e4b0",
   "metadata": {},
   "source": [
    "As an example, we use the **Q-learning** algorithm to evaluate policies based on the observed data, with the linear regression models defined as the following:\n",
    "\\begin{align}\n",
    "Q(s,a,\\boldsymbol{\\beta}) = &\\beta_{00}+\\beta_{01}*\\textrm{Glucose}+\\beta_{02}*\\textrm{PaO2_FiO2}\\\\\n",
    "                    &I(a_1=1)*\\{\\beta_{10}+\\beta_{11}*\\textrm{Glucose}+\\beta_{12}*\\textrm{PaO2_FiO2}\\},\n",
    "\\end{align}\n",
    "\n",
    "Using the code below, we evaluated two target polices (regimes). The first one is a fixed treatement regime that applies no treatment (Policy1), with an estimated value of .9999. Another is a fixed treatment regime that applies treatment all the time (Policy2), with an estimated value of .7646. Therefore, the treatment effect of Policy2 comparing to Policy1 is -.2353, implying that receiving IV input increase the mortality rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88152436-d5eb-4ffd-ac45-d40fe19bdcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_data.rename(columns = {'Died within 48H':'R', 'Glucose':'S1', 'PaO2_FiO2':'S2', 'IV Input':'A'}, inplace = True)\n",
    "R = single_data['R'] #lower the better\n",
    "S = single_data[['S1','S2']]\n",
    "A = single_data[['A']]\n",
    "# specify the model you would like to use\n",
    "model_info = [{\"model\": \"R~S1+S2+A+S1*A+S2*A\",\n",
    "              'action_space':{'A':[0,1]}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "566b8bb8-80b1-4c29-8d92-3f273484094d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the policy with no treatment\n",
    "N=len(S)\n",
    "regime = pd.DataFrame({'A':[0]*N}).set_index(S.index)\n",
    "#evaluate the regime\n",
    "QLearn = QLearning.QLearning()\n",
    "QLearn.train(S, A, R, model_info, T=1, regime = regime, evaluate = True, mimic3_clip = True)\n",
    "QLearn.predict_value(S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10f6441a-273c-4022-802d-e8d2df2336f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.764561656518231"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluating the policy that gives IV input at both stages\n",
    "N=len(S)\n",
    "regime = pd.DataFrame({'A':[1]*N}).set_index(S.index)\n",
    "#evaluate the regime\n",
    "QLearn = QLearning.QLearning()\n",
    "QLearn.train(S, A, R, model_info, T=1, regime = regime, evaluate = True, mimic3_clip = True)\n",
    "QLearn.predict_value(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54de121-0b8b-4412-9678-3941846423c0",
   "metadata": {},
   "source": [
    "## CPL: Single-Stage Policy Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49f86ca-4a31-470d-b3b2-837b4c7dbcbf",
   "metadata": {},
   "source": [
    "Further, to find an optimal policy maximizing the expected value, we use the **Q-learning** algorithm again to do policy optimization. Using the regression model we specified above and the code in the following block, the estimated optimal policy is summarized as the following regime.\n",
    "\n",
    "1. We would recommend $A=0$ (IV_Input = 0) if $-.0004*\\textrm{Glucose}+.0012*\\textrm{PaO2_FiO2}<.5510$\n",
    "2. Else, we would recommend $A=1$ (IV_Input = 1).\n",
    "    \n",
    "Appling the estimated optimal regime to individuals in the observed data, we summarize the regime pattern for each patients in the following table:\n",
    "\n",
    "| # patients | IV_Input | \n",
    "|------------|----------|\n",
    "| 51         | 0        |\n",
    "| 6          | 1        |\n",
    "The estimated value of the estimated optimal policy is **.9999**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a5a82ac-ef51-4899-b626-02cbee491120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "opt_d: A\n",
      "0    51\n",
      "1     6\n",
      "dtype: int64\n",
      "opt value: 0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "# initialize the learner\n",
    "QLearn = QLearning.QLearning()\n",
    "# train the policy\n",
    "QLearn.train(S, A, R, model_info, T=1, mimic3_clip = True)\n",
    "# get the summary of the fitted Q models using the following code\n",
    "#print(\"fitted model Q0:\",QLearn.fitted_model[0].summary())\n",
    "#print(\"fitted model Q1:\",QLearn.fitted_model[1].summary())\n",
    "#4. recommend action\n",
    "opt_d = QLearn.recommend_action(S).value_counts()\n",
    "#5. get the estimated value of the optimal regime\n",
    "V_hat = QLearn.predict_value(S)\n",
    "print(\"opt_d:\",opt_d)\n",
    "print(\"opt value:\",V_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dcd03a-13db-4924-8340-3df258236487",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "[1]Robins, J. M. and Greenland, S. Identifiability and exchangeability for direct and indirect effects. Epidemiology, pp. 143–155, 1992.\n",
    "\n",
    "[2]Hong, G. (2010). Ratio of mediator probability weighting for estimating natural direct and indirect effects. In Proceedings of the American Statistical Association, biometrics section (pp. 2401-2415).\n",
    "\n",
    "[3] Tchetgen, E. J. T., & Shpitser, I. (2012). Semiparametric theory for causal mediation analysis: efficiency bounds, multiple robustness, and sensitivity analysis. Annals of statistics, 40(3), 1816."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}