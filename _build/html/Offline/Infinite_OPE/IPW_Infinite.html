
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Importance Sampling for Policy Evaluation (Infinite Horizon) &#8212; Causal Decision Making</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Doubly Robust Estimator for Policy Evaluation (Infinite Horizon)" href="DR_Infinite.html" />
    <link rel="prev" title="Fitted-Q Evaluation" href="FQE.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Causal Decision Making</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../Map.html">
                    Overview
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introduction
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../Examples.html">
   <em>
    Motivating Examples
   </em>
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../Preliminary.html">
   Preliminary
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Preliminary/Causal%20Inference%20Preliminary.html">
     Average Treatment Effect
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Preliminary/Heterogenous%20Treatement%20Effect.html">
     Heterogenous Treatment Effect
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Causal Structure Learning (CSL)
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../Preliminary/Causal%20Discovery%20Preliminary.html">
   Causal Discovery Preliminary
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Causal_Discovery/Testing-based%20Learner%20-%20PC%20Algorithm.html">
   Testing-based Learner - PC Algorithm
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Causal_Discovery/Functional-based%20Learner%20-%20LiNGAM%20Algorithm.html">
   Functional-based Learner - LiNGAM Algorithm
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Causal_Discovery/Score-based%20Learner%20-%20NOTEARS%20Algorithm.html">
   Score-based Learner - NOTEARS Algorithm
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Causal Effect Learning (CEL)
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../Causal_Effect_Learning/Scenario%201/Single%20Stage.html">
   Single Stage
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Causal_Effect_Learning/Scenario%201/ATE.html">
     ATE estimation (Single Stage)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Causal_Effect_Learning/Scenario%201/HTE.html">
     Heterogeneous Treatment Effect Estimation (Single Stage)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../Causal_Effect_Learning/Scenario%202/underMDP.html">
   Markov Decision Processes
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Causal_Effect_Learning/Scenario%202/ATE.html">
     ATE
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Causal_Effect_Learning/Scenario%202/HTE.html">
     HTE
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Causal_Effect_Learning/Scenario%203/Multiple%20Stage.html">
   Multiple Stageâ€“Finite Horizon
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Causal_Effect_Learning/Scenario%204/Miscellaneous.html">
   Miscellaneous
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Causal Policy Learning (CPL)--Scenario 1
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Single%20Stage.html">
   Single Stage (DTR)
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Finite/Discrete.html">
   Discrete Action Space
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Finite/Q-learning_Single.html">
     Q-Learning (Single Stage)
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Finite/A-learning_Single.html">
     A-Learning (Single Stage)
    </a>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../Finite/Classification.html">
     Reduction to Classification Problems
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
    <label for="toctree-checkbox-5">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../Finite/Classification/O-Learning.html">
       Outcome Weighted Learning
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../Finite/Classification/E-learning.html">
       Entropy learning
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Finite/Quantile/QuantileOTR_test.html">
     <strong>
      Quantile Optimal Treatment Regime
     </strong>
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Finite/Continuous.html">
   Continuous Action Space
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Finite/Continuous/Deep%20Jump%20Learner.html">
     Deep Jump Learner for Continuous Actions
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Finite/Continuous/Kernel-Based%20Learner.html">
     Kernel-Based Learner
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Finite/Continuous/Outcome%20Learning.html">
     Outcome Learning
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Plan%20to%20Do.html">
   Plan to do
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/>
  <label for="toctree-checkbox-7">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Finite/Policy%20Search.html">
     Policy Search
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Finite/Concordance.html">
     Concordance-assisted learning
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Causal Policy Learning (CPL)--Scenario 2
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../Online/Bandits.html">
   Overview: Bandits ALgorithm
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../Online/MAB/MAB.html">
   Multi-Armed Bandits (MAB)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/>
  <label for="toctree-checkbox-8">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Online/MAB/Epsilon_Greedy.html">
     <span class="math notranslate nohighlight">
      \(\epsilon\)
     </span>
     -Greedy
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Online/MAB/UCB.html">
     UCB
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Online/MAB/TS.html">
     TS
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../Online/Contextual_Bandits/Contextual_Bandits.html">
   Contextual Bandits
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/>
  <label for="toctree-checkbox-9">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Online/Contextual_Bandits/LinUCB.html">
     LinUCB
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Online/Contextual_Bandits/LinTS.html">
     LinTS
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../Online/Meta_Bandits/Meta_Bandits.html">
   Meta Bandits
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/>
  <label for="toctree-checkbox-10">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Online/Meta_Bandits/Meta_TS.html">
     Meta Thompson Sampling
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Online/Meta_Bandits/MTTS.html">
     Multi-Task Thompson Sampling (MTTS)
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../Online/Slate/Structured_Bandit.html">
   Structured Bandit (Slate Recommendation)
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/>
  <label for="toctree-checkbox-11">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../Online/Slate/Learning%20to%20rank.html">
     Online Learning to Rank (Cascading Bandit)
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/>
    <label for="toctree-checkbox-12">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../Online/Slate/Cascade/TS_Cascade.html">
       TS_Cascade
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../Online/Slate/Cascade/CascadeLinTS.html">
       CascadeLinTS
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../Online/Slate/Cascade/MTSS_Cascade.html">
       MTSS_Cascade
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../Online/Slate/Combinatorial%20Optimization.html">
     Online Combinatorial Optimization (Combinatorial Semi-Bandit)
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/>
    <label for="toctree-checkbox-13">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../Online/Slate/Combinatorial-Semi/CombTS.html">
       CombTS
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../Online/Slate/Combinatorial-Semi/CombLinTS.html">
       CombLinTS
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../Online/Slate/Combinatorial-Semi/MTSS_Comb.html">
       MTSS_Comb
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../../Online/Slate/Assortment%20Optimization.html">
     Dynamic Assortment Optimization (Multinomial Logit Bandit)
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/>
    <label for="toctree-checkbox-14">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../../Online/Slate/MNL/TS_MNL_Beta.html">
       TS_MNL
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../Online/Slate/MNL/TS_Contextual_MNL.html">
       TS_Contextual_MNL
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="../../Online/Slate/MNL/MTSS_MNL.html">
       MTSS_MNL
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../OnlineEval/Online%20Policy%20Evaluation.html">
   Online Policy Evaluation
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/>
  <label for="toctree-checkbox-15">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../OnlineEval/Doubly%20Robust%20Online%20Policy%20Evaluator.html">
     Doubly Robust Online Policy Evaluator
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../OnlineEval/Inverse%20Probability%20Weighted%20Online%20Policy%20Evaluator.html">
     Inverse Probability Weighted Online Policy Evaluator
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../OnlineEval/Direct%20Online%20Policy%20Evaluator.html">
     Direct Online Policy Evaluator
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Causal Policy Learning (CPL)--Scenario 3
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="../preliminary_MDP-potential-outcome.html">
   Preliminary: Off-policy Evaluation and Optimization in Markov Decision Processes
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/>
  <label for="toctree-checkbox-16">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active has-children">
    <a class="reference internal" href="Evaluation.html">
     Offline Evaluation
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/>
    <label for="toctree-checkbox-17">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul class="current">
     <li class="toctree-l3">
      <a class="reference internal" href="FQE.html">
       Fitted-Q Evaluation
      </a>
     </li>
     <li class="toctree-l3 current active">
      <a class="current reference internal" href="#">
       Importance Sampling for Policy Evaluation (Infinite Horizon)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="DR_Infinite.html">
       Doubly Robust Estimator for Policy Evaluation (Infinite Horizon)
      </a>
     </li>
     <li class="toctree-l3">
      <a class="reference internal" href="Deeply_Debiased.html">
       Deeply-Debiased Off-Policy Evaluation
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="Optimization.html">
     Offline Optimization
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/>
    <label for="toctree-checkbox-18">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="FQI.html">
       Fitted-Q Iteration
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../OnlineRL.html">
   Online RL
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Causal Policy Learning (CPL)--Scenario 4
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Multi%20Stage.html">
   Multiple Stages (DTR)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Finite/Q-learning_Multiple.html">
   Q-Learning (Multiple Stages)
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Finite/A-learning_Multiple.html">
   A-Learning (Multiple Stages)
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/docs/Offline/Infinite_OPE/IPW_Infinite.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/executablebooks/jupyter-book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2FOffline/Infinite_OPE/IPW_Infinite.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/Offline/Infinite_OPE/IPW_Infinite.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#main-idea">
   Main Idea
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#breaking-the-curse-of-horizon-with-stationary-distribution">
   Breaking the curse of horizon with stationary distribution
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#demo-todo">
   Demo [TODO]
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#note">
   Note
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Importance Sampling for Policy Evaluation (Infinite Horizon)</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#main-idea">
   Main Idea
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#breaking-the-curse-of-horizon-with-stationary-distribution">
   Breaking the curse of horizon with stationary distribution
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#demo-todo">
   Demo [TODO]
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#note">
   Note
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="importance-sampling-for-policy-evaluation-infinite-horizon">
<h1>Importance Sampling for Policy Evaluation (Infinite Horizon)<a class="headerlink" href="#importance-sampling-for-policy-evaluation-infinite-horizon" title="Permalink to this headline">#</a></h1>
<p>Another important approach is importance sampling (IS), also known as inverse propensity score or inverse propensity weighting methods.
IS has been widely used in statistics, and the idea can be extended to OPE after appropriately handling the temporal dependency.</p>
<p><em><strong>Advantages</strong></em>:</p>
<ol class="simple">
<li><p>Conceptually simple and easy to implement</p></li>
<li><p>Low bias. Specifically, with known propensity scores, the vanilla version is unbiased.</p></li>
</ol>
<p><em><strong>Appropriate application situations</strong></em>:</p>
<p>Due to the large variance and the curse of horizon, IS generally performs well in problems with</p>
<ol class="simple">
<li><p>Short horizon</p></li>
<li><p>Sufficient policy match between the behaviour policy and the target policy.</p></li>
</ol>
<div class="section" id="main-idea">
<h2>Main Idea<a class="headerlink" href="#main-idea" title="Permalink to this headline">#</a></h2>
<p>IS estimates the value by reweighting the observed rewards with importance ratios between the target and behavior policy [1]. For simplicity, we assume the behaviour policy <span class="math notranslate nohighlight">\(b\)</span> is known.</p>
<p>To begin with, for every trajectory index <span class="math notranslate nohighlight">\(i\)</span> and any <span class="math notranslate nohighlight">\(t \in \{0, 1, \dots, T - 1\}\)</span>, we define the <span class="math notranslate nohighlight">\(t\)</span>-step cumulative <strong>importance ratio</strong> between the target policy <span class="math notranslate nohighlight">\(\pi\)</span> and the behaviour policy <span class="math notranslate nohighlight">\(b\)</span> as</p>
<div class="amsmath math notranslate nohighlight">
\[\begin{align*}
    \rho^i_t = \prod_{t'=0}^{t} \frac{\pi(A_{i,t'}|S_{i,t'})}{b(A_{i,t'}|S_{i,t'})}. 
\end{align*}\]</div>
<p>Since the transition and reward generation probabilities are shared  between both policies, this ratio is equal to the probability ratio of observing the <span class="math notranslate nohighlight">\(i\)</span>th trajectory until time point <span class="math notranslate nohighlight">\(t\)</span>.</p>
<p>The standard <strong>(trajectory-wise) IS</strong> estimator [2] regards each trajectory (and the corresponding observed cumulative reward, <span class="math notranslate nohighlight">\(\sum_{t=0}^{T-1} \gamma^t R_{i,t}\)</span>) as one realization, and it estimates <span class="math notranslate nohighlight">\(\eta^{\pi}\)</span> by</p>
<div class="amsmath math notranslate nohighlight" id="equation-15db39ad-c4df-4f6d-92b4-ce346a45827f">
<span class="eqno">(100)<a class="headerlink" href="#equation-15db39ad-c4df-4f6d-92b4-ce346a45827f" title="Permalink to this equation">#</a></span>\[\begin{align}\label{eqn:IS}
    \hat{\eta}^{\pi}_{IS} = \frac{1}{n} \sum_{i=1}^n \rho^i_T (\sum_{t=0}^{T-1} \gamma^t R_{i,t}). 
\end{align}\]</div>
<p>In contrast, the <strong>step-wise IS</strong> [2]  focuses on reweighting each immediate reward <span class="math notranslate nohighlight">\(R_{i,t}\)</span> and typically yields a lower variance than the trajectory-wise IS. It is defined as</p>
<div class="amsmath math notranslate nohighlight" id="equation-740ded7c-7095-4d75-aea1-2b937bd40e90">
<span class="eqno">(101)<a class="headerlink" href="#equation-740ded7c-7095-4d75-aea1-2b937bd40e90" title="Permalink to this equation">#</a></span>\[\begin{align}\label{eqn:stepIS}
    \hat{\eta}^{\pi}_{StepIS} = \frac{1}{n} \sum_{i=1}^n \Big[ \sum_{t=0}^{T-1} \rho^i_t  \gamma^t R_{i,t} \Big]. 
\end{align}\]</div>
<p>In addition to these two IS-type estimators, their <strong>self-normalized variants</strong> are also commonly considered [3].
Specifically, we can define the normalization factor <span class="math notranslate nohighlight">\(\bar{\rho}_t = N^{-1} \sum_{i=1}^N \rho^i_t\)</span>, and replace the <span class="math notranslate nohighlight">\(\rho^i_t\)</span> term by <span class="math notranslate nohighlight">\(\rho^i_t / \bar{\rho}_t\)</span>.
The resulting estimators are biased but consistent, and they generally yield lower variance than their counterparts.
This comparison reflects the bias-variance trade-off.</p>
</div>
<div class="section" id="breaking-the-curse-of-horizon-with-stationary-distribution">
<h2>Breaking the curse of horizon with stationary distribution<a class="headerlink" href="#breaking-the-curse-of-horizon-with-stationary-distribution" title="Permalink to this headline">#</a></h2>
<p>Traditional IS methods (and related DR methods) have exponential variance with the number of steps and hence will soon become unstable when the trajectory is long.  To avoid this issue,  [4] made an important step forward by proposing to utilize the stationary distributions of the Markov process to marginalize the importance ratio. We need to assume the stationarity assumption (SA), that the state process <span class="math notranslate nohighlight">\(\{S_{i,t}\}_{t \ge 0}\)</span> is strictly stationary.</p>
<p>Let <span class="math notranslate nohighlight">\(p_b(s)\)</span> and  <span class="math notranslate nohighlight">\(p_b(s, a)\)</span> denote the stationary density function of the state and the state-action pair under the policy <span class="math notranslate nohighlight">\(b\)</span>, respectively.
The key observation is that, under the stationary assumption and when the data is weakly dependent, we can consider the importance ratios computed on each state-action pair rather than on each  trajectory, and hence break the curse of horizon.
We introduce the average visitation distribution under a policy <span class="math notranslate nohighlight">\(\pi\)</span> as <span class="math notranslate nohighlight">\(d^{\pi}(s)= (1 - \gamma)^{-1} \sum_{t=0}^{+\infty} \gamma^{t} p_t^{\pi}(s)\)</span>, where <span class="math notranslate nohighlight">\(p_t^{\pi}(s)\)</span> denotes the probability of <span class="math notranslate nohighlight">\(\{S_t = s\}\)</span> following policy <span class="math notranslate nohighlight">\(\pi\)</span> with  <span class="math notranslate nohighlight">\(S_{0}\sim \mathbb{G}\)</span>.
Define <span class="math notranslate nohighlight">\(\widetilde{\omega}^{\pi}(s) = d^{\pi}(s) / d^{b}(s)\)</span>.
Therefore, <span class="math notranslate nohighlight">\(\widetilde{\omega}^{\pi}(s)\)</span> can be understood as a marginalized version of the importance ratio. With a similar change-of-measure trick as in IS, we can obtain the relationship that</p>
<div class="amsmath math notranslate nohighlight" id="equation-a73cf67a-30dc-4af4-bc38-20887922ced2">
<span class="eqno">(102)<a class="headerlink" href="#equation-a73cf67a-30dc-4af4-bc38-20887922ced2" title="Permalink to this equation">#</a></span>\[\begin{equation}\label{eqn:breaking}
    \eta^{\pi} =  \mathbb{E}_{(s,a) \sim p_b(s, a), r \sim \mathcal{R}(\cdot; s, a)} \widetilde{\omega}^{\pi}(s) \frac{\pi(a|s)}{b(a|s)} r. 
\end{equation}\]</div>
<p>According to this relationship, we can construct an estimator by replacing the nuisance functions  with their estimates and then approximating the expectation by its empirical mean over <span class="math notranslate nohighlight">\(\{(S_{i,t},A_{i,t},R_{i,t},S_{i,t+1})\}\)</span>.
The nuisance function <span class="math notranslate nohighlight">\(\widetilde{\omega}^{\pi}(s)\)</span> is typically learned by solving an optimization problem, which we will omit to save space.
The optimization is similar to a relevant task that we will discuss in the next section, which is more related with our proposal.</p>
</div>
<div class="section" id="demo-todo">
<h2>Demo [TODO]<a class="headerlink" href="#demo-todo" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># After we publish the pack age, we can directly import it</span>
<span class="c1"># TODO: explore more efficient way</span>
<span class="c1"># we can hide this cell later</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">()</span>
<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="s1">&#39;..&#39;</span><span class="p">)</span>
<span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="s1">&#39;../CausalDM&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="gt">---------------------------------------------------------------------------</span>
<span class="ne">FileNotFoundError</span><span class="g g-Whitespace">                         </span>Traceback (most recent call last)
<span class="o">&lt;</span><span class="n">ipython</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="mi">1</span><span class="o">-</span><span class="n">d7635db18706</span><span class="o">&gt;</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">5</span> <span class="n">os</span><span class="o">.</span><span class="n">getcwd</span><span class="p">()</span>
<span class="g g-Whitespace">      </span><span class="mi">6</span> <span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="s1">&#39;..&#39;</span><span class="p">)</span>
<span class="ne">----&gt; </span><span class="mi">7</span> <span class="n">os</span><span class="o">.</span><span class="n">chdir</span><span class="p">(</span><span class="s1">&#39;../CausalDM&#39;</span><span class="p">)</span>
<span class="g g-Whitespace">      </span><span class="mi">8</span> 

<span class="ne">FileNotFoundError</span>: [WinError 2] The system cannot find the file specified: &#39;../CausalDM&#39;
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">#</a></h2>
<p>[1] Precup D. Eligibility traces for off-policy policy evaluation[J]. Computer Science Department Faculty Publication Series, 2000: 80.</p>
<p>[2] Thomas P S. Safe reinforcement learning[J]. 2015.</p>
<p>[3] Jiang N, Li L. Doubly robust off-policy value evaluation for reinforcement learning[C]//International Conference on Machine Learning. PMLR, 2016: 652-661.</p>
<p>[4] Liu Q, Li L, Tang Z, et al. Breaking the curse of horizon: Infinite-horizon off-policy estimation[J]. Advances in Neural Information Processing Systems, 2018, 31.</p>
</div>
<div class="section" id="note">
<h2>Note<a class="headerlink" href="#note" title="Permalink to this headline">#</a></h2>
<ol class="simple">
<li><p>When the behaviour policy is unknown, we can estimate it from data by regarding the task as a classification problem and using methods such as logistic regression.</p></li>
<li><p>We note that, in principle, IS-based methods (and doubly robust methods to be reviewed in the next section) only apply to the finite-horizon setting, where the  trajectory is truncated at a finite time step <span class="math notranslate nohighlight">\(T\)</span>.
The estimand is
<span class="math notranslate nohighlight">\(\mathbb{E}^{\pi}_{s \sim \mathbb{G}} (\sum_{t=0}^{T-1} \gamma^t R_{t}|S_{0}=s)\)</span> instead of
<span class="math notranslate nohighlight">\(\mathbb{E}^{\pi}_{s \sim \mathbb{G}} (\sum_{t=0}^{+\infty} \gamma^t R_{t}|S_{0}=s)\)</span>.
However, when <span class="math notranslate nohighlight">\(T\)</span> is relatively large and <span class="math notranslate nohighlight">\(\gamma\)</span> is not quite close to <span class="math notranslate nohighlight">\(1\)</span>, the difference between <span class="math notranslate nohighlight">\(\sum_{t=0}^{T-1} \gamma^t\)</span> and <span class="math notranslate nohighlight">\(\sum_{t=0}^{\infty} \gamma^t\)</span> is negligible and is usually ignored, and they are still commonly used as baselines.</p></li>
<li><p>We note that (SA) is not a strong assumption. Recall that <span class="math notranslate nohighlight">\(\{S_{i,t}\}_{t \ge 0}\)</span> is generated by following the stationary policy <span class="math notranslate nohighlight">\(b\)</span>. (SA) is automatically  satisfied when the initial distribution equals the stationary distribution. Besides, When the MDP is a Harris ergodic chain , the process will eventually mix well and we can replace the stationary distribution with its limiting assumption and the following discussions will continue to hold.</p></li>
</ol>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./Offline\Infinite_OPE"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="FQE.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Fitted-Q Evaluation</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="DR_Infinite.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Doubly Robust Estimator for Policy Evaluation (Infinite Horizon)</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Causal Decision Making Team<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>