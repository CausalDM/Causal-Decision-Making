Search.setIndex({"docnames": ["0_Learner Template", "0_Motivating_Examples/CEL", "0_Motivating_Examples/CPL", "0_Motivating_Examples/CSL", "1_Preliminary/(old) Causal Inference 101", "1_Preliminary/Causal Inference 101_old", "1_Preliminary/Causal Inference Preliminary", "1_Preliminary/Policy Evaluation and Optimization", "1_Preliminary/Preliminary", "2_Causal_Structure_Learning/Causal Discovery", "2_Causal_Structure_Learning/Causal Mediation Analysis", "2_Causal_Structure_Learning/Functional-based Learner", "2_Causal_Structure_Learning/Preliminaries of Causal Graphs", "2_Causal_Structure_Learning/Score-based Learner", "2_Causal_Structure_Learning/Testing-based Learner", "3_Causal_Effect_Learning/Scenario 1/ATE", "3_Causal_Effect_Learning/Scenario 1/DR-Learner", "3_Causal_Effect_Learning/Scenario 1/Dragonnet", "3_Causal_Effect_Learning/Scenario 1/GRF", "3_Causal_Effect_Learning/Scenario 1/HTE", "3_Causal_Effect_Learning/Scenario 1/Lp-R-Learner", "3_Causal_Effect_Learning/Scenario 1/Meta Learners", "3_Causal_Effect_Learning/Scenario 1/Other Approaches", "3_Causal_Effect_Learning/Scenario 1/R-Learner", "3_Causal_Effect_Learning/Scenario 1/R-Learner, DR-Learner, Lp-R-Learner", "3_Causal_Effect_Learning/Scenario 1/S-learner", "3_Causal_Effect_Learning/Scenario 1/Single Stage", "3_Causal_Effect_Learning/Scenario 1/T-learner", "3_Causal_Effect_Learning/Scenario 1/X-learner", "3_Causal_Effect_Learning/Scenario 2/ATE", "3_Causal_Effect_Learning/Scenario 2/HTE", "3_Causal_Effect_Learning/Scenario 2/underMDP", "3_Causal_Effect_Learning/Scenario 3/ATE", "3_Causal_Effect_Learning/Scenario 3/DiD", "3_Causal_Effect_Learning/Scenario 3/H1SL_H2SL", "3_Causal_Effect_Learning/Scenario 3/HTE", "3_Causal_Effect_Learning/Scenario 3/Panel Data", "3_Causal_Effect_Learning/Scenario 3/R-DiD", "3_Causal_Effect_Learning/Scenario 3/Synthetic Control", "3_Causal_Effect_Learning/Scenario 3/Synthetic DiD", "3_Causal_Effect_Learning/Scenario 3/Synthetic Learner", "3_Causal_Effect_Learning/Scenario 3/Synthetic X-Learner", "3_Causal_Effect_Learning/Scenario 4/Miscellaneous", "4_Causal_Policy_Learning/Scenario1/A-learning_Single", "4_Causal_Policy_Learning/Scenario1/Classification", "4_Causal_Policy_Learning/Scenario1/Classification/E-learning", "4_Causal_Policy_Learning/Scenario1/Classification/O-Learning", "4_Causal_Policy_Learning/Scenario1/Continuous", "4_Causal_Policy_Learning/Scenario1/Continuous/Deep Jump Learner", "4_Causal_Policy_Learning/Scenario1/Continuous/Kernel-Based Learner", "4_Causal_Policy_Learning/Scenario1/Continuous/Outcome Learning", "4_Causal_Policy_Learning/Scenario1/Discrete", "4_Causal_Policy_Learning/Scenario1/Micellaneous/Adaptively Collected Data", "4_Causal_Policy_Learning/Scenario1/Micellaneous/Concordance", "4_Causal_Policy_Learning/Scenario1/Micellaneous/Policy Search", "4_Causal_Policy_Learning/Scenario1/Micellaneous/Survival", "4_Causal_Policy_Learning/Scenario1/PlanToDo", "4_Causal_Policy_Learning/Scenario1/Q-learning_Single", "4_Causal_Policy_Learning/Scenario1/Quantile/QuantileOTR_test", "4_Causal_Policy_Learning/Scenario1/Single Stage", "4_Causal_Policy_Learning/Scenario1/Test/A_Q test", "4_Causal_Policy_Learning/Scenario2/DR_Infinite", "4_Causal_Policy_Learning/Scenario2/Deeply_Debiased", "4_Causal_Policy_Learning/Scenario2/Evaluation", "4_Causal_Policy_Learning/Scenario2/FQE", "4_Causal_Policy_Learning/Scenario2/FQI", "4_Causal_Policy_Learning/Scenario2/IPW_Infinite", "4_Causal_Policy_Learning/Scenario2/Inference", "4_Causal_Policy_Learning/Scenario2/Model_based_Infinite", "4_Causal_Policy_Learning/Scenario2/Optimization", "4_Causal_Policy_Learning/Scenario2/Spatial_temporal_DR", "4_Causal_Policy_Learning/Scenario2/archive/archive_preliminary_MDP", "4_Causal_Policy_Learning/Scenario2/preliminary_MDP-potential-outcome", "4_Causal_Policy_Learning/Scenario3/A-learning_Multiple", "4_Causal_Policy_Learning/Scenario3/MediatedQ-learning_Multiple", "4_Causal_Policy_Learning/Scenario3/Multi Stage", "4_Causal_Policy_Learning/Scenario3/Q-learning_Multiple", "4_Causal_Policy_Learning/Scenario4/Bandits", "4_Causal_Policy_Learning/Scenario4/Contextual_Bandits/Contextual_Bandits", "4_Causal_Policy_Learning/Scenario4/Contextual_Bandits/LinTS", "4_Causal_Policy_Learning/Scenario4/Contextual_Bandits/LinUCB", "4_Causal_Policy_Learning/Scenario4/MAB/Epsilon_Greedy", "4_Causal_Policy_Learning/Scenario4/MAB/MAB", "4_Causal_Policy_Learning/Scenario4/MAB/TS", "4_Causal_Policy_Learning/Scenario4/MAB/UCB", "4_Causal_Policy_Learning/Scenario4/Meta_Bandits/MTTS", "4_Causal_Policy_Learning/Scenario4/Meta_Bandits/Meta_Bandits", "4_Causal_Policy_Learning/Scenario4/Meta_Bandits/Meta_TS", "4_Causal_Policy_Learning/Scenario4/OnlineEval/Direct Online Policy Evaluator", "4_Causal_Policy_Learning/Scenario4/OnlineEval/Doubly Robust Online Policy Evaluator", "4_Causal_Policy_Learning/Scenario4/OnlineEval/Inverse Probability Weighted Online Policy Evaluator", "4_Causal_Policy_Learning/Scenario4/OnlineEval/Online Policy Evaluation", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/CascadeLinTS", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/Learning to rank", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/MTSS_Cascade", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/TS_Cascade", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/CombLinTS", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/CombTS", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/Combinatorial Optimization", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/MTSS_Comb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/Assortment Optimization", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/MTSS_MNL", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/TS_Contextual_MNL", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/TS_MNL_Beta", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/UCB-MNL", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Structured_Bandit", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single-Item Recommendation", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/Epsilon Greedy", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/LinTS", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/LinUCB", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/Multi-Task", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/MultiTask/MTTS", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/MultiTask/Meta-TS", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/TS", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/UCB1", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Slate Recommendation", "4_Causal_Policy_Learning/Scenario5/OnlineRL_Markov", "4_Causal_Policy_Learning/Scenario6/OnlineRL_non_Markov", "5_Case_Study/MIMIC3/Case_Study_1", "5_Case_Study/MIMIC3/MIMIC3-Demo", "5_Case_Study/MIMIC3/MIMIC3_DTR", "5_Case_Study/MIMIC3/MIMIC3_MediationAnalysis", "5_Case_Study/MovieLens/Case_Study_2", "Overview", "README", "_old files(to delete)/Map"], "filenames": ["0_Learner Template.ipynb", "0_Motivating_Examples/CEL.ipynb", "0_Motivating_Examples/CPL.ipynb", "0_Motivating_Examples/CSL.ipynb", "1_Preliminary/(old) Causal Inference 101.ipynb", "1_Preliminary/Causal Inference 101_old.md", "1_Preliminary/Causal Inference Preliminary.ipynb", "1_Preliminary/Policy Evaluation and Optimization.md", "1_Preliminary/Preliminary.md", "2_Causal_Structure_Learning/Causal Discovery.ipynb", "2_Causal_Structure_Learning/Causal Mediation Analysis.ipynb", "2_Causal_Structure_Learning/Functional-based Learner.ipynb", "2_Causal_Structure_Learning/Preliminaries of Causal Graphs.ipynb", "2_Causal_Structure_Learning/Score-based Learner.ipynb", "2_Causal_Structure_Learning/Testing-based Learner.ipynb", "3_Causal_Effect_Learning/Scenario 1/ATE.ipynb", "3_Causal_Effect_Learning/Scenario 1/DR-Learner.ipynb", "3_Causal_Effect_Learning/Scenario 1/Dragonnet.ipynb", "3_Causal_Effect_Learning/Scenario 1/GRF.ipynb", "3_Causal_Effect_Learning/Scenario 1/HTE.ipynb", "3_Causal_Effect_Learning/Scenario 1/Lp-R-Learner.ipynb", "3_Causal_Effect_Learning/Scenario 1/Meta Learners.ipynb", "3_Causal_Effect_Learning/Scenario 1/Other Approaches.ipynb", "3_Causal_Effect_Learning/Scenario 1/R-Learner.ipynb", "3_Causal_Effect_Learning/Scenario 1/R-Learner, DR-Learner, Lp-R-Learner.ipynb", "3_Causal_Effect_Learning/Scenario 1/S-learner.ipynb", "3_Causal_Effect_Learning/Scenario 1/Single Stage.ipynb", "3_Causal_Effect_Learning/Scenario 1/T-learner.ipynb", "3_Causal_Effect_Learning/Scenario 1/X-learner.ipynb", "3_Causal_Effect_Learning/Scenario 2/ATE.md", "3_Causal_Effect_Learning/Scenario 2/HTE.md", "3_Causal_Effect_Learning/Scenario 2/underMDP.md", "3_Causal_Effect_Learning/Scenario 3/ATE.md", "3_Causal_Effect_Learning/Scenario 3/DiD.ipynb", "3_Causal_Effect_Learning/Scenario 3/H1SL_H2SL.ipynb", "3_Causal_Effect_Learning/Scenario 3/HTE.md", "3_Causal_Effect_Learning/Scenario 3/Panel Data.md", "3_Causal_Effect_Learning/Scenario 3/R-DiD.ipynb", "3_Causal_Effect_Learning/Scenario 3/Synthetic Control.ipynb", "3_Causal_Effect_Learning/Scenario 3/Synthetic DiD.ipynb", "3_Causal_Effect_Learning/Scenario 3/Synthetic Learner.ipynb", "3_Causal_Effect_Learning/Scenario 3/Synthetic X-Learner.ipynb", "3_Causal_Effect_Learning/Scenario 4/Miscellaneous.md", "4_Causal_Policy_Learning/Scenario1/A-learning_Single.ipynb", "4_Causal_Policy_Learning/Scenario1/Classification.md", "4_Causal_Policy_Learning/Scenario1/Classification/E-learning.ipynb", "4_Causal_Policy_Learning/Scenario1/Classification/O-Learning.ipynb", "4_Causal_Policy_Learning/Scenario1/Continuous.md", "4_Causal_Policy_Learning/Scenario1/Continuous/Deep Jump Learner.ipynb", "4_Causal_Policy_Learning/Scenario1/Continuous/Kernel-Based Learner.md", "4_Causal_Policy_Learning/Scenario1/Continuous/Outcome Learning.md", "4_Causal_Policy_Learning/Scenario1/Discrete.md", "4_Causal_Policy_Learning/Scenario1/Micellaneous/Adaptively Collected Data.ipynb", "4_Causal_Policy_Learning/Scenario1/Micellaneous/Concordance.ipynb", "4_Causal_Policy_Learning/Scenario1/Micellaneous/Policy Search.ipynb", "4_Causal_Policy_Learning/Scenario1/Micellaneous/Survival.ipynb", "4_Causal_Policy_Learning/Scenario1/PlanToDo.md", "4_Causal_Policy_Learning/Scenario1/Q-learning_Single.ipynb", "4_Causal_Policy_Learning/Scenario1/Quantile/QuantileOTR_test.ipynb", "4_Causal_Policy_Learning/Scenario1/Single Stage.md", "4_Causal_Policy_Learning/Scenario1/Test/A_Q test.ipynb", "4_Causal_Policy_Learning/Scenario2/DR_Infinite.ipynb", "4_Causal_Policy_Learning/Scenario2/Deeply_Debiased.ipynb", "4_Causal_Policy_Learning/Scenario2/Evaluation.md", "4_Causal_Policy_Learning/Scenario2/FQE.ipynb", "4_Causal_Policy_Learning/Scenario2/FQI.ipynb", "4_Causal_Policy_Learning/Scenario2/IPW_Infinite.ipynb", "4_Causal_Policy_Learning/Scenario2/Inference.ipynb", "4_Causal_Policy_Learning/Scenario2/Model_based_Infinite.ipynb", "4_Causal_Policy_Learning/Scenario2/Optimization.md", "4_Causal_Policy_Learning/Scenario2/Spatial_temporal_DR.ipynb", "4_Causal_Policy_Learning/Scenario2/archive/archive_preliminary_MDP.ipynb", "4_Causal_Policy_Learning/Scenario2/preliminary_MDP-potential-outcome.ipynb", "4_Causal_Policy_Learning/Scenario3/A-learning_Multiple.ipynb", "4_Causal_Policy_Learning/Scenario3/MediatedQ-learning_Multiple.ipynb", "4_Causal_Policy_Learning/Scenario3/Multi Stage.md", "4_Causal_Policy_Learning/Scenario3/Q-learning_Multiple.ipynb", "4_Causal_Policy_Learning/Scenario4/Bandits.md", "4_Causal_Policy_Learning/Scenario4/Contextual_Bandits/Contextual_Bandits.ipynb", "4_Causal_Policy_Learning/Scenario4/Contextual_Bandits/LinTS.ipynb", "4_Causal_Policy_Learning/Scenario4/Contextual_Bandits/LinUCB.ipynb", "4_Causal_Policy_Learning/Scenario4/MAB/Epsilon_Greedy.ipynb", "4_Causal_Policy_Learning/Scenario4/MAB/MAB.ipynb", "4_Causal_Policy_Learning/Scenario4/MAB/TS.ipynb", "4_Causal_Policy_Learning/Scenario4/MAB/UCB.ipynb", "4_Causal_Policy_Learning/Scenario4/Meta_Bandits/MTTS.ipynb", "4_Causal_Policy_Learning/Scenario4/Meta_Bandits/Meta_Bandits.ipynb", "4_Causal_Policy_Learning/Scenario4/Meta_Bandits/Meta_TS.ipynb", "4_Causal_Policy_Learning/Scenario4/OnlineEval/Direct Online Policy Evaluator.ipynb", "4_Causal_Policy_Learning/Scenario4/OnlineEval/Doubly Robust Online Policy Evaluator.ipynb", "4_Causal_Policy_Learning/Scenario4/OnlineEval/Inverse Probability Weighted Online Policy Evaluator.ipynb", "4_Causal_Policy_Learning/Scenario4/OnlineEval/Online Policy Evaluation.md", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/CascadeLinTS.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/Learning to rank.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/MTSS_Cascade.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/TS_Cascade.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/CombLinTS.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/CombTS.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/Combinatorial Optimization.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/MTSS_Comb.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/Assortment Optimization.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/MTSS_MNL.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/TS_Contextual_MNL.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/TS_MNL_Beta.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/UCB-MNL.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Structured_Bandit.ipynb", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single-Item Recommendation.ipynb", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/Epsilon Greedy.ipynb", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/LinTS.ipynb", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/LinUCB.md", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/Multi-Task.md", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/MultiTask/MTTS.md", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/MultiTask/Meta-TS.md", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/TS.ipynb", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/UCB1.ipynb", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Slate Recommendation.ipynb", "4_Causal_Policy_Learning/Scenario5/OnlineRL_Markov.ipynb", "4_Causal_Policy_Learning/Scenario6/OnlineRL_non_Markov.ipynb", "5_Case_Study/MIMIC3/Case_Study_1.md", "5_Case_Study/MIMIC3/MIMIC3-Demo.ipynb", "5_Case_Study/MIMIC3/MIMIC3_DTR.ipynb", "5_Case_Study/MIMIC3/MIMIC3_MediationAnalysis.ipynb", "5_Case_Study/MovieLens/Case_Study_2.md", "Overview.md", "README.md", "_old files(to delete)/Map.md"], "titles": ["Learner Name (Single/Multiple Stages/Infinite Horizon)", "<em>Causal Effect Learning (CEL)</em>", "<em>Causal Policy Learning (CPL)</em>", "<em>Causal Structure Learning (CSL)</em>", "Causal Inference 101", "Causal Inference 101", "Causal Inference Preliminary", "Policy Evaluation and Optimization", "Preliminary", "Causal Discovery", "Causal Mediation Analysis", "Functional-based Learner", "Preliminaries of Causal Graphs", "Score-based Learner", "Testing-based Learner", "ATE Estimation", "<strong>5. DR-learner</strong>", "<strong>8. Dragon Net</strong>", "<strong>7. Generalized Random Forest</strong>", "HTE Estimation", "<strong>6. Lp-R-learner</strong>", "<strong>Meta Learners</strong>", "<strong>Other Approaches</strong>", "<strong>4. R learner</strong>", "<strong>R-Learner, DR-Learner, and Lp-R-Learner</strong>", "<strong>1. S-learner</strong>", "<strong>Single Stage</strong>", "<strong>2. T-learner</strong>", "<strong>3. X-learner</strong>", "ATE", "HTE", "Markov Decision Processes", "ATE", "<strong>Difference in Difference</strong>", "<strong>H1SL and H2SL</strong>", "HTE", "Panel Data", "<strong>R-DiD</strong>", "<strong>Synthetic Control</strong>", "<strong>Synthetic DiD</strong>", "<strong>Synthetic Learner</strong>", "<strong>Synthetic X-Learner</strong>", "Miscellaneous", "A-Learning (Single Stage)", "Reduction to Classification Problems", "Entropy learning", "Outcome Weighted Learning", "Continuous Action Space", "Deep Jump Learner for Continuous Actions", "Kernel-Based Learner", "Outcome Learning", "Discrete Action Space", "Adaptively Collected Data", "Concordance-assisted learning", "Policy Search", "Time-to-Event Data", "Plan To Do", "Q-Learning (Single Stage)", "<strong>Quantile Optimal Treatment Regime</strong>", "Single Stage", "Test A-Learning Single", "Doubly Robust Estimator for Policy Evaluation (Infinite Horizon)", "Deeply-Debiased Off-Policy Evaluation", "Policy Evaluation", "Fitted-Q Evaluation", "Fitted-Q Iteration", "Importance Sampling for Policy Evaluation (Infinite Horizon)", "Confidence Interval in OPE", "Q-Learning (Infinite Horizon)", "Policy Optimization", "Infinite Horizon Importance Sampling for Policy Evaluation", "Preliminary: Off-policy Evaluation and Optimization in Markov Decision Processes", "Preliminary: Off-policy Evaluation and Optimization in Markov Decision Processes", "A-Learning (Multiple Stages)", "MediatedQ-Learning (Multiple Stages)", "Multiple Stages (DTR)", "Q-Learning (Multiple Stages)", "Overview: Bandits ALgorithm", "Contextual Bandits", "LinTS", "LinUCB", "<span class=\"math notranslate nohighlight\">\\(\\epsilon\\)</span>-Greedy", "Multi-Armed Bandits (MAB)", "TS", "UCB", "Multi-Task Thompson Sampling (MTTS)", "Meta Bandits", "Meta Thompson Sampling", "Direct Online Policy Evaluator", "Doubly Robust Online Policy Evaluator", "Inverse Probability Weighted Online Policy Evaluator", "Online Policy Evaluation", "CascadeLinTS", "Online Learning to Rank (Cascading Bandit)", "MTSS_Cascade", "TS_Cascade", "CombLinTS", "CombTS", "Online Combinatorial Optimization (Combinatorial Semi-Bandit)", "MTSS_Comb", "Dynamic Assortment Optimization (Multinomial Logit Bandit)", "MTSS_MNL", "TS_Contextual_MNL", "TS_MNL", "UCB_MNL", "Structured Bandit (Slate Recommendation)", "Single-Item Recommendation", "Epsilon_Greedy", "LinTS", "LinUCB", "Multi-Task", "MTTS", "Meta-TS", "TS", "UCB1", "Slate Recommendation", "Ooline Policy Learning and Evaluation in Markovian Environments", "Ooline Policy Learning in Non-Markovian Environments", "MIMIC III", "Mimic3 Demo", "CPL: 3-Stage DTR", "Multi-Stage Mediation Analysis", "MovieLens", "Overview", "Content of every notebook", "&lt;no title&gt;"], "terms": {"an": [0, 1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 26, 27, 28, 43, 46, 48, 57, 58, 59, 62, 64, 65, 66, 67, 70, 71, 72, 73, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 113, 114, 115, 116, 117, 120, 121, 123, 124], "overview": [0, 10, 11, 12, 14], "includ": [0, 2, 5, 9, 26, 57, 59, 72, 73, 75, 76, 77, 78, 82, 83, 86, 88, 89, 90, 92, 94, 96, 97, 98, 99, 101, 102, 103, 105, 106, 107, 108, 113, 114, 115, 116, 119, 120, 121, 123], "brief": [0, 117, 123], "introduct": [0, 5, 28, 71, 72, 78, 81, 82, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104, 106, 107, 116, 117], "evolut": 0, "i": [0, 1, 2, 4, 6, 9, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 24, 25, 26, 43, 48, 57, 58, 59, 61, 62, 64, 65, 66, 67, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 113, 114, 115, 116, 117, 120], "e": [0, 1, 2, 4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 43, 46, 48, 57, 58, 59, 61, 62, 64, 65, 66, 70, 71, 72, 73, 76, 77, 78, 79, 80, 81, 83, 85, 86, 87, 88, 89, 90, 92, 94, 95, 96, 97, 99, 100, 101, 102, 103, 106, 108, 113, 114, 116, 117, 123], "when": [0, 2, 4, 5, 6, 10, 12, 13, 14, 15, 17, 19, 21, 26, 27, 48, 58, 61, 62, 64, 66, 70, 71, 72, 79, 83, 85, 87, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 106, 108, 113, 115, 117, 119, 121, 123], "first": [0, 5, 9, 10, 14, 15, 17, 18, 19, 20, 21, 22, 24, 25, 46, 57, 58, 61, 62, 64, 70, 78, 84, 85, 89, 90, 92, 94, 95, 103, 114, 116, 120, 121, 123, 124], "develop": [0, 1, 2, 9, 14, 18, 22, 46, 48, 86, 97, 102, 103], "ani": [0, 4, 5, 6, 9, 11, 13, 15, 19, 21, 22, 25, 27, 28, 48, 58, 61, 62, 66, 70, 71, 72, 73, 75, 76, 77, 78, 84, 86, 92, 93, 94, 95, 105, 115, 116, 117, 120, 121, 123], "altern": [0, 15, 43, 73, 100, 116], "extens": [0, 5, 19, 20, 24, 43, 57, 61, 62, 70, 73, 76, 78, 82, 106, 116, 117, 123], "applic": [0, 1, 2, 3, 9, 10, 12, 20, 46, 48, 61, 64, 66, 71, 72, 74, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 106, 115, 121], "situat": [0, 11, 13, 14, 48, 61, 64, 66, 78, 79, 80, 81, 83, 84, 85, 87, 88, 89, 90, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104], "describ": [0, 6, 26, 105, 119, 124], "data": [0, 2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 19, 21, 22, 24, 43, 46, 48, 57, 60, 61, 62, 66, 70, 71, 72, 73, 76, 79, 80, 81, 83, 84, 85, 87, 88, 89, 90, 104, 116, 119, 120, 121], "structur": [0, 2, 5, 10, 12, 15, 17, 19, 43, 46, 57, 62, 73, 75, 76, 77, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 116, 121], "can": [0, 1, 2, 4, 5, 6, 9, 10, 11, 13, 15, 17, 18, 19, 20, 21, 22, 24, 25, 27, 28, 43, 46, 48, 57, 58, 59, 61, 62, 64, 65, 66, 67, 68, 70, 72, 73, 76, 77, 79, 81, 83, 85, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 113, 114, 115, 116, 119, 121, 123, 124], "analyz": [0, 120, 121], "make": [0, 4, 5, 6, 9, 15, 17, 48, 57, 58, 76, 77, 78, 81, 88, 89, 90, 116, 117, 123, 124], "connect": [0, 12, 72, 116], "between": [0, 1, 2, 4, 6, 14, 15, 19, 21, 28, 43, 48, 57, 60, 66, 70, 72, 73, 80, 83, 85, 89, 90, 94, 95, 101, 102, 103, 106, 123], "real": [0, 2, 3, 9, 12, 17, 18, 19, 20, 22, 24, 43, 48, 57, 73, 76, 77, 88, 89, 90, 92, 97, 104], "mention": [0, 70, 123], "motiv": [0, 2, 4, 15, 57, 61, 62, 64, 65, 70, 71, 76, 78, 82, 86, 92, 93, 98, 100, 116, 119], "exampl": [0, 1, 2, 4, 5, 6, 9, 14, 17, 18, 19, 21, 22, 43, 57, 58, 61, 62, 70, 73, 76, 77, 78, 79, 81, 82, 83, 84, 86, 93, 94, 98, 99, 100, 101, 108, 113, 116, 120, 123], "we": [0, 1, 2, 3, 4, 6, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 43, 46, 48, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 113, 114, 115, 116, 117, 119, 120, 121, 123, 124], "us": [0, 1, 2, 4, 6, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 43, 48, 57, 58, 59, 60, 62, 65, 66, 70, 71, 72, 73, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 99, 101, 102, 103, 104, 105, 106, 107, 108, 113, 114, 115, 116, 117, 119, 120, 121, 123, 124], "advantag": [0, 11, 13, 14, 43, 48, 58, 61, 62, 64, 66, 67, 73, 79, 80, 81, 83, 84, 85, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 106, 123, 124], "descript": [0, 93, 98, 100, 115], "clear": 0, "definit": [0, 10, 26, 43, 58, 62, 64, 71, 72, 73, 93, 119], "concept": [0, 19, 72, 93], "abstract": 0, "pseudo": [0, 16, 24, 58, 73, 76, 124], "In": [0, 1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 43, 46, 48, 57, 58, 61, 62, 66, 67, 70, 71, 72, 73, 76, 77, 78, 79, 80, 82, 83, 86, 87, 88, 89, 90, 92, 93, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 108, 113, 115, 116, 117, 119, 120, 121, 123], "follow": [0, 2, 3, 4, 5, 9, 10, 11, 13, 14, 15, 17, 19, 21, 23, 24, 26, 43, 46, 48, 57, 58, 59, 61, 62, 64, 65, 66, 67, 70, 71, 72, 73, 76, 77, 78, 82, 88, 89, 90, 94, 95, 99, 101, 104, 105, 106, 115, 116, 119, 120, 121, 123], "exhibit": [0, 43, 48, 57, 73, 76, 88, 89, 90, 104], "how": [0, 1, 2, 3, 9, 10, 12, 17, 21, 26, 43, 46, 48, 57, 58, 59, 60, 61, 70, 73, 76, 77, 78, 86, 88, 89, 90, 104, 105, 115, 116], "appli": [0, 10, 11, 16, 17, 19, 20, 24, 43, 48, 57, 58, 61, 62, 66, 70, 73, 76, 82, 85, 87, 88, 89, 90, 104, 106, 116, 117, 120, 123], "do": [0, 5, 10, 12, 15, 23, 24, 43, 46, 48, 57, 58, 73, 76, 80, 84, 95, 97, 103, 114, 116, 120, 123], "respect": [0, 4, 6, 9, 13, 43, 48, 57, 58, 61, 64, 66, 70, 71, 72, 73, 76, 88, 89, 90, 116], "import": [0, 1, 2, 3, 10, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 43, 46, 48, 57, 58, 59, 60, 61, 62, 64, 65, 67, 68, 72, 73, 76, 104, 107, 108, 113, 114, 117, 119, 120, 121], "from": [0, 1, 2, 3, 4, 6, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 43, 46, 48, 57, 58, 59, 60, 61, 62, 66, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 106, 107, 108, 113, 114, 115, 116, 117, 119, 120, 121, 123], "causaldm": [0, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 43, 46, 57, 59, 60, 61, 62, 64, 65, 66, 67, 68, 70, 73, 76, 79, 80, 81, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104, 107, 108, 113, 114, 120, 121, 124], "alearn": [0, 43, 60, 73], "test": [0, 1, 9, 10, 11, 12, 13, 16, 20, 23, 24, 26, 43, 46, 57, 73, 76, 119, 123], "shared_simul": [0, 46, 60, 73, 76], "numpi": [0, 10, 11, 13, 14, 16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 43, 46, 58, 60, 73, 76, 79, 80, 81, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104, 107, 108, 113, 114, 119, 121], "np": [0, 10, 11, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 43, 46, 48, 58, 60, 73, 76, 79, 80, 81, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104, 107, 108, 113, 114, 119, 121], "find": [0, 2, 4, 6, 9, 14, 15, 26, 43, 48, 57, 58, 73, 76, 77, 78, 82, 83, 86, 88, 89, 90, 93, 96, 97, 98, 99, 100, 105, 106, 108, 113, 116, 120, 121, 124], "optim": [0, 2, 5, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 24, 43, 46, 48, 57, 60, 61, 62, 64, 65, 66, 70, 73, 76, 77, 78, 82, 83, 86, 88, 89, 90, 93, 94, 96, 97, 99, 101, 103, 104, 105, 106, 107, 108, 113, 114, 115, 117, 123, 124], "regim": [0, 2, 15, 19, 43, 48, 57, 60, 73, 76, 107, 108, 113, 114, 120, 121, 123], "appropri": [0, 11, 17, 58, 61, 64, 66, 70, 85, 94, 97, 101, 120, 121, 124], "interpret": [0, 3, 10, 13, 43, 48, 57, 79, 80, 81, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103, 107, 108, 113, 114], "A": [0, 1, 2, 3, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 46, 48, 57, 58, 59, 61, 62, 70, 71, 72, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 113, 114, 115, 116, 119, 120, 121], "sentenc": [0, 107, 108, 113, 114], "analysi": [0, 3, 9, 11, 13, 14, 26, 48, 74, 81, 84, 94, 100, 105, 106, 107, 108, 113, 114, 115, 119, 123], "result": [0, 2, 4, 5, 10, 15, 17, 18, 19, 20, 21, 22, 24, 26, 27, 28, 43, 48, 57, 60, 61, 62, 64, 66, 70, 73, 76, 92, 94, 95, 98, 107, 108, 113, 114, 119, 121, 123], "estim": [0, 1, 2, 5, 6, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 43, 46, 48, 57, 58, 60, 62, 64, 65, 66, 67, 70, 71, 72, 73, 76, 80, 81, 84, 88, 89, 90, 94, 95, 97, 104, 106, 107, 108, 113, 114, 116, 117, 119, 120, 121, 123], "fix": [0, 20, 43, 57, 58, 64, 65, 73, 76, 78, 81, 88, 89, 90, 107, 116, 117, 120, 121], "valu": [0, 2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 20, 21, 22, 23, 24, 26, 43, 46, 48, 57, 58, 59, 60, 61, 62, 64, 65, 66, 70, 72, 73, 76, 78, 81, 82, 86, 88, 89, 90, 93, 106, 107, 119, 120, 121], "subfield": 1, "infer": [1, 2, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 24, 25, 26, 57, 58, 62, 72, 74, 88, 89, 90, 100, 103, 116, 117, 121, 123], "aim": [1, 2, 6, 11, 13, 14, 15, 17, 18, 19, 21, 22, 27, 43, 57, 59, 64, 65, 72, 73, 76, 78, 82, 86, 93, 98, 100, 105, 115, 116, 123], "identifi": [1, 3, 9, 10, 11, 13, 14, 15, 17, 18, 21, 22, 25], "conduct": [1, 26, 58, 121], "statist": [1, 2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 16, 18, 19, 20, 22, 24, 33, 34, 37, 38, 39, 40, 41, 43, 46, 48, 58, 61, 62, 66, 67, 70, 73, 78, 79, 80, 86, 88, 89, 90, 92, 93, 95, 97, 106, 108, 116, 117, 121, 123], "specif": [1, 2, 3, 4, 5, 6, 10, 15, 17, 18, 19, 21, 22, 25, 26, 43, 57, 58, 61, 62, 65, 66, 67, 70, 71, 72, 76, 77, 79, 81, 83, 85, 86, 87, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 106, 107, 108, 113, 115, 121, 123], "intervent": [1, 2, 4, 6, 10, 12, 15, 26], "system": [1, 5, 9, 10, 11, 12, 13, 14, 17, 19, 48, 66, 70, 71, 77, 78, 82, 85, 86, 87, 93, 94, 97, 99, 100, 101, 102, 105, 106, 117], "It": [1, 2, 4, 5, 19, 24, 64, 65, 66, 70, 72, 79, 80, 81, 83, 84, 85, 92, 94, 95, 96, 97, 98, 99, 101, 102, 106, 108, 113, 116, 117], "tri": [1, 24], "answer": [1, 2, 17], "question": [1, 2, 17, 61, 70], "what": [1, 2, 73, 76, 77, 100], "have": [1, 2, 3, 4, 6, 10, 12, 15, 17, 26, 46, 58, 59, 61, 66, 70, 71, 72, 75, 77, 78, 85, 86, 87, 92, 102, 105, 106, 115, 116, 119, 123, 124], "done": [1, 116], "someth": [1, 60], "differ": [1, 2, 3, 4, 5, 6, 12, 15, 21, 27, 43, 57, 58, 59, 60, 66, 70, 71, 72, 73, 76, 78, 79, 82, 83, 85, 86, 87, 89, 90, 94, 95, 97, 98, 99, 101, 102, 105, 106, 108, 113, 116, 117, 123], "s": [1, 2, 3, 5, 6, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 26, 27, 28, 43, 57, 59, 61, 62, 64, 65, 66, 70, 71, 72, 73, 75, 76, 78, 79, 80, 81, 85, 86, 87, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 116, 120, 123], "consequ": [1, 4, 15, 48, 61, 70], "excecut": 1, "polici": [1, 5, 15, 19, 21, 22, 24, 46, 60, 64, 65, 67, 78, 81, 121, 124], "quantifi": [1, 2, 3, 10, 84, 89, 90, 93, 119], "etc": [1, 2, 17, 19, 43, 57, 78, 98, 105, 115], "suppos": [1, 9, 10, 11, 12, 13, 14, 19, 43, 59, 73, 75, 78, 79, 80, 81, 82, 83, 84, 93, 98, 100, 107, 108, 113, 114, 116], "you": [1, 5, 10, 43, 46, 57, 58, 76, 95, 120, 124], "ar": [1, 2, 3, 4, 6, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 24, 25, 27, 28, 43, 46, 57, 58, 59, 61, 62, 64, 66, 70, 71, 72, 73, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 105, 106, 107, 108, 113, 114, 115, 116, 119, 120, 121, 123, 124], "medic": [1, 15], "research": [1, 2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 61, 65, 70, 97, 100, 103, 104, 123], "who": [1, 2, 4, 6, 15, 26, 59, 79, 80, 85, 86, 119], "just": [1, 18, 20, 21, 22, 24, 27, 116], "fictiti": 1, "hopefulli": 1, "allevi": 1, "patient": [1, 2, 26, 48, 58, 86, 119, 120], "symptom": 1, "hypertens": 1, "sinc": [1, 4, 10, 15, 59, 62, 66, 77, 78, 82, 88, 89, 90, 100, 106, 113, 116, 117, 123], "thi": [1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 15, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 46, 48, 58, 59, 61, 62, 64, 65, 66, 67, 68, 70, 71, 72, 77, 78, 81, 82, 84, 86, 93, 98, 99, 100, 101, 104, 105, 106, 107, 108, 113, 114, 115, 116, 117, 119, 120, 121, 123, 124], "newli": [1, 48], "drug": [1, 3], "must": [1, 2, 5], "go": [1, 124], "through": [1, 2, 5, 9, 10, 11, 12, 14, 15, 17, 72, 78, 82, 85, 86, 93, 100, 103, 105, 106, 115, 116, 119, 121], "preclin": 1, "bitro": 1, "vivo": 1, "three": [1, 6, 9, 11, 13, 14, 15, 16, 17, 18, 20, 21, 23, 24, 25, 27, 28, 58, 77, 78, 79, 80, 81, 83, 84, 87, 88, 89, 90, 92, 94, 95, 96, 99, 101, 102, 103, 105, 106, 115, 116, 117, 121, 123], "phase": 1, "final": [1, 2, 17, 19, 20, 21, 24, 27, 28, 57, 58, 61, 62, 64, 65, 70, 71, 73, 76, 78, 79, 80, 83, 94, 101, 102, 103, 108, 113, 116, 120, 121, 123], "approv": 1, "confirm": [1, 4, 6, 15], "potenti": [1, 2, 15, 19, 21, 27, 28, 43, 57, 58, 62, 64, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 88, 89, 90, 93, 95, 96, 97, 98, 99, 100, 105, 116, 119], "side": [1, 64, 65, 116], "dure": [1, 2, 3, 16, 59], "procedur": [1, 6, 11, 16, 17, 19, 24, 62, 67], "usual": [1, 2, 15, 58, 66, 70], "evalu": [1, 5, 11, 13, 14, 15, 18, 21, 22, 26, 60, 65, 67, 78, 106, 121, 123], "mesur": 1, "well": [1, 9, 11, 13, 19, 21, 26, 46, 58, 64, 66, 70, 71, 72, 81, 82, 92, 96, 98, 99, 106, 107, 116, 117, 123], "perform": [1, 9, 13, 17, 18, 19, 20, 21, 22, 24, 27, 46, 58, 61, 64, 65, 66, 70, 78, 79, 80, 81, 83, 84, 85, 87, 88, 89, 90, 106, 107, 116], "compar": [1, 3, 15, 16, 18, 20, 21, 22, 24, 61, 70, 81, 87, 116, 120, 121], "placebo": 1, "other": [1, 2, 3, 4, 5, 6, 9, 13, 15, 17, 19, 21, 24, 26, 27, 43, 48, 57, 62, 70, 71, 72, 73, 76, 77, 78, 79, 82, 86, 92, 95, 96, 97, 98, 99, 102, 103, 105, 106, 115, 116, 123], "exist": [1, 2, 4, 5, 6, 9, 10, 11, 12, 13, 17, 19, 43, 48, 57, 61, 72, 93, 100, 105, 115, 116, 123], "treatment": [1, 2, 4, 9, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 43, 46, 48, 57, 59, 62, 72, 73, 76, 77, 86, 106, 116, 119, 120, 121, 123], "method": [1, 2, 5, 10, 12, 13, 17, 19, 20, 21, 25, 27, 28, 43, 48, 57, 58, 61, 62, 64, 65, 66, 67, 70, 73, 76, 87, 88, 89, 90, 116, 117, 123, 124], "experiment": [1, 4, 6, 15, 123], "design": [1, 17, 18, 19, 22, 61, 62, 70, 94, 99, 101, 116], "wide": [1, 2, 9, 15, 19, 61, 66, 70, 77, 78, 81, 82, 86, 92, 94, 98, 99, 101, 105, 106, 107, 123], "known": [1, 2, 3, 9, 12, 15, 21, 25, 43, 66, 70, 71, 72, 73, 77, 82, 83, 85, 86, 87, 88, 89, 90, 93, 94, 98, 99, 100, 101, 106, 108, 113, 116, 117, 123], "b": [1, 2, 9, 10, 11, 13, 14, 15, 16, 18, 19, 20, 21, 22, 24, 25, 27, 28, 43, 46, 48, 57, 58, 61, 66, 70, 71, 72, 73, 76, 77, 78, 79, 83, 85, 86, 87, 92, 93, 96, 98, 99, 105, 106, 108, 113, 114, 115, 120], "randomli": [1, 2, 4, 6, 16, 17, 18, 20, 23, 25, 27, 28, 81, 107], "assign": [1, 2, 4, 6, 12, 15, 19, 21, 22, 46, 57, 72, 76], "one": [1, 2, 4, 5, 6, 15, 19, 21, 25, 43, 46, 58, 61, 62, 64, 66, 70, 72, 73, 78, 82, 83, 86, 92, 93, 94, 95, 100, 101, 102, 103, 105, 106, 108, 113, 116, 120], "two": [1, 2, 3, 4, 5, 6, 10, 14, 15, 16, 17, 20, 21, 24, 27, 28, 58, 59, 61, 62, 66, 70, 72, 77, 78, 82, 83, 86, 88, 89, 90, 94, 99, 101, 106, 113, 116, 119, 120, 121, 123, 124], "group": [1, 2, 4, 6, 15, 19, 21, 27, 28, 43, 58, 73, 82, 98, 106, 119, 123], "receiv": [1, 2, 4, 6, 15, 57, 59, 71, 72, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 106, 107, 108, 113, 114, 115, 120, 123], "measur": [1, 3, 4, 6, 9, 10, 11, 12, 13, 14, 15, 19, 62, 66, 72, 116, 120, 123], "sbp": 1, "systol": 1, "blood": 1, "pressur": [1, 26, 119], "each": [1, 2, 3, 4, 6, 9, 10, 11, 13, 14, 18, 19, 20, 21, 22, 24, 27, 43, 48, 57, 59, 66, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 106, 107, 108, 113, 114, 115, 119, 120, 121, 123], "both": [1, 4, 5, 6, 11, 13, 14, 15, 17, 21, 27, 48, 58, 61, 62, 66, 70, 72, 81, 85, 87, 94, 99, 101, 107, 113, 116, 120, 123], "befor": [1, 10, 11, 15, 16, 20, 21, 22, 24, 87, 120], "after": [1, 2, 3, 11, 13, 14, 17, 23, 24, 26, 46, 59, 61, 62, 64, 65, 66, 67, 68, 70, 71, 76, 79, 81, 83, 84, 95, 104, 107, 108, 113, 114, 116, 119, 121], "By": [1, 17, 19, 43, 57, 59, 62, 71, 72, 76, 81, 85, 105, 107], "analys": 1, "abl": [1, 4, 6, 15, 17, 19, 83, 85, 119], "determin": [1, 9, 12, 14, 81, 85, 94, 99, 100, 101, 102, 103, 105, 115], "treat": [1, 17, 26, 105, 119, 123], "shop": [1, 19], "websit": [1, 2, 19, 26, 75, 78, 82, 86, 105, 106, 124], "seller": 1, "often": [1, 4, 6, 17, 21, 27, 58], "veri": [1, 3, 5, 19, 21, 25, 27, 58, 123], "cautiou": 1, "about": [1, 2, 4, 5, 6, 15, 17, 18, 20, 21, 22, 24, 28, 59, 78, 83, 86, 87], "custom": [1, 2, 19, 58, 59, 85, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103], "purchas": [1, 2, 59, 100, 101, 102, 103, 104], "experi": [1, 4, 6, 15, 19, 46, 72, 78, 82, 86, 88, 89, 90, 105, 106], "whenev": [1, 2, 78, 82, 93, 100], "consum": 1, "satisfi": [1, 9, 15, 17, 18, 22, 23, 24, 58, 61, 62, 66, 70, 78, 82, 86, 96, 97, 98, 99, 105, 106, 115, 116], "item": [1, 2, 20, 77, 78, 79, 81, 82, 83, 84, 85, 86, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 107, 108, 114, 115, 123], "thei": [1, 2, 4, 5, 6, 66, 70, 72, 78, 82, 86, 105, 106], "bought": 1, "order": [1, 2, 9, 10, 11, 12, 13, 14, 17, 18, 20, 22, 24, 58, 62, 85, 86, 87, 92, 93, 94, 95, 96, 97, 99, 101, 102, 103, 105, 115], "wrong": [1, 60], "size": [1, 21, 22, 24, 43, 48, 57, 58, 60, 96, 97, 98, 99, 121, 123], "cloth": [1, 19], "broken": 1, "miss": [1, 5, 16, 72], "sever": [1, 2, 16, 17, 19, 23, 24, 26, 105, 119, 123], "option": [1, 18, 20, 22, 24, 43, 48, 57, 60, 73, 76, 78, 79, 80, 81, 83, 84, 107, 108, 113, 114], "provid": [1, 2, 12, 14, 19, 26, 27, 28, 43, 57, 60, 62, 70, 72, 73, 76, 81, 85, 88, 89, 90, 102, 107, 116, 117, 121, 124], "address": [1, 2, 17, 19, 48, 81, 85, 116, 123], "problem": [1, 2, 3, 10, 17, 18, 19, 22, 23, 24, 46, 57, 58, 61, 62, 64, 65, 66, 70, 76, 77, 81, 83, 84, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104, 107, 114, 116, 117, 119, 123, 124], "For": [1, 2, 3, 4, 5, 6, 17, 19, 20, 21, 24, 26, 28, 43, 57, 58, 59, 61, 66, 70, 72, 73, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 113, 114, 116, 119, 123], "mai": [1, 2, 3, 4, 6, 10, 15, 18, 19, 22, 46, 58, 72, 78, 79, 86, 108, 119, 124], "offer": [1, 2, 62, 81, 100, 101, 102, 103, 104, 105, 115], "1": [1, 4, 5, 6, 10, 16, 18, 19, 20, 22, 23, 24, 27, 28, 46, 58, 59, 60, 61, 62, 64, 65, 66, 67, 70, 71, 72, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 113, 114, 115, 116, 117, 119, 120, 121], "fulli": [1, 78, 82, 85, 86, 106, 116], "refund": 1, "without": [1, 21, 23, 71, 72, 90, 123], "return": [1, 2, 17, 20, 21, 22, 23, 24, 43, 48, 57, 58, 60, 73, 76, 116, 119, 120, 121], "2": [1, 10, 16, 18, 19, 20, 22, 23, 24, 25, 28, 33, 34, 37, 38, 39, 40, 41, 46, 58, 59, 60, 61, 62, 64, 65, 66, 67, 70, 71, 74, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 113, 114, 115, 116, 117, 119, 120, 121], "3": [1, 5, 10, 16, 17, 18, 20, 22, 23, 24, 25, 26, 27, 43, 46, 48, 57, 58, 60, 73, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 113, 114, 115, 116, 117, 119], "discount": [1, 62, 70, 71, 72, 116], "next": [1, 10, 19, 21, 28, 58, 66, 70, 71, 72, 89, 90, 119, 124], "compens": [1, 123], "level": [1, 3, 4, 5, 6, 19, 58, 116, 119, 123], "vari": [1, 74, 78, 121], "accord": [1, 2, 4, 6, 12, 17, 26, 62, 64, 66, 72, 83, 85, 103, 106, 108, 113, 119, 123], "primari": [1, 3, 17, 59, 77, 123], "goal": [1, 2, 3, 17, 26, 46, 58, 62, 71, 72, 78, 82, 86, 88, 89, 90, 98, 100, 105, 106, 123, 124], "outcom": [1, 2, 3, 10, 12, 15, 16, 17, 19, 20, 21, 23, 24, 27, 28, 43, 48, 57, 58, 59, 73, 74, 76, 77, 85, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 116, 120, 121, 123], "so": [1, 2, 4, 5, 9, 11, 13, 15, 17, 20, 23, 24, 26, 58, 71, 72, 76, 81, 84, 106, 107, 114, 119], "examin": [1, 93, 121, 123], "which": [1, 2, 3, 4, 5, 6, 10, 12, 15, 17, 18, 19, 21, 22, 23, 24, 26, 27, 28, 43, 46, 48, 57, 58, 61, 65, 66, 70, 71, 72, 73, 76, 77, 78, 79, 82, 83, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 106, 107, 108, 113, 115, 116, 117, 119, 120, 121, 123], "take": [1, 11, 13, 14, 21, 28, 46, 58, 62, 71, 76, 78, 81, 82, 83, 85, 86, 87, 92, 94, 96, 97, 98, 99, 101, 102, 103, 104, 106, 107, 120, 121, 123], "histori": [1, 2, 26, 43, 57, 58, 59, 72, 81, 88, 89, 90, 106, 107, 116, 117, 123], "maxim": [1, 2, 26, 46, 48, 57, 58, 76, 77, 78, 82, 86, 93, 105, 106, 116, 120], "profit": [1, 2, 100, 105, 115], "asid": [1, 19, 58], "abov": [1, 4, 6, 9, 10, 11, 15, 16, 17, 18, 19, 21, 22, 24, 25, 28, 48, 100, 116, 119, 120, 124], "idea": [1, 17, 20, 21, 23, 24, 25, 116, 124], "fundament": 1, "ha": [1, 2, 3, 5, 9, 10, 13, 18, 19, 22, 23, 43, 46, 48, 57, 58, 61, 62, 66, 67, 70, 75, 79, 82, 83, 84, 85, 86, 94, 97, 98, 100, 101, 105, 106, 108, 113, 114, 116, 121], "broad": [1, 17], "our": [1, 2, 4, 6, 15, 17, 18, 22, 48, 58, 62, 66, 67, 70, 72, 76, 86, 88, 89, 90, 116, 121], "daili": 1, "live": 1, "leverag": [1, 14, 18, 20, 22, 24, 48, 87, 116], "studi": [1, 2, 3, 4, 5, 6, 9, 13, 15, 19, 26, 59, 61, 64, 70, 78, 82, 86, 105, 106, 117, 121, 123], "new": [1, 2, 4, 6, 17, 20, 43, 58, 59, 73, 76, 78, 85, 86, 87, 98, 105, 106, 115, 116, 123], "catalyst": 1, "rate": [1, 2, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 23, 24, 25, 26, 27, 28, 48, 61, 62, 70, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 93, 105, 106, 107, 116, 119, 120, 121], "chemic": 1, "reaction": 1, "smoke": 1, "risk": 1, "lung": 1, "cancer": 1, "ad": [1, 4, 6, 19, 43, 73, 88, 89, 90, 98, 105, 115], "exposur": [1, 2, 3, 10, 19, 74, 121, 123], "convers": [1, 2, 19], "bui": [1, 101, 102, 103], "product": [1, 2, 100, 105, 115], "extracurricular": 1, "remedi": 1, "class": [1, 4, 9, 23, 24, 48, 58, 61, 62, 64, 70, 77, 78, 84, 86, 94, 99, 101, 105, 106, 114, 115, 117, 123], "improv": [1, 2, 5, 16, 17, 18, 19, 20, 23, 25, 27, 28, 58, 92, 116, 117], "student": [1, 16, 17, 18, 20, 23, 25, 26, 27, 28, 78, 79, 80, 85, 86, 106], "grade": 1, "cdot": [1, 4, 6, 9, 10, 11, 12, 13, 14, 15, 18, 20, 22, 23, 24, 43, 48, 59, 61, 62, 64, 65, 66, 70, 71, 72, 73, 75, 76, 77, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 92, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 107, 108, 113, 114, 116, 123], "social": [1, 123], "phenomena": 1, "natur": [1, 2, 5, 10, 12, 23, 24, 46, 58, 116, 119, 121], "quantif": 1, "allow": [1, 2, 4, 5, 6, 20, 46, 48, 57, 58, 62, 72, 76, 123], "understand": [1, 10, 19, 57, 76, 81, 116], "relationship": [1, 3, 4, 6, 9, 10, 11, 12, 13, 14, 46, 57, 66, 79, 94, 101, 103, 108, 116, 123], "methodolog": [1, 9, 12, 43, 73], "onli": [1, 2, 4, 5, 6, 12, 15, 17, 58, 59, 61, 62, 66, 67, 70, 71, 72, 77, 87, 92, 93, 94, 95, 100, 101, 102, 103, 116, 123, 124], "scientif": [1, 4, 6], "also": [1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 19, 21, 23, 24, 25, 43, 57, 58, 60, 61, 64, 65, 66, 70, 72, 73, 76, 83, 85, 86, 94, 95, 96, 97, 98, 99, 100, 101, 103, 106, 108, 113, 117, 119, 123], "practic": [1, 2, 48, 57, 62, 76, 78, 79, 81, 82, 83, 85, 88, 89, 90, 92, 94, 95, 96, 97, 99, 101, 102, 103, 106, 107, 108, 113, 116], "where": [1, 2, 4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 43, 46, 48, 57, 58, 59, 61, 62, 64, 66, 67, 70, 71, 72, 73, 76, 77, 78, 79, 81, 82, 83, 85, 86, 87, 88, 89, 90, 93, 94, 96, 98, 99, 100, 101, 105, 106, 107, 115, 116, 119, 123, 124], "seek": [1, 123], "user": [2, 4, 6, 10, 16, 17, 18, 20, 23, 24, 25, 26, 27, 28, 43, 46, 57, 73, 76, 78, 79, 80, 81, 82, 85, 86, 87, 93, 96, 97, 99, 100, 101, 102, 103, 105, 106, 107, 115], "growth": 2, "engag": 2, "critic": [2, 5, 17, 26, 61, 70, 72, 119], "fast": [2, 9, 10, 11, 12, 13, 14, 61, 123], "chang": [2, 20, 21, 26, 48, 66, 73, 96, 119, 124], "market": 2, "campaign": [2, 59], "internet": 2, "compani": [2, 19], "encourag": [2, 46], "The": [2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 33, 34, 37, 38, 39, 40, 41, 43, 46, 48, 57, 58, 59, 61, 62, 64, 65, 66, 70, 71, 72, 73, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 106, 107, 108, 113, 114, 115, 116, 117, 119, 120, 121, 123, 124], "posit": [2, 4, 6, 11, 13, 14, 15, 21, 25, 43, 57, 73, 76, 86, 105, 115], "effect": [2, 3, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 46, 59, 62, 76, 100, 105, 115, 120, 121], "desir": [2, 3, 58], "busi": 2, "lead": [2, 19, 62], "surplu": 2, "oper": [2, 10, 12, 15, 17, 62, 100, 103, 104], "cost": [2, 24, 46, 103], "increas": [2, 48, 62, 77, 81, 88, 89, 90, 106, 119, 120], "impel": 2, "carri": 2, "out": [2, 10, 16, 17, 18, 19, 20, 23, 25, 27, 28, 57, 72], "more": [2, 3, 4, 5, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 24, 25, 27, 28, 43, 46, 48, 58, 59, 61, 62, 64, 65, 66, 67, 68, 70, 72, 73, 78, 80, 81, 87, 96, 97, 99, 102, 103, 104, 106, 107, 108, 113, 114, 116, 124], "refin": 2, "strategi": 2, "acquisit": 2, "retent": 2, "associ": [2, 4, 5, 6, 9, 11, 13, 46, 48, 58, 72, 77, 88, 89, 90, 117, 119, 123], "massiv": [2, 19], "scale": [2, 9, 20, 24, 48, 64, 77, 92, 93, 94, 96, 98, 99, 101, 102, 106, 123], "promot": 2, "balanc": [2, 71, 83, 106], "increment": [2, 116], "sustain": 2, "invest": [2, 43, 57, 73, 76], "roi": [2, 83, 105, 106, 113, 114, 115], "requir": [2, 9, 11, 14, 17, 18, 22, 43, 46, 48, 58, 61, 62, 70, 72, 73, 76, 86, 116, 123], "predict": [2, 5, 18, 21, 22, 25, 27, 28, 48, 57, 76, 116, 119], "caus": [2, 4, 6, 9, 11, 12, 13, 14, 19, 20, 46, 58, 119], "action": [2, 4, 6, 19, 26, 43, 46, 57, 58, 59, 60, 61, 62, 64, 65, 66, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 113, 114, 115, 116, 117, 119, 120, 121, 123], "uplift": [2, 58, 59], "model": [2, 6, 10, 12, 15, 17, 21, 23, 24, 25, 27, 28, 43, 48, 57, 58, 60, 61, 62, 64, 70, 71, 72, 73, 76, 77, 79, 80, 85, 86, 88, 89, 90, 92, 93, 94, 96, 99, 100, 101, 102, 103, 105, 106, 108, 115, 120, 123], "heterogen": [2, 9, 16, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 85, 93, 94, 98, 99, 100, 101, 123], "attent": [2, 3, 9, 11, 12, 13, 14, 48, 77, 88, 89, 90, 106, 119, 123], "literatur": [2, 9, 15, 19, 48, 61, 67, 70, 72, 86, 103, 116, 117, 121, 123, 124], "book": [2, 5, 57, 76, 116, 123, 124], "sampl": [2, 4, 6, 16, 17, 18, 20, 21, 22, 24, 43, 46, 48, 57, 58, 61, 62, 67, 71, 78, 79, 81, 82, 83, 86, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 107, 108, 113, 114, 115, 116, 123], "code": [2, 9, 10, 17, 18, 22, 38, 46, 60, 115, 120, 121, 124], "relat": [2, 9, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 43, 66, 71, 72, 73, 77, 78, 86, 106, 116, 119, 123], "under": [2, 3, 4, 5, 6, 9, 10, 15, 16, 17, 19, 20, 21, 24, 25, 27, 28, 43, 46, 48, 57, 61, 62, 64, 66, 70, 78, 85, 87, 94, 99, 100, 101, 102, 103, 106, 121, 123, 124], "set": [2, 3, 5, 9, 10, 11, 12, 13, 14, 18, 22, 23, 26, 48, 60, 62, 66, 70, 71, 72, 76, 81, 87, 88, 89, 90, 92, 94, 95, 96, 97, 99, 101, 102, 103, 107, 116, 117, 119, 121, 123, 124], "point": [2, 16, 17, 18, 20, 22, 23, 25, 27, 28, 46, 48, 57, 59, 64, 65, 66, 67, 71, 72, 73, 76, 82, 86, 116, 117], "interest": [2, 3, 4, 6, 10, 12, 17, 18, 19, 22, 43, 48, 57, 58, 59, 70, 73, 76, 92, 93, 94, 95, 116, 119, 121, 123], "dataset": [2, 3, 19, 24, 26, 43, 48, 57, 59, 71, 72, 75, 76, 78, 82, 86, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 106, 115, 116, 119], "space": [2, 9, 26, 43, 48, 57, 59, 61, 66, 70, 71, 72, 73, 76, 79, 80, 81, 83, 84, 86, 87, 88, 89, 90, 96, 97, 99, 105, 107, 108, 113, 114, 115], "should": [2, 10, 12, 16, 17, 60, 73, 76, 79, 92, 94, 95, 96, 97, 99, 101, 102, 124], "variou": [2, 3, 11, 13, 57, 61, 70, 76, 87, 96, 105, 123], "email": [2, 43, 57, 58], "sent": 2, "total": [2, 10, 12, 19, 48, 58, 59, 73, 78, 81, 82, 84, 85, 92, 94, 95, 96, 97, 99, 101, 102, 103, 105, 106, 107, 114, 115, 119, 121, 123], "amount": [2, 17, 93, 119], "spent": [2, 48, 59], "fetch_hillstrom": [2, 58, 59], "discret": [2, 4, 5, 6, 26, 48, 58, 71, 72, 79, 80, 81, 83, 84, 119, 123], "q": [2, 5, 9, 17, 43, 48, 58, 60, 61, 62, 70, 71, 72, 73, 77, 81, 83, 85, 87, 94, 99, 101, 103, 106, 107, 116, 120, 121, 123], "much": [2, 3, 19], "spend": [2, 43, 57, 58, 59], "averag": [2, 9, 12, 15, 16, 17, 19, 20, 21, 24, 28, 43, 57, 62, 66, 67, 73, 76, 81, 84, 107, 114, 116, 119, 121, 123], "add": [2, 5, 20, 43, 57, 58, 85, 93, 98, 100, 124], "quantil": [2, 67, 123], "continu": [2, 4, 6, 9, 10, 11, 12, 13, 14, 43, 57, 58, 66, 70, 71, 73, 76, 81, 83, 84, 85, 87, 96, 97, 98, 99, 119, 123, 124], "owl": [2, 123], "john": [2, 5, 71, 72, 116], "wanamak": 2, "onc": [2, 5, 85, 87, 93], "phrase": 2, "half": 2, "monei": [2, 59], "advertis": [2, 19, 96, 97, 98, 99], "wast": 2, "troubl": 2, "don": [2, 20, 58, 101, 102, 103], "t": [2, 4, 5, 6, 10, 11, 13, 14, 15, 17, 18, 19, 20, 22, 24, 28, 43, 46, 48, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 113, 114, 115, 116, 119, 120, 121, 123], "know": [2, 19, 58], "indic": [2, 4, 6, 11, 13, 14, 15, 26, 48, 81, 89, 90, 93, 100, 101, 102, 103, 105, 119, 120], "high": [2, 3, 4, 9, 10, 11, 12, 13, 14, 15, 43, 73, 116, 119], "intent": 2, "convert": [2, 4, 6, 11, 13, 14, 58, 73, 76, 120], "todai": 2, "digit": 2, "techniqu": [2, 61, 70, 123], "enabl": [2, 9, 10, 12, 17, 94, 99, 101], "lift": 2, "via": [2, 3, 4, 9, 10, 11, 12, 13, 14, 15, 61, 62, 64, 70, 71, 85, 88, 89, 90, 94, 99, 100, 101, 116, 117], "random": [2, 4, 6, 9, 11, 12, 13, 14, 15, 16, 19, 20, 23, 33, 34, 37, 38, 39, 40, 41, 58, 60, 67, 71, 72, 78, 79, 80, 81, 82, 83, 85, 86, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103, 106, 107, 108, 119, 121], "control": [2, 3, 4, 5, 6, 9, 12, 15, 16, 19, 20, 21, 23, 24, 26, 27, 28, 43, 73, 116, 119, 121, 123], "select": [2, 10, 46, 48, 59, 71, 77, 78, 79, 80, 81, 82, 83, 84, 86, 92, 94, 95, 96, 97, 99, 100, 101, 103, 104, 106, 107, 108, 113, 114, 116, 117, 119, 123], "form": [2, 11, 15, 61, 65, 70, 71, 79, 83, 85, 87, 94, 101, 116], "interven": [2, 4, 6, 9, 12], "cannot": [2, 4, 6, 11, 14, 15, 62, 72, 117], "base": [2, 4, 5, 9, 10, 12, 15, 16, 17, 18, 19, 21, 22, 23, 25, 43, 46, 48, 57, 61, 62, 64, 65, 66, 70, 72, 73, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 92, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 106, 107, 108, 113, 114, 117, 119, 120, 121, 123], "collect": [2, 3, 4, 6, 17, 19, 22, 26, 58, 71, 72, 78, 82, 86, 100, 105, 106, 116, 119, 123], "converion": 2, "even": [2, 117, 123], "win": 2, "impress": [2, 19], "those": [2, 5, 16, 46, 72, 79, 80, 81, 83, 84, 85, 87], "With": [2, 43, 46, 66, 94, 101, 105, 121], "wearabl": 2, "devic": 2, "easili": [2, 21, 27, 79, 83, 88, 94, 95, 97, 101, 102, 108, 113], "keep": [2, 6, 10, 12, 20, 100, 103], "track": [2, 9], "own": [2, 86, 123], "meanwhil": [2, 71], "util": [2, 10, 11, 13, 14, 17, 20, 57, 61, 62, 66, 67, 70, 73, 76, 78, 79, 80, 85, 86, 92, 94, 100, 101, 102, 103, 105, 116, 117, 119, 120], "manag": [2, 124], "increasingli": 2, "hot": 2, "topic": [2, 116], "among": [2, 4, 9, 10, 11, 12, 13, 14, 58, 64, 70, 77, 78, 82, 85, 86, 94, 99, 101, 106, 121, 123], "them": [2, 6, 10, 17, 21, 27, 58, 70, 82, 93, 100, 102, 106], "decid": [2, 18, 22, 92, 94, 95, 96, 97, 98, 99], "biggest": 2, "challeng": [2, 3, 10, 62, 67, 116, 117], "given": [2, 4, 6, 11, 13, 14, 15, 16, 17, 21, 23, 24, 26, 28, 43, 48, 57, 58, 61, 62, 64, 67, 70, 71, 72, 73, 76, 77, 79, 80, 88, 89, 90, 94, 99, 101, 116, 123], "activ": 2, "suggest": [2, 4, 43, 64, 77, 84, 105, 106, 114], "help": [2, 26, 76, 78, 82, 86, 105, 106], "regul": [2, 3, 10, 12], "psycholog": 2, "howev": [2, 4, 6, 9, 12, 15, 18, 19, 21, 22, 24, 27, 43, 61, 62, 66, 67, 70, 73, 76, 83, 106, 108, 113, 116, 117], "send": [2, 43, 57, 96, 97, 99], "written": [2, 5, 9, 14, 15, 19, 20, 24], "intuit": [2, 46, 78, 81, 106, 107], "asleep": 2, "intens": [2, 19], "workout": 2, "rare": [2, 67], "exercis": 2, "would": [2, 4, 19, 21, 25, 43, 46, 57, 58, 59, 71, 72, 75, 76, 77, 78, 79, 80, 81, 82, 83, 86, 87, 88, 89, 90, 93, 98, 100, 105, 106, 108, 113, 115, 116, 117, 120, 123], "decreas": [2, 3, 62, 81, 106, 107, 119], "To": [2, 13, 15, 17, 18, 21, 22, 48, 58, 61, 62, 66, 70, 71, 81, 87, 93, 94, 101, 116, 124], "number": [2, 4, 9, 11, 13, 14, 20, 21, 22, 24, 26, 43, 46, 48, 58, 66, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 106, 107, 114, 115, 119, 123], "formal": [2, 3, 4, 15, 17, 23, 24, 70, 72, 93, 98], "reinforc": [2, 5, 9, 10, 11, 12, 13, 14, 57, 64, 65, 66, 70, 71, 72, 76, 81, 106, 107, 116, 117, 121], "mdp": [2, 61, 66, 70, 71, 72, 116, 117], "seri": [2, 5, 18, 22, 43, 66, 70, 73], "stage": [2, 16, 17, 24, 123], "condit": [2, 4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 24, 43, 48, 58, 61, 62, 72, 73, 85, 88, 89, 90, 94, 99, 101, 105, 116, 117], "affect": [2, 3, 4, 6, 12, 15, 46, 123], "previou": [2, 17, 19, 72, 78, 84, 86, 88, 89, 90, 94, 99, 101, 105, 106, 115, 123], "delai": [2, 20, 76, 121], "current": [2, 3, 20, 58, 71, 72, 77, 88, 89, 90, 116, 123], "decis": [2, 5, 9, 15, 17, 43, 48, 57, 58, 59, 73, 76, 77, 86, 88, 89, 90, 100, 116, 117, 123, 124], "subsequ": [2, 4, 6, 105], "regard": [2, 19, 62, 64, 66, 70, 78, 123], "cumul": [2, 66, 71, 72, 77, 78, 82, 86, 94, 99, 101, 105, 106, 116], "sequenc": [2, 24, 75, 77, 86, 105, 115, 117], "longitudin": [2, 74], "subject": [2, 4, 6, 15, 19, 21, 43, 57, 73, 76], "experienc": 2, "entir": [2, 5, 17, 94, 99, 101, 119], "formul": [2, 9, 13, 72, 99, 123], "illustr": [2, 17, 18, 22, 26, 58, 62, 77, 82, 88, 89, 90, 106, 116, 119, 123], "context": [2, 17, 48, 77, 78, 88, 89, 90, 123], "hiv": 2, "infect": [2, 3], "time": [2, 5, 9, 10, 11, 13, 14, 16, 19, 24, 43, 48, 58, 62, 66, 70, 71, 72, 73, 74, 78, 81, 82, 84, 85, 86, 88, 89, 90, 105, 106, 107, 114, 116, 117, 119, 121, 123], "datamdp": [2, 73, 75, 76], "cd4": 2, "count": [2, 81, 84, 107, 114], "wa": [2, 4, 9, 13, 15, 23, 24, 26, 46, 57, 58, 73, 76, 117], "all": [2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 23, 24, 25, 26, 27, 28, 43, 46, 57, 58, 62, 70, 72, 73, 75, 76, 78, 85, 86, 88, 89, 90, 93, 96, 97, 98, 99, 102, 104, 105, 106, 115, 116, 117, 119, 120, 121, 123], "interact": [2, 20, 24, 86, 105, 115], "same": [2, 4, 5, 6, 15, 18, 19, 21, 22, 27, 28, 43, 46, 57, 62, 72, 73, 76, 87, 96, 97, 100, 101, 102, 103, 105, 116], "possibl": [2, 4, 6, 9, 13, 21, 28, 62, 96, 97, 99, 123], "style": [2, 14, 104], "mani": [2, 3, 5, 9, 10, 12, 46, 64, 70, 71, 72, 88, 89, 90, 94, 99, 101, 105, 115, 116], "channel": [2, 58], "distribut": [2, 4, 6, 9, 14, 21, 22, 24, 46, 58, 59, 62, 70, 71, 72, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 106, 108, 113, 116, 117, 123], "credit": 2, "correspond": [2, 4, 6, 10, 12, 43, 46, 48, 57, 58, 61, 62, 66, 67, 70, 72, 73, 76, 78, 81, 82, 83, 84, 85, 86, 87, 93, 94, 97, 100, 101, 102, 103, 105, 106, 107, 108, 113, 114, 115, 116, 117, 123], "contribut": [2, 3, 10], "recent": [2, 3, 9, 11, 12, 13, 14, 17, 20, 21, 22, 24, 43, 46, 48, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 70, 73, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104, 106, 107, 108, 113, 114, 117, 120, 121, 124], "becom": [2, 23, 24, 62, 66, 117], "rule": [2, 46, 48, 97], "simpl": [2, 18, 22, 64, 65, 66, 77, 81, 86, 99, 106, 107, 123], "been": [2, 4, 6, 9, 13, 15, 18, 22, 26, 48, 58, 61, 66, 67, 70, 77, 82, 83, 85, 86, 97, 102, 106, 108, 113, 119], "long": [2, 61, 66, 70, 100, 123], "ever": 2, "enhanc": 2, "capabl": 2, "driven": 2, "attempt": 2, "popular": [2, 48, 65, 93, 94, 100, 103, 105, 106, 115, 116], "framework": [2, 4, 6, 15, 78, 79, 85, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 115, 121], "classic": [2, 4, 6, 9, 14, 21, 23, 24, 48, 57, 64, 76, 78, 82, 83, 106, 113, 117, 123, 124], "bandit": [2, 5, 88, 89, 90, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104, 107, 108, 114, 115, 117], "prefer": [2, 19, 20, 21, 27], "click": [2, 19, 93, 101, 102, 103, 105], "overal": [2, 19, 21, 22, 24, 43, 57, 58, 73, 76, 78, 82, 93, 94, 98, 99, 100, 101, 106, 119, 123], "repres": [2, 4, 6, 9, 11, 12, 13, 14, 15, 26, 48, 116, 119, 120, 123], "movi": [2, 78, 81, 82, 86, 101, 102, 103, 105, 106, 115], "youtub": 2, "netflix": 2, "agent": [2, 58, 71, 72, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 106, 108, 113, 115, 116], "list": [2, 11, 13, 14, 60, 73, 87, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 105, 115, 119, 123], "video": [2, 58], "visit": [2, 48, 62, 66, 78, 82, 86, 93, 100, 105, 106, 116], "site": [2, 10, 11, 16, 17, 18, 20, 21, 22, 23, 24, 43, 57, 60, 73, 76, 120, 121], "either": [2, 4, 6, 15, 26, 43, 57, 59, 61, 64, 65, 70, 73, 76, 78, 81, 83, 84, 85, 87, 89, 92, 94, 95, 96, 97, 99, 100, 101, 102, 103, 105, 106, 107, 114, 116, 117, 123], "leav": [2, 3, 82, 86, 93, 105, 123], "typic": [2, 61, 66, 67, 70, 77, 78, 82, 98, 99, 116, 123], "larg": [2, 17, 19, 26, 46, 60, 61, 62, 64, 66, 70, 72, 77, 81, 83, 84, 85, 86, 87, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 106, 114, 119], "avail": [2, 4, 6, 9, 10, 13, 14, 17, 38, 59, 72, 78, 82, 86, 92, 93, 99, 100, 105, 106, 115, 119], "therefor": [2, 17, 43, 57, 62, 64, 65, 66, 78, 82, 83, 86, 87, 93, 96, 97, 99, 106, 108, 113, 116, 120, 123], "explor": [2, 21, 46, 58, 61, 62, 64, 65, 66, 67, 68, 70, 76, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 92, 95, 104, 106, 107, 108, 113, 114, 116], "exploit": [2, 19, 81, 82, 83, 84, 88, 89, 90, 95, 106, 107, 108, 113, 114], "inform": [2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 17, 19, 21, 26, 28, 43, 48, 59, 66, 70, 73, 75, 77, 78, 79, 80, 83, 85, 86, 87, 89, 90, 92, 93, 94, 96, 97, 99, 100, 101, 102, 105, 106, 108, 113, 115, 117, 121, 123, 124], "far": [2, 81, 84, 106, 107], "approach": [2, 3, 4, 6, 15, 16, 17, 18, 21, 24, 43, 46, 57, 61, 62, 64, 65, 66, 67, 70, 73, 76, 77, 78, 100, 102, 103, 104, 106, 116, 117, 123], "As": [2, 15, 20, 21, 24, 25, 27, 28, 61, 62, 64, 70, 71, 72, 77, 79, 80, 84, 85, 87, 92, 94, 95, 106, 108, 114, 116, 119, 120, 121, 123], "chapter": [2, 59, 72, 78, 82, 86, 92, 94, 95, 96, 97, 99, 101, 102, 103, 105, 106, 115, 116, 117, 123], "genr": [2, 78, 82, 86, 105, 106], "five": [2, 101, 102, 103, 105], "whose": [2, 3, 72, 123], "unknown": [2, 9, 12, 13, 66, 70, 77, 78, 82, 83, 85, 87, 88, 89, 90, 94, 99, 101, 106, 108, 113, 123], "over": [2, 3, 21, 48, 61, 62, 66, 70, 87, 88, 89, 90, 103, 106, 116, 119, 123], "satisfact": [2, 26, 78, 82, 86, 105, 106], "movielen": [2, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 100, 101, 102, 103, 105, 106, 115], "arm": [2, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 97, 98, 105, 106, 107, 114, 115, 123], "contextu": [2, 77, 79, 80, 82, 88, 89, 90, 100, 101, 102, 106, 108, 123], "meta": [2, 19, 28, 77, 85, 93, 94, 98, 99, 100, 101, 105, 123], "multipl": [2, 9, 10, 11, 12, 13, 14, 17, 43, 46, 58, 60, 77, 87, 117, 123], "million": [2, 3, 9, 10, 11, 12, 13, 14], "try": [2, 16, 17, 23, 24, 26, 106, 119, 124], "assort": [2, 101, 103, 104, 105, 115, 123], "rank": [2, 92, 94, 95, 105, 115, 123], "top": [2, 9, 10, 11, 12, 13, 14, 72, 78, 82, 86, 92, 93, 94, 95, 103, 105, 106, 116], "restaur": [2, 92, 93, 94, 95], "true": [2, 3, 10, 11, 13, 14, 17, 18, 20, 21, 22, 24, 43, 46, 57, 58, 59, 60, 62, 64, 73, 76, 79, 80, 81, 83, 85, 87, 89, 101, 103, 104, 105, 106, 107, 108, 113, 114, 119, 120], "expect": [2, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 43, 46, 48, 57, 61, 66, 70, 71, 72, 73, 76, 78, 79, 80, 83, 85, 86, 87, 89, 90, 95, 97, 106, 119, 120], "yelp": [2, 92, 93, 94, 95], "discuss": [2, 9, 66, 70, 71, 72, 87, 116, 123, 124], "offlin": [2, 26, 48, 58, 89, 116, 117, 123], "prevent": 2, "unnecessari": [2, 119], "essenti": [2, 3, 70, 85, 117], "variant": [2, 3, 66, 81, 106, 107, 116], "frequent": 2, "commerci": 2, "googl": 2, "displai": [2, 5, 17, 92, 93, 94, 95], "twitter": 2, "view": [2, 3, 23, 70, 89, 90, 119], "bipartit": 2, "match": [2, 16, 61, 66, 89, 90, 98, 101, 102, 103, 105, 115, 123], "need": [2, 20, 24, 43, 48, 58, 66, 73, 78, 82, 83, 84, 86, 87, 93, 98, 100, 105, 106, 108, 113, 115, 116, 117, 121, 124], "show": [2, 4, 10, 15, 19, 58, 61, 70, 72, 81, 89, 92, 94, 95, 98, 100, 106, 107], "most": [2, 5, 9, 11, 12, 13, 14, 17, 20, 21, 22, 24, 25, 43, 46, 48, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 70, 71, 72, 73, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 113, 114, 115, 116, 119, 120, 121, 123], "like": [2, 5, 19, 21, 25, 26, 27, 43, 46, 57, 58, 62, 76, 78, 82, 86, 105, 106, 120], "attract": [2, 3, 4, 9, 11, 12, 13, 14, 15, 21, 58, 88, 89, 90, 93, 94, 95, 96, 97, 98, 99, 105], "while": [2, 6, 10, 12, 21, 27, 43, 46, 58, 73, 77, 78, 87, 94, 99, 101, 102, 121, 123], "adher": 2, "budget": 2, "constraint": [2, 5, 9, 10, 13, 20, 64, 96, 97, 98, 99, 105, 115], "feedback": [2, 77, 78, 79, 82, 86, 88, 89, 90, 94, 98, 99, 101, 105, 106, 108, 113, 115], "achiev": [2, 17, 19, 20, 24, 46, 61, 62, 70, 83, 87], "whom": 2, "its": [2, 5, 9, 11, 13, 17, 19, 20, 21, 24, 46, 48, 61, 62, 65, 66, 70, 71, 72, 78, 83, 85, 86, 89, 92, 106, 108, 113, 116, 123, 124], "chanc": 2, "accept": [2, 5], "adult": [2, 96, 97, 98, 99], "combinatori": [2, 94, 96, 97, 99, 101, 104, 105, 115, 123], "world": [2, 77, 78, 82, 86, 92, 97, 106], "across": [2, 85, 86, 96], "retail": 2, "adjust": [2, 10, 87], "period": [2, 11, 119, 120, 121, 123], "rideshar": 2, "servic": [2, 93], "weather": 2, "occur": [2, 72, 116], "outsid": [2, 3, 10], "airlin": 2, "rais": [2, 16, 60, 121], "ticket": 2, "farewel": 2, "date": [2, 85, 87], "rise": [2, 15], "low": [2, 5, 61, 66, 70, 103, 105, 117, 119], "evalut": 2, "section": [2, 4, 6, 15, 17, 19, 20, 21, 24, 66, 67, 70, 72, 116, 119, 121, 123, 124], "harper": 2, "f": [2, 10, 20, 61, 70, 73, 76, 87, 93, 94, 99, 101, 105, 115, 120, 124], "m": [2, 5, 10, 12, 15, 16, 17, 19, 20, 23, 24, 43, 48, 57, 58, 61, 62, 64, 71, 73, 74, 76, 78, 79, 85, 86, 87, 88, 89, 90, 92, 93, 97, 100, 101, 102, 106, 108, 121, 123], "konstan": 2, "j": [2, 9, 11, 13, 14, 15, 16, 17, 19, 20, 21, 24, 25, 27, 28, 43, 58, 62, 70, 72, 73, 77, 78, 85, 86, 87, 88, 89, 90, 94, 100, 101, 102, 103, 104, 106, 113, 114, 116, 121], "acm": [2, 48], "transact": 2, "intellig": [2, 5, 19, 48, 77, 78, 79, 80, 86, 92, 93, 95, 106, 108, 116, 117], "tii": 2, "19": [2, 5, 10, 43, 60, 61, 119, 121], "2015": [2, 5, 46, 57, 66, 70, 76, 77, 93, 96, 98, 106, 116], "asghar": 2, "n": [2, 4, 6, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 43, 46, 48, 57, 58, 59, 60, 61, 62, 64, 65, 66, 70, 71, 72, 73, 75, 76, 78, 79, 81, 82, 83, 84, 85, 86, 87, 92, 93, 94, 96, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 114, 115, 116, 119, 120, 121, 123, 124], "review": [2, 9, 12, 17, 19, 43, 48, 66, 67, 70, 73, 82, 94, 99, 101, 105, 106, 124], "arxiv": [2, 5, 9, 10, 11, 12, 13, 14, 16, 19, 20, 24, 48, 61, 64, 78, 82, 83, 88, 89, 90, 92, 93, 94, 98, 99, 100, 101, 102, 105, 106, 115, 116, 117, 121], "preprint": [2, 5, 9, 10, 11, 12, 13, 14, 16, 19, 20, 24, 48, 61, 64, 78, 82, 83, 88, 89, 90, 92, 93, 94, 98, 99, 100, 101, 102, 105, 106, 115, 116, 117, 121], "1605": 2, "05362": 2, "2016": [2, 5, 61, 66, 70, 92, 93, 94, 98, 101, 116], "asuncion": 2, "newman": 2, "d": [2, 5, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 23, 24, 43, 48, 57, 58, 62, 66, 70, 71, 72, 73, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 105, 106, 113, 114, 115, 116, 121], "uci": 2, "machin": [2, 5, 9, 10, 11, 12, 13, 14, 15, 17, 19, 21, 25, 27, 28, 61, 62, 65, 66, 67, 70, 77, 78, 79, 81, 84, 86, 87, 93, 96, 97, 98, 103, 105, 106, 107, 108, 113, 114, 115, 116], "repositori": [2, 9, 10, 11, 13, 124], "2007": [2, 9, 10, 11, 12, 13, 14, 78], "tsiati": [2, 15, 43, 73, 123], "davidian": [2, 15, 43, 73, 123], "hollowai": [2, 123], "laber": [2, 15, 43, 73, 123], "2019": [2, 3, 5, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 24, 25, 27, 28, 33, 34, 37, 38, 39, 40, 41, 61, 64, 78, 82, 93, 95, 100, 101, 102, 103, 104, 106, 123], "precis": [2, 19, 79, 83, 85, 87, 94, 101, 123], "medicin": [2, 19, 46, 88, 89, 90, 123], "chapman": [2, 123], "hall": [2, 123], "crc": [2, 123], "era": [3, 10], "revolut": [3, 10], "area": [3, 10, 46, 82, 88, 89, 90, 106, 116], "gener": [3, 4, 6, 10, 19, 21, 26, 33, 34, 37, 38, 39, 40, 41, 46, 48, 57, 61, 64, 66, 67, 70, 71, 72, 76, 77, 78, 82, 86, 88, 89, 90, 98, 105, 106, 108, 114, 115, 123, 124], "graph": [3, 10, 123], "direct": [3, 9, 10, 11, 12, 13, 14, 58, 62, 64, 65, 70, 77, 100, 103, 116, 119, 121], "indirect": [3, 10, 12, 119, 121], "mediat": [3, 9, 11, 13, 14, 72, 74], "intermedi": 3, "variabl": [3, 4, 6, 9, 10, 11, 12, 13, 14, 16, 17, 19, 20, 21, 22, 24, 26, 46, 57, 58, 67, 72, 75, 76, 78, 82, 86, 93, 106, 116, 117, 120, 123], "instanc": [3, 46, 60, 87, 94, 101], "outbreak": 3, "coronaviru": [3, 10], "diseas": 3, "chines": [3, 10], "govern": 3, "taken": [3, 59, 62, 75, 86, 89, 90, 123], "extrem": [3, 21, 27], "stop": [3, 88, 89, 90, 93, 105], "viru": 3, "lock": [3, 17], "wuhan": 3, "down": 3, "jan": [3, 9, 10, 11, 12, 13, 14], "23rd": 3, "2020": [3, 5, 9, 11, 12, 13, 14, 16, 18, 19, 20, 23, 24, 48, 78, 79, 83, 92, 97, 99, 102, 103, 106, 108, 116, 117], "12": [3, 5, 9, 10, 11, 12, 13, 14, 22, 26, 43, 57, 58, 60, 78, 106, 117, 119, 120, 121], "citi": [3, 10], "hubei": [3, 10], "lockdown": [3, 10], "directli": [3, 5, 12, 17, 26, 43, 46, 57, 58, 61, 62, 64, 65, 66, 67, 68, 70, 71, 72, 73, 95, 99, 103, 104, 107, 108, 113, 114, 116, 117, 121], "block": [3, 5, 120, 121], "peopl": [3, 25, 26, 27, 28], "stimul": [3, 58], "quarantin": 3, "further": [3, 10, 12, 20, 24, 58, 62, 94, 96, 97, 99, 101, 105, 115, 120, 121, 123], "migrat": 3, "countrywid": 3, "china": [3, 10], "thu": [3, 9, 12, 15, 17, 18, 20, 22, 24, 48, 58, 72, 86, 88, 89, 90], "indirectli": 3, "reduc": [3, 10, 12, 20, 58, 62], "great": [3, 19, 93], "crisi": 3, "mechan": [3, 10, 72], "individu": [3, 4, 6, 10, 15, 21, 26, 28, 43, 46, 48, 57, 59, 62, 73, 75, 76, 100, 105, 115, 120], "decad": 3, "discoveri": [3, 12, 48], "disentangl": [3, 9, 11, 12, 13, 14], "complex": [3, 5, 9, 11, 12, 13, 14, 21, 27, 48, 62, 96, 97, 99, 103, 117, 123], "field": [3, 43, 73, 77], "4": [3, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 26, 27, 28, 43, 46, 48, 57, 58, 60, 62, 70, 73, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 93, 94, 98, 99, 100, 101, 104, 105, 106, 107, 108, 113, 114, 115, 116, 119, 120, 121], "5": [3, 9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 43, 46, 48, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 70, 73, 74, 76, 78, 82, 83, 86, 87, 93, 94, 98, 100, 101, 102, 103, 104, 106, 107, 108, 113, 114, 119, 120, 121], "singl": [3, 21, 25, 27, 48, 61, 70, 73, 76, 107, 108, 113, 114, 119, 123], "nucleotid": 3, "polymorph": 3, "snp": 3, "person": [3, 9, 43, 48, 57, 73, 76, 78, 106, 124], "genom": 3, "fewer": 3, "non": [3, 9, 10, 12, 13, 14, 17, 19, 26, 43, 46, 57, 58, 73, 76, 89, 90], "spuriou": 3, "protein": 3, "systemat": [3, 124], "phenotyp": 3, "focu": [3, 4, 6, 12, 16, 17, 18, 19, 20, 23, 25, 27, 28, 43, 64, 73, 77, 78, 82, 86, 88, 89, 90, 99, 100, 101, 106, 116, 123], "brem": 3, "kruglyak": 3, "2005": [3, 5, 57, 65, 76, 117], "discov": [3, 105], "featur": [3, 4, 6, 12, 15, 16, 23, 26, 46, 48, 59, 78, 79, 80, 85, 86, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 106, 108, 115, 116, 119, 121, 123], "explain": 3, "104": [3, 20, 43, 82], "segreg": 3, "simul": [3, 6, 10, 12, 17, 26, 78, 82, 86, 105], "genet": 3, "divers": [3, 57, 76, 123], "strain": 3, "by4716": 3, "rm11": 3, "1a": [3, 20, 24], "contain": [3, 4, 6, 9, 11, 12, 13, 14, 15, 17, 19, 26, 48, 59, 75, 87, 88, 89, 90, 93, 105, 115, 123, 124], "thousand": [3, 73, 76, 120], "genotyp": 3, "rich": 3, "influenc": [3, 10, 12, 62, 123], "target": [3, 10, 21, 22, 24, 48, 57, 58, 61, 64, 66, 70, 71, 72, 76, 89, 98, 120, 121, 123], "herit": 3, "due": [3, 14, 61, 62, 64, 65, 66, 67, 103, 116, 117, 119, 121, 123], "dimension": [3, 4, 9, 10, 11, 12, 13, 14, 15, 18, 22, 43, 62, 73, 86, 105, 115, 117, 123], "name": [3, 5, 9, 11, 13, 14, 16, 17, 23, 24, 43, 48, 58, 61, 64, 70, 73, 76, 77, 82, 84, 86, 94, 98, 106, 114, 116, 120], "quantit": 3, "loci": 3, "qtl": 3, "involv": [3, 77, 116], "parsimoni": 3, "reveal": 3, "necessari": [3, 4, 6, 79, 94, 95, 96, 97, 101, 102], "depend": [3, 5, 48, 62, 66, 70, 72, 77, 78, 88, 89, 90, 98, 99, 100, 103, 105, 115, 116, 117, 123], "present": [3, 62, 71, 92, 94, 95, 96, 97, 99, 101, 102, 103, 123], "toward": [3, 62, 93, 94, 98, 99, 100, 101, 105], "yer124c": 3, "daughter": 3, "cell": [3, 5, 46, 61, 62, 64, 65, 66, 67, 68, 70, 104, 107, 108, 113, 114], "particip": 3, "pathwai": 3, "wall": 3, "metabol": 3, "delet": [3, 11, 13, 14], "separ": [3, 19, 21, 27, 28, 61, 70, 98], "divis": 3, "sensit": [3, 43, 46, 73], "against": [3, 62], "consid": [4, 6, 9, 11, 12, 13, 14, 19, 43, 57, 58, 59, 61, 62, 64, 65, 66, 70, 71, 72, 73, 76, 78, 79, 82, 83, 85, 86, 87, 92, 93, 94, 96, 97, 99, 100, 101, 102, 105, 108, 113, 115, 121, 123], "popul": [4, 6, 15], "doe": [4, 6, 9, 11, 12, 13, 14, 78, 92, 94, 95, 117, 121, 123], "y": [4, 6, 10, 12, 15, 16, 17, 19, 20, 24, 43, 46, 48, 57, 58, 60, 73, 76, 77, 78, 88, 89, 90, 93, 94, 97, 98, 99, 100, 101, 103, 105, 106, 115, 123], "establish": [4, 6, 14, 57, 62, 76], "respons": [4, 5, 6, 15, 21, 25, 27, 100, 101, 102, 103, 117], "advoc": [4, 6], "neyman": [4, 6], "rubin": [4, 6], "robin": [4, 6, 15, 17, 43, 73], "denot": [4, 6, 9, 11, 13, 19, 20, 21, 24, 26, 27, 48, 58, 61, 62, 64, 65, 66, 70, 71, 72, 77, 78, 82, 85, 86, 88, 89, 90, 93, 98, 100, 105, 106, 115, 116, 119, 123], "vector": [4, 6, 9, 11, 12, 13, 14, 20, 24, 72, 78, 79, 83, 86, 93, 94, 99, 100, 101, 105, 108, 113, 115, 116, 117, 123], "simplic": [4, 6, 21, 66, 96, 97, 99, 123], "simplest": [4, 5, 6, 58], "case": [4, 6, 9, 11, 13, 14, 15, 17, 19, 21, 23, 24, 27, 43, 46, 57, 58, 73, 76, 84, 113, 115, 121, 123, 124], "binari": [4, 6, 10, 17, 26, 43, 46, 57, 59, 73, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 92, 93, 94, 95, 98, 100, 101, 102, 103, 106, 119, 120, 123], "0": [4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 43, 46, 48, 57, 58, 59, 60, 61, 62, 64, 65, 66, 70, 71, 72, 73, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 113, 114, 116, 119, 120, 121, 123], "sai": [4, 6, 9, 11, 13, 14], "versu": [4, 6, 17, 23, 26, 119, 123], "acquir": [4, 6], "app": [4, 6, 120, 121], "download": [4, 6, 17, 22, 58], "baselin": [4, 6, 11, 13, 14, 15, 21, 26, 66, 70, 78, 85, 86, 106], "observ": [4, 5, 6, 9, 11, 13, 15, 17, 19, 20, 21, 22, 24, 25, 46, 48, 57, 59, 61, 62, 64, 66, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 101, 104, 105, 106, 107, 114, 115, 116, 117, 120, 121, 123], "summar": [4, 6, 9, 10, 17, 19, 21, 25, 27, 58, 82, 117, 120, 121, 123], "z_i": [4, 6, 9, 11, 12, 13, 14, 20, 24], "x_i": [4, 15, 46, 48, 58], "t_i": [4, 15, 71, 72], "y_i": [4, 15, 46, 48, 58], "th": [4, 6, 15, 18, 22, 62, 66, 67, 71, 72, 86, 93, 121], "covari": [4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 24, 85, 87, 96, 97, 99, 119], "prior": [4, 6, 11, 77, 78, 79, 83, 85, 86, 87, 94, 95, 96, 97, 99, 101, 102, 103, 106, 108, 113, 121], "assum": [4, 6, 9, 11, 13, 23, 24, 43, 46, 57, 66, 71, 72, 73, 76, 77, 78, 79, 80, 82, 83, 85, 86, 87, 92, 94, 95, 96, 97, 99, 100, 101, 102, 103, 105, 106, 108, 113, 115, 117, 123], "chosen": [4, 6, 16, 17, 18, 19, 20, 23, 25, 27, 28, 64, 72, 78, 89, 90, 93, 94, 98, 100, 101, 102, 103], "henc": [4, 6, 10, 15, 26, 46, 61, 66, 70, 78, 82, 86, 94, 101, 106, 116, 117], "sometim": [4, 6, 116], "refer": [4, 5, 6, 58, 124], "counterfactu": [4, 6, 72, 116], "becaus": [4, 6, 20], "realiti": [4, 6], "hypothet": [4, 6], "contrari": [4, 6], "fact": [4, 6, 61, 62, 64, 65, 70, 71, 78, 116], "actual": [4, 6, 15, 117], "than": [4, 6, 10, 19, 20, 21, 24, 25, 27, 28, 48, 61, 62, 66, 67, 70, 72, 78, 80, 82, 86, 106], "notion": [4, 6], "defin": [4, 5, 6, 10, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 27, 43, 48, 57, 58, 61, 62, 66, 67, 70, 71, 72, 73, 76, 81, 88, 89, 90, 93, 94, 98, 105, 106, 107, 115, 120, 123], "now": [4, 6, 16, 21, 58, 105, 116], "deduc": [4, 6], "x": [4, 6, 15, 17, 18, 19, 20, 22, 23, 24, 43, 46, 48, 57, 58, 60, 77, 79, 80, 85, 87, 88, 89, 90, 95, 96, 106, 108, 115], "sutva": [4, 6, 15, 72], "stabl": [4, 6, 10, 15, 23, 119], "unit": [4, 6, 15, 123], "begin": [4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 43, 46, 48, 57, 58, 61, 62, 64, 65, 66, 67, 70, 71, 72, 73, 76, 79, 80, 81, 83, 84, 85, 87, 88, 89, 90, 92, 93, 94, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 114, 115, 116, 120, 123], "align": [4, 6, 15, 17, 23, 24, 43, 46, 57, 61, 62, 66, 70, 71, 73, 76, 79, 80, 81, 83, 84, 103, 107, 108, 114, 116, 120], "end": [4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 43, 46, 48, 57, 58, 61, 62, 64, 65, 66, 67, 70, 71, 72, 73, 76, 79, 80, 81, 83, 84, 85, 87, 88, 89, 90, 92, 93, 94, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 113, 114, 115, 116, 120, 121, 123], "That": [4, 6, 15, 19, 23, 24, 58], "regardless": [4, 6, 15], "interfer": [4, 6, 15], "No": [4, 6, 9, 11, 13, 14, 15, 17, 43, 46, 48, 57, 58, 61, 62, 64, 65, 66, 67, 68, 70, 73, 76, 79, 80, 81, 83, 84, 85, 86, 87, 92, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 107, 108, 113, 114, 120, 121, 123], "unmeasur": [4, 6, 9, 11, 13, 14, 15, 21, 25, 72, 117], "confound": [4, 5, 6, 9, 11, 12, 13, 14, 15, 21, 25, 72, 117, 120, 121, 123], "strong": [4, 6, 14, 15, 18, 22, 66, 70], "ignor": [4, 6, 15, 66, 70, 73, 76, 88, 89, 90, 120, 124], "perp": [4, 6, 15, 72], "refut": [4, 6, 15], "believ": [4, 6, 15], "relev": [4, 6, 15, 66], "reason": [4, 6, 9, 12, 14, 15, 19, 24], "p": [4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 17, 19, 20, 21, 24, 25, 27, 28, 43, 46, 48, 60, 70, 71, 72, 73, 78, 79, 80, 81, 84, 85, 87, 92, 94, 96, 97, 98, 99, 101, 102, 104, 106, 107, 108, 113, 114, 116, 121, 123, 124], "ensur": [4, 6, 15, 72], "similar": [4, 5, 6, 15, 46, 61, 62, 65, 66, 70, 72, 73, 77, 79, 80, 81, 83, 84, 85, 86, 87, 92, 93, 108, 116, 123], "vice": [4, 6, 15], "versa": [4, 6, 15], "text": [4, 5, 6, 12, 15, 16, 17, 19, 21, 24, 25, 27, 28, 46, 57, 59, 61, 64, 65, 71, 76, 84, 85, 87, 94, 99, 101, 102, 116], "ATE": [4, 6, 12, 17, 19, 25, 27, 121], "There": [4, 5, 6, 19, 58, 59, 84, 116], "deriv": [4, 6, 18, 21, 22, 28, 43, 48, 62, 67, 76, 99, 121], "confoun": 4, "come": [4, 96, 97, 123], "consider": 4, "e_x": [4, 15], "quad": [4, 15, 18, 21, 22, 28, 43, 73, 85, 87, 88, 89, 90, 94, 99, 101], "similarli": [4, 10, 15, 43, 61, 62, 70, 71, 72, 73, 85, 87, 98, 99, 105, 119, 121], "mu": [4, 15, 16, 21, 24, 25, 79, 83, 85, 86, 87, 88, 89, 90, 92, 94, 99, 101, 120], "gamma": [4, 15, 17, 20, 24, 43, 61, 62, 64, 65, 66, 70, 71, 72, 73, 79, 80, 85, 87, 92, 94, 96, 99, 101, 102, 108, 116], "paramet": [4, 9, 11, 15, 17, 18, 20, 22, 24, 48, 79, 81, 84, 85, 87, 94, 99, 100, 101, 103, 106, 107, 108, 121], "mle": 4, "least": [4, 15, 20, 21, 24, 78, 82, 86, 100, 105, 106], "squar": [4, 15, 20, 24], "Then": [4, 9, 10, 11, 12, 13, 14, 15, 18, 22, 67, 73, 76, 78, 82, 84, 86, 88, 89, 90, 94, 99, 101, 105, 106, 114, 115, 116, 124], "hat": [4, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 43, 57, 58, 61, 64, 66, 70, 71, 72, 73, 76, 80, 81, 85, 92, 96, 104, 116], "sum_": [4, 15, 17, 18, 22, 43, 48, 57, 58, 61, 62, 64, 65, 66, 67, 70, 71, 72, 73, 78, 82, 84, 86, 88, 89, 90, 92, 93, 94, 98, 99, 100, 101, 102, 103, 104, 106, 114, 116], "anoth": [4, 5, 9, 17, 19, 58, 66, 67, 70, 116, 120], "pi": [4, 15, 16, 20, 24, 46, 57, 58, 61, 62, 64, 65, 66, 67, 70, 71, 72, 76, 88, 89, 90, 116], "get": [4, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 43, 57, 58, 59, 60, 73, 76, 79, 80, 81, 82, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103, 115, 120], "function": [4, 5, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 43, 46, 48, 57, 58, 61, 62, 64, 65, 66, 70, 72, 73, 78, 80, 81, 85, 88, 89, 90, 94, 96, 97, 99, 100, 101, 102, 105, 106, 107, 115, 116, 123], "One": [4, 15, 61, 70, 116, 124], "difficult": [4, 15, 81], "build": [4, 5, 70, 78, 121, 123, 124], "simpli": [4, 58, 86, 96], "stratifi": 4, "choos": [4, 16, 17, 18, 20, 23, 25, 26, 27, 28, 61, 62, 70, 77, 78, 82, 84, 86, 88, 89, 90, 94, 98, 99, 100, 101, 105, 106, 114, 115], "cutoff": 4, "c_0": 4, "c_1": 4, "c_k": 4, "belong": [4, 26, 64], "k": [4, 5, 9, 10, 11, 12, 13, 14, 20, 24, 48, 58, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 113, 114, 115, 116], "c_": [4, 43, 73, 81, 84, 107, 114], "le": [4, 5, 48, 61, 62, 64, 65, 71, 72, 93], "bar": [4, 18, 22, 66, 72, 75, 76, 116], "_": [4, 9, 11, 13, 14, 15, 16, 17, 18, 19, 21, 22, 24, 25, 27, 28, 43, 46, 48, 57, 58, 59, 61, 62, 64, 65, 66, 67, 70, 71, 72, 73, 75, 76, 79, 83, 85, 86, 87, 88, 89, 90, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104, 105, 106, 108, 113, 114, 115, 116, 123], "1k": 4, "0k": 4, "n_k": 4, "theoret": [4, 19, 62, 72, 87, 100, 105, 115, 124], "justif": 4, "semiparametr": [4, 16, 19, 20, 23, 24, 61, 62, 70], "theori": [4, 17, 19, 20, 24, 43, 46, 62, 73, 78, 100, 101, 103], "augment": [4, 15, 46, 62], "ipw": [4, 15, 58], "probabl": [4, 15, 46, 48, 58, 61, 62, 66, 70, 71, 81, 82, 87, 100, 105, 106, 107], "everi": [4, 15, 61, 66, 70, 78, 82, 85, 86, 87, 92, 94, 99, 101, 102, 106, 116], "themselv": [4, 15], "did": [4, 15, 73, 76, 123], "frac": [4, 15, 16, 17, 18, 20, 22, 24, 43, 46, 48, 57, 58, 61, 62, 66, 70, 73, 81, 84, 100, 101, 102, 103, 104, 106, 107, 114], "ty": 4, "unbias": [4, 15, 66], "left": [4, 15, 18, 20, 22, 23, 24, 48, 58, 61, 70, 73, 88, 89, 90, 123], "right": [4, 9, 12, 15, 18, 20, 22, 23, 24, 48, 58, 61, 64, 65, 70, 73, 88, 89, 90, 116, 123], "t_iy_i": [4, 15], "combin": [4, 15, 20, 21, 24, 25, 27, 28, 58, 61, 62, 70, 84, 86, 116], "obtain": [4, 9, 11, 13, 17, 18, 20, 21, 22, 23, 24, 27, 28, 58, 62, 66, 76, 97, 98, 116, 123], "call": [4, 5, 9, 10, 11, 12, 13, 14, 15, 17, 20, 21, 22, 24, 27, 43, 46, 48, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 70, 73, 76, 79, 80, 81, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104, 107, 108, 113, 114, 120, 121, 124], "whether": [5, 89, 90, 101, 102, 103, 119], "write": [5, 15, 18, 22], "content": [5, 20, 24, 123], "jupyt": [5, 124], "notebook": [5, 120, 121], "ipynb": [5, 9, 14], "regular": [5, 48, 70, 85], "md": 5, "ll": [5, 26], "flavor": 5, "stand": [5, 43, 73, 100], "markedli": 5, "slight": 5, "variat": [5, 9], "commonmark": 5, "small": [5, 46, 119, 123], "syntax": 5, "sphinx": 5, "ecosystem": 5, "power": [5, 20, 24, 124], "tool": [5, 15], "kind": [5, 20, 67], "markup": 5, "languag": [5, 77], "serv": [5, 15, 17, 26, 72], "purpos": [5, 15, 26, 119], "line": [5, 19, 27, 61, 70, 124], "wherea": [5, 72, 121], "span": 5, "input": [5, 17, 20, 26, 60, 119, 120, 121, 123], "being": [5, 81, 84, 86, 87, 93, 94, 99, 100, 101, 103, 105, 107, 114, 119, 120, 121], "At": [5, 71, 73, 76, 78, 79, 81, 83, 84, 93, 94, 96, 99, 101, 106, 107, 108, 113, 114, 120], "insert": 5, "mydirectivenam": 5, "my": [5, 19], "work": [5, 9, 13, 17, 43, 58, 62, 73, 76], "alreadi": [5, 18, 22, 57, 58, 76], "doesn": [5, 123], "pre": [5, 11, 72, 81, 105, 106, 107, 123], "note": [5, 10, 11, 13, 14, 17, 19, 21, 28, 43, 46, 57, 58, 59, 71, 72, 73, 76, 79, 81, 83, 84, 85, 86, 87, 92, 94, 95, 96, 97, 99, 100, 101, 102, 105, 108, 113, 115, 117], "box": 5, "here": [5, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 22, 43, 46, 48, 62, 71, 73, 76, 79, 80, 81, 83, 84, 85, 86, 87, 89, 90, 92, 94, 95, 96, 97, 99, 101, 102, 103, 105, 106, 107, 113, 115, 121], "built": [5, 46, 70], "see": [5, 9, 10, 11, 13, 14, 20, 21, 23, 24, 25, 27, 62, 70, 78, 82, 87, 105, 106, 119, 123], "document": [5, 16, 17, 18, 20, 23, 25, 26, 27, 28, 119, 124], "less": [5, 19, 43, 48, 73, 116], "pattern": [5, 120], "some": [5, 15, 16, 19, 21, 24, 27, 43, 48, 58, 61, 62, 70, 72, 73, 87, 88, 89, 90, 94, 105, 115, 119, 123], "rolenam": 5, "again": [5, 76, 120], "valid": [5, 20, 62, 67, 72, 116], "doc": [5, 10, 23, 119], "page": [5, 16, 19, 20, 23, 24, 66, 77, 98, 105, 106, 115, 117, 124], "rel": [5, 21, 27, 66, 70, 86, 123], "path": [5, 10, 24], "intro": 5, "cite": [5, 70], "store": [5, 89], "bibtex": 5, "holdgraf_evidence_2014": 5, "render": 5, "moreov": [5, 15, 19, 61, 62, 70], "bibliographi": 5, "properli": [5, 9], "bib": 5, "look": [5, 19, 22, 62], "egw05": [5, 65], "damien": [5, 65], "ernst": [5, 65], "pierr": [5, 65], "geurt": [5, 65], "loui": [5, 65], "wehenkel": [5, 65], "tree": [5, 18, 19, 22, 58, 65], "batch": [5, 20, 64, 65, 94, 99, 101, 116], "mode": [5, 24, 65, 73, 76, 94, 99, 101, 120], "learn": [5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 27, 28, 58, 62, 64, 65, 66, 67, 70, 71, 72, 77, 78, 79, 81, 82, 84, 85, 86, 87, 88, 89, 90, 92, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 113, 114, 115, 120, 121, 124], "journal": [5, 9, 10, 11, 12, 13, 14, 16, 19, 20, 23, 24, 43, 46, 58, 65, 72, 73, 74, 78, 88, 89, 90, 100, 117, 121], "hzal18": [5, 116], "tuoma": [5, 116], "haarnoja": [5, 116], "aurick": [5, 116], "zhou": [5, 48, 58, 61, 66, 77, 103, 106, 116], "pieter": [5, 116], "abbeel": [5, 116], "sergei": [5, 116], "levin": [5, 116], "soft": [5, 116], "actor": 5, "off": [5, 48, 61, 64, 66, 67, 70, 82, 88, 89, 90, 95, 106, 116, 117, 124], "maximum": [5, 58, 73, 76, 80, 81, 84, 85, 98, 105, 107, 114, 115, 116], "entropi": [5, 15, 116], "deep": [5, 17, 19, 43, 73, 116, 117, 121, 123], "stochast": [5, 61, 70, 71, 72, 77, 78, 82, 86, 88, 89, 90, 105, 106, 115, 116], "intern": [5, 9, 10, 11, 12, 13, 14, 16, 19, 20, 24, 48, 61, 62, 66, 67, 70, 77, 78, 79, 80, 86, 87, 92, 93, 95, 96, 97, 98, 103, 105, 106, 108, 115, 116, 117, 124], "confer": [5, 9, 10, 11, 12, 13, 14, 17, 19, 48, 61, 62, 66, 67, 70, 77, 78, 79, 80, 86, 87, 92, 93, 95, 96, 97, 98, 100, 101, 103, 105, 106, 108, 115, 116, 117], "1861": [5, 17, 116], "1870": [5, 116], "pmlr": [5, 19, 48, 61, 62, 66, 67, 70, 77, 78, 79, 86, 87, 92, 93, 95, 96, 97, 98, 100, 101, 103, 105, 106, 108, 115, 116], "2018": [5, 9, 10, 11, 12, 14, 15, 17, 43, 46, 48, 58, 66, 70, 71, 72, 73, 77, 81, 98, 100, 102, 106, 107, 113, 114, 116], "hk20": [5, 117], "yichun": [5, 10, 117], "hu": [5, 117], "nathan": [5, 61, 117], "kallu": [5, 48, 61, 117], "dtr": [5, 57, 76, 117, 121, 123], "adapt": [5, 17, 18, 19, 20, 22, 24, 46, 48, 57, 72, 76, 77, 81, 94, 95, 97, 99, 101, 102, 104, 106, 107, 116, 117], "regret": [5, 43, 71, 72, 73, 77, 82, 85, 86, 87, 94, 96, 99, 101, 106, 117], "02791": [5, 117], "jl16": [5, 61, 66], "nan": [5, 10, 20, 61, 64, 66], "jiang": [5, 61, 64, 66, 70, 77, 106], "lihong": [5, 61, 66], "li": [5, 15, 48, 61, 66, 70, 78, 79, 80, 88, 89, 90, 92, 100, 102, 103, 106, 108, 116, 117], "doubli": [5, 6, 16, 19, 20, 24, 43, 48, 58, 62, 66, 70, 73, 88, 90], "robust": [5, 16, 19, 20, 24, 43, 48, 58, 62, 66, 70, 73, 85, 88, 90, 93, 94, 98, 99, 100, 101, 105, 121, 123], "652": [5, 61, 66, 70], "661": [5, 61, 66, 70, 78, 106], "ku19": [5, 61], "masatoshi": [5, 61], "uehara": [5, 61], "effici": [5, 15, 16, 19, 21, 24, 28, 46, 61, 62, 64, 65, 66, 67, 68, 70, 80, 85, 86, 87, 92, 94, 96, 97, 98, 99, 100, 101, 103, 104, 107, 108, 113, 114, 116], "break": [5, 61, 70], "curs": [5, 18, 22, 61, 62, 70], "horizon": [5, 62, 71, 72, 96, 97, 99, 116, 117, 123], "doubl": [5, 15, 17, 20, 24, 70, 89, 116], "1909": [5, 61], "05850": [5, 61], "lvy19": [5, 64], "hoang": [5, 61, 64], "cameron": [5, 61, 64], "voloshin": [5, 61, 64], "yisong": [5, 61, 64], "yue": [5, 9, 10, 11, 12, 13, 14, 61, 64], "1903": [5, 64], "08738": [5, 64], "lltz18": [5, 66], "qiang": [5, 61, 66], "liu": [5, 46, 61, 66, 70], "ziyang": [5, 61, 66], "tang": [5, 61, 66, 70], "dengyong": [5, 61, 66], "infinit": [5, 62, 71, 72, 78, 116, 117, 123], "advanc": [5, 9, 10, 11, 12, 13, 14, 19, 21, 48, 66, 70, 85, 86, 87, 97, 100, 101, 102, 124], "neural": [5, 9, 10, 11, 12, 13, 14, 17, 19, 48, 66, 70, 77, 85, 86, 87, 97, 100, 101, 102, 106], "process": [5, 9, 10, 11, 12, 13, 14, 17, 19, 20, 48, 61, 66, 70, 77, 85, 86, 87, 96, 97, 99, 100, 101, 102, 105, 106, 116, 117, 121, 123], "5356": [5, 66], "5366": [5, 66], "mgkulic21": [5, 117], "lingheng": [5, 117], "meng": [5, 117], "rob": [5, 117], "gorbet": [5, 117], "dana": [5, 117], "kuli": [5, 117], "\u0107": [5, 117], "memori": [5, 20, 117], "pomdp": [5, 117, 123], "2021": [5, 9, 13, 16, 19, 20, 23, 24, 48, 58, 62, 67, 85, 86, 87, 88, 89, 90, 117, 120, 121], "ieee": [5, 117], "rsj": [5, 117], "robot": [5, 117], "iro": [5, 117], "5619": [5, 117], "5626": [5, 21, 117], "mbm": [5, 116], "16": [5, 10, 18, 20, 58, 60, 116, 119, 120, 121], "volodymyr": [5, 116], "mnih": [5, 116], "adria": [5, 116], "puigdomenech": [5, 116], "badia": [5, 116], "mehdi": [5, 116], "mirza": [5, 116], "alex": [5, 116], "grave": [5, 116], "timothi": [5, 116], "lillicrap": [5, 116], "tim": [5, 116], "harlei": [5, 116], "david": [5, 9, 10, 11, 12, 13, 14, 17, 19, 116, 123], "silver": [5, 116], "korai": [5, 116], "kavukcuoglu": [5, 116], "asynchron": [5, 116], "1928": [5, 116], "1937": [5, 116], "mk": [5, 116], "15": [5, 10, 17, 20, 22, 26, 57, 58, 60, 116, 119, 120, 121], "andrei": [5, 116], "rusu": [5, 116], "joel": [5, 116], "veness": [5, 116], "marc": [5, 116], "g": [5, 9, 10, 11, 12, 13, 14, 17, 20, 21, 26, 28, 43, 58, 61, 62, 64, 66, 70, 71, 72, 77, 81, 85, 87, 94, 99, 100, 101, 102, 106, 107, 116, 117, 123], "bellemar": [5, 116], "martin": [5, 72, 116], "riedmil": [5, 116], "andrea": [5, 116], "fidjeland": [5, 116], "georg": [5, 116], "ostrovski": [5, 116], "human": [5, 116], "518": [5, 116], "7540": [5, 116], "529": [5, 116], "533": [5, 88, 89, 90, 116], "pre00": [5, 66], "doina": [5, 66], "precup": [5, 66, 70], "elig": [5, 66, 70, 116], "trace": [5, 66, 70, 116], "comput": [5, 9, 13, 19, 66, 70, 78, 85, 94, 100, 101, 102, 103, 116], "scienc": [5, 9, 10, 11, 12, 13, 14, 19, 21, 25, 27, 28, 43, 66, 70, 73, 94, 101, 123], "depart": [5, 66, 70], "faculti": [5, 66, 70], "public": [5, 22, 66, 70], "80": [5, 43, 58, 60, 66, 70, 73], "2000": [5, 9, 10, 11, 12, 13, 14, 57, 66, 70, 76, 99, 107, 108, 113, 114], "put14": [5, 72], "l": [5, 20, 23, 24, 48, 61, 70, 71, 72, 77, 78, 79, 80, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 121], "puterman": [5, 71, 72], "markov": [5, 9, 11, 13, 14, 66, 93, 116, 117, 123], "dynam": [5, 15, 43, 46, 48, 57, 71, 72, 73, 76, 101, 103, 104, 105, 115, 116, 117, 121, 123], "program": [5, 71, 72, 94, 100, 101, 103], "wilei": [5, 71, 72], "son": [5, 71, 72], "2014": [5, 9, 10, 11, 12, 13, 14, 43, 58, 71, 72, 73], "sla": [5, 116], "schulman": [5, 116], "michael": [5, 116], "jordan": [5, 116], "philipp": [5, 116], "moritz": [5, 116], "trust": [5, 116], "region": [5, 116], "1889": [5, 116], "1897": [5, 116], "swd": [5, 116], "17": [5, 10, 58, 60, 116, 119, 121], "filip": [5, 116], "wolski": [5, 116], "prafulla": [5, 116], "dhariw": [5, 116], "alec": [5, 116], "radford": [5, 116], "oleg": [5, 116], "klimov": [5, 116], "proxim": [5, 116], "algorithm": [5, 9, 10, 12, 19, 20, 21, 24, 25, 27, 28, 46, 61, 65, 71, 72, 78, 79, 82, 85, 86, 87, 88, 89, 90, 92, 95, 96, 97, 102, 103, 116, 120, 123, 124], "1707": [5, 83, 105, 106, 115, 116], "06347": [5, 116], "2017": [5, 9, 10, 11, 12, 13, 14, 16, 19, 20, 22, 24, 58, 74, 77, 83, 100, 101, 103, 105, 106, 115, 116, 117, 121], "swcs21": [5, 62], "chengchun": [5, 62, 116, 117], "shi": [5, 17, 19, 43, 48, 62, 67, 72, 73, 116, 117, 121], "runzh": [5, 62], "wan": [5, 62, 67, 85, 86, 93, 94, 98, 99, 100, 101, 105], "victor": [5, 17, 19, 62], "chernozhukov": [5, 15, 17, 62, 67], "rui": [5, 9, 10, 11, 12, 13, 14, 46, 58, 62, 116, 117], "song": [5, 9, 10, 11, 12, 13, 14, 43, 46, 48, 57, 58, 62, 73, 76, 85, 86, 88, 89, 90, 93, 94, 98, 99, 100, 101, 105, 116, 117, 121], "deepli": [5, 67], "debias": [5, 15, 17, 67], "interv": [5, 18, 22, 48, 57, 58, 62, 71, 72, 88, 89, 90, 116, 117], "9580": [5, 62, 67], "9591": [5, 62, 67], "swl": [5, 72], "20": [5, 9, 10, 14, 18, 22, 43, 48, 57, 58, 60, 72, 99, 101, 102, 119], "shi2020reinforc": [5, 72], "szls20": [5, 116], "sheng": [5, 116], "zhang": [5, 15, 77, 103, 106, 116], "wenbin": [5, 9, 10, 11, 12, 13, 14, 116], "lu": [5, 9, 10, 11, 12, 13, 14, 43, 48, 73, 88, 89, 90, 106, 116], "2001": [5, 26, 116, 119], "04515": [5, 116], "szy": [5, 117], "22": [5, 10, 18, 22, 43, 57, 60, 116, 117], "jin": [5, 100, 102, 117], "zhu": [5, 9, 10, 11, 12, 13, 14, 48, 100, 102, 117], "shen": [5, 77, 88, 89, 90, 106, 117], "ye": [5, 9, 117, 123], "shikai": [5, 117], "luo": [5, 117], "hongtu": [5, 117], "confid": [5, 16, 19, 20, 24, 57, 80, 82, 84, 88, 89, 90, 104, 114, 116, 117], "american": [5, 46, 58, 88, 89, 90, 117], "2022": [5, 18, 22, 86, 93, 94, 98, 99, 100, 101, 105, 117], "ss96": [5, 116], "satind": [5, 116], "singh": [5, 116], "richard": [5, 9, 10, 11, 12, 13, 14, 72, 116], "sutton": [5, 71, 72, 81, 106, 107, 116], "replac": [5, 10, 12, 43, 48, 58, 62, 66, 70, 116], "123": [5, 10, 20, 116, 119], "158": [5, 76, 116], "1996": [5, 116], "spa12": [5, 117], "matthij": [5, 117], "tj": [5, 73, 117], "spaan": [5, 117], "partial": [5, 10, 12, 23, 24, 26, 43, 73, 96, 97, 99, 117, 119, 123], "state": [5, 6, 11, 13, 14, 19, 21, 26, 27, 58, 61, 62, 64, 65, 66, 70, 71, 72, 116, 117, 121], "art": [5, 11, 13, 14, 19, 61, 70, 117, 123], "387": [5, 117], "414": [5, 117], "2012": [5, 26, 46, 77, 100, 105, 115, 117, 119], "sut88": [5, 116], "tempor": [5, 9, 10, 66, 70, 116], "9": [5, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 43, 57, 58, 60, 70, 73, 76, 106, 108, 113, 116, 119, 120, 121], "44": [5, 58, 60, 116, 119], "1988": [5, 16, 19, 20, 23, 24, 94, 116], "sb18": [5, 72, 116], "andrew": [5, 72, 116], "barto": [5, 71, 72, 81, 106, 107, 116], "mit": [5, 71, 72, 81, 106, 107, 116], "press": [5, 71, 72, 81, 83, 106, 107, 116], "tfl": [5, 61], "yihao": [5, 61], "feng": [5, 61], "bia": [5, 15, 21, 22, 24, 46, 48, 58, 61, 62, 64, 66, 70, 117, 119], "reduct": [5, 61, 117], "represent": [5, 9, 10, 11, 12, 13, 14, 46, 61], "tb16": [5, 61], "philip": [5, 61, 66], "thoma": [5, 61, 66, 70], "emma": [5, 61], "brunskil": [5, 61], "2139": [5, 61], "2148": [5, 61], "tho15": [5, 66], "safe": [5, 20, 66, 70], "doctor": [5, 12, 66], "dissert": [5, 66], "univers": [5, 66, 83, 106], "massachusett": [5, 66], "amherst": [5, 66], "uhj19": [5, 61], "jiawei": [5, 61], "huang": [5, 61], "minimax": [5, 61, 62], "weight": [5, 9, 10, 11, 12, 13, 14, 15, 17, 18, 20, 21, 22, 24, 28, 61, 62, 66, 70, 98, 105, 115, 123], "1910": [5, 61], "12809": [5, 61], "vhgs16": [5, 116], "hado": [5, 116], "van": [5, 16, 19, 20, 24, 74, 83, 99, 105, 106, 113, 114, 115, 116, 121], "hasselt": [5, 116], "arthur": [5, 116], "guez": [5, 116], "proceed": [5, 19, 21, 25, 27, 28, 43, 48, 73, 78, 80, 106, 116], "aaai": [5, 116], "artifici": [5, 19, 48, 77, 78, 79, 80, 86, 92, 93, 95, 106, 108, 116], "volum": [5, 116], "30": [5, 10, 26, 60, 116], "vljy19": [5, 61, 64], "empir": [5, 61, 64, 66, 72, 78, 82, 106], "1911": [5, 61, 64], "06854": [5, 61, 64], "zlpm17": [5, 117], "pengfei": [5, 117], "xin": [5, 117], "pascal": [5, 117], "poupart": [5, 117], "guanghui": [5, 117], "miao": [5, 117], "On": [5, 46, 48, 117], "1704": [5, 117], "07978": [5, 117], "If": [5, 57, 73, 76, 85, 86, 92, 96, 99, 105, 115, 124], "insid": 5, "jupytext": 5, "metadata": [5, 22, 85, 86], "run": [5, 10, 14, 17, 20, 116], "command": [5, 124], "init": 5, "print": [5, 11, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 43, 57, 60, 73, 76, 119, 120], "default": [5, 9, 11, 20, 57, 58, 85, 87, 92, 116, 124], "kernel": [5, 18, 19, 20, 22, 24, 46, 48, 61, 70, 71, 72, 116, 123], "output": [5, 11, 17, 48], "rest": [5, 6, 10, 12, 17, 88, 89, 90, 119], "nb": 5, "r": [6, 10, 12, 15, 16, 17, 18, 19, 21, 22, 25, 27, 28, 43, 48, 57, 58, 59, 61, 66, 67, 70, 71, 72, 73, 75, 76, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 113, 114, 115, 116, 119, 120, 121, 123], "s_i": [6, 15, 17, 18, 19, 20, 21, 22, 23, 24, 28, 123], "a_i": [6, 15, 17, 18, 19, 20, 22, 23, 24, 46, 48, 58, 59, 88, 89, 90, 123], "r_i": [6, 15, 17, 18, 19, 20, 21, 22, 23, 24, 28, 43, 59, 73, 75, 88, 89, 90, 123], "equival": [6, 9, 10, 11, 12, 13, 14, 46, 62, 77, 82, 106], "pearl": [6, 9, 10, 11, 12, 13, 14], "spirt": [6, 9, 10, 11, 12, 13, 14], "mathemat": [6, 10, 12, 43, 73, 98, 105, 115], "physic": [6, 10, 12, 123], "hold": [6, 10, 12, 66, 70, 71, 72], "constant": [6, 10, 12, 21, 27, 46], "unchang": [6, 10, 12], "regress": [6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 23, 24, 25, 27, 28, 43, 57, 58, 64, 66, 70, 73, 76, 94, 120], "propens": [6, 12, 15, 16, 17, 20, 21, 23, 24, 28, 43, 48, 58, 66, 70, 73], "score": [6, 9, 12, 15, 16, 17, 20, 21, 23, 24, 26, 28, 43, 48, 58, 66, 70, 73, 119, 123], "roust": 6, "introduc": [6, 15, 17, 18, 19, 20, 21, 22, 24, 25, 28, 43, 61, 62, 66, 67, 70, 71, 72, 73, 76, 77, 78, 84, 85, 87, 88, 89, 90, 93, 100, 103, 106, 114, 116, 117, 123, 124], "cel": [6, 17], "detail": [6, 10, 12, 15, 16, 17, 19, 20, 21, 24, 28, 59, 62, 82, 106, 123, 124], "hte": [6, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 119], "captur": [6, 17, 18, 21, 22, 48, 89, 90], "heterogenieti": 6, "quit": [6, 17, 19, 21, 66, 70, 123], "few": [6, 19, 61, 70, 72, 78, 82, 86, 98, 106, 123], "deal": [6, 94, 95, 99, 101, 104, 123], "reli": [9, 12, 13, 61, 70], "locat": [9, 12], "reward": [9, 12, 15, 19, 21, 22, 24, 26, 46, 57, 58, 59, 66, 71, 72, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 113, 114, 115, 116, 121, 123], "conveni": [9, 12], "violat": [9, 12, 62], "emerg": [9, 12], "basic": [9, 15, 16, 21, 24, 25, 28, 43, 96, 97, 99, 123], "wai": [9, 21, 23, 24, 28, 46, 58, 61, 62, 64, 65, 66, 67, 68, 70, 76, 104, 107, 108, 113, 114, 116], "mathcal": [9, 10, 11, 12, 13, 14, 43, 48, 61, 62, 66, 70, 71, 72, 73, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 113, 114, 115, 116, 123], "mathbf": [9, 10, 11, 12, 13, 14], "z": [9, 10, 11, 12, 13, 14, 16, 17, 19, 20, 24, 70, 83, 92, 93, 95, 96, 98, 105, 106, 113, 114, 115, 121], "node": [9, 11, 12, 13, 14, 123], "edg": [9, 10, 11, 12, 13, 14], "said": [9, 11, 12, 13, 14], "parent": [9, 11, 12, 13, 14, 124], "z_j": [9, 11, 12, 13, 14], "let": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 27, 28, 48, 57, 61, 62, 66, 70, 71, 72, 75, 78, 82, 86, 93, 98, 100, 105, 106, 115, 116], "pa_": [9, 11, 12, 13, 14], "cycl": [9, 11, 12, 13, 14], "acycl": [9, 10, 11, 12, 13, 14], "dag": [9, 10, 11, 12, 13, 14, 119], "character": [9, 10, 11, 12, 13, 14, 65, 71, 89, 90, 92, 94, 100, 105, 115], "z_1": [9, 11, 12, 13, 14], "z_2": [9, 11, 12, 13, 14], "z_d": [9, 11, 12, 13, 14], "rightarrow": [9, 11, 12, 13, 14, 20, 24], "mean": [9, 11, 12, 13, 14, 19, 48, 57, 58, 60, 61, 66, 70, 72, 73, 76, 79, 81, 83, 84, 85, 87, 88, 89, 90, 94, 96, 97, 98, 99, 101, 102, 106, 107, 108, 113, 114, 116, 119, 123], "propos": [9, 10, 13, 14, 17, 46, 48, 61, 62, 66, 67, 70, 73, 88, 89, 90, 92, 121, 123], "plusibl": 9, "up": [9, 13, 18, 20, 22, 24, 72, 77, 85, 87, 116, 123], "markovian": 9, "unless": [9, 14], "certain": [9, 17, 58, 72, 117], "assumpt": [9, 11, 13, 14, 16, 17, 19, 21, 24, 25, 46, 62, 66, 70, 72, 77, 78, 89, 93, 94, 99, 101, 116, 117, 123], "specifi": [9, 10, 11, 15, 18, 22, 23, 24, 43, 46, 57, 59, 62, 72, 73, 76, 89, 106, 107, 108, 113, 120], "type": [9, 15, 59, 60, 61, 62, 64, 65, 66, 67, 70, 73, 76, 78, 82, 83, 86, 88, 89, 100, 101, 102, 103, 104, 106, 120, 123, 124], "focus": [9, 19, 58, 66, 82, 93, 105, 106, 115, 116, 123], "local": [9, 14, 18, 19, 20, 21, 22, 24, 58, 124], "independ": [9, 10, 11, 12, 13, 14, 15, 20, 24, 58, 59, 72, 96, 116], "skeleton": [9, 123], "orient": [9, 10, 14], "pc": [9, 10, 11, 12, 13, 123], "et": [9, 11, 12, 14, 15, 16, 24, 46, 58, 61, 62, 66, 67, 70, 72, 81, 84, 88, 89, 90, 92, 96, 106, 107, 114, 116], "al": [9, 11, 12, 14, 15, 16, 24, 46, 58, 61, 62, 66, 67, 70, 72, 81, 84, 88, 89, 90, 92, 96, 106, 107, 114, 116], "kalisch": [9, 10, 11, 12, 13, 14], "b\u00fchlmann": [9, 10, 11, 12, 13, 14], "easi": [9, 14, 19, 21, 23, 24, 25, 57, 64, 66, 76, 81, 100], "shah": [9, 10, 11, 12, 13, 14], "peter": [9, 10, 11, 12, 13, 14, 16, 19, 20, 23, 24], "second": [9, 15, 21, 27, 43, 48, 62, 73, 92, 94, 95, 116, 123], "ica": [9, 13, 14], "lingam": [9, 13, 14, 123], "shimizu": [9, 10, 11, 12, 13, 14], "2006": [9, 10, 11, 12, 13, 14, 16, 19, 20, 24, 95], "cam": [9, 10, 11, 12, 13, 14], "last": [9, 10, 11, 13, 14, 15, 17, 20, 21, 22, 24, 26, 43, 46, 48, 57, 58, 59, 60, 61, 62, 64, 65, 66, 67, 68, 70, 71, 73, 76, 79, 80, 81, 83, 84, 85, 87, 89, 90, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104, 107, 108, 113, 114, 120, 121, 123], "greedi": [9, 10, 11, 12, 13, 14, 82, 88, 89, 90, 107, 116, 123], "search": [9, 10, 11, 12, 13, 14, 93, 116], "ge": [9, 61, 62, 66, 70, 71, 72, 85, 86, 93, 94, 98, 99, 100, 101, 105, 116, 121], "chicker": [9, 10, 11, 12, 13, 14], "2002": [9, 10, 11, 12, 13, 14, 78, 81, 84, 106, 107, 114], "fge": 9, "ramsei": [9, 10, 11, 12, 13, 14], "bayesian": [9, 10, 11, 12, 13, 14, 85, 86, 94, 95, 97, 99, 101], "zheng": [9, 10, 11, 12, 14, 74, 121], "open": [9, 10, 26, 73, 76, 119, 120, 121, 124], "construct": [9, 10, 11, 12, 13, 14, 16, 20, 21, 24, 25, 61, 62, 64, 66, 67, 70, 85, 116], "notear": [9, 11, 14, 119, 123], "vae": [9, 13], "parameter": [9, 13, 85, 87, 94, 99, 101, 116], "network": [9, 10, 11, 12, 13, 14, 17, 19, 48, 58], "yu": [9, 10, 11, 12, 13, 14, 19, 21, 25, 27, 28, 46, 58], "friendli": [9, 13], "gnn": [9, 10, 11, 12, 13, 14], "chen": [9, 10, 11, 12, 13, 14, 88, 89, 90, 97, 98, 105, 115], "cai": [9, 11, 12, 13, 14, 48, 88, 89, 90], "cut": [9, 13], "support": [9, 20, 24, 72, 78, 83, 84, 87, 116, 123], "train": [9, 10, 16, 17, 18, 19, 20, 22, 23, 24, 43, 46, 57, 60, 73, 76, 79, 80, 92, 120, 121, 123], "free": [9, 64, 123], "gaussian": [9, 10, 12, 13, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 96, 97, 99, 108, 113, 123], "o": [9, 10, 11, 12, 13, 14, 15, 17, 123], "max": [9, 48, 57, 58, 61, 70, 76, 123], "adjac": [9, 10, 11, 13, 14, 123], "b_": [9, 11, 13, 14], "leq": [9, 11, 13, 14, 88, 89, 90, 98, 100, 123], "matrix": [9, 10, 11, 13, 14, 79, 83, 85, 94, 96, 97, 99, 101, 102, 105, 119, 121], "otherwis": [9, 11, 13, 14, 57, 59, 76, 81, 87, 93, 107, 124], "nest": [9, 11, 13, 14, 43, 73], "faith": [9, 11, 13, 14], "suffici": [9, 11, 13, 14, 17, 61, 66], "pair": [9, 11, 13, 14, 61, 62, 66, 70, 72, 79, 83, 94, 95, 97, 101, 102, 103, 108, 113], "epsilon": [9, 11, 13, 14, 17, 23, 24, 58, 82, 88, 89, 90, 107, 116, 123], "label": [9, 10, 11, 13, 14, 46, 48, 61, 62, 64, 66, 67, 70, 71, 72, 85, 88, 89, 90, 93, 94, 99, 100, 101, 105, 115, 116], "lsem_x": [9, 11, 13, 14], "jointli": [9, 11, 13, 14, 43, 73], "error": [9, 11, 13, 14, 16, 19, 43, 57, 73, 76, 120], "plu": [9, 11, 13], "n_i": [9, 11, 13], "anm": [9, 11, 13], "f_i": [9, 11, 13], "special": [9, 11, 13, 121, 123], "handl": [9, 11, 13, 14, 19, 21, 24, 48, 66, 70, 73, 76, 106, 119, 120, 123], "version": [9, 11, 13, 16, 17, 18, 22, 61, 62, 66, 70, 78, 81, 82, 100, 106, 107, 117, 120, 121], "f_2": [9, 13], "f_1": [9, 13], "nonlinear": [9, 13, 21, 27], "transform": [9, 13, 43], "fisher": [9, 14], "implement": [9, 11, 13, 14, 18, 19, 21, 22, 25, 46, 48, 57, 58, 64, 66, 76, 85, 87, 88, 89, 90, 123, 124], "py": [9, 10, 11, 13, 14, 16, 17, 20, 21, 22, 23, 24, 27, 43, 46, 48, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 70, 73, 76, 79, 80, 81, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104, 107, 108, 113, 114, 119, 120, 121], "packag": [9, 10, 11, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 43, 46, 57, 58, 59, 60, 73, 76, 94, 101, 119, 120, 121, 124], "http": [9, 10, 11, 13, 14, 17, 22, 23, 26, 59, 119, 124], "github": [9, 10, 11, 13, 14, 17, 79, 80, 81, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103, 124], "com": [9, 10, 11, 13, 14, 17, 26, 59, 124], "bd2kccd": [9, 14], "highli": [9, 14], "java": [9, 14], "blob": [9, 14], "20pc": [9, 14], "20in": [9, 14], "20action": [9, 14], "recov": [9, 11], "hyper": [9, 11, 84, 121], "cdt15": [9, 11], "xunzheng": [9, 13], "incorpor": [9, 10, 19, 81, 83, 106, 107], "auto": 9, "encod": [9, 73, 76, 120], "modifi": [9, 12, 17, 79, 83, 94, 95, 96, 97, 99, 101, 102, 108, 113, 121], "smooth": [9, 48], "evid": 9, "lower": [9, 11, 13, 14, 58, 61, 66, 70, 89, 96, 120], "bound": [9, 19, 20, 24, 61, 62, 70, 71, 72, 80, 82, 84, 87, 88, 89, 90, 96, 104, 114], "loss": [9, 10, 17, 19, 20, 71, 72, 123], "fishmoon1234": 9, "pytorch": [9, 10], "paszk": 9, "anoc": [9, 11, 12, 13, 14], "cvae": 9, "constrain": [9, 10, 11, 12, 13, 14], "novel": [9, 10, 17, 70], "identif": [9, 10, 11, 12, 13, 14, 123, 124], "publicli": [9, 10, 119], "anonym": [9, 10, 26, 119], "judea": [9, 10, 11, 12, 13, 14], "survei": [9, 10, 11, 12, 13, 14, 78, 82, 98, 100, 106, 124], "96": [9, 10, 11, 12, 13, 14, 20, 43, 57, 60, 113, 114, 119], "146": [9, 10, 11, 12, 13, 14, 82], "2009": [9, 10, 11, 12, 13, 14], "pater": [9, 10, 11, 12, 13, 14], "clark": [9, 10, 11, 12, 13, 14], "glymour": [9, 10, 11, 12, 13, 14], "schein": [9, 10, 11, 12, 13, 14], "stuart": [9, 10, 11, 12, 13, 14], "kauffman": [9, 10, 11, 12, 13, 14], "valerio": [9, 10, 11, 12, 13, 14], "aimal": [9, 10, 11, 12, 13, 14], "frank": [9, 10, 11, 12, 13, 14], "wimberli": [9, 10, 11, 12, 13, 14], "gene": [9, 10, 11, 12, 13, 14], "express": [9, 10, 11, 12, 13, 14, 18, 21, 22, 25, 61, 70, 77, 83], "microarrai": [9, 10, 11, 12, 13, 14], "marku": [9, 10, 11, 12, 13, 14], "8": [9, 10, 11, 12, 13, 14, 16, 18, 19, 20, 21, 23, 24, 25, 27, 28, 57, 58, 60, 62, 66, 67, 70, 76, 78, 106, 108, 113, 119, 120, 121], "mar": [9, 10, 11, 12, 13, 14], "613": [9, 10, 11, 12, 13, 14], "636": [9, 10, 11, 12, 13, 14], "rajen": [9, 10, 11, 12, 13, 14], "jona": [9, 10, 11, 12, 13, 14], "hard": [9, 10, 11, 12, 13, 14], "generalis": [9, 10, 11, 12, 13, 14], "1804": [9, 10, 11, 12, 13, 14], "07203": [9, 10, 11, 12, 13, 14], "shohei": [9, 10, 11, 12, 13, 14], "patrik": [9, 10, 11, 12, 13, 14], "hoyer": [9, 10, 11, 12, 13, 14], "aapo": [9, 10, 11, 12, 13, 14], "hyv\u00e4rinen": [9, 10, 11, 12, 13, 14], "antti": [9, 10, 11, 12, 13, 14], "kerminen": [9, 10, 11, 12, 13, 14], "7": [9, 10, 11, 12, 13, 14, 16, 17, 19, 20, 21, 23, 24, 25, 26, 27, 28, 46, 48, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 70, 78, 93, 100, 104, 106, 107, 108, 113, 114, 119, 120, 121], "oct": [9, 10, 11, 12, 13, 14], "2003": [9, 10, 11, 12, 13, 14, 43, 73], "2030": [9, 10, 11, 12, 13, 14], "6": [9, 10, 11, 12, 13, 14, 16, 17, 18, 21, 22, 23, 25, 26, 27, 28, 43, 46, 48, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 70, 76, 78, 100, 104, 105, 106, 107, 108, 113, 114, 119, 121], "ernest": [9, 10, 11, 12, 13, 14], "penal": [9, 10, 11, 12, 13, 14, 19, 46, 57, 76], "annal": [9, 10, 11, 12, 13, 14, 18, 19, 22, 33, 34, 37, 38, 39, 40, 41, 43, 73], "42": [9, 10, 11, 12, 13, 14, 58, 60, 79, 80, 81, 83, 84, 85, 87, 107, 108, 113, 114], "2526": [9, 10, 11, 12, 13, 14], "2556": [9, 10, 11, 12, 13, 14], "maxwel": [9, 10, 11, 12, 13, 14], "nov": [9, 10, 11, 12, 13, 14], "507": [9, 10, 11, 12, 13, 14, 95], "554": [9, 10, 11, 12, 13, 14], "joseph": [9, 10, 11, 12, 13, 14], "madelyn": [9, 10, 11, 12, 13, 14], "ruben": [9, 10, 11, 12, 13, 14], "sanchez": [9, 10, 11, 12, 13, 14], "romero": [9, 10, 11, 12, 13, 14], "magnet": [9, 10, 11, 12, 13, 14], "reson": [9, 10, 11, 12, 13, 14], "imag": [9, 10, 11, 12, 13, 14, 17], "analyt": [9, 10, 11, 12, 13, 14, 59], "121": [9, 10, 11, 12, 13, 14, 20, 26], "129": [9, 10, 11, 12, 13, 14, 119], "xun": [9, 10, 11, 12, 13, 14], "bryon": [9, 10, 11, 12, 13, 14], "aragam": [9, 10, 11, 12, 13, 14], "pradeep": [9, 10, 11, 12, 13, 14], "ravikumar": [9, 10, 11, 12, 13, 14], "eric": [9, 10, 11, 12, 13, 14], "xing": [9, 10, 11, 12, 13, 14], "tear": [9, 10, 11, 12, 13, 14], "pp": [9, 10, 11, 12, 13, 14, 43, 48, 73, 77, 78, 79, 80, 86, 87, 92, 93, 95, 96, 97, 98, 100, 101, 103, 108], "9472": [9, 10, 11, 12, 13, 14], "9483": [9, 10, 11, 12, 13, 14], "10": [9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 43, 46, 48, 57, 58, 60, 80, 94, 96, 97, 99, 101, 106, 119, 120, 121], "jie": [9, 10, 11, 12, 13, 14], "tian": [9, 10, 11, 12, 13, 14], "gao": [9, 10, 11, 12, 13, 14], "mo": [9, 10, 11, 12, 13, 14], "1904": [9, 10, 11, 12, 13, 14, 78, 82, 106], "10098": [9, 10, 11, 12, 13, 14], "11": [9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 23, 25, 26, 27, 28, 43, 57, 58, 60, 70, 106, 113, 114, 119, 120, 121], "shengyu": [9, 10, 11, 12, 13, 14], "zhitang": [9, 10, 11, 12, 13, 14], "1906": [9, 10, 11, 12, 13, 14], "04477": [9, 10, 11, 12, 13, 14], "hengrui": [9, 10, 11, 12, 13, 14], "demand": 10, "kei": [10, 17, 26, 46, 48, 66, 93, 124], "factor": [10, 66, 71, 72, 93, 94, 95, 96, 97, 99, 100, 105], "guid": [10, 80, 83, 85, 87, 106, 108, 113, 116], "downstream": 10, "task": [10, 20, 62, 64, 66, 70, 72, 77, 82, 86, 87, 106], "m_1": [10, 12], "m_2": [10, 12], "m_p": [10, 12], "dimens": [10, 12, 117], "give": [10, 18, 22, 25, 27, 28, 71, 78, 82, 86, 106, 120, 121], "te": [10, 12, 121], "de": [10, 12, 62, 77, 106], "ie": [10, 12], "equat": [10, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 48, 58, 61, 62, 64, 65, 66, 67, 70, 71, 73, 84, 85, 87, 88, 89, 90, 92, 93, 94, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 114, 115, 116], "split": [10, 12, 15, 18, 22, 61, 62, 70, 92, 93, 94, 98, 99, 101, 105, 115, 116, 119], "remov": [10, 11, 12, 46, 120, 121], "citet": [10, 67, 70], "pearl2009caus": 10, "dm": [10, 15, 61, 64, 70], "dm_i": 10, "big": [10, 15, 16, 17, 18, 20, 22, 24, 43, 46, 48, 61, 62, 64, 65, 66, 70, 71, 73, 85, 89, 92, 101, 116], "m_i": 10, "_i": [10, 21, 28, 43, 58, 59, 79, 88, 89, 90, 94, 99, 101, 105, 108, 115], "omega_i": 10, "setminu": 10, "except": [10, 17, 73], "im": [10, 121], "def_im": 10, "im_i": 10, "firstli": [10, 84, 106, 114], "sourc": [10, 124], "degre": [10, 11, 13, 14, 19, 20, 24, 92], "freedom": 10, "smaller": [10, 21, 24, 119], "decompos": [10, 62, 94, 99, 101, 121], "compon": [10, 11, 57, 61, 70, 71, 121, 123], "row": [10, 16, 17, 18, 20, 21, 23, 25, 26, 27, 28, 58, 77, 119], "compos": 10, "investig": [10, 78], "spread": 10, "major": [10, 57, 78, 83, 94, 99, 101, 106, 108, 113, 116, 121], "panda": [10, 11, 16, 17, 18, 20, 22, 23, 25, 26, 27, 28, 58, 60, 73, 76, 119, 120, 121], "pd": [10, 14, 16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 43, 57, 58, 60, 73, 76, 119, 120, 121], "os": [10, 11, 13, 14, 46, 61, 62, 64, 65, 66, 67, 68, 70, 79, 80, 81, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104, 107, 108, 113, 114, 119, 120, 121], "pickl": [10, 26, 48, 119, 121], "data_typ": 10, "realdata": 10, "real_data_fil": 10, "covid19": 10, "pkl": 10, "epoch": [10, 17, 100, 101, 102, 103, 104], "100": [10, 15, 24, 43, 48, 58, 60, 73, 85, 101, 102, 106, 119], "node_numb": 10, "32": [10, 16, 19, 20, 24, 60, 78, 100, 101, 102, 119], "sample_s": 10, "38": [10, 18, 22, 43, 58, 60], "batch_siz": [10, 17], "rep_numb": 10, "namespac": 10, "simu_g_fil": 10, "s1_trueg": 10, "graph_degre": 10, "a_typ": [10, 11, 13, 14], "seed": [10, 11, 13, 14, 16, 20, 21, 22, 23, 24, 46, 48, 58, 60, 79, 80, 81, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104, 106, 107, 108, 113, 114, 119, 121], "2333": [10, 48], "k_max_it": 10, "original_lr": 10, "003": [10, 43], "alinaxu": [10, 16, 17, 18, 20, 23, 24, 25, 26, 27, 28], "opt": [10, 11, 16, 17, 18, 20, 21, 22, 23, 24, 43, 57, 60, 73, 76, 120], "anaconda3": [10, 11, 16, 17, 18, 20, 21, 22, 23, 24, 43, 57, 60, 73, 76, 120], "lib": [10, 11, 16, 17, 18, 20, 21, 22, 23, 24, 43, 57, 58, 60, 73, 76, 120, 121], "python3": [10, 11, 16, 17, 18, 20, 21, 22, 23, 24, 43, 57, 58, 60, 73, 76, 120, 121], "torch": 10, "lr_schedul": 10, "138": [10, 20, 119], "userwarn": [10, 17, 23], "detect": [10, 48], "step": [10, 16, 17, 20, 21, 23, 24, 25, 27, 28, 46, 58, 60, 61, 62, 66, 70, 75, 88, 89, 90, 116, 121], "later": [10, 26, 43, 46, 61, 62, 64, 65, 66, 67, 68, 70, 73, 104, 107, 108, 113, 114], "opposit": [10, 46], "failur": [10, 26, 119], "skip": [10, 17], "schedul": [10, 20, 85, 87, 101, 104], "org": [10, 22, 23, 119], "html": [10, 23, 59, 119, 124], "warn": [10, 16, 23, 43, 57, 58, 60, 73, 76], "best": [10, 17, 48, 57, 76, 78, 105, 121], "elbo": 10, "2604245517164468": 10, "nll": 10, "001169236510424758": 10, "mse": 10, "307728190154737e": 10, "05": [10, 17, 18, 22, 58, 120, 121], "seaborn": 10, "sn": 10, "matplotlib": [10, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 58, 119], "pyplot": [10, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 119], "plt": [10, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 58, 119], "load": [10, 24, 26, 121], "join": [10, 58], "anoce_result": 10, "rb": [10, 121], "calcul": [10, 17, 19, 58, 61, 64, 70, 73, 76, 79, 80, 81, 84, 85, 87, 101, 103, 106, 107, 108, 114], "calculate_effect": [10, 119], "plot": [10, 11, 13, 14, 119], "covid": 10, "matshow": 10, "cmap": 10, "bwr": 10, "vmin": 10, "vmax": 10, "fig1": 10, "gcf": 10, "colorbar": 10, "df": [10, 11, 13, 14, 20], "datafram": [10, 14, 21, 22, 23, 43, 57, 58, 60, 73, 76, 119, 120, 121], "arrai": [10, 16, 17, 18, 20, 23, 25, 26, 27, 28, 43, 46, 48, 58, 60, 73, 92, 95, 96, 97, 99, 101, 102, 103, 104, 107, 108, 113, 114, 119, 121, 123], "read_csv": [10, 16, 17, 18, 20, 23, 25, 26, 27, 28, 73, 76, 119, 120, 121], "csv": [10, 16, 17, 18, 20, 23, 25, 26, 27, 28, 119, 120, 121], "column": [10, 14, 16, 17, 18, 20, 21, 23, 25, 26, 27, 28, 43, 58, 60, 92, 94, 96, 99, 101, 102, 119, 120], "31": [10, 11, 13, 57, 60, 70], "round": [10, 11, 13, 14, 16, 17, 18, 20, 23, 25, 27, 28, 43, 57, 73, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 106, 107, 108, 113, 114, 115], "reshap": [10, 11, 13, 14, 17, 21, 25, 48, 121], "shenzhen": 10, "198": [10, 26, 73], "027": 10, "guangzhou": 10, "099": 10, "059": 10, "beij": 10, "036": [10, 16], "039": [10, 16], "chengdu": 10, "081": [10, 82], "019": [10, 23], "shanghai": 10, "016": 10, "063": 10, "dongguan": 10, "066": 10, "023": 10, "suzhou": 10, "064": 10, "xian": 10, "051": 10, "042": 10, "hangzhou": 10, "097": 10, "083": 10, "zhengzhou": 10, "069": 10, "062": 10, "chongq": 10, "021": 10, "changsha": 10, "073": 10, "034": 10, "nanj": 10, "094": 10, "044": 10, "13": [10, 11, 13, 14, 18, 22, 26, 60, 106, 119, 120, 121], "kunm": 10, "006": [10, 60], "040": 10, "14": [10, 11, 13, 14, 18, 20, 22, 26, 60, 119, 120, 121], "tianjin": 10, "075": 10, "049": 10, "hefei": 10, "020": [10, 23], "007": 10, "046": 10, "wenzhou": 10, "302": 10, "030": [10, 23], "18": [10, 58, 60, 78, 86, 106, 121], "nanchang": 10, "050": 10, "004": [10, 60], "zhoukou": 10, "008": 10, "013": 10, "fuyang": 10, "21": [10, 18, 22, 43, 57, 58, 60, 94], "shangqiu": 10, "yueyang": 10, "002": [10, 101], "012": [10, 120], "23": [10, 22, 43, 57, 58, 60], "zhumadian": 10, "024": [10, 23], "24": [10, 57, 58, 60], "changd": 10, "001": 10, "25": [10, 11, 13, 14, 16, 17, 18, 20, 22, 23, 25, 26, 27, 28, 57, 58, 60, 76, 79, 80, 85, 119], "nanyang": 10, "029": [10, 23], "26": [10, 46, 58, 60], "022": 10, "27": [10, 60], "xinyang": 10, "031": [10, 23], "28": [10, 58, 60, 97], "anq": 10, "009": 10, "29": [10, 43, 58, 60, 73], "jiujiang": 10, "017": [10, 23], "mt_data": 10, "zero": [10, 11, 13, 14, 21, 25, 26, 43, 48, 58, 61, 70, 73, 79, 85, 92, 94, 95, 96, 97, 99, 104, 107, 108, 113, 114], "fig": [10, 123], "figur": [10, 17, 123], "figsiz": 10, "ax": 10, "add_subplot": 10, "cax": 10, "shrink": 10, "horizont": 10, "cities_nam": 10, "set_xtick": 10, "arang": [10, 20], "len": [10, 11, 13, 14, 16, 17, 18, 20, 21, 23, 24, 25, 27, 28, 43, 46, 48, 57, 58, 60, 73, 76, 78, 82, 86, 87, 105, 106, 119, 120, 121], "set_ytick": 10, "set_xticklabel": 10, "rotat": 10, "90": [10, 58, 60], "set_yticklabel": 10, "linear": [10, 12, 19, 23, 24, 46, 78, 79, 80, 88, 89, 90, 92, 96, 99, 100, 101, 102, 103, 106, 108, 120], "addit": [10, 12, 14, 21, 61, 62, 66, 67, 70, 71, 72, 87, 123], "graphic": [10, 12], "uniqu": [11, 13, 14, 48, 64, 65, 71, 72, 116], "invari": [11, 13, 14, 123], "trasform": [11, 13, 14], "disadvantag": [11, 13, 14, 79, 80, 81, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103], "knowledg": [11, 48, 78, 79, 83, 86, 87, 108, 113], "realiz": [11, 13, 14, 66, 83], "underli": [11, 13, 14, 17, 19, 71, 72, 88, 117], "lsem": [11, 14], "g_j": [11, 13], "differenti": [11, 13], "argument": [11, 13, 17, 20, 62], "corollari": [11, 13], "threshold": 11, "synthetic_dataset": [11, 13, 14], "1234": [11, 13, 14], "300": [11, 13, 14, 17, 18, 20, 48, 82], "ground_truth_g": [11, 13, 14], "simulate_random_dag": [11, 13, 14], "graph_typ": [11, 13, 14], "erdo": [11, 13, 14], "renyi": [11, 13, 14], "w_rang": [11, 13, 14], "c": [11, 13, 14, 15, 17, 18, 22, 43, 46, 48, 57, 58, 67, 70, 73, 76, 77, 78, 79, 81, 83, 84, 85, 86, 87, 92, 93, 94, 95, 101, 102, 103, 104, 105, 106, 107, 108, 114, 115, 121], "ones": [11, 13, 14, 21, 25, 43, 46, 58, 60, 73, 83, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103, 113, 121], "simulate_lsem": [11, 13, 14], "plot_net": [11, 13, 14, 119], "nx": [11, 13, 14, 58], "to_numpy_arrai": [11, 13, 14], "labels_nam": [11, 13, 14, 119], "rang": [11, 13, 14, 48, 57, 60, 73, 98, 121, 123], "modulenotfounderror": [11, 13, 14, 48], "traceback": [11, 13, 14, 17, 20, 21, 22, 24, 43, 46, 48, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 70, 73, 76, 79, 80, 81, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104, 107, 108, 113, 114, 120, 121], "var": [11, 13, 14, 17, 20, 21, 22, 24, 27, 43, 46, 48, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 70, 73, 76, 79, 80, 81, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104, 107, 108, 113, 114, 119, 120, 121], "folder": [11, 13, 14, 17, 20, 21, 22, 24, 27, 43, 46, 48, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 70, 73, 76, 79, 80, 81, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104, 107, 108, 113, 114, 119, 120, 121, 124], "9j": [11, 13, 14, 17, 20, 21, 22, 24, 27, 43, 46, 48, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 70, 73, 76, 79, 80, 81, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104, 107, 108, 113, 114, 119, 120, 121], "vb5nb4rd5bx0gr1q5ytx9q600000gn": [11, 13, 14, 17, 20, 21, 22, 24, 27, 43, 46, 48, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 70, 73, 76, 79, 80, 81, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104, 107, 108, 113, 114, 119, 120, 121], "ipykernel_14441": 11, "2370726509": [11, 13, 14], "modul": [11, 13, 14, 17, 20, 21, 22, 24, 43, 46, 48, 57, 58, 60, 61, 62, 64, 65, 66, 67, 68, 70, 73, 76, 79, 80, 81, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104, 107, 108, 113, 114, 120, 121], "pip": [11, 14, 18, 22, 58, 124], "instal": [11, 14, 18, 22, 58, 124], "igraph": 11, "factor_analyz": 11, "directlingam": 11, "fit": [11, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 43, 57, 58, 60, 73, 76, 119, 120], "adjacency_matrix_": 11, "ica_r": 11, "ab": [11, 13, 14], "fdr": [11, 13, 14], "tpr": [11, 13, 14], "shd": [11, 13, 14], "count_accuraci": [11, 13, 14], "digraph": [11, 13, 14], "statsmodel": [11, 18, 22, 57, 120, 121], "tsa": [11, 120, 121], "tsa_model": [11, 120, 121], "futurewarn": [11, 16, 120, 121], "int64index": [11, 120, 121], "deprec": [11, 17, 120, 121], "futur": [11, 71, 72, 120, 121], "index": [11, 14, 17, 18, 20, 22, 23, 48, 57, 66, 76, 86, 93, 119, 120, 121, 124], "dtype": [11, 20, 23, 43, 57, 58, 60, 73, 76, 119, 120, 121], "instead": [11, 16, 17, 18, 20, 21, 22, 23, 25, 27, 28, 57, 61, 66, 70, 73, 76, 78, 85, 94, 99, 101, 116, 119, 120, 121, 124], "to_datetim": [11, 120, 121], "datetimeindex": [11, 120, 121], "float64index": [11, 120, 121], "67": [11, 13, 14, 20, 57, 60, 77, 100, 103, 104, 106], "prune": [11, 13, 14], "metric": [11, 13, 14, 17, 46], "fals": [11, 13, 14, 18, 20, 22, 43, 57, 79, 80, 85, 87, 101, 102, 103, 104, 107, 119, 121], "ham": [11, 13, 14], "distanc": [11, 13, 14], "smallest": [11, 13, 14, 21, 48], "revers": [11, 13, 14], "account": [11, 13, 14, 76, 83, 85, 93, 94, 98, 99, 100, 101, 121, 123], "neg": [11, 13, 14, 20, 43, 46, 57, 73, 76, 119, 121], "better": [11, 13, 14, 17, 18, 21, 22, 27, 28, 43, 57, 59, 61, 73, 76, 81, 84, 119, 120], "00": [11, 13, 14, 22, 43, 57, 58, 60, 73, 120], "50": [11, 13, 14, 26, 48, 57, 60, 121], "62": [11, 13, 14, 17, 26, 60, 73], "daggnn": [11, 13, 14], "equal": [11, 13, 14, 48, 61, 62, 66, 70, 71, 93, 96, 97, 99, 100], "varianc": [11, 13, 14, 21, 22, 24, 48, 61, 62, 66, 67, 70, 79, 83, 108, 113, 116], "biometrika": [11, 13, 14, 15, 16, 19, 20, 23, 24], "101": [11, 13, 14, 20, 24, 58, 121], "219": [11, 13, 14], "228": [11, 13, 14, 21, 22], "2013": [11, 13, 14, 15, 21, 78, 79, 97, 98, 105, 106, 108, 115], "mooij": [11, 13, 14], "janz": [11, 13, 14], "sch\u00f6lkopf": [11, 13, 14], "cma": 12, "dissect": 12, "transmit": 12, "comprehens": [12, 26, 119], "cate": [12, 19], "moder": 13, "sem": 13, "good": [13, 21, 64, 65, 72, 83, 106, 116], "analysis": 13, "contrain": 13, "ipykernel_14451": 13, "notears_linear": [13, 119], "lambda1": [13, 119], "loss_typ": [13, 119], "l2": [13, 119], "notears_r": 13, "author": [14, 17], "nois": [14, 85, 96, 97, 123], "normal": [14, 17, 58, 60, 61, 66, 67, 70, 85, 89, 97, 98], "sparsiti": [14, 46, 78], "teat": 14, "ipykernel_14456": 14, "pydot": 14, "git": [14, 124], "pycaus": 14, "start_vm": 14, "tetrad": 14, "tetradrunn": 14, "new_df": 14, "map": [14, 64, 65, 72, 77, 88, 89, 90, 116, 123, 124], "02": [14, 43, 57, 60, 73, 120], "format": [14, 73], "algoid": 14, "testid": 14, "gettetradgraph": 14, "getnod": 14, "dot_str": 14, "tetradgraphtodot": 14, "graph_from_dot_data": 14, "node_a": 14, "fill": 14, "fillcolor": 14, "red": 14, "add_nod": 14, "nx_pydot": 14, "from_pydot": 14, "pc_re": 14, "trial": [15, 77, 106], "ve": [15, 19, 123], "preliminari": 15, "notat": [15, 72, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104, 124], "rl": [15, 62, 71, 72, 116, 117, 123], "main": [15, 20, 23, 24, 116, 123, 124], "common": [15, 19, 21, 25, 73, 76, 96, 98, 120, 123], "causal": [15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 27, 74, 116, 117, 121, 124], "consist": [15, 16, 17, 19, 20, 21, 23, 24, 25, 26, 46, 58, 61, 64, 66, 67, 70, 71, 72, 89, 98, 105, 115, 119], "These": [15, 19, 21, 61, 62, 70, 72], "nuc": [15, 21, 25], "remark": [15, 81, 85, 87, 107], "commonli": [15, 19, 64, 65, 66, 67, 70, 71, 78, 79, 88, 89, 90, 108], "impos": [15, 64, 72], "automat": [15, 66, 70, 72, 87], "behavior": [15, 21, 22, 24, 58, 66, 71, 72, 89, 93, 100, 105, 115], "strictli": [15, 66, 70], "re": [15, 20, 86, 123], "shown": [15, 17, 83, 85, 93, 106, 108, 113], "below": [15, 16, 17, 21, 23, 24, 25, 27, 73, 76, 78, 82, 86, 106, 117, 119, 120, 121, 123], "rh": [15, 116], "rid": 15, "pure": [15, 116], "categori": [15, 61, 64, 70, 106, 123], "IS": [15, 61, 66, 70], "dr": [15, 19, 20, 48, 61, 66, 70], "widehat": [15, 16, 17, 24, 48, 61, 62, 64, 65, 67, 70, 88, 89, 90, 116], "invers": [15, 58, 66, 70], "aipw": [15, 58], "proce": [15, 72], "bigg": [15, 17], "flip": 15, "role": [15, 88, 89, 90], "third": [15, 61, 70, 92, 94, 95], "misspecif": [15, 43, 62, 73, 79, 92, 96, 102], "term": [15, 20, 24, 61, 62, 66, 70, 76, 78, 85, 89, 90], "correct": 15, "correctli": [15, 62, 89], "prove": [15, 16, 20, 24, 46, 61, 62, 67], "mild": [15, 16, 19, 24, 61], "semi": [15, 96, 97, 99, 104, 105, 115], "parametr": [15, 17, 70], "converg": [15, 17, 19, 20, 24, 48, 61, 62, 64, 65, 70, 123], "found": [15, 43, 59, 73, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104, 123, 124], "sequenti": [15, 43, 58, 72, 73, 77, 82, 85, 87, 88, 89, 90, 98, 106], "681": 15, "694": 15, "v": [15, 16, 17, 18, 19, 20, 22, 23, 24, 46, 48, 57, 61, 67, 70, 71, 72, 80, 88, 89, 90, 93, 94, 95, 97, 100, 101, 102, 103, 104, 116], "chetverikov": [15, 17], "demir": [15, 17], "duflo": [15, 17], "hansen": [15, 17], "w": [15, 17, 20, 21, 43, 48, 57, 72, 73, 74, 75, 76, 77, 78, 80, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 115, 116, 121, 123], "newei": [15, 17], "kennedi": [16, 19, 20, 24], "extend": [16, 24, 46, 66, 70], "oracl": [16, 19, 20, 23, 24], "theorem": [16, 17, 24, 70, 99, 116], "nuisanc": [16, 18, 20, 22, 24, 61, 62, 66, 70], "i_": [16, 20, 24, 62], "mu_a": [16, 24], "mathbb": [16, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 43, 46, 48, 58, 61, 62, 64, 65, 66, 70, 71, 72, 73, 88, 89, 90, 116, 123], "phi": [16, 24, 43, 73, 79, 83, 85, 87, 92, 94, 96, 99, 101, 102, 108], "_a": [16, 20, 24, 80], "_1": [16, 24, 58, 62, 120], "_0": [16, 24, 58], "i_2": [16, 20, 24, 62], "yield": [16, 17, 21, 24, 27, 48, 58, 61, 62, 66, 70], "tau": [16, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 58, 62, 116], "_n": [16, 20, 23, 24, 58], "sklearn": [16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 46, 119], "ensembl": [16, 17, 18, 20, 23, 25, 27, 28, 119], "gradientboostingregressor": [16, 17, 18, 20, 23, 25, 27, 28], "linear_model": [16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 57, 119], "linearregress": [16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 119], "logisticregress": [16, 18, 20, 21, 22, 23, 24, 28, 119], "causal_effect_learn": [16, 17, 18, 20, 23, 24], "single_stag": [16, 17, 18, 20, 23, 24], "drlearner": [16, 24], "movielens_cel": [16, 17, 18, 20, 23, 25, 26, 27, 28], "cdm": [16, 17, 18, 20, 23, 25, 26, 27, 28], "pop": [16, 17, 18, 20, 23, 25, 27, 28], "user_id": [16, 17, 18, 20, 23, 25, 26, 27, 28], "movie_id": [16, 17, 18, 20, 23, 25, 26, 27, 28], "ag": [16, 17, 18, 20, 23, 25, 26, 27, 28, 61, 62, 64, 65, 66, 67, 68, 70, 78, 86, 104, 106, 107, 108, 113, 114], "drama": [16, 17, 18, 20, 23, 25, 26, 27, 28, 78, 82, 86, 87, 105, 106], "gender_m": [16, 17, 18, 20, 23, 25, 26, 27, 28], "occupation_academ": [16, 17, 18, 20, 23, 25, 26, 27, 28], "educ": [16, 17, 18, 20, 23, 25, 26, 27, 28, 78, 86, 106], "occupation_colleg": [16, 17, 18, 20, 23, 25, 26, 27, 28], "grad": [16, 17, 18, 20, 23, 25, 26, 27, 28, 78, 79, 80, 85, 86, 106], "occupation_execut": [16, 17, 18, 20, 23, 25, 26, 27, 28], "manageri": [16, 17, 18, 20, 23, 25, 26, 27, 28, 78, 86, 106], "occupation_oth": [16, 17, 18, 20, 23, 25, 26, 27, 28], "occupation_technician": [16, 17, 18, 20, 23, 25, 26, 27, 28], "engin": [16, 17, 18, 20, 23, 24, 25, 26, 27, 28, 73, 76, 78, 86, 106, 120], "48": [16, 17, 18, 20, 23, 25, 26, 27, 28, 60, 78, 119, 120], "1193": [16, 17, 18, 20, 23, 25, 26, 27, 28], "919": [16, 17, 18, 20, 23, 25, 26, 27, 28], "527": [16, 17, 18, 20, 23, 25, 26, 27, 28], "1721": [16, 17, 18, 20, 23, 25, 26, 27, 28], "150": [16, 17, 18, 20, 23, 25, 26, 27, 28, 60], "65637": [16, 17, 18, 20, 23, 25, 27, 28], "5878": [16, 17, 18, 20, 23, 25, 26, 27, 28], "3300": [16, 17, 18, 20, 23, 25, 26, 27, 28], "65638": [16, 17, 18, 20, 23, 25, 27, 28], "1391": [16, 17, 18, 20, 23, 25, 26, 27, 28], "65639": [16, 17, 18, 20, 23, 25, 27, 28], "185": [16, 17, 18, 20, 23, 25, 26, 27, 28], "65640": [16, 17, 18, 20, 23, 25, 27, 28], "2232": [16, 17, 18, 20, 23, 25, 26, 27, 28], "65641": [16, 17, 18, 20, 23, 25, 27, 28], "426": [16, 17, 18, 20, 23, 25, 26, 27, 28], "65642": [16, 17, 18, 20, 23, 25, 26, 27, 28], "userinfo_index": [16, 17, 18, 20, 23, 25, 26, 27, 28, 119], "sanda": [16, 17, 18, 20, 21, 23, 25, 26, 27, 28], "iloc": [16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 48, 119], "n_fold": [16, 20, 23, 24], "y_model": [16, 20, 23, 24], "max_depth": [16, 18, 20, 21, 22, 23, 24, 25, 27, 28, 119, 121], "ps_model": [16, 23, 24], "rlearner_model": [16, 23, 24], "hte_dr_learn": [16, 24], "to_numpi": [16, 17, 21, 22, 23, 24, 25], "493": 16, "were": 16, "pass": [16, 20, 121], "start": [16, 17, 23, 24, 71, 76, 79, 80, 81, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103, 107, 108, 113, 114, 119], "unseen": 16, "t_1": [16, 62, 71, 72, 123], "seen": 16, "yet": [16, 48, 117], "messag": [16, 58], "t_0": [16, 123], "fold": [16, 20, 23, 24, 58], "r2": [16, 23, 24], "baselearn": [16, 24], "pslearner": [16, 24], "735": 16, "038": 16, "037": 16, "734": [16, 23], "1000": [16, 17, 20, 21, 23, 25, 27, 28, 46, 58, 60, 94, 101, 102, 104, 105], "5000": [16, 17, 23, 25, 26, 27, 28], "05672212": 16, "73726057": 16, "09360586": 16, "ate_dr_learn": 16, "sum": [16, 17, 18, 20, 21, 22, 23, 24, 25, 27, 28, 58, 60, 62, 84, 105, 106, 114, 119], "sci": [16, 17, 18, 20, 23, 25, 26, 27, 28, 78, 79, 80, 82, 83, 86, 106], "fi": [16, 17, 18, 20, 23, 25, 26, 27, 28, 78, 79, 80, 82, 83, 86, 106], "3541": 16, "conclus": [16, 17, 18, 20, 21, 23, 24, 25, 27, 28, 119], "xinkun": [16, 19, 20, 23, 24], "nie": [16, 19, 20, 23, 24, 121], "stefan": [16, 18, 19, 20, 22, 23, 24, 33, 34, 37, 38, 39, 40, 41, 123], "wager": [16, 18, 19, 20, 22, 23, 24, 33, 34, 37, 38, 39, 40, 41, 123], "quasi": [16, 19, 20, 23, 24], "108": [16, 17, 19, 20, 23, 24, 26, 121], "299": [16, 19, 20, 23, 24], "319": [16, 19, 20, 23, 24], "robinson": [16, 19, 20, 23, 24], "root": [16, 19, 20, 23, 24], "econometrica": [16, 19, 20, 23, 24], "econometr": [16, 19, 20, 23, 24], "societi": [16, 19, 20, 23, 24, 43, 73], "931": [16, 19, 20, 23, 24, 73, 76, 120], "954": [16, 19, 20, 23, 24], "edward": [16, 19, 20, 24], "h": [16, 19, 20, 24, 43, 48, 76, 77, 85, 86, 87, 88, 89, 90, 92, 93, 94, 96, 99, 100, 101, 102, 105, 106, 114, 115], "2004": [16, 19, 20, 24, 43, 73], "14497": [16, 19, 20, 24], "der": [16, 19, 20, 24, 74, 121], "laan": [16, 19, 20, 24, 74, 121], "biostatist": [16, 19, 20, 24, 43, 73], "lee": [16, 19, 20, 24], "okui": [16, 19, 20, 24], "whang": [16, 19, 20, 24], "uniform": [16, 19, 20, 24, 58], "band": [16, 19, 20, 24], "1207": [16, 19, 20, 24], "1225": [16, 19, 20, 24], "foster": [16, 19, 20, 24], "syrgkani": [16, 19, 20, 24], "orthogon": [16, 19, 20, 24, 77, 106], "1901": [16, 19, 20, 24], "09036": [16, 19, 20, 24], "claudiashi57": 17, "dragonnet": 19, "learner": [17, 18, 19, 22, 26, 43, 46, 57, 58, 60, 73, 76, 104, 107, 108, 113, 114, 119, 120, 121, 123], "test_output": 17, "train_output": 17, "train_and_predict_dragon": 17, "targeted_regular": 17, "output_dir": 17, "master": 17, "knob_loss": 17, "dragonnet_loss_binarycross": 17, "ratio": [17, 26, 61, 62, 66, 70, 119], "val_split": 17, "64": [17, 18, 22, 57, 60], "am": 17, "2023": [17, 121], "03": [17, 43, 59, 73, 120], "06": [58, 97, 120], "678437": [], "tensorflow": 17, "core": [17, 20], "platform": [17, 58], "cpu_feature_guard": 17, "cc": 17, "193": 17, "oneapi": 17, "librari": [17, 24], "onednn": 17, "cpu": 17, "instruct": [17, 88, 89, 90], "sse4": 17, "rebuild": 17, "compil": 17, "flag": 17, "kera": 17, "optimizer_v2": 17, "adam": 17, "110": [17, 24, 26, 119, 121], "lr": 17, "learning_r": 17, "super": 17, "self": [17, 20, 24, 43, 57, 60, 61, 66, 70, 73, 76, 120], "__init__": [17, 20, 24, 73, 76, 120], "kwarg": [17, 20, 73, 76, 120], "gradient_desc": 17, "sgd": 17, "keyboardinterrupt": [17, 20], "ipykernel_14474": [], "2268767057": 17, "y_unscal": 17, "105": [17, 20, 43, 58, 119, 121], "sgd_lr": 17, "momentum": 17, "nesterov": 17, "106": [17, 26, 43, 119, 121], "107": [17, 43, 46, 121], "x_train": 17, "yt_train": 17, "callback": [17, 20, 24], "sgd_callback": 17, "validation_split": 17, "109": [17, 24, 104], "traceback_util": 17, "error_handl": 17, "arg": [17, 20, 23, 24, 43, 46, 57, 58, 61, 64, 65, 71, 72, 73, 76, 79, 80, 83, 84, 92, 94, 95, 96, 97, 99, 100, 101, 102, 103, 114, 116, 120], "filtered_tb": 17, "none": [17, 18, 20, 22, 24, 26, 57, 58, 60, 73, 76, 81, 85, 93, 107, 113, 120, 121], "63": [17, 18, 58, 60], "fn": 17, "65": [17, 26, 43, 48, 57, 58, 60, 73, 121], "pylint": 17, "disabl": 17, "66": [17, 20, 57, 58, 60, 119, 121], "_process_traceback_fram": 17, "__traceback__": 17, "verbos": [17, 18, 20, 22, 73, 76, 120], "validation_data": 17, "shuffl": 17, "class_weight": [17, 20], "sample_weight": [17, 20], "initial_epoch": 17, "steps_per_epoch": 17, "validation_step": 17, "validation_batch_s": 17, "validation_freq": 17, "max_queue_s": 17, "worker": 17, "use_multiprocess": 17, "1412": [], "log": [20, 84, 114, 116], "tmp_log": 17, "1413": [], "end_step": [], "data_handl": 17, "step_incr": [], "1414": [], "on_train_batch_end": [], "1415": [], "stop_train": [], "1416": [], "436": [], "437": [], "_should_call_train_batch_hook": [], "438": [93, 95], "_call_batch_hook": [], "modekei": [], "439": 121, "440": [], "def": [20, 24, 48, 58, 60, 73, 76, 120, 121], "on_test_batch_begin": [], "hook": [], "289": [], "290": [], "helper": [], "batch_": [], "291": [], "292": [], "293": [], "dict_kei": [17, 26], "q_t0": 17, "q_t1": 17, "ep": [17, 20], "hte_dragonnet": 17, "32294464": 17, "43536925": 17, "33986402": 17, "aaverag": 17, "ate_dragonnet": 17, "3225": 17, "claudia": [17, 19], "blei": [17, 19], "veitch": [17, 19], "33rd": 17, "neurip": 17, "susan": [18, 19, 22, 33, 34, 37, 38, 39, 40, 41, 123], "athei": [18, 19, 22, 33, 34, 37, 38, 39, 40, 41, 123], "juli": [18, 19, 22, 33, 34, 37, 38, 39, 40, 41, 86, 87, 98], "tibshirani": [18, 19, 22, 33, 34, 37, 38, 39, 40, 41], "solut": [17, 18, 22, 46, 48, 64, 65, 71, 116, 124], "moment": [18, 22], "psi_": [18, 22, 43, 61, 62, 67, 70, 73], "nu": [18, 22], "o_i": [18, 22, 48], "care": [18, 22, 26, 119], "xi": [18, 22, 61, 70], "beta": [17, 18, 22, 23, 24, 43, 57, 58, 76, 79, 83, 85, 87, 94, 95, 101, 103, 113, 120, 121, 123], "induc": [18, 20, 22], "solv": [18, 22, 23, 24, 43, 46, 48, 57, 61, 62, 64, 65, 66, 70, 71, 72, 73, 83, 97, 100, 105, 106, 108, 113, 115, 116], "alpha_i": [18, 22], "alpha": [17, 18, 20, 22, 58, 62, 67, 71, 72, 79, 80, 85, 87, 92, 95, 103, 108, 116], "otim": [18, 22], "vv": [18, 22], "notic": [18, 22, 79, 95, 96, 103, 108], "formula": [18, 22, 57, 124], "ordinari": [18, 22], "prone": [18, 22], "grf": [18, 19, 22], "quantiti": [18, 22], "grow": [18, 22, 70, 117], "dot": [18, 20, 22, 43, 58, 61, 66, 70, 73, 78, 82, 86, 93, 100, 105, 106, 115, 123], "l_b": [18, 22], "fall": [18, 22], "leaf": [18, 22], "frequenc": [18, 22, 79, 80, 92, 94, 99, 101, 102], "alpha_": [18, 22, 87], "bi": [18, 22], "boldsymbol": [18, 22, 43, 57, 59, 73, 75, 76, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 105, 107, 108, 114, 115, 120], "x_0": [18, 22], "flexibl": [18, 22, 48, 62, 88, 89, 90, 123], "lprlearner": [18, 20, 24], "_util_causaldm": [18, 21, 22, 24, 43, 57, 59], "econml": [18, 22], "python": [17, 18, 22, 58, 94, 101, 124], "joblib": [18, 20, 22, 58], "scikit": [18, 22, 58, 59], "scipi": [18, 20, 22, 58, 121], "shap": [18, 22], "41": [18, 22, 57, 60], "40": [18, 22, 58, 60, 119], "lightgbm": [18, 22, 24, 119], "spars": [18, 22], "threadpoolctl": [18, 22, 58], "slicer": [18, 22], "numba": [18, 22], "55": [17, 18, 60, 94, 101, 119], "tqdm": [18, 22, 58, 119], "cloudpickl": [18, 22], "patsi": [18, 22], "dateutil": [18, 22, 58], "pytz": [18, 22, 58], "wheel": [18, 22], "35": [18, 58, 60], "setuptool": [18, 22], "llvmlite": [18, 22], "39": [18, 22, 43, 58, 60], "0rc1": 18, "pypars": [18, 58], "six": [18, 22, 58, 123], "demo": [18, 22, 60, 124], "causalforest": [18, 22], "causalivforest": [18, 22], "regressionforest": [18, 22], "dml": [17, 18, 22], "causalforestdml": [18, 22], "est": [18, 22], "criterion": [18, 22], "het": [18, 22], "n_estim": [18, 22], "400": [18, 22, 60, 121], "min_samples_leaf": [18, 22], "min_var_fraction_leaf": [18, 22], "min_var_leaf_on_v": [18, 22], "min_impurity_decreas": [18, 22], "max_sampl": [18, 22], "45": [18, 22, 58, 60], "min_balancedness_tol": [18, 22], "warm_start": [18, 22], "fit_intercept": [18, 20, 22, 46], "subforest_s": [18, 22], "honest": [18, 22], "n_job": [18, 20, 22, 46], "random_st": [18, 20, 22], "1235": [18, 22], "hte_grf": [18, 22], "flatten": [18, 22, 121], "900": [18, 20], "3605": 18, "3783": 18, "3646": 18, "ate_grf": 18, "358": [18, 20], "47": [18, 19, 22, 26, 33, 34, 37, 38, 39, 40, 41, 60, 81, 84, 106, 107, 114, 119], "1148": [18, 19, 22, 33, 34, 37, 38, 39, 40, 41], "1178": [18, 19, 22, 33, 34, 37, 38, 39, 40, 41], "execut": [17, 19, 78, 86, 106], "setup": [19, 23, 24, 46, 60, 61, 62, 100, 116, 117, 123], "triplet": [19, 71, 72, 123], "trajectori": [19, 66, 70, 71, 72, 116, 123], "imagin": 19, "terminolog": 19, "lot": [19, 58, 71], "recommend": [19, 26, 43, 46, 48, 57, 60, 73, 76, 77, 78, 82, 86, 93, 98, 100, 120], "adversit": 19, "impact": [19, 119, 121], "annual": 19, "incom": [19, 100, 101, 102, 103], "expos": [19, 123], "statu": [19, 26, 58, 89, 90, 119], "pictur": [19, 58], "dress": 19, "femal": [19, 78], "higher": [19, 25, 27, 28, 62, 78, 82, 86, 106, 119], "male": [19, 78, 79, 80, 85, 86, 106], "clearli": [19, 123], "granular": 19, "averg": 19, "characsterist": 19, "subsect": [19, 26, 70], "briefli": [19, 77, 106], "lp": 19, "forest": [19, 33, 34, 37, 38, 39, 40, 41], "paper": [19, 20, 24, 116], "pleas": [19, 20, 21, 24, 28], "easiest": [19, 21, 23, 24, 58], "apporach": 19, "enough": [19, 62, 124], "complic": [19, 21, 27, 62], "worth": [19, 99], "sensibl": 19, "trend": [19, 21, 78, 113, 114, 123], "cancel": 19, "tend": [19, 21], "particularli": [19, 43, 57, 73, 76], "larger": [19, 27, 43, 57, 59, 62, 70, 73, 76], "part": [19, 58, 62, 116, 121, 123, 124], "properti": [19, 103, 113], "minim": [17, 19, 20, 61, 62, 70, 71, 72, 77, 82, 94, 99, 101, 106], "boost": [19, 58], "acheiv": 19, "guarante": [17, 19, 72, 124], "alwai": [19, 43, 57, 62, 78, 82, 83, 86, 95, 97, 103, 106, 108, 113, 121], "faster": [19, 48, 62, 70], "might": [19, 60, 61, 119], "computation": [19, 67, 94, 99, 101, 103, 117], "polynomi": [19, 20, 24], "tradeoff": [19, 62], "nonparametr": [19, 70], "inherit": 19, "dragon": 19, "net": 19, "qualiti": [17, 19], "outperform": [19, 79, 92, 95, 96, 97, 102, 103], "kunzel": [19, 21, 25, 27, 28], "sekhon": [19, 21, 25, 27, 28], "bickel": [19, 21, 25, 27, 28], "metalearn": [19, 21, 25, 27, 28], "nation": [19, 21, 25, 27, 28, 123], "academi": [19, 21, 25, 27, 28], "116": [19, 21, 25, 27, 28, 43, 57, 88, 89, 90, 121], "4156": [19, 21, 25, 27, 28], "4165": [19, 21, 25, 27, 28], "alicia": 19, "curth": 19, "mihaela": 19, "schaar": 19, "1810": 19, "1818": 19, "residu": [20, 23, 24], "cross": [20, 24, 58], "relax": [20, 24, 62, 123], "breviti": [20, 24], "1b": [20, 24], "basi": [20, 24, 61, 70, 85, 121], "k_": [20, 24], "hs": [20, 24], "bandwidth": [20, 24, 48], "eta": [20, 22, 23, 24, 58, 61, 62, 64, 66, 67, 70, 71, 72, 94, 99, 100, 101, 105, 115], "mu_1": [20, 21, 24, 27, 28], "mu_0": [20, 21, 24, 27, 28], "estimt": [20, 24], "_b": [20, 24], "_r": [17, 20, 24], "theta": [17, 20, 24, 79, 81, 83, 85, 92, 93, 94, 95, 96, 97, 99, 101, 102, 103, 105, 107, 108, 113, 115, 116, 120], "min_": [17, 20, 23, 24, 58, 61, 64, 65, 116], "tb": [20, 24], "s_0": [20, 24, 62, 71, 72, 116], "repeat": [20, 24, 76, 106, 116], "twice": [20, 24], "n_": [20, 24], "samplem": [20, 24], "tradit": [20, 24, 66], "milder": [20, 24, 62], "object": [17, 20, 23, 43, 46, 57, 58, 78, 82, 83, 93, 105, 106, 108, 113, 116, 119], "sample_index": 20, "tolist": 20, "ps_model_a": [20, 24], "ps_model_b": [20, 24], "lprlearner_model": [20, 24], "hte_lp_r_learn": [20, 24], "ipykernel_14521": 20, "3692478981": 20, "93": [20, 60], "94": [20, 57, 58, 60], "y_learner": [20, 23, 24], "fold1b": 20, "95": [20, 60, 101], "ps_learner_b": 20, "97": [20, 43, 60, 102, 119], "_logist": 20, "1587": [20, 97], "els": [20, 24, 43, 57, 120, 121], "1588": 20, "1589": 20, "fold_coefs_": 20, "parallel": [20, 123], "1590": 20, "1591": 20, "__call__": [17, 20], "iter": [17, 20, 58, 62, 64, 73, 76, 85, 94, 99, 101, 116, 120], "1041": 20, "remain": 20, "job": 20, "1042": 20, "_iter": 20, "1043": 20, "dispatch_one_batch": 20, "1044": 20, "_original_iter": 20, "1045": 20, "859": 20, "860": 20, "861": 20, "_dispatch": 20, "862": 20, "863": 20, "777": 20, "_lock": 20, "778": 20, "job_idx": 20, "_job": 20, "779": 20, "_backend": 20, "apply_async": 20, "cb": 20, "780": 20, "complet": [20, 26, 43, 73, 85, 87], "quickli": [20, 117], "781": 20, "_parallel_backend": 20, "func": [20, 73, 76, 120], "206": [20, 26, 119], "207": [20, 57], "208": [20, 78, 80], "immediateresult": 20, "209": 20, "210": [20, 58], "570": 20, "avoid": [20, 61, 62, 66, 70], "571": [20, 22], "572": 20, "573": [20, 73, 76, 120], "574": [20, 26, 73, 76, 120], "260": 20, "261": 20, "parallel_backend": 20, "_n_job": 20, "262": 20, "263": 20, "264": [20, 58], "listcomp": 20, "214": [20, 21, 73, 78, 80], "215": [20, 58], "config_context": 20, "config": 20, "216": 20, "217": [20, 58], "218": 20, "_logistic_regression_path": 20, "pos_class": 20, "cs": [20, 46, 94, 101], "max_it": 20, "tol": 20, "solver": 20, "coef": 20, "dual": 20, "penalti": [20, 121], "intercept_sc": 20, "multi_class": 20, "check_input": 20, "max_squared_sum": 20, "l1_ratio": 20, "804": 20, "searchsort": 20, "805": 20, "806": 20, "opt_r": 20, "807": 20, "808": 20, "w0": 20, "_minim": 20, "fun": [20, 58], "x0": 20, "jac": 20, "hess": 20, "hessp": 20, "621": 20, "622": 20, "elif": [17, 20], "meth": 20, "bfg": 20, "623": 20, "_minimize_lbfgsb": 20, "624": 20, "625": [20, 119], "tnc": 20, "lbfgsb": 20, "disp": 20, "maxcor": 20, "ftol": 20, "gtol": 20, "maxfun": 20, "maxit": 20, "iprint": 20, "maxl": 20, "finite_diff_rel_step": 20, "unknown_opt": 20, "until": [20, 64, 65, 66, 85, 87, 100, 101, 102, 103, 104, 116], "359": 20, "overwrit": 20, "360": [20, 26], "func_and_grad": 20, "361": 20, "task_str": 20, "startswith": 20, "new_x": 20, "362": 20, "_differentiable_funct": 20, "fun_and_grad": 20, "265": [20, 58], "array_equ": 20, "266": 20, "_update_x_impl": 20, "267": [20, 58, 121], "_update_fun": 20, "268": 20, "_update_grad": 20, "269": [20, 26], "231": 20, "232": [20, 60], "f_updat": 20, "233": 20, "_update_fun_impl": 20, "234": 20, "235": [20, 81, 84, 106, 107, 114], "update_fun": 20, "135": [20, 78, 79, 82, 106, 108], "136": [20, 26, 119], "137": [20, 119], "fun_wrap": 20, "139": 20, "132": [20, 43, 57, 121], "undefin": 20, "behaviour": [20, 46, 66, 70, 100], "133": [20, 48, 119, 121], "longer": [20, 117], "link": [20, 88, 89, 90, 124], "134": 20, "copi": [20, 23, 25, 58, 119, 121], "72": [20, 60], "73": [20, 60, 119], "74": [20, 46, 60], "_compute_if_need": 20, "75": [20, 58, 60, 119], "_valu": 20, "76": [20, 60, 100, 101, 103, 119], "asarrai": 20, "68": [20, 23, 46, 57, 60], "fg": 20, "69": [20, 60, 119], "70": [20, 58, 60], "_logistic_loss_and_grad": 20, "120": [20, 73, 119], "logist": [20, 43, 58, 66, 70, 79, 80, 85, 92, 94, 101, 102, 108], "122": [20, 26], "log_logist": 20, "yz": 20, "124": [20, 121], "expit": [20, 121], "extmath": 20, "783": 20, "is_1d": 20, "ndim": 20, "784": [20, 73, 76, 120], "atleast_2d": 20, "785": [20, 73, 76, 120], "check_arrai": 20, "float64": [20, 57, 76, 121], "786": [20, 73, 76, 120], "787": [20, 73, 76, 120], "n_sampl": 20, "n_featur": 20, "shape": [20, 58, 60, 73, 121], "accept_spars": 20, "accept_large_spars": 20, "force_all_finit": 20, "ensure_2d": 20, "allow_nd": 20, "ensure_min_sampl": 20, "ensure_min_featur": 20, "798": 20, "799": 20, "800": 20, "_assert_all_finit": 20, "allow_nan": 20, "801": 20, "802": 20, "msg_dtype": 20, "overflow": 20, "102": [20, 24], "is_float": 20, "fc": 20, "103": [20, 24, 43, 119], "isfinit": 20, "_safe_accumulator_op": 20, "op": [20, 61, 64, 66, 70, 71, 72, 123], "893": 20, "894": 20, "895": 20, "896": 20, "897": 20, "__array_function__": 20, "fromnumer": 20, "axi": [20, 58, 60, 123], "keepdim": 20, "initi": [20, 26, 43, 46, 48, 57, 58, 60, 62, 64, 65, 66, 70, 71, 72, 76, 80, 81, 84, 104, 107, 114, 116, 120], "2257": 20, "2258": 20, "2259": 20, "_wrapreduct": 20, "2260": 20, "2261": 20, "obj": 20, "ufunc": 20, "passkwarg": 20, "71": [20, 43, 60, 119], "_novalu": 20, "dictcomp": 20, "42383282": 20, "61112563": 20, "12977467": 20, "ate_lp_r_learn": 20, "3884": 20, "foundament": [21, 25], "esitm": [21, 25], "plug": [17, 21, 25, 48, 61, 62, 64, 70], "supervis": [21, 25, 27, 28], "n0": [21, 22, 24, 58], "mc": [21, 22, 24, 58, 116], "223": [21, 22, 24, 58], "data_behavior": [21, 22, 24], "get_data_simul": [21, 22, 24], "data_target": [21, 22, 24], "hte_tru": [21, 22, 24], "unboundlocalerror": [21, 22], "ipykernel_14532": 21, "2180662469": [21, 22], "227": [21, 22], "229": [21, 22], "referenc": [21, 22, 24], "s1": [21, 24, 60], "s2": [21, 24, 60], "034775": [21, 58], "453145": [21, 58], "167637": 21, "084880": [21, 58], "234459": [21, 58], "553798": 21, "144626": [21, 58], "040543": [21, 58], "956732": 21, "148426": [21, 58], "021139": [21, 58], "095578": 21, "120852": [21, 58], "377594": [21, 58], "323133": 21, "995": [21, 58], "022440": [21, 58], "887551": [21, 58], "797542": 21, "996": [21, 58], "411179": [21, 58], "655833": [21, 58], "722846": 21, "997": [21, 58], "155706": [21, 58], "992197": [21, 58], "140100": 21, "998": [21, 58], "510241": [21, 58], "828438": [21, 58], "167118": 21, "999": [21, 58, 101, 103], "744187": [21, 58], "857147": [21, 58], "458481": 21, "s_learner": [21, 25], "lgbmregressor": [21, 24, 119], "hstack": [21, 25, 43, 58, 60, 73], "hte_s_learn": [21, 25, 27], "1492": 21, "1687": 21, "589": 21, "0319": 21, "8354": 21, "5843": 21, "4577": 21, "0791": [21, 97], "2961": [21, 22, 24], "4475": [21, 22, 24], "731": [21, 22, 24], "2863": [21, 22, 24], "4471": [21, 22, 24], "1839": [21, 22, 24], "3869": [21, 22, 24], "238": [21, 22, 24], "bias_s_learn": 21, "variance_s_learn": 21, "2857192464627009": 21, "079505077680185": 21, "toi": 21, "although": [21, 62, 67, 119], "cover": 21, "mu0": [21, 27, 28, 119], "mu1": [21, 27, 28, 60, 119], "hte_t_learn": [21, 27, 119], "glanc": 21, "869": 21, "8733": 21, "6596": 21, "3087": 21, "2298": 21, "5598": 21, "2745": 21, "8211": 21, "bias_t_learn": 21, "variance_t_learn": 21, "29138198450323705": 21, "810391408711312": 21, "overfit": [21, 27], "provabl": [21, 28, 106], "imput": [21, 28], "tild": [17, 21, 28, 62, 73, 76, 79, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103, 108, 113], "delta": [21, 28, 85, 87], "tau_1": [21, 28], "tau_0": [21, 28], "s_t0": [21, 28], "s_t1": [21, 28], "r_t0": [21, 28], "r_t1": [21, 28], "unobserv": [21, 28, 117, 123], "origin": [21, 26, 28, 43, 57, 58, 59, 87, 116, 119], "n_t0": [21, 28], "n_t1": [21, 28], "delta0": [21, 28], "delta1": [21, 28], "tau0": [21, 28], "tau1": [21, 28], "hte_x_learn": [21, 28], "predict_proba": [21, 28, 119], "9341": 21, "9235": 21, "2944": 21, "4147": 21, "5443": 21, "roughli": [21, 61, 62, 123], "catch": 21, "synthet": [21, 123], "slightli": [21, 70, 72, 117], "bias_x_learn": 21, "variance_x_learn": 21, "2827518068171628": 21, "7686646616779012": 21, "worst": 21, "ipykernel_14537": 22, "pypi": 22, "pkg": 22, "dev": 22, "colab": 22, "cp38": 22, "manylinux_2_17_x86_64": 22, "manylinux2014_x86_64": 22, "whl": [22, 58], "mb": 22, "2k": 22, "90m": 22, "0m": 22, "32m3": 22, "31m96": 22, "36m0": 22, "25hrequir": 22, "usr": [22, 24, 58], "dist": [22, 58], "py2": 22, "py3": [22, 58], "77": [22, 58, 60, 78], "kb": [22, 58], "32m77": 22, "31m12": 22, "manylinux2010_x86_64": 22, "32m571": 22, "31m58": 22, "56": [17, 22, 48, 60, 78, 86, 106], "importlib": 22, "0dev0": 22, "57": [22, 58, 60], "zipp": 22, "successfulli": [22, 58], "2344": 22, "612": 22, "7801": 22, "6886": 22, "6297": 22, "2293": 22, "4417": 22, "819": 22, "okai": 22, "bias_grf": 22, "variance_grf": 22, "706857912147952": 22, "198946462195667": 22, "came": [23, 24], "g_0": [23, 24], "u": [23, 24, 62, 84, 114, 124], "m_0": [23, 24], "manipul": [23, 24], "l_0": [23, 24], "rlearner": [23, 24], "hte_r_learn": [23, 24], "ps_learner": [23, 24], "015": 23, "739": 23, "740": 23, "736": 23, "018": 23, "725": [23, 26], "settingwithcopywarn": [23, 119], "slice": [23, 119], "loc": [23, 58, 119], "row_index": [23, 119], "col_index": [23, 119], "caveat": [23, 119], "pydata": [23, 119], "user_guid": [23, 119], "x_residu": 23, "intercept": [23, 43, 57, 58, 60, 76, 92, 94, 96, 99, 101, 102], "443": 23, "028": 23, "05127254": 23, "08881288": 23, "10304225": 23, "ate_r_learn": 23, "0755": 23, "oserror": 24, "ipykernel_14550": 24, "1454775972": 24, "pathlib": 24, "booster": 24, "register_logg": 24, "early_stop": 24, "log_evalu": 24, "print_evalu": 24, "record_evalu": 24, "reset_paramet": 24, "cvbooster": 24, "cv": 24, "_lib": 24, "_load_lib": 24, "111": 24, "112": 24, "99": [24, 43, 58, 60, 121], "lib_path": 24, "ctype": 24, "cdll": 24, "loadlibrari": 24, "lgbm_getlasterror": 24, "restyp": 24, "c_char_p": 24, "cfunctyp": 24, "458": 24, "459": [24, 58], "460": 24, "_dlltype": 24, "461": 24, "462": 24, "__class_getitem__": 24, "classmethod": 24, "_type": 24, "genericalia": 24, "use_errno": 24, "use_last_error": 24, "winmod": 24, "380": [24, 121], "381": 24, "382": 24, "_handl": [17, 24], "_dlopen": 24, "_name": 24, "383": 24, "384": [24, 121], "dlopen": 24, "lib_lightgbm": 24, "0x0006": 24, "libomp": 24, "dylib": 24, "file": [24, 27, 46, 61, 62, 64, 65, 66, 67, 68, 70, 73, 76, 79, 80, 81, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104, 107, 108, 113, 114, 120, 121, 124], "942": 24, "943": [24, 97], "958": 24, "966": 24, "951": 24, "948": [17, 24], "957": 24, "932": [24, 73, 76, 120], "950": [24, 121], "944": 24, "683": 24, "584": 24, "659": 24, "705": 24, "677": [24, 73, 76, 120], "536": [24, 58], "667": 24, "642": [24, 26], "669": 24, "551": 24, "4971": 24, "0231": 24, "0514": 24, "0037": 24, "0943": 24, "4128": 24, "1436": 24, "4714": 24, "bias_r_learn": 24, "variance_r_learn": 24, "010664510462813687": 24, "3201771635462656": 24, "amaz": 24, "significantli": [24, 121], "980": [24, 58], "978": 24, "947": [17, 24], "975": 24, "946": [17, 24], "940": 24, "2566": 24, "0408": 24, "8131": 24, "0906": 24, "5665": 24, "7341": 24, "6459": 24, "272": 24, "bias_dr_learn": 24, "variance_dr_learn": 24, "29436318987432813": 24, "011818461500106": 24, "lp_r": 24, "0353": 24, "2368": 24, "0444": 24, "0884": 24, "6845": 24, "6876": 24, "6223": 24, "85": [24, 60], "bias_lp_r_learn": 24, "variance_lp_r_learn": 24, "2909913487561472": 24, "1822936738050482": 24, "incred": 24, "sanda_all1": 25, "sanda_all0": 25, "13686218": 25, "52931381": 25, "11991968": 25, "ate_s_learn": [25, 27], "1441": 25, "inclin": [25, 27, 28, 119], "fiction": [25, 27, 28], "dislik": 26, "scope": 26, "onlin": [26, 72, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104, 105, 106, 107, 108, 113, 114, 115, 116, 117, 123, 124], "cmab": [26, 79, 80], "_env_realcmab": [26, 79, 80], "env": [26, 79, 80, 81, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104, 107, 108, 113, 114], "get_movielen": 26, "xs": [26, 85, 94, 99, 101, 102], "mean_ri": 26, "standardized_x": 26, "data_ml": 26, "users_index": 26, "movie_gener": 26, "comedi": [26, 78, 79, 81, 82, 84, 85, 86, 105, 106], "thriller": [26, 78, 80, 81, 82, 83, 85, 86, 87, 105, 106], "data_cel": 26, "concat": [26, 58], "4220": 26, "2355": 26, "14400": 26, "2918": 26, "16752": 26, "2791": 26, "20195": 26, "2797": 26, "21689": 26, "2321": 26, "393463": 26, "3299": 26, "395410": 26, "892": 26, "396058": 26, "397794": 26, "1812": 26, "400719": 26, "3830": 26, "49563": 26, "data_cel_al": 26, "drop": [26, 58, 76], "to_csv": [26, 119], "11057": 26, "25871": 26, "31166": 26, "40383": 26, "303406": 26, "320275": 26, "332011": 26, "382221": 26, "397209": 26, "watch": [17, 26, 58, 81], "175": [26, 82, 86, 119], "save": [26, 66, 85, 124], "www": 26, "kaggl": [26, 119], "asjad99": 26, "mimiciii": 26, "access": [17, 26, 119, 124], "center": [26, 119], "databas": [26, 119], "clinic": [26, 77, 106, 119], "61": [26, 57, 58, 60, 119, 121], "532": [26, 119], "admiss": [26, 119], "boston": [26, 119], "teach": [26, 119], "hospit": [26, 119], "demograph": [26, 119], "vital": [26, 88, 89, 90, 119], "lab": [26, 119], "cohort": [26, 119], "sepsi": [26, 119], "meet": [26, 119], "criteria": [17, 26, 119], "ventil": 26, "particular": [26, 58, 61, 70, 116, 123], "characterist": [26, 123], "physiolog": 26, "whole": [26, 58], "mimic3_sepsis_data": 26, "mimic3_data": [26, 119], "head": [17, 26, 60, 73, 119, 120, 121], "bloc": [26, 121], "icustayid": [26, 119, 121], "charttim": 26, "gender": [26, 78, 86, 106], "elixhaus": 26, "re_admiss": 26, "died_in_hosp": 26, "died_within_48h_of_out_tim": [26, 119], "mortality_90d": 26, "input_tot": 26, "input_4hourli": 26, "output_tot": 26, "output_4hourli": 26, "cumulated_bal": 26, "sofa": [26, 120, 121], "sir": 26, "vaso_input": 26, "iv_input": [26, 119, 120, 121], "7245486000": 26, "17639": 26, "826435": 26, "6527": 26, "0000": [26, 121], "13617": 26, "520": 26, "7090": 26, "884898": 26, "6898241400": 26, "30766": 26, "069028": 26, "383136": 26, "5805732000": 26, "12049": 26, "217303": 26, "976040": 26, "4264269300": 26, "30946": 26, "970000": 26, "1300": 26, "340": 26, "160": [26, 82, 121], "960": [26, 104, 121], "125000": [26, 119], "5707825200": 26, "19793": 26, "588912": 26, "9552": 26, "6830": 26, "540": 26, "2722": 26, "457625": 26, "33": [26, 60, 97, 119], "7214122800": 26, "24524": 26, "747419": 26, "10661": 26, "0483": 26, "5746": 26, "4915": 26, "049099": 26, "glucos": [26, 119, 120, 121], "pao2": [26, 119, 120, 121], "pao2_fio2": [26, 119, 120, 121], "mimic3_data_select": 26, "84": [26, 57, 58, 60], "000000": [26, 119, 121], "168": [26, 119], "59": [26, 46, 60, 119], "444444": 26, "148148": 26, "125": [26, 121], "192": 26, "690": 26, "647482": 26, "727273": 26, "179": 26, "447": [26, 93, 95], "499993": 26, "187": 26, "347": 26, "222222": 26, "4995": 26, "375000": 26, "787683": 26, "005547": 26, "965110": 26, "4996": 26, "333333": [26, 121], "143": [26, 82, 121], "846153": 26, "025000": 26, "4997": 26, "258": 26, "500000": [26, 119, 121], "923": 26, "214286": 26, "402531": 26, "4998": 26, "144": [26, 121], "376": [26, 43], "752": [26, 119], "172130": 26, "4999": 26, "113": [26, 58, 119], "999996": 26, "record": [26, 59], "data_cel_select": [26, 119], "oxygen": [26, 119], "fraction": [26, 119], "deliv": [26, 119], "fio2": [26, 119], "organ": [26, 119], "assess": [26, 59, 119], "dysfunct": [26, 119], "iv": [26, 119, 120, 121], "volumn": [26, 119], "fluid": [26, 119], "administ": [26, 119], "addition": 26, "creat": [17, 26, 73, 76, 120], "aspect": 26, "hte_tlet": 27, "_learner": 27, "ipykernel_14603": 27, "1153805520": 27, "syntaxerror": 27, "eol": 27, "scan": 27, "string": 27, "liter": 27, "3598282": 27, "34648075": 27, "35533324": 27, "ate_t_learn": 27, "3571": 27, "estiamt": 27, "33630057": 28, "31723622": 28, "37261498": 28, "ate_x_learn": 28, "3566": 28, "contrast": [43, 60, 66, 73, 89, 90, 105, 123], "incent": [43, 57, 73, 76], "comparison": [43, 66, 73, 117], "mainli": [43, 57, 64, 65, 73, 76, 78, 82, 86, 94, 99, 101, 106, 117, 123], "convent": [43, 72, 73, 100], "soon": [43, 66, 73], "word": [17, 43, 57, 71, 72, 73, 76, 78, 82, 86, 105, 106, 115], "multinomi": [43, 57, 59, 73, 76, 101, 102, 103, 105, 115], "constrast": [43, 73], "furthermor": [43, 73, 78, 82, 85, 86, 94, 99, 101, 106], "omega": [43, 61, 62, 66, 70, 73], "c_j": 43, "blip": [43, 73], "max_": [43, 58, 65, 71, 72, 73, 76, 79, 80, 83, 84, 92, 94, 95, 96, 97, 99, 100, 101, 102, 103, 114, 116], "psi": [43, 48, 73, 85], "hand": [43, 48, 57, 64, 65, 76, 116], "substitut": [43, 100, 105, 115], "euqat": 43, "appendix": 43, "bootstrap": [43, 57, 60, 67, 73, 76], "utilz": [43, 73], "boostrap": [43, 57, 73], "resampl": [43, 57, 73, 76], "standard": [43, 57, 60, 61, 62, 66, 67, 70, 73, 76, 79, 83, 85, 87, 89, 95, 96, 97, 100, 102, 103, 104, 108, 123], "get_data": [43, 57, 59], "target_col": [43, 57, 58, 59], "binary_trt": [43, 57, 59], "2d": 43, "newaxi": [43, 60], "model_info": [43, 57, 60, 73, 76, 120], "x_prop": [43, 60, 73], "recenc": [43, 57, 58, 59], "x_q0": [43, 60, 73], "x_c": [43, 60, 73], "action_spac": [43, 57, 60, 73, 76, 120], "phi_": 43, "01": [17, 43, 57, 58, 60, 73, 120], "exp": [43, 60, 85], "gamma_": 43, "j0": 43, "j1": 43, "j2": 43, "attributeerror": [43, 57], "ipykernel_14651": 43, "15241541": 43, "true_prop": [43, 60], "n_b": [43, 57, 60, 73, 76], "boots_fit": 43, "98": [43, 60], "_fit": 43, "fitted_model": [43, 57, 60, 73, 76, 120], "_fit_model": 43, "pseudo_y_prev": 43, "get_pseudo_i": 43, "attribut": [43, 57, 121], "opt_d": [43, 57, 60, 73, 76, 120], "recommend_act": [43, 46, 57, 73, 76, 120], "value_count": [43, 57, 76, 120], "v_hat": [43, 57, 60, 73, 76, 120], "predict_valu": [43, 57, 73, 76, 120], "3389e": 43, "0295e": 43, "3272e": 43, "1025e": 43, "7135e": 43, "7582e": 43, "202": 43, "int64": [43, 57, 58, 60, 76, 120], "126": [43, 57, 60, 121], "18615811062617": 43, "005": 43, "mail": [43, 57, 58, 59], "women": [43, 57, 58, 59], "men": [43, 57, 58, 59], "deviaiton": [43, 57, 60, 73, 76], "amai": [43, 57, 60, 73, 76], "reliabl": [43, 57, 60, 73, 76], "fitted_param": [43, 57, 60, 73, 76], "fitted_valu": [43, 57, 60, 73, 76], "value_avg": [43, 57, 60, 73, 76], "value_std": [43, 57, 60, 73, 76], "param": [43, 57, 60, 73, 76], "predict_value_boot": [43, 57, 73, 76], "value_hat": [43, 57, 60, 73, 76], "3843662825924": 43, "989242109807423": 43, "200": [43, 57, 58, 60, 73, 76], "replic": [43, 57], "37488160184647": 43, "37": [43, 46, 57, 58, 60, 119], "std": [43, 57, 60, 73, 76], "37127842161804": 43, "2024261616976": 43, "placehold": [43, 73, 76], "schult": [43, 73], "institut": [43, 73], "640": [43, 73], "seattl": [43, 73], "symposium": [43, 73], "189": [43, 73], "326": [43, 73], "springer": [43, 73, 77, 78, 106], "york": [43, 73], "ny": [43, 58, 73], "murphi": [43, 57, 73, 76], "royal": [43, 73], "331": [43, 73, 77], "355": [43, 73], "liang": [43, 73, 77, 106], "88": [43, 58, 60, 73, 119], "fan": [43, 73], "46": [43, 60, 73, 99], "925": [43, 73], "a_": [43, 59, 61, 62, 64, 65, 66, 70, 71, 72, 73, 75, 76, 81, 84, 85, 86, 87, 92, 94, 96, 97, 99, 100, 105, 106, 107, 114, 115, 116, 123], "publish": [46, 61, 62, 64, 65, 66, 67, 68, 70, 104, 107, 108, 113, 114], "todo": [46, 57, 60, 68, 76, 104, 107, 108, 113, 114, 115, 123], "hide": [46, 61, 62, 64, 65, 66, 67, 68, 70, 104, 107, 108, 113, 114], "getcwd": [46, 61, 62, 64, 65, 66, 67, 68, 70, 79, 80, 81, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104, 107, 108, 113, 114, 120, 121], "chdir": [46, 61, 62, 64, 65, 66, 67, 68, 70, 79, 80, 81, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104, 107, 108, 113, 114, 120, 121], "filenotfounderror": [46, 61, 62, 64, 65, 66, 67, 68, 70, 73, 76, 79, 80, 81, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104, 107, 108, 113, 114, 120, 121], "ipykernel_14661": 46, "2987427551": 46, "errno": [46, 61, 62, 64, 65, 66, 67, 68, 70, 73, 76, 79, 80, 81, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104, 107, 108, 113, 114, 120, 121], "directori": [46, 61, 62, 64, 65, 66, 67, 68, 70, 73, 76, 79, 80, 81, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104, 107, 108, 113, 114, 120, 121], "stai": 46, "close": [46, 61, 66, 70, 73, 76, 83, 116, 120], "share": [46, 62, 66, 70, 85, 86, 94, 99, 101, 116, 124], "foundat": [46, 71, 78, 113, 114], "min": [46, 48, 58, 81], "neq": 46, "classif": [46, 64, 66, 70], "classifi": [46, 59], "impli": [46, 61, 71, 72, 120, 123], "why": 46, "w_i": 46, "shift": [46, 116, 123], "though": 46, "finit": [17, 46, 57, 62, 66, 70, 76, 81, 84, 87, 106, 107, 114], "instabl": 46, "svm": 46, "tbd": 46, "owl_simu": 46, "generate_test_cas": [46, 60], "case1": 46, "sigma": [46, 61, 62, 67, 70, 79, 83, 85, 87, 94, 96, 97, 99, 101, 108, 113, 114], "xai": [46, 60], "outcomeweightedlearn": 46, "linearsvc": 46, "svc": 46, "model_select": 46, "gridsearchcv": 46, "cross_val_scor": 46, "clf": 46, "logspac": 46, "param_grid": 46, "dict": [46, 73], "assignment_prob": 46, "your": [46, 58, 124], "asymptot": [17, 46, 61, 62, 70, 89, 116], "notabl": [46, 78], "meantim": [46, 89], "zhao": 46, "yingqi": 46, "499": [17, 46, 78], "1106": 46, "1118": 46, "ying": 46, "regimen": [46, 57, 76], "3776": 46, "3788": 46, "lou": 46, "zhilan": 46, "jun": 46, "shao": 46, "menggang": 46, "biometr": 46, "506": 46, "516": 46, "stat": 46, "sim": [46, 61, 62, 64, 66, 70, 71, 72, 79, 83, 85, 87, 88, 89, 90, 92, 93, 94, 96, 98, 99, 100, 101, 102, 103, 105, 115, 116], "const": 46, "despit": [17, 48, 119], "paid": [48, 123], "domain": [48, 105, 115], "dose": 48, "price": [48, 100, 101, 102, 103], "contin": 48, "discontinu": 48, "i2dr": 48, "unlik": [48, 117], "idr": 48, "ingredi": 48, "multi": [48, 59, 73, 77, 78, 86, 87, 97, 98, 105, 106, 115, 123], "overcom": 48, "limit": [48, 58, 62, 66, 70, 84, 114, 116], "bullet": [48, 62], "densiti": [48, 58, 61, 62, 66, 70, 71], "eqnarrai": [48, 61, 62, 64, 65, 70, 71, 72, 116], "eqn": [48, 61, 62, 64, 66, 67, 70, 71, 72, 85, 93, 94, 99, 101, 105, 115, 116], "almost": [48, 72], "sure": [48, 72], "naiv": 48, "concern": [48, 119], "psi_h": 48, "trade": [48, 66, 72, 82, 88, 89, 90, 95, 106], "decai": [48, 62], "union": [48, 73, 76, 120], "q_": [48, 58, 73, 76], "dnn": 48, "argmin_": [48, 70], "substack": [48, 64, 65], "gamma_n": 48, "argmax_": [48, 85, 87, 88, 89, 90, 100, 101, 102, 103, 104, 106, 108, 113, 114], "foral": [48, 71, 72, 88, 89, 90, 93, 94, 98, 99, 100, 101, 103], "argmax": 48, "value_djq": 48, "warfarin": 48, "djl_opt": 48, "data_gen": 48, "data_gener": 48, "realdatagener": 48, "file_nam": [48, 119], "real_envir": 48, "djl_partit": 48, "djl_agent": 48, "djlearn_opt": 48, "mlp_max_it": 48, "ipykernel_14666": 48, "2744164990": 48, "partit": 48, "033": [48, 103], "067": 48, "167": [48, 76], "333": 48, "minut": 48, "opt_polici": 48, "train_data": 48, "xt": 48, "3333333333333333": 48, "0th": 48, "djl_eval": 48, "pi_evalu": 48, "act_list": 48, "linspac": 48, "x_max": 48, "org_data": 48, "x_min": 48, "val": 48, "act": 48, "append": [48, 57, 60], "regr_mean": 48, "djlearn_ev": 48, "10022123966200729": 48, "4833333333333334": 48, "calibr": 48, "34": [48, 58, 60, 85, 86, 87], "2111": 48, "08885": 48, "kosorok": [48, 57, 76], "august": 48, "assist": 48, "26th": 48, "sigkdd": 48, "mine": 48, "march": 48, "1243": [48, 58], "1251": 48, "earli": [17, 57, 76, 88, 89, 90], "kept": [57, 76], "evolv": [57, 76], "hope": [57, 76], "straightforward": [57, 62, 64, 76, 83, 113, 116], "ol": 57, "r_": [57, 59, 61, 62, 64, 65, 66, 70, 71, 72, 73, 78, 80, 82, 84, 85, 86, 87, 92, 94, 96, 99, 105, 106, 114, 115, 123], "qlearn": [57, 60, 76, 120], "want": [57, 58, 73, 76, 95, 124], "beta_": [57, 87, 120], "regressionresultswrapp": 57, "0x7f9d6aa73be0": 57, "202956": 57, "239801": 57, "611375": 57, "526133": 57, "152892": 57, "843148": 57, "000549": 57, "007584": 57, "000416": 57, "371": 57, "48792828230138": 57, "53": [17, 57, 58, 60], "0005": 57, "0076": 57, "0004histori": 57, "49": [57, 58, 60], "ipykernel_14691": 57, "3664914869": 57, "regime_sampl": 57, "x_sampl": 57, "a_sampl": 57, "y_sampl": 57, "boot": 57, "v1": 57, "reward_nam": 57, "shold": 57, "set_index": [57, 76, 120, 121], "40675465960642": 57, "115": [57, 93], "95548975939548": 57, "502988081748748": 57, "wang": [57, 58, 76, 77, 97, 98, 105, 106, 115, 121], "zeng": [57, 76], "statistica": [57, 76, 94], "sinica": [57, 76], "901": [57, 76], "sandwich": 57, "project": 57, "ci": [57, 62, 71, 72], "extendour": 58, "satisfactori": 58, "prolong": 58, "tail": 58, "preval": 58, "heavi": [58, 116, 124], "unstabl": [58, 66], "skew": 58, "surviv": [58, 74, 121], "median": 58, "moodi": 58, "invert": 58, "cummul": 58, "qunatil": 58, "year": [58, 59, 79, 80, 85, 117], "feasibl": [58, 60, 62, 76, 98, 102, 116, 117], "misspecifi": 58, "pretain": 58, "c_i": 58, "rho_": 58, "beta_1": 58, "fine": 58, "grid": 58, "beta_0": 58, "u_": [58, 84, 106, 114], "1n": 58, "0n": 58, "1i": [58, 73, 75, 76], "0i": 58, "proper": 58, "nelder": 58, "mead": 58, "x1": 58, "x2": 58, "x_1": 58, "x_2": 58, "nameerror": [58, 94], "ipykernel_14696": 58, "478063769": 58, "quantile_otr": 58, "quantileotr": 58, "mocondquant_0": 58, "mocondquant_1": 58, "coeffici": [58, 79], "coef_original_scal": 58, "q_est": [58, 60], "dr_qopt": 58, "mopropen": 58, "notbinaryrandom": 58, "termin": [58, 88, 89, 90, 124], "129150": 58, "gradient": [58, 61, 70, 88, 89, 90], "final_simplex": 58, "0401e": 58, "04": [58, 120], "0062e": 58, "3241e": 58, "9385e": 58, "9699e": 58, "9649e": 58, "9516e": 58, "0098e": 58, "7645e": 58, "9178e": 58, "9988e": 58, "6791e": 58, "1197": 58, "119701027689532": 58, "nfev": 58, "nit": 58, "success": 58, "0000e": 58, "3468e": 58, "7854e": 58, "scikit_uplift": 58, "request": 58, "cycler": 58, "kiwisolv": 58, "chardet": 58, "idna": 58, "certifi": 58, "urllib3": 58, "sklift": 58, "return_x_y_t": 58, "history_seg": 58, "zip_cod": [58, 59], "newbi": [58, 59], "142": [58, 119], "surburban": 58, "phone": [58, 59], "350": [58, 82], "329": 58, "08": [58, 120], "rural": [58, 59], "web": [58, 59, 78, 93, 105, 106, 115], "180": 58, "500": [17, 58, 82, 86, 96, 97, 99, 104], "750": [58, 119], "675": 58, "83": [58, 60], "urban": [58, 59], "63995": 58, "54": [17, 58, 60], "63996": 58, "91": [58, 60, 119], "63997": 58, "63998": 58, "552": 58, "multichannel": [58, 59], "63999": 58, "472": 58, "82": [58, 60, 77, 106], "64000": 58, "578": [58, 59], "inplac": [58, 120], "332": 58, "451": [58, 82], "63466": 58, "63552": 58, "63743": 58, "63876": 58, "63883": 58, "segment": 58, "length": [58, 71, 72, 93, 96, 97, 99, 100], "get_dummi": 58, "prefix": [58, 73, 76, 120], "countri": 58, "anymor": 58, "zip_code_rur": 58, "channel_multichannel": 58, "categor": [58, 87, 123], "integ": [58, 86, 105, 115], "subset": [58, 72, 93, 96, 97, 98, 99, 100, 105, 115, 116, 119], "ntreatment": 58, "na": [58, 104, 107, 108, 113, 114, 120, 121], "zip_code_surburban": [58, 59], "zip_code_urban": [58, 59], "channel_phon": [58, 59], "channel_web": [58, 59], "297": 58, "149": [17, 58], "117": 58, "239": 58, "154": [58, 121], "exceed": 58, "502953": 58, "1895e": 58, "7227e": 58, "4110e": 58, "8883e": 58, "3248e": 58, "6189e": 58, "4630e": 58, "8951e": 58, "8789e": 58, "1688e": 58, "1876e": 58, "7185e": 58, "4111e": 58, "9113e": 58, "3260e": 58, "6160e": 58, "5493e": 58, "8964e": 58, "8975e": 58, "1777e": 58, "1816e": 58, "7171e": 58, "4095e": 58, "8872e": 58, "3259e": 58, "6174e": 58, "7327e": 58, "8731e": 58, "9187e": 58, "1762e": 58, "1882e": 58, "7222e": 58, "4113e": 58, "8993e": 58, "3252e": 58, "6171e": 58, "6759e": 58, "9012e": 58, "9038e": 58, "1803e": 58, "1924e": 58, "7234e": 58, "4088e": 58, "8863e": 58, "3250e": 58, "6158e": 58, "4646e": 58, "9095e": 58, "8690e": 58, "2013e": 58, "1900e": 58, "7211e": 58, "4096e": 58, "8999e": 58, "3246e": 58, "6178e": 58, "3607e": 58, "9148e": 58, "9045e": 58, "1516e": 58, "1880e": 58, "9149e": 58, "6187e": 58, "4407e": 58, "9451e": 58, "8686e": 58, "1759e": 58, "1875e": 58, "7196e": 58, "4083e": 58, "9025e": 58, "6157e": 58, "5918e": 58, "9206e": 58, "8949e": 58, "1680e": 58, "1872e": 58, "7252e": 58, "4081e": 58, "8846e": 58, "3243e": 58, "6168e": 58, "4315e": 58, "8960e": 58, "8996e": 58, "1701e": 58, "1925e": 58, "7192e": 58, "4085e": 58, "8711e": 58, "3264e": 58, "6172e": 58, "5903e": 58, "9406e": 58, "8946e": 58, "1745e": 58, "1889e": 58, "7195e": 58, "4101e": 58, "8838e": 58, "3258e": 58, "6177e": 58, "4543e": 58, "9190e": 58, "8917e": 58, "181": 58, "5661e": 58, "6834e": 58, "bin": 58, "patch": 58, "hist": [58, 119], "facecolor": 58, "blue": 58, "xlabel": 58, "r1": 58, "ylabel": 58, "titl": 58, "histogram": [58, 119], "xlim": 58, "ylim": 58, "face": 58, "_c": 58, "rho": [58, 61, 66, 70], "_j": [58, 62, 85, 86, 87], "qdr_qope": 58, "mixtur": 58, "mdn": 58, "gbdt": 58, "futher": 58, "quanatil": 58, "025941": 58, "121537": 58, "806875": 58, "637488": 58, "363393": 58, "641093": 58, "525509": 58, "381373": 58, "342528": 58, "780761": 58, "quantileop": 58, "qope_est": 58, "927600463556344": 58, "5961404868027": 58, "lan": 58, "ben": 58, "sherwood": 58, "523": 58, "1254": 58, "week": 59, "merchandis": 59, "compris": [59, 123], "nine": 59, "month": 59, "dollar": 59, "past": [59, 72, 81], "suburban": 59, "ident": [59, 79, 83, 85, 94, 96, 99, 101, 102, 104, 107, 108, 113, 114, 121], "flase": 59, "blog": 59, "minethatdata": 59, "2008": [59, 100], "phi1": 60, "phi2": 60, "psi1": 60, "psi2": 60, "random_binari": 60, "450": [60, 76], "a1": [60, 73, 76, 120], "binomi": [60, 94], "60": 60, "a2": [60, 73, 76, 120], "astyp": 60, "int": 60, "mu2": 60, "y_opt": 60, "opt_tru": 60, "optimal_a": 60, "optimal_v": 60, "250": 60, "720": 60, "1108": 60, "575955081366": 60, "estimate_value_boot": 60, "estimated_contrast": [60, 73], "estimated_prop": 60, "prop": 60, "estimate_valu": 60, "typeerror": 60, "ipykernel_14702": 60, "1171830641": 60, "assert": 60, "36": [60, 96, 119], "isinst": 60, "ndarrai": 60, "invalid": 60, "153": [60, 82], "a0": 60, "8969": 60, "9788": 60, "s1a1": 60, "del": 60, "1102": 60, "524126394967": 60, "554474056899934": 60, "379": 60, "334892": 60, "318229": 60, "628596": 60, "027810": 60, "313279": 60, "716134": 60, "729627": 60, "050612": 60, "335": 60, "294202": 60, "253088": 60, "460437": 60, "091607": 60, "664498": 60, "409741": 60, "410791": 60, "090007": 60, "200070": 60, "071281": 60, "474": 60, "508450": 60, "375403": 60, "517774": 60, "092061": 60, "114": [60, 82], "a_est": 60, "c0": 60, "c1": 60, "vhat": 60, "q0": [60, 76, 120], "q1": [60, 76, 120], "opt_v": 60, "rep": 60, "43": 60, "51": 60, "52": [17, 60, 119], "58": 60, "78": [60, 100, 101, 103], "79": [60, 119], "81": 60, "86": [60, 121], "87": 60, "89": 60, "92": 60, "248": 60, "2674": 60, "9966": 60, "718": 60, "432": 60, "9964": 60, "1119": 60, "7158350462053": 60, "366": [60, 104], "5116": 60, "157": 60, "1218": [60, 73, 76, 120], "7812": 60, "0755e": 60, "4913e": 60, "3333e": 60, "8864e": 60, "1197e": 60, "0288e": 60, "5741e": 60, "1112": [60, 76], "2353635304949": 60, "1120": 60, "4987706735005": 60, "10000": [60, 83], "decent": 61, "short": [61, 66, 117], "signific": [61, 119, 121], "fqe": [61, 64, 65, 70], "integr": [61, 70], "bellman": [61, 64, 65, 70, 71, 116], "bellman_q": [61, 64, 70, 71, 116], "r_t": [61, 64, 65, 70, 71, 77, 78, 79, 81, 82, 83, 84, 86, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 106, 114, 115, 116, 123], "s_": [61, 62, 64, 65, 66, 70, 71, 72, 104, 116, 123], "a_t": [61, 62, 64, 65, 70, 71, 72, 73, 77, 78, 79, 80, 81, 82, 83, 84, 86, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 103, 105, 106, 107, 108, 113, 114, 115, 116, 123], "s_t": [61, 62, 64, 65, 66, 70, 71, 72, 116, 123], "wise": [61, 66, 70], "stepi": [61, 66, 70], "stepdr": [61, 70], "i_t": [61, 66, 70, 93], "besid": [61, 64, 65, 66, 70, 116], "recurs": [61, 70, 71], "debia": [61, 62, 70], "reflect": [61, 66, 70, 72, 78, 82, 86, 106], "mi": [61, 62, 70], "sens": [61, 62, 70], "per": [61, 70, 79, 80, 85], "suffer": [61, 70, 119], "huge": [61, 70, 116], "widetild": [61, 66, 70], "equiv": [61, 62, 70, 85, 88, 89, 90, 93], "drl": [61, 62, 70], "margin": [61, 62, 66, 70], "infti": [61, 62, 64, 65, 66, 70, 71], "p_t": [61, 62, 66, 70], "p_b": [61, 66, 70], "recal": [61, 62, 66, 67, 70, 116, 117], "manner": [61, 70], "tini": [61, 62, 70], "textrm": [61, 62, 67, 70, 120], "nt": [61, 62, 67, 70, 121], "sqrt": [61, 70, 80, 84, 104, 114], "weakli": [61, 66, 70], "lower_bound": [61, 67, 70], "tupl": [61, 62, 70, 71, 77, 86, 105, 115, 116, 117], "proven": [61, 70], "speak": [61, 62, 70], "pack": [61, 62, 64, 65, 66, 67, 68, 70, 104, 107, 108, 113, 114], "ipykernel_14709": 61, "2982377520": [61, 64, 65, 68], "eqn_omega": [61, 70], "mini": [61, 70], "solvel": [61, 70], "sup_": [61, 70], "simplifi": [61, 70, 71, 88, 89, 90], "reproduc": [61, 70], "hilbert": [61, 70], "rkh": [61, 70], "outer": [61, 70], "descent": [61, 70, 88, 89, 90, 116], "approxim": [61, 66, 70, 85, 87, 92, 94, 96, 101, 102], "still": [62, 66, 70, 85, 117], "stationari": [62, 70, 71, 72, 77], "slow": 62, "wald": [62, 67, 88, 89], "nomin": 62, "coverag": 62, "weaker": 62, "deeper": 62, "new_drl_term": 62, "a_0": [62, 72, 116], "dirac": 62, "p_": [62, 70, 88, 89, 90], "event": 62, "numer": [62, 64, 65, 78, 82, 86, 105, 106, 115], "debiasterm": 62, "protect": [17, 62, 89], "tr": 62, "tripli": [62, 121], "ci_tr": 62, "z_": [62, 67], "nuisans": 62, "i_1": 62, "t_": 62, "disjoint": 62, "t_2": 62, "counterpart": [62, 66], "arbitrari": 62, "ipykernel_14714": 62, "3779975037": [62, 66, 67, 70], "breakthrough": 62, "spirit": 62, "uncorrel": 62, "hoeffd": 62, "decomposit": 62, "degener": 62, "environ": [64, 77, 78, 82, 86, 88, 89, 90, 105, 106, 115, 119], "conceptu": [64, 66], "contract": [64, 65, 116], "ell": [64, 65, 116], "ipykernel_14719": 64, "fqi": [65, 116], "ipykernel_14724": 65, "vanilla": 66, "reweight": 66, "prod_": 66, "transit": [66, 71, 72, 116, 117], "immedi": [66, 71, 72, 121], "_t": [66, 72, 73, 75, 76, 78, 88, 89, 90, 93, 94, 99, 100, 101, 105, 115, 116], "bias": 66, "exponenti": 66, "issu": [66, 81, 116], "made": [66, 77], "forward": 66, "stationar": [66, 71], "sa": [66, 70], "rather": [66, 72], "understood": 66, "trick": [66, 73], "omit": 66, "ipykernel_14729": 66, "principl": [66, 70], "truncat": [66, 70, 121], "estimand": [66, 70], "neglig": [66, 70, 121], "harri": [66, 70], "ergod": [66, 70], "chain": [66, 70], "eventu": [66, 70], "mix": [66, 70, 99], "ref": [67, 70], "sec": [67, 70], "adopt": [67, 94], "tighter": 67, "concentr": [67, 98], "inequ": 67, "curse_horizon": [67, 70], "explicitli": [67, 89, 90, 94, 99, 101], "kallus2019effici": [67, 70], "eqref": [67, 70], "ci_drl": 67, "upper": [67, 80, 82, 84, 88, 89, 90, 104, 114], "ipykernel_14734": 67, "ipykernel_14739": 68, "ipykernel_14744": 70, "textit": 70, "citep": 70, "jiang2016doubl": 70, "farajtabar2018mor": 70, "uehara2019minimax": 70, "rotnitzky1995semiparametr": 70, "carefulli": [70, 84, 116], "thomas2016data": 70, "our_method": 70, "superior": [70, 85], "gain": 70, "tang2019doubl": 70, "upon": [70, 78, 123], "vspace": 70, "1cm": 70, "worthi": 70, "denomin": 70, "modif": 70, "throw": 70, "awai": [70, 90], "geometr": [70, 94, 100, 101, 103], "2cm": 70, "mean_": 70, "proof": 70, "cramer": 70, "rao": 70, "bickel1993effici": 70, "van2000asymptot": 70, "liu2018break": 70, "ineffici": [70, 83, 84, 87], "mass": 71, "enter": 71, "throughout": [71, 119], "report": [71, 123], "move": 71, "readi": 71, "t_n": [71, 72], "uniformli": [71, 72], "def_valu": [71, 72], "benefit": [71, 72], "_l": [71, 72], "_u": [71, 72], "opo": [71, 72], "repeatedli": [72, 86], "perspectii": 72, "implicitli": 72, "writ": 72, "ground": [72, 116], "literautr": 72, "a_1": [72, 116, 120], "y_t": [72, 116], "had": [72, 116], "w_t": [72, 75, 92, 94, 95, 116], "y_0": [72, 116], "s_1": [72, 116], "cup_": [72, 116], "determinist": [72, 85, 88, 89, 90, 94, 99, 100, 101, 105, 115], "homogen": 72, "central": [72, 77, 82, 106], "ma": [72, 116, 117], "subseteq": [72, 98, 100, 116], "cmia": [72, 116, 117], "w_": [72, 93, 94, 116], "statioanri": 72, "ii": [72, 106, 117], "shall": 72, "wors": 72, "ca": 72, "sra": 72, "s_j": 72, "a_j": 72, "y_j": 72, "markovobserv": 72, "robserv": 72, "interchang": 72, "m_t": 73, "h_": [73, 75, 76, 123], "ti": [73, 75, 76], "till": [73, 75, 76], "q_t": [73, 116], "h_t": 73, "v_": [73, 100, 101, 104], "t0": 73, "omega_": 73, "d_t": 73, "backward": [73, 76], "previous": [73, 79, 80, 81, 83, 84, 85, 87], "eqaut": 73, "accordingli": [73, 79, 83, 84, 95, 97, 103, 108, 113, 114], "m_k": 73, "h_ti": 73, "datamdp_feas": [73, 76], "txt": [73, 76], "sep": [73, 76, 120], "cd4_0": [73, 76], "cd4_6": [73, 76], "cd4_12": [73, 76], "a3": [73, 76, 120], "ipykernel_14759": 73, "3951783812": 73, "_decor": [73, 76, 120], "wrapper": [73, 76, 120], "309": [73, 76, 82, 100, 120], "stacklevel": [73, 76, 120], "310": [73, 76, 120], "311": [73, 76, 82, 120], "312": [73, 76, 82, 120], "313": [73, 76, 82, 120], "io": [73, 76, 120, 124], "parser": [73, 76, 120], "reader": [73, 76, 116, 120], "filepath_or_buff": [73, 76, 120], "delimit": [73, 76, 120], "header": [73, 76, 119, 120], "index_col": [73, 76, 120], "usecol": [73, 76, 120], "squeez": [73, 76, 120], "mangle_dupe_col": [73, 76, 120], "true_valu": [73, 76, 120], "false_valu": [73, 76, 120], "skipinitialspac": [73, 76, 120], "skiprow": [73, 76, 120], "skipfoot": [73, 76, 120], "nrow": [73, 76, 120], "na_valu": [73, 76, 120], "keep_default_na": [73, 76, 120], "na_filt": [73, 76, 120], "skip_blank_lin": [73, 76, 120], "parse_d": [73, 76, 120], "infer_datetime_format": [73, 76, 120], "keep_date_col": [73, 76, 120], "date_pars": [73, 76, 120], "dayfirst": [73, 76, 120], "cache_d": [73, 76, 120], "chunksiz": [73, 76, 120], "compress": [73, 76, 120], "decim": [73, 76, 120], "linetermin": [73, 76, 120], "quotechar": [73, 76, 120], "quot": [73, 76, 120], "doublequot": [73, 76, 120], "escapechar": [73, 76, 120], "comment": [73, 76, 120], "encoding_error": [73, 76, 120], "dialect": [73, 76, 120], "error_bad_lin": [73, 76, 120], "warn_bad_lin": [73, 76, 120], "on_bad_lin": [73, 76, 120], "delim_whitespac": [73, 76, 120], "low_memori": [73, 76, 120], "memory_map": [73, 76, 120], "float_precis": [73, 76, 120], "storage_opt": [73, 76, 120], "676": [73, 76, 120], "kwd": [17, 73, 76, 120], "updat": [73, 76, 79, 80, 81, 83, 84, 85, 87, 89, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104, 107, 108, 113, 114, 116, 120, 123, 124], "kwds_default": [73, 76, 120], "678": [73, 76, 120], "_read": [73, 76, 120], "679": [73, 76, 120], "680": [73, 76, 120], "575": [73, 76, 120], "textfileread": [73, 76, 120], "576": [73, 76, 120], "577": [73, 76, 120], "930": [73, 76, 120], "iohandl": [73, 76, 120], "_engin": [73, 76, 120], "_make_engin": [73, 76, 120], "933": [73, 76, 120], "934": [73, 76, 120], "1214": [73, 76, 120], "str": [17, 73, 76, 120], "pathlik": [73, 76, 120], "readcsvbuff": [73, 76, 120], "byte": [73, 76, 120], "1215": [73, 76, 120], "bool": [73, 76, 120], "1216": [73, 76, 120], "get_handl": [73, 76, 120], "overload": [73, 76, 120], "1217": [73, 76, 120], "path_or_buf": [73, 76, 120], "is_text": [73, 76, 120], "ioarg": [73, 76, 120], "788": [73, 76, 120], "5872e": 73, "0493e": 73, "9347e": 73, "2010e": 73, "568": 73, "1057": 73, "8412e": 73, "2479e": 73, "1162": 73, "4662578531918": 73, "3156513295758": 73, "559003921896037": 73, "245571": 73, "595014": 73, "143433": 73, "440232": 73, "3966192806022": 73, "626837283714682": 73, "omega_t": 73, "w_1": 75, "w_2": 75, "multistag": 76, "pi_": [76, 116], "d_": 76, "prepar": [76, 105], "reset": 76, "reset_index": [76, 119], "ipykernel_14770": 76, "1696292620": 76, "q2": 76, "898024": 76, "102009": 76, "116478": 76, "002859": 76, "171": [76, 121], "676661": 76, "454044": 76, "288382": 76, "921595": 76, "015938": 76, "553900": 76, "477566": 76, "551396": 76, "334465": 76, "182": [76, 119, 121], "312429": 76, "703112": 76, "550": 76, "1113": [76, 96, 98], "3004201781748": 76, "9663576650953": 76, "6050454629164577": 76, "BE": 76, "THE": 76, "AS": 76, "THAT": 76, "OF": 76, "979": 76, "4518636939481": 76, "0772776227565": 76, "2034780374001155": 76, "accuraci": 76, "financ": [77, 82, 106, 123], "slot": 77, "casino": 77, "gambler": 77, "plai": [77, 78, 82, 84, 86, 88, 89, 90, 98], "earn": 77, "payout": 77, "element": [77, 93], "produc": 77, "divid": [77, 123], "adversari": 77, "pacakg": 77, "four": [77, 85, 94, 97, 99, 101, 120, 121], "distinct": 77, "along": [77, 123], "laern": 77, "durand": [77, 106], "achilleo": [77, 106], "iacovid": [77, 106], "strati": [77, 106], "mitsi": [77, 106], "pineau": [77, 106], "mous": [77, 106], "novo": [77, 106], "carcinogenesi": [77, 106], "healthcar": [77, 82, 86, 106], "zha": [77, 106], "portfolio": [77, 106], "choic": [17, 77, 93, 94, 100, 105, 106, 115, 121], "twenti": [77, 106], "fourth": [77, 106], "joint": [77, 106], "xu": [77, 106], "811": [77, 106], "821": [77, 106], "bouneffouf": [77, 78, 82, 106], "bouzeghoub": 77, "gan\u00e7arski": 77, "novemb": [77, 103], "mobil": 77, "awar": 77, "324": 77, "berlin": [77, 78], "heidelberg": [77, 78], "primarili": 78, "profil": 78, "occup": [78, 86, 106], "season": 78, "temperatur": 78, "aid": 78, "mab": [78, 81, 83, 84, 86, 106], "tast": 78, "film": 78, "ultim": [78, 82, 86, 93, 98, 100, 105, 106], "lipschitz": 78, "linucb": [78, 106, 123], "lint": [78, 106, 123], "static": [78, 85, 94, 99, 124], "nonstationari": 78, "1m": [78, 82, 86, 105, 106], "highest": [78, 81, 82, 83, 84, 86, 93, 94, 95, 96, 97, 99, 105, 106, 107, 108, 113, 114], "colleg": [78, 79, 80, 85, 86, 106], "academ": [78, 86, 106], "technician": [78, 86, 106], "writer": [78, 86, 106], "bernoulli": [78, 82, 86, 93, 94, 95, 98, 99, 108, 113], "chu": [78, 80, 106], "reyzin": [78, 80], "schapir": [78, 80, 106], "2011": [78, 80, 88, 89, 90, 102], "june": [78, 79, 80, 92, 93, 96, 98, 100, 101, 103, 108], "payoff": [78, 79, 80, 106, 108], "fourteenth": [78, 80], "jmlr": [78, 80], "workshop": [78, 80], "agraw": [78, 79, 100, 101, 102, 103, 104, 106, 108], "goyal": [78, 79, 100, 101, 103, 104, 106, 108], "thompson": [78, 79, 82, 83, 86, 88, 89, 90, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 105, 108, 113, 114, 115, 123], "127": [78, 79, 106, 108, 119], "kveton": [78, 79, 85, 86, 87, 92, 93, 96, 98, 105, 106, 108, 115], "zaheer": [78, 79, 85, 86, 87, 92, 106, 108], "szepesvari": [78, 79, 86, 87, 92, 93, 105, 106, 108, 115], "ghavamzadeh": [78, 79, 86, 92, 106, 108], "boutili": [78, 79, 86, 87, 92, 106, 108], "2066": [78, 79, 92, 106, 108], "2076": [78, 79, 92, 106, 108], "rish": [78, 82, 106], "10040": [78, 82, 106], "slivkin": [78, 82, 106], "286": 78, "hazan": 78, "megiddo": 78, "513": [78, 121], "langford": [78, 88, 89, 90, 106], "2010": [78, 106], "april": [78, 93, 95], "articl": [78, 106], "19th": [78, 106], "670": [78, 106], "auer": [78, 81, 84, 106, 107, 114], "cesa": [78, 81, 84, 106, 107, 114], "bianchi": [78, 81, 84, 106, 107, 114], "freund": 78, "nonstochast": 78, "multiarm": [78, 81, 84, 106, 107, 114], "siam": 78, "scalabl": [79, 80, 85, 87, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 123], "ucb": [79, 80, 82, 92, 95, 96, 97, 102, 103, 104, 106, 114], "suscept": [79, 92, 96, 102], "avial": [79, 105, 108, 115], "consdier": [79, 108], "ts": [79, 80, 82, 85, 86, 87, 94, 95, 97, 99, 101, 102, 103, 106, 108, 123], "domian": [79, 83, 108, 113], "thecorrespond": [79, 108], "posterior": [79, 80, 81, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103, 106, 108, 113], "greatest": [79, 83, 95, 108, 113], "distirbut": [79, 83, 95, 97, 103, 108, 113], "rewad": [79, 83, 95, 97, 103, 108, 113], "ipykernel_14782": 79, "836241344": [79, 80, 81, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103], "imit": [79, 80, 81, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103], "_env": [79, 80, 81, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103], "single_contextual_env": [79, 80], "deviat": [79, 83, 85, 87, 96, 97], "prior_theta_u": [79, 108], "prior_theta_cov": [79, 108], "covarainc": [79, 83], "lints_gaussian_ag": [79, 87, 108], "lints_gaussian": [79, 108], "get_phi": [79, 80, 85], "take_act": [79, 80, 81, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104, 107, 108, 113, 114], "get_reward": [79, 80, 81, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104, 107, 108, 113, 114], "receive_reward": [79, 80, 81, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104, 107, 108, 113, 114], "feature_info": [79, 80, 85], "encount": [79, 80], "old": [79, 80, 85], "retrain_freq": [79, 80, 92, 108], "glm": [79, 80, 106, 123], "lints_glm_ag": 79, "lints_glm": 79, "specifci": 80, "gaussain": 80, "theta_a": [80, 81, 83, 107], "u_a": [80, 84, 114], "theta_": [80, 81, 83, 92, 93, 94, 95, 96, 98, 100, 103, 107, 108, 113, 120], "ipykernel_14787": 80, "exploration_t": 80, "linucb_gaussian_ag": 80, "linucb_gaussian": 80, "linucb_glm_ag": 80, "linucb_glm": 80, "ideal": [81, 116], "domin": 81, "eploit": 81, "epsilon_t": [81, 107], "epsilon_": [81, 85, 87, 106, 107], "pull": [81, 84, 85, 107, 114], "c_a": [81, 84, 107, 114], "decrease_ep": [81, 107], "specfi": [81, 107], "ipykernel_14792": 81, "epsilon_greedi": 81, "_env_realmab": [81, 83, 84], "single_gaussian_env": [81, 83, 84, 107, 108, 113, 114], "emploi": [81, 100, 105], "greedy_ag": [81, 107], "single_bernoulli_env": [81, 83, 84, 108, 113], "fischer": [81, 84, 106, 107, 114], "256": [81, 84, 106, 107, 114], "satisf": [82, 93], "tackl": [82, 106], "preprocess": [82, 86], "tabl": [82, 120, 121], "045": 82, "288": 82, "204": 82, "096": 82, "170": 82, "287": 82, "076": 82, "305": 82, "176": 82, "278": 82, "455": 82, "553": 82, "421": [82, 101, 102], "420": 82, "07272": [82, 106], "Be": 83, "especi": [83, 85, 100, 105, 115, 123], "uncertainti": [83, 84], "dilemma": [83, 106, 108, 113], "greedili": [83, 84, 94, 99, 101, 106, 108, 113, 114], "nearli": [83, 106, 108, 113], "manual": [83, 113, 124], "r_0": 83, "ipykernel_14802": 83, "reward_typ": [83, 113], "u_prior_mean": [83, 97, 113], "u_prior_cov": [83, 113], "ts_gaussian_ag": [83, 113], "prior_phi_beta": [83, 113], "ts_bernoulli_ag": [83, 113], "russo": [83, 105, 106, 113, 114, 115], "kazerouni": [83, 105, 106, 113, 114, 115], "osband": [83, 105, 106, 113, 114, 115], "wen": [83, 92, 93, 96, 98, 105, 106, 113, 114, 115], "tutori": [83, 93, 98, 99, 100, 101, 105, 106, 113, 114, 115, 124], "0203": [83, 106], "lattimor": [83, 106], "szepesv": [83, 106], "ari": [83, 106], "cambridg": [83, 106], "radiu": [84, 106, 114], "2log": 84, "ucb1": [84, 106, 123], "ipykernel_14807": 84, "ucb_ag": [84, 104, 114], "hierarch": [85, 86, 94, 99, 101], "alignedat": [85, 87, 94, 99, 101], "inter": [85, 93, 94, 98, 99, 100, 101, 123], "intra": 85, "y_": [85, 87, 93, 94, 97, 98, 99, 100, 101, 103], "mu_": [85, 86, 87, 120], "hierachical_model": 85, "explicit": [85, 87, 94, 101], "pymc3": [85, 87, 94, 101, 102], "mathmet": 85, "simultan": [85, 94, 99, 101], "ipykernel_14812": 85, "meta_bandit": [85, 87], "mtts_gaussian": 85, "_env_realmultitask": [85, 87], "multitask_env": [85, 87], "episod": [85, 87], "preced": [85, 87], "concurr": 85, "theta_prior_mean": 85, "theta_prior_cov": 85, "delta_cov": 85, "approximate_solut": 85, "finish": [85, 87], "update_freq": [85, 87, 94, 99, 101, 102, 104], "mtts_gaussian_ag": 85, "mtts_agent": 85, "posterior_u": [85, 87, 113], "posterior_cov_diag": [85, 87], "mtts_binari": 85, "phi_beta": [85, 87, 94, 101, 104, 107, 108, 113], "mtts_binary_ag": 85, "posterior_alpha": [85, 87, 113], "posterior_beta": [85, 87, 113], "29655": [85, 86], "29668": [85, 86], "basu": [85, 86, 87], "szepesv\u00e1ri": [85, 86, 87], "28029": [85, 86, 87], "28041": [85, 86, 87], "acceler": 86, "perspect": [86, 95, 97, 116], "arbitrati": 86, "decsion": 86, "lack": [86, 123], "a_k": 86, "r_k": 86, "konobeev": [86, 87], "hsu": [86, 87], "mladenov": [86, 87], "5884": [86, 87], "5893": [86, 87], "hong": 86, "7724": 86, "7741": 86, "maintain": [87, 116], "demonstr": 87, "accommod": [87, 96], "ipykernel_14822": 87, "meta_ts_gaussian": 87, "sigma_0": 87, "sigma_q": 87, "meta_ts_gaussian_ag": 87, "meta_ts_ag": 87, "episode_finish": 87, "meta_post": 87, "candid": [87, 92, 94, 95, 96, 97, 99, 101, 102, 103], "candi_mean": 87, "entri": [87, 93], "meta_ts_binari": 87, "meta_ts_binary_ag": 87, "ongo": [88, 89, 90], "econom": [88, 89, 90, 123], "crucial": [88, 89, 90], "exposit": [88, 89, 90], "dud\u00edk": [88, 89, 90], "suvta": [88, 89, 90], "dr_est": [88, 89, 90], "2110": [88, 89, 90], "15501": [88, 89, 90], "240": [88, 89, 90], "255": [88, 89, 90], "534": [88, 89, 90], "708": [88, 89, 90], "719": [88, 89, 90], "1103": [88, 89, 90], "4601": [88, 89, 90], "dream": 89, "architectur": [89, 117], "tripl": 89, "x_t": 89, "buffer": [89, 116], "pi_b": 89, "pi_t": 89, "histor": [89, 90, 117], "kappa_t": [89, 90], "pr": [89, 90], "kappa": [89, 90], "overlap": 90, "zong": [92, 93], "laplac": 92, "mid": [92, 94, 95, 96, 97, 99, 100, 101, 102, 103, 106, 114], "inroduct": [92, 94, 95, 96, 97, 99, 101, 102, 103], "cascad": [92, 94, 95, 105, 115, 123], "ipykernel_14845": 92, "structured_bandit": [92, 94, 95, 96, 97, 99, 101, 102, 103], "_env_realcascad": [92, 94, 95], "cascading_env": [92, 94, 95], "itm": [92, 94, 95, 96, 97, 99, 101, 102, 103], "considerd": [92, 96, 99], "lints_ag": [92, 96, 102], "fisrt": [92, 96, 99], "restatur": [92, 94, 95, 96, 97, 99, 101, 102, 103], "1301": 92, "2087": 92, "1123": 92, "unfortun": [92, 94, 95], "ni": [92, 93], "sung": [92, 93], "ke": [92, 93], "1603": [92, 93], "05359": [92, 93], "sort": 93, "slate": [93, 98, 100, 103, 104], "f_r": [93, 94, 99, 101, 105, 115], "bottom": [93, 105], "she": 93, "latent": 93, "e_": [93, 94], "visibl": 93, "theta_i": [93, 94, 95, 97, 98, 99, 100, 101, 102, 103], "probabilist": [93, 94, 101], "mathmat": 93, "model_cascad": [93, 94], "permut": 93, "ts_cascad": 93, "cascadelint": [93, 123], "mtss_cascad": 93, "chuklin": 93, "rijk": 93, "synthesi": 93, "lectur": 93, "retriev": [93, 105], "2202": [93, 94, 98, 99, 100, 101, 105], "13227": [93, 94, 98, 99, 100, 101, 105], "ashkan": [93, 96, 98, 105, 115], "767": [93, 105, 115], "776": [93, 103, 105, 115], "cheung": [93, 95], "tan": [93, 95], "zhong": [93, 95], "22nd": [93, 95], "mtss": [94, 99, 101, 123], "general_hierach": [94, 99, 101], "mtt": [94, 99, 101], "subsum": [94, 99, 101, 105, 115], "full": [94, 99, 123], "enjoi": [94, 101], "conjug": [94, 95, 101, 103, 113], "facilit": [94, 99, 101], "deploy": [94, 99, 101], "ipykernel_14855": 94, "gamma_prior_mean": [94, 99, 101, 102], "gamma_prior_cov": [94, 99, 101, 102], "coverainc": [94, 101, 102], "n_init": [94, 101, 102, 104], "draw": [94, 101, 102], "mtss_agent": [94, 99, 101], "tmp": 94, "ipykernel_540529": 94, "4210367235": 94, "2189": 94, "1610": 94, "1206": 94, "forcina": 94, "franconi": 94, "rivista": 94, "di": [94, 119, 120, 121], "applicata": 94, "salvati": [94, 101], "wiecki": [94, 101], "fonnesbeck": [94, 101], "peerj": [94, 101], "e55": [94, 101], "doi": [94, 101], "7717": [94, 101], "ipykernel_14860": 95, "u_prior_alpha": [95, 103], "u_prior_beta": [95, 103], "ts_agent": [95, 97, 103], "2690": 95, "reach": 96, "kalman": 96, "filter": 96, "exact": 96, "Of": [96, 97, 99], "cours": [96, 97, 99], "welcom": [96, 97, 99], "ipykernel_14865": 96, "combinatorial_semi": [96, 97, 99], "_env_realcomb": [96, 97, 99], "combsemi_env": [96, 97, 99], "prior_gamma_mu": 96, "prior_gamma_cov": [96, 99], "lints_semi": 96, "tot_r": [96, 97, 99], "480": 96, "1895": 96, "1700": 96, "2219": 96, "2807": 96, "1593": 96, "2784": 96, "172": [96, 119, 121], "2831": 96, "1523": [96, 99], "8214": 96, "2055": 96, "408": 96, "0487": 96, "8551": 96, "1778": 96, "595": 96, "9068": 96, "6194": 96, "9444": [96, 99], "3574891974648375": 96, "1122": [96, 98], "began": 97, "famili": 97, "sub": [97, 116], "bay": [97, 99], "ipykernel_14870": 97, "u_prior_cov_diag": 97, "diagon": 97, "ts_semi": 97, "1054": 97, "2060": 97, "494": 97, "1488": 97, "1351": 97, "1816": 97, "898": 97, "1114": [97, 99], "321": 97, "8094": 97, "8462": 97, "8306": 97, "6929": 97, "6706": 97, "6444": 97, "5902": 97, "5764": [97, 99], "0607550383245": 97, "yuan": [97, 98, 105, 115], "februari": 97, "151": [17, 97, 98, 105, 115, 121], "159": [97, 98, 105, 115], "perrault": 97, "boursier": 97, "valko": 97, "perchet": 97, "5429": 97, "5440": 97, "alloc": [98, 105, 115], "scenario": [98, 123], "pali": 98, "sigma_2": [98, 99], "combt": [98, 123], "comblint": [98, 123], "mtss_comb": 98, "sankararaman": 98, "5114": 98, "5122": 98, "lmm": 99, "sigma_1": 99, "ipykernel_14880": 99, "prior_gamma_mean": 99, "mtss_semi": 99, "686": 99, "2132": 99, "689": 99, "1645": 99, "1733": 99, "2671": 99, "1611": 99, "2099": 99, "1668": 99, "9462": 99, "4307": 99, "9867": 99, "846": 99, "504": 99, "3613": 99, "6928": 99, "45535406270607": 99, "pari": 99, "golrezaei": 99, "ssrn": 99, "3651397": 99, "mnl": [100, 101, 102, 103, 104, 123], "arguabl": 100, "eta_0": 100, "eta_1": 100, "eta_": [100, 101, 102, 103, 104], "eta_k": 100, "revenu": [100, 101, 102, 103], "convention": 100, "v_i": 100, "mnldist": 100, "cup": 100, "v_0": 100, "intract": [100, 103], "appear": [100, 101, 102, 103, 104], "matter": 100, "ts_mnl": 100, "ts_contextual_mnl": 100, "mtss_mnl": 100, "pentico": 100, "european": 100, "190": [100, 119, 121], "295": 100, "luce": [100, 105, 115], "courier": [100, 105, 115], "corpor": [100, 105, 115], "avadhanula": [100, 101, 102, 103, 104], "zeevi": [100, 101, 103, 104], "oh": [100, 101, 102], "iyengar": [100, 101, 102], "1453": [100, 103, 104], "1485": [100, 103, 104], "ou": [100, 102], "1805": [100, 102], "02971": [100, 102], "concret": 101, "eqn1": 101, "logit": [101, 102, 103, 105, 115], "ipykernel_14890": 101, "_env_realmnl": [101, 102, 103], "mnl_env": [101, 102, 103, 104], "same_reward": [101, 102, 103, 104], "clip": [101, 103], "275": [101, 121], "448": [101, 102], "836": [101, 102], "9493188224156814": 101, "id": [101, 102, 103, 121], "framwork": 102, "realtionship": 102, "ipykernel_14895": 102, "mnl_ts_contextu": 102, "298": 102, "9729194890231303": 102, "tulabandhula": 102, "tractabl": [102, 103], "14033": 102, "multinomila": 103, "nice": [103, 113], "ipykernel_14900": 103, "ts_mnl_beta": 103, "mnl_t": 103, "864": 103, "394": [103, 119], "911": 103, "430": [103, 119], "03330462654669619": 103, "dong": 103, "switch": [103, 124], "2607": 103, "2615": 103, "48log": 104, "longleaf": [104, 107, 108, 113, 114, 120, 121], "home": [104, 107, 108, 113, 114, 120, 121], "lge": [104, 107, 108, 113, 114, 120, 121], "ipykernel_14905": 104, "3636065689": [104, 107, 108, 113, 114], "_env_mnl": 104, "20000": 104, "update_freq_linear": 104, "with_intercept": [104, 107, 108, 113, 114], "x_mu": [104, 107, 108, 113, 114], "x_sigma": [104, 107, 108, 113, 114], "sigma_gamma": [104, 107, 108, 113, 114], "mu_gamma": 104, "exp_r": 104, "519": 104, "906": 104, "main_raw_model": [105, 115], "cardin": [105, 115], "exclud": [105, 115], "appeal": 105, "brows": 105, "02038": [105, 115], "2015a": [105, 115], "strike": 106, "unfamiliar": 106, "iii": [106, 120, 121], "guaasian": [106, 123], "glmt": 106, "guassian": [106, 123], "2071": 106, "2080": 106, "ipykernel_14920": 107, "sigma_theta": [107, 108, 113, 114], "mu_theta": [107, 108, 113, 114], "specifii": 107, "cnt": [107, 108], "rewrit": 108, "ipykernel_14925": 108, "lints_bernoulli_ag": 108, "lints_bernoulli": 108, "breward": 113, "ipykernel_14933": 113, "4375": 113, "ipykernel_14938": 114, "rs": 114, "1249": 114, "cook": 115, "vast": 116, "disucss": 116, "hear": 116, "materi": 116, "recap": 116, "appraoch": 116, "mont": 116, "carlo": 116, "td": 116, "wait": 116, "paradigm": [116, 117], "trasit": 116, "schema": 116, "trpo": 116, "ppo": 116, "simplist": 116, "descient": 116, "around": [116, 119], "fortun": [116, 117], "bigtriangledown_": 116, "abil": 116, "dqn": 116, "replai": 116, "scratch": 116, "Such": 116, "q_0": 116, "effiic": 116, "a2c": 116, "sac": 116, "a3c": 116, "pomdp_comparison": 117, "valuabl": 117, "lag": [117, 119, 121], "infeas": 117, "horiozn": 117, "belief": 117, "nn": [17, 117], "privaci": 119, "he": 119, "mortal": [119, 120], "hour": [119, 120], "diagram": 119, "load_ext": 119, "autoreload": 119, "randn": 119, "rseed": 119, "npseed": 119, "math": 119, "datetim": 119, "multiprocess": 119, "pool": 119, "functool": 119, "omp_num_thread": 119, "subset_rl_data_final_cont": 119, "mimic3_bas": 119, "within": [119, 120, 121, 124], "48h": [119, 121], "ipykernel_14958": 119, "3276196379": 119, "1006": 119, "000": 119, "173913": 119, "428571": 119, "148": [17, 119, 121], "758782": 119, "140": 119, "barcontain": 119, "artist": 119, "mimic_fin": 119, "mimic3_multi_stag": 119, "wb": 119, "dump": 119, "748": 119, "98685": 119, "142857": 119, "749": 119, "200000": [119, 121], "751": 119, "545455": 119, "818182": 119, "030303": 119, "118": 119, "196": 119, "666667": [119, 121], "692": 119, "lag_k": 119, "new_sofa": 119, "mimic3_sampl": 119, "groupbi": 119, "1767327135": 119, "mimic3_single_stag": 119, "152": [17, 119, 121], "081590": 119, "800000": 119, "600000": [119, 121], "1204": 119, "794872": 119, "782051": 119, "668956": 119, "153846": 119, "4132": 119, "364286": 119, "956461": 119, "252": [119, 121], "883864": 119, "4201": 119, "145": 119, "580087": 119, "083333": 119, "539": 119, "065657": 119, "363636": 119, "5170": 119, "174": 119, "525000": 119, "147": 119, "350198": 119, "616727": 119, "437500": 119, "6504": 119, "081169": 119, "836364": 119, "423": 119, "090909": 119, "mimic3_data_fin": 119, "smaple_demo": 119, "est_mt": 119, "w_threshold": 119, "plot_mt": 119, "demo_res_mt": 119, "demo_res_net": 119, "fste": 119, "81464196": 119, "7182284": 119, "79568369": 119, "35571593": 119, "70458444": 119, "fsde": 119, "49979442": 119, "25446085": 119, "25575045": 119, "fsie": 119, "31443638": 119, "53623245": 119, "53993324": 119, "administrait": 119, "35384615": 119, "70769231": 119, "06153846": 119, "41538462": 119, "76923077": 119, "12307692": 119, "47692308": 119, "83076923": 119, "18461538": 119, "53846154": 119, "gap": 119, "intak": 119, "death": 119, "administr": 119, "gradientboostingclassifi": 119, "42850795": 119, "04122985": 119, "37054069": 119, "0055272": 119, "10384686": 119, "01457029": 119, "16909439": 119, "28221447": 119, "05764574": 119, "008193": 119, "30211856": 119, "0551675": 119, "01006845": 119, "09689565": 119, "10600407": 119, "18238777": 119, "44978522": 119, "19716563": 119, "289073": 119, "03827421": 119, "22619666": 119, "1875545": 119, "23778146": 119, "20841167": 119, "73958005": 119, "11909299": 119, "09661241": 119, "15624675": 119, "3466977": 119, "42682439": 119, "353852": 119, "12244475": 119, "53581201": 119, "38763738": 119, "00624024": 119, "02708992": 119, "08227609": 119, "09644005": 119, "19550407": 119, "30207966": 119, "03525717": 119, "34339108": 119, "30668368": 119, "11740263": 119, "23538089": 119, "41147115": 119, "46029296": 119, "10346963": 119, "51161134": 119, "04498817": 119, "18302802": 119, "21907476": 119, "54002382": 119, "23518752": 119, "06635588": 119, "83090637": 119, "3999141": 119, "health": 119, "seem": [17, 119], "counterintuit": 119, "remind": 119, "pai": 119, "20399937380848096": 119, "49003107": 119, "50057977": 119, "20914573": 119, "66345884": 119, "23977303": 119, "0794276": 119, "34455499": 119, "36109094": 119, "19848057": 119, "58006391": 119, "11359767": 119, "23537098": 119, "18899855": 119, "64967052": 119, "63723815": 119, "05042186": 119, "26366224": 119, "00872736": 119, "32914701": 119, "51474347": 119, "41667122": 119, "54158338": 119, "71321121": 119, "26489405": 119, "0774718": 119, "52229178": 119, "61766863": 119, "57557176": 119, "94774448": 119, "55186488": 119, "29666119": 119, "35960446": 119, "20136832": 119, "77408578": 119, "19227108": 119, "11463203": 119, "35932623": 119, "29545405": 119, "86337085": 119, "95171379": 119, "61272862": 119, "00475441": 119, "06064992": 119, "64206127": 119, "75432718": 119, "20535944": 119, "37009124": 119, "35431129": 119, "78816905": 119, "76940612": 119, "68175408": 119, "74628053": 119, "10881984": 119, "17531085": 119, "07151351": 119, "82140618": 119, "01038676": 119, "bad": 119, "08642818615808806": 119, "086": 119, "mimic": [120, 121], "died_within_48h": [120, 121], "aliv": 120, "dtr_data": 120, "mimic3_dtr_3stag": 120, "ipykernel_14963": 120, "213967264": 120, "rhel8": [120, 121], "anaconda": [120, 121], "ood": [120, 121], "q_1": 120, "q_2": 120, "a_2": 120, "_2": 120, "07": 120, "q_3": 120, "a_3": 120, "09": 120, "_3": 120, "010": 120, "011": 120, "polic": 120, "treatement": 120, "policy1": 120, "9211": 120, "policy2": 120, "5645": 120, "3565": 120, "renam": 120, "glucose_1": 120, "s1_1": 120, "glucose_2": 120, "s1_2": 120, "glucose_3": 120, "s1_3": 120, "pao2_1": 120, "s2_1": 120, "pao2_2": 120, "s2_2": 120, "pao2_3": 120, "s2_3": 120, "pao2_fio2_1": 120, "s3_1": 120, "pao2_fio2_2": 120, "s3_2": 120, "pao2_fio2_3": 120, "s3_3": 120, "sofa_1": 120, "s4_1": 120, "sofa_2": 120, "s4_2": 120, "sofa_3": 120, "s4_3": 120, "iv_input_1": [120, 121], "iv_input_2": [120, 121], "iv_input_3": [120, 121], "mimic3_clip": 120, "92108006173226": 120, "5645453516018072": 120, "3565347101304528": 120, "0001": [120, 121], "0018": 120, "0011": 120, "0405": 120, "2529": 120, "0020": 120, "0395": 120, "3912": 120, "0024": 120, "0107": 120, "0040": 120, "0416": 120, "0181": 120, "appl": 120, "9997": 120, "summari": [120, 123], "9996830260361399": 120, "nde": 121, "857": 121, "344": 121, "mimic3_mdtr_data_dict_3stag": 121, "mimic3_mdtr": 121, "mdtr_data": 121, "mimic3_mdtr_3stag": 121, "ipykernel_14968": 121, "2449485823": 121, "mediated_qlearn": 121, "mediatedqlearn": 121, "regime_control": 121, "regime_target": 121, "dim_stat": 121, "dim_medi": 121, "est_nde_ni": 121, "513078": 121, "857103": 121, "344024": 121, "multipli": 121, "dierct": 121, "dde": 121, "dme": 121, "0919": 121, "0273": 121, "0165": 121, "0093": 121, "0026": 121, "0083": 121, "1056": 121, "0278": 121, "dive": 121, "insignific": 121, "conclud": 121, "mrl": 121, "evaluator_linear": 121, "problearn": 121, "pmlearner": 121, "rewardlearn": 121, "palearn": 121, "ratiolearn": 121, "ratiolinearlearn": 121, "qlearner_linear": 121, "qlearner": 121, "mrl_df": 121, "mimic3_mrl_df": 121, "31005": 121, "next_glucos": 121, "next_pao2": 121, "next_pao2_fio2": 121, "833333": 121, "364": 121, "310339": 121, "247": 121, "499996": 121, "427": 121, "777778": 121, "131": 121, "250000": 121, "272727": 121, "681818": 121, "184": 121, "370": 121, "074074": 121, "185185": 121, "163": 121, "749998": 121, "225": 121, "161": 121, "337": 121, "842": 121, "166": 121, "165": 121, "mimic3_mrl_data_dict": 121, "mimic3_mrl": 121, "control_polici": 121, "get_a": 121, "action_valu": 121, "target_polici": 121, "pa": [17, 121], "prob_arr": 121, "valueerror": 121, "expectation_mcmc_it": 121, "expectation_mcmc_iter_q3": 121, "expectation_mcmc_iter_q_diff": 121, "problearner_paramet": 121, "splitter": 121, "ratio_ndim": 121, "t_depend_target": 121, "t_dependent_q": 121, "scaler": 121, "est_obj1": 121, "l2penalti": 121, "q_set": 121, "product_tensor": 121, "include_intercept": 121, "min_l": 121, "estimate_de_me_s": 121, "est_value1": 121, "est_demes": 121, "se_value1": 121, "se_demes": 121, "spline": 121, "dimems": 121, "ide_mr": 121, "ime_mr": 121, "dde_mr": 121, "dme_mr": 121, "se": 121, "se_ide_mr": 121, "se_ime_mr": 121, "se_dde_mr": 121, "se_dme_mr": 121, "se_at": 121, "09194078443951989": 121, "00013943674272351314": 121, "016468700996400024": 121, "002637657312209113": 121, "10563239138098725": 121, "027343302687903085": 121, "9048964630756934e": 121, "00929541056015874": 121, "008264805521827638": 121, "027791871119537882": 121, "362460836897925": 121, "8428070556269627": 121, "7717023782668493": 121, "3191433004978724": 121, "8008376955492906": 121, "wu": 121, "2301": 121, "13348": 121, "workflow": 123, "depict": 123, "merit": 123, "downsid": 123, "miscellan": 123, "subtract": 123, "wish": 123, "epidemiolog": 123, "ccc": 123, "hline": 123, "vdot": 123, "hdashlin": 123, "substanti": 123, "willing": 123, "adequ": 123, "sc": 123, "correpond": 123, "conjunct": 123, "bowl": 123, "quatil": 123, "otr": 123, "jump": 123, "comb": 123, "dmitri": 123, "arkhangelski": 123, "hirshberg": 123, "guido": 123, "imben": 123, "technic": 123, "bureau": 123, "practition": 124, "handbook": 124, "complement": 124, "unifi": 124, "api": 124, "desktop": 124, "branch": 124, "visiabl": 124, "_build": 124, "commit": 124, "push": 124, "cd": 124, "password": 124, "gh": 124, "reinstal": 124, "fail": 124, "credenti": 124, "token": 124, "cname": 124, "att": 17, "versatil": 17, "ml": 17, "angl": 17, "innov": 17, "discard": 17, "irrelev": 17, "minimum": 17, "tmle": 17, "imporv": 17, "stabil": 17, "amd": 17, "archetectur": 17, "ipython": 17, "singlestag": 17, "png": 17, "width": 17, "layer": 17, "resourc": 17, "crossentropi": 17, "hyperparamet": 17, "extra": 17, "check": 17, "513155": 17, "ipykernel_22269": 17, "1407": 17, "1408": 17, "on_train_batch_begin": 17, "1409": 17, "train_funct": 17, "1410": 17, "should_sync": 17, "1411": 17, "async_wait": 17, "eager": 17, "def_funct": 17, "913": 17, "914": 17, "optionalxlacontext": 17, "_jit_compil": 17, "915": 17, "_call": 17, "916": 17, "917": 17, "new_tracing_count": 17, "experimental_get_tracing_count": 17, "945": 17, "defun": 17, "never": 17, "_stateless_fn": 17, "callabl": 17, "_stateful_fn": 17, "949": 17, "releas": 17, "thread": 17, "2451": 17, "graph_funct": 17, "2452": 17, "filtered_flat_arg": 17, "_maybe_define_funct": 17, "2453": 17, "_call_flat": 17, "2454": 17, "captured_input": 17, "2455": 17, "cancellation_manag": 17, "1858": 17, "executing_eagerli": 17, "1859": 17, "tape": 17, "1860": 17, "_build_call_output": 17, "_inference_funct": 17, "ctx": 17, "1862": 17, "forward_backward": 17, "_select_forward_and_backward_funct": 17, "495": 17, "_interpolatefunctionerror": 17, "496": 17, "497": 17, "498": 17, "signatur": 17, "num_output": 17, "_num_output": 17, "quick_execut": 17, "op_nam": 17, "attr": 17, "ensure_initi": 17, "tensor": 17, "pywrap_tf": 17, "tfe_py_execut": 17, "device_nam": 17, "_notokstatusexcept": 17, "ramet": 17}, "objects": {}, "objtypes": {}, "objnames": {}, "titleterms": {"learner": [0, 9, 10, 11, 13, 14, 16, 20, 21, 23, 24, 25, 27, 28, 40, 41, 48, 49, 79, 80, 81, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103], "name": [0, 123], "singl": [0, 19, 26, 43, 57, 58, 59, 60, 106], "multipl": [0, 73, 74, 75, 76], "stage": [0, 19, 26, 43, 57, 58, 59, 73, 74, 75, 76, 120, 121], "infinit": [0, 61, 66, 68, 70, 121], "horizon": [0, 61, 66, 68, 70, 121], "main": [0, 11, 14, 19, 43, 46, 48, 57, 58, 61, 62, 64, 65, 66, 67, 68, 70, 73, 76, 79, 80, 81, 83, 84, 85, 87, 88, 89, 90, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104, 107, 108, 113, 114], "idea": [0, 11, 14, 19, 43, 46, 48, 57, 58, 61, 62, 64, 65, 66, 67, 68, 70, 73, 76, 79, 80, 81, 83, 84, 85, 87, 88, 89, 90, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104, 107, 108, 113, 114], "algorithm": [0, 11, 13, 14, 43, 57, 58, 73, 76, 77, 81, 83, 84, 93, 94, 98, 99, 100, 101, 104, 106, 107, 108, 113, 114], "detail": [0, 9, 11, 13, 14, 43, 48, 57, 73, 76, 81, 83, 84, 94, 99, 101, 104, 107, 108, 113, 114], "kei": [0, 43, 57, 73, 76, 79, 80, 81, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104, 107, 108, 113, 114], "step": [0, 43, 57, 73, 76, 79, 80, 81, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104, 107, 108, 113, 114, 124], "demo": [0, 11, 13, 14, 43, 46, 48, 57, 58, 61, 62, 64, 65, 66, 67, 70, 73, 76, 79, 80, 81, 83, 84, 85, 87, 88, 89, 90, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104, 107, 108, 113, 114, 119], "code": [0, 5, 11, 13, 14, 43, 48, 57, 73, 76, 79, 80, 81, 83, 84, 85, 87, 88, 89, 90, 92, 94, 95, 96, 97, 99, 101, 102, 103, 104, 107, 108, 113, 114], "1": [0, 2, 9, 11, 12, 13, 14, 15, 17, 21, 25, 26, 43, 48, 57, 68, 73, 76, 88, 89, 90, 106, 123, 124], "polici": [0, 2, 7, 43, 48, 54, 57, 58, 61, 62, 63, 66, 68, 69, 70, 71, 72, 73, 76, 88, 89, 90, 91, 116, 117, 120, 123], "learn": [0, 1, 2, 3, 26, 43, 45, 46, 48, 50, 53, 57, 60, 61, 68, 73, 74, 76, 93, 116, 117, 119, 123], "2": [0, 2, 9, 11, 12, 13, 14, 15, 17, 21, 26, 27, 43, 48, 57, 68, 73, 76, 88, 89, 90, 123, 124], "evalu": [0, 7, 43, 48, 57, 58, 61, 62, 63, 64, 66, 68, 70, 71, 72, 73, 76, 88, 89, 90, 91, 116, 120], "refer": [0, 2, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 33, 34, 37, 38, 39, 40, 41, 43, 46, 48, 57, 61, 62, 64, 65, 66, 67, 70, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 113, 114, 115, 116, 117, 121, 123], "causal": [1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 26, 72, 119, 123], "effect": [1, 4, 6, 10, 12, 26, 119, 123], "cel": [1, 26, 123], "clinic": [1, 2], "trial": 1, "advertis": 1, "market": 1, "more": 1, "beyond": 1, "cpl": [2, 120, 123], "scenario": 2, "fix": [2, 123], "independ": [2, 123], "state": [2, 123], "person": [2, 12], "incent": 2, "ad": [2, 5], "target": [2, 17], "bid": 2, "markovian": [2, 116, 117, 123], "transit": [2, 123], "mobil": 2, "health": 2, "3": [2, 9, 11, 12, 13, 14, 15, 21, 28, 88, 89, 90, 120, 121, 123], "non": [2, 11, 117, 123], "healthcar": 2, "trail": 2, "multi": [2, 82, 85, 110, 121], "touch": 2, "attribut": 2, "4": [2, 23, 24, 123], "adapt": [2, 52, 123], "recommend": [2, 79, 80, 81, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103, 105, 106, 115], "system": 2, "onlin": [2, 88, 89, 90, 91, 93, 98], "dynam": [2, 100], "price": 2, "5": [2, 16, 24, 123], "6": [2, 20, 24, 123], "structur": [3, 9, 11, 13, 14, 78, 82, 105, 123], "csl": [3, 123], "spread": 3, "covid": 3, "19": 3, "gene": 3, "express": 3, "trait": 3, "yeast": 3, "infer": [4, 5, 6], "101": [4, 5], "potenti": [4, 6, 72, 124], "outcom": [4, 6, 46, 50, 72, 119], "assumpt": [4, 6, 15], "averag": [4, 6], "regress": 4, "model": [4, 9, 11, 13, 14, 116, 117], "propens": 4, "score": [4, 13], "stratif": 4, "invers": [4, 90], "weight": [4, 46, 90], "doubli": [4, 15, 61, 89], "robust": [4, 15, 61, 89], "estim": [4, 15, 19, 61], "what": [5, 123], "myst": 5, "ar": 5, "role": 5, "direct": [5, 15, 88], "us": [5, 46], "citat": 5, "execut": 5, "your": 5, "markdown": 5, "file": 5, "preliminari": [6, 8, 12, 71, 72], "do": [6, 56], "oper": 6, "treatment": [6, 10, 12, 58], "heterogen": [6, 12], "optim": [7, 58, 68, 69, 71, 72, 98, 100, 116, 120], "discoveri": [9, 10, 11, 13, 14, 119], "gener": [9, 11, 12, 13, 14, 18, 22, 58, 79, 80, 81, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103], "graph": [9, 11, 12, 13, 14], "terminolog": [9, 11, 12, 13, 14], "overview": [9, 13, 48, 77, 79, 80, 81, 83, 84, 85, 87, 89, 92, 94, 95, 96, 97, 99, 101, 102, 103, 123], "popular": 9, "graphic": [9, 11, 13, 14, 78, 82], "linear": [9, 11, 13, 14], "equat": [9, 11, 13, 14], "addit": [9, 11, 13], "nois": [9, 11, 13], "lsem": [9, 13], "method": [9, 15, 106], "To": [9, 56], "Be": 9, "mediat": [10, 12, 121], "analysi": [10, 12, 121], "from": 10, "tabl": 10, "anoc": 10, "cvae": 10, "cai": 10, "et": [10, 13], "al": [10, 13], "2020": 10, "function": [11, 71], "base": [11, 13, 14, 49, 67, 116], "goal": [11, 13, 14], "applic": [11, 13, 14], "gaussian": [11, 14, 106], "gaussain": 11, "synthet": [11, 13, 14, 38, 39, 40, 41], "dataset": [11, 13, 14, 58], "ica": 11, "lingam": 11, "summari": [11, 13, 14], "result": [11, 13, 14], "under": [11, 13, 14, 72, 88, 89, 90], "differ": [11, 13, 14, 19, 33], "toi": 12, "exampl": 12, "decis": [12, 31, 68, 71, 72], "make": 12, "remark": 12, "notear": 13, "zheng": 13, "2018": 13, "test": [14, 60], "pc": 14, "ATE": [15, 29, 32], "identif": 15, "import": [15, 66, 70, 79, 80, 81, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103, 124], "sampl": [15, 66, 70, 85, 87, 106], "dr": [16, 24], "movielen": [16, 17, 18, 20, 23, 25, 27, 28, 122], "data": [16, 17, 18, 20, 23, 25, 26, 27, 28, 36, 52, 55, 58, 59, 75, 78, 82, 86, 93, 98, 100, 105, 106, 115, 123], "8": [17, 22], "dragon": [17, 22], "net": [17, 22], "7": [18, 22], "random": [18, 22], "forest": [18, 22], "hte": [19, 30, 35], "approach": [19, 22], "The": 19, "advantag": 19, "lp": [20, 24], "r": [20, 23, 24, 37], "meta": [21, 86, 87, 112], "s": [21, 25], "t": [21, 27], "x": [21, 28, 41], "other": 22, "real": [26, 58, 59, 75, 78, 82, 86, 93, 98, 100, 105, 106, 115], "movi": 26, "len": 26, "pre": [26, 58], "process": [26, 31, 58, 71, 72], "final": 26, "select": 26, "mimic3": [26, 119], "markov": [31, 71, 72], "h1sl": 34, "h2sl": 34, "panel": [36, 123], "did": [37, 39], "control": 38, "miscellan": 42, "A": [43, 60, 73, 123], "reduct": 44, "classif": 44, "problem": [44, 59, 75, 78, 82, 86, 93, 98, 100, 105, 106, 115], "entropi": 45, "when": [46, 124], "should": 46, "i": [46, 123], "owl": 46, "spars": 46, "a1": 46, "deriv": 46, "continu": [47, 48], "action": [47, 48, 51], "space": [47, 51], "deep": 48, "jump": 48, "difficulti": 48, "kernel": 49, "discret": 51, "collect": 52, "concord": 53, "assist": 53, "search": 54, "time": 55, "event": 55, "plan": 56, "q": [57, 64, 65, 68, 76], "quantil": 58, "regim": 58, "motiv": 58, "set": [58, 59, 75, 78, 82, 86, 93, 98, 100, 105, 106, 115], "simul": [58, 106], "off": [58, 62, 71, 72], "qope": 58, "doubl": 61, "reinforc": 61, "stationari": [61, 66], "distribut": [61, 66, 67], "todo": [61, 62, 64, 65, 66, 67, 70], "note": [61, 62, 66, 67, 70], "deepli": 62, "debias": 62, "fit": [64, 65], "iter": 65, "break": 66, "curs": 66, "confid": [67, 106], "interv": 67, "op": 67, "asymptot": 67, "ci": 67, "drl": 67, "valu": [71, 116], "framework": [72, 88, 89, 90], "identifi": 72, "mediatedq": 74, "dtr": [75, 120], "bandit": [77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 93, 98, 100, 105, 106, 123], "contextu": 78, "lint": [79, 108], "environ": [79, 80, 81, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103, 116, 117], "specifi": [79, 80, 81, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103], "hyperparamet": [79, 80, 81, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103], "interact": [79, 80, 81, 83, 84, 85, 87, 92, 94, 95, 96, 97, 99, 101, 102, 103], "bernoulli": [79, 80, 81, 83, 84, 85, 87, 106], "linucb": [80, 109], "epsilon": [81, 106], "greedi": [81, 106], "arm": 82, "mab": 82, "ts": [83, 88, 89, 90, 112, 113], "ucb": [84, 88, 89, 90], "task": [85, 110], "thompson": [85, 87, 106], "mtt": [85, 111], "eg": [88, 89, 90], "probabl": [89, 90], "explor": [89, 90], "cascadelint": 92, "rank": 93, "cascad": 93, "support": [93, 98, 100, 106], "mtss_cascad": 94, "ts_cascad": 95, "comblint": 96, "combt": 97, "combinatori": 98, "semi": 98, "mtss_comb": 99, "assort": 100, "multinomi": 100, "logit": 100, "mtss_mnl": 101, "ts_contextual_mnl": 102, "ts_mnl": 103, "ucb_mnl": 104, "slate": [105, 115], "item": 106, "claasic": 106, "upper": 106, "bound": 106, "epsilon_greedi": 107, "ucb1": 114, "oolin": [116, 117], "gradient": 116, "approxim": 116, "dp": 116, "actor": 116, "critic": 116, "mimic": 118, "iii": 118, "regard": 119, "died_within_48h": 119, "variabl": 119, "sofa": 119, "longitudin": 121, "introduct": 123, "expect": 123, "sl": 123, "ml": 123, "case1": 123, "paradigm": 123, "d": 123, "pl": 123, "case2": 123, "case3": 123, "case4": 123, "case5": 123, "case6": 123, "appendix": 123, "singeldtr": 123, "mdp": 123, "b": 123, "multidtr": 123, "c": 123, "content": 124, "everi": 124, "notebook": 124, "how": 124, "contribut": 124, "compil": 124, "new": 124, "version": 124, "option": 124, "publish": 124, "error": 124, "messag": 124, "run": 124, "ghp": 124, "part": 17, "dragonnet": 17, "regular": 17}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinxcontrib.bibtex": 9, "sphinx": 56}})