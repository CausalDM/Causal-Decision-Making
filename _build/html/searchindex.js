Search.setIndex({"docnames": ["0_Learner Template", "0_Motivating_Examples/CEL", "0_Motivating_Examples/CPL", "0_Motivating_Examples/CSL", "1_Preliminary/(old) Causal Inference 101", "1_Preliminary/Causal Inference 101_old", "1_Preliminary/Causal Inference Preliminary", "1_Preliminary/Policy Evaluation and Optimization", "1_Preliminary/Preliminary", "2_Causal_Structure_Learning/Causal Discovery", "2_Causal_Structure_Learning/Causal Mediation Analysis", "2_Causal_Structure_Learning/Functional-based Learner", "2_Causal_Structure_Learning/Preliminaries of Causal Graphs", "2_Causal_Structure_Learning/Score-based Learner", "2_Causal_Structure_Learning/Testing-based Learner", "3_Causal_Effect_Learning/Scenario 1/ATE", "3_Causal_Effect_Learning/Scenario 1/DR-Learner", "3_Causal_Effect_Learning/Scenario 1/Dragonnet", "3_Causal_Effect_Learning/Scenario 1/GRF", "3_Causal_Effect_Learning/Scenario 1/HTE", "3_Causal_Effect_Learning/Scenario 1/Lp-R-Learner", "3_Causal_Effect_Learning/Scenario 1/Mediation Analysis", "3_Causal_Effect_Learning/Scenario 1/Meta Learners", "3_Causal_Effect_Learning/Scenario 1/Other Approaches", "3_Causal_Effect_Learning/Scenario 1/R-Learner", "3_Causal_Effect_Learning/Scenario 1/R-Learner, DR-Learner, Lp-R-Learner", "3_Causal_Effect_Learning/Scenario 1/S-learner", "3_Causal_Effect_Learning/Scenario 1/Single Stage", "3_Causal_Effect_Learning/Scenario 1/T-learner", "3_Causal_Effect_Learning/Scenario 1/X-learner", "3_Causal_Effect_Learning/Scenario 2/ATE", "3_Causal_Effect_Learning/Scenario 2/HTE", "3_Causal_Effect_Learning/Scenario 2/underMDP", "3_Causal_Effect_Learning/Scenario 3/DiD", "3_Causal_Effect_Learning/Scenario 3/Extensions", "3_Causal_Effect_Learning/Scenario 3/H1SL_H2SL", "3_Causal_Effect_Learning/Scenario 3/Matrix Completion", "3_Causal_Effect_Learning/Scenario 3/MediatedQ-learning_Multiple", "3_Causal_Effect_Learning/Scenario 3/Panel Data", "3_Causal_Effect_Learning/Scenario 3/R-DiD", "3_Causal_Effect_Learning/Scenario 3/Synthetic Control", "3_Causal_Effect_Learning/Scenario 3/Synthetic DiD", "3_Causal_Effect_Learning/Scenario 3/Synthetic Learner", "3_Causal_Effect_Learning/Scenario 3/Synthetic X-Learner", "3_Causal_Effect_Learning/Scenario 4/Miscellaneous", "4_Causal_Policy_Learning/Scenario1/A-learning_Single", "4_Causal_Policy_Learning/Scenario1/Classification", "4_Causal_Policy_Learning/Scenario1/Classification/O-Learning", "4_Causal_Policy_Learning/Scenario1/Continuous", "4_Causal_Policy_Learning/Scenario1/Continuous/Deep Jump Learner", "4_Causal_Policy_Learning/Scenario1/Continuous/Kernel-Based Learner", "4_Causal_Policy_Learning/Scenario1/Continuous/Outcome Learning", "4_Causal_Policy_Learning/Scenario1/Discrete", "4_Causal_Policy_Learning/Scenario1/Micellaneous/Adaptively Collected Data", "4_Causal_Policy_Learning/Scenario1/Micellaneous/Concordance", "4_Causal_Policy_Learning/Scenario1/Micellaneous/Policy Search", "4_Causal_Policy_Learning/Scenario1/Micellaneous/Survival", "4_Causal_Policy_Learning/Scenario1/PlanToDo", "4_Causal_Policy_Learning/Scenario1/Q-learning_Single", "4_Causal_Policy_Learning/Scenario1/Quantile/QuantileOTR_test", "4_Causal_Policy_Learning/Scenario1/Single Stage", "4_Causal_Policy_Learning/Scenario1/Test/A_Q test", "4_Causal_Policy_Learning/Scenario2/DR_Infinite", "4_Causal_Policy_Learning/Scenario2/Deeply_Debiased", "4_Causal_Policy_Learning/Scenario2/Evaluation", "4_Causal_Policy_Learning/Scenario2/FQE", "4_Causal_Policy_Learning/Scenario2/FQI", "4_Causal_Policy_Learning/Scenario2/IPW_Infinite", "4_Causal_Policy_Learning/Scenario2/Inference", "4_Causal_Policy_Learning/Scenario2/MediationRL", "4_Causal_Policy_Learning/Scenario2/Model_based_Infinite", "4_Causal_Policy_Learning/Scenario2/Optimization", "4_Causal_Policy_Learning/Scenario2/Spatial_temporal_DR", "4_Causal_Policy_Learning/Scenario2/archive/archive_preliminary_MDP", "4_Causal_Policy_Learning/Scenario2/preliminary_MDP-potential-outcome", "4_Causal_Policy_Learning/Scenario3/A-learning_Multiple", "4_Causal_Policy_Learning/Scenario3/Multi Stage", "4_Causal_Policy_Learning/Scenario3/Q-learning_Multiple", "4_Causal_Policy_Learning/Scenario4/Bandits", "4_Causal_Policy_Learning/Scenario4/Contextual_Bandits/Contextual_Bandits", "4_Causal_Policy_Learning/Scenario4/Contextual_Bandits/LinTS", "4_Causal_Policy_Learning/Scenario4/Contextual_Bandits/LinUCB", "4_Causal_Policy_Learning/Scenario4/MAB/Epsilon_Greedy", "4_Causal_Policy_Learning/Scenario4/MAB/MAB", "4_Causal_Policy_Learning/Scenario4/MAB/TS", "4_Causal_Policy_Learning/Scenario4/MAB/UCB", "4_Causal_Policy_Learning/Scenario4/Meta_Bandits/MTTS", "4_Causal_Policy_Learning/Scenario4/Meta_Bandits/Meta_Bandits", "4_Causal_Policy_Learning/Scenario4/Meta_Bandits/Meta_TS", "4_Causal_Policy_Learning/Scenario4/OnlineEval/Direct Online Policy Evaluator", "4_Causal_Policy_Learning/Scenario4/OnlineEval/Doubly Robust Online Policy Evaluator", "4_Causal_Policy_Learning/Scenario4/OnlineEval/Inverse Probability Weighted Online Policy Evaluator", "4_Causal_Policy_Learning/Scenario4/OnlineEval/Online Policy Evaluation", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/CascadeLinTS", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/Learning to rank", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/MTSS_Cascade", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/TS_Cascade", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/CombLinTS", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/CombTS", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/Combinatorial Optimization", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/MTSS_Comb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/Assortment Optimization", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/MTSS_MNL", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/TS_Contextual_MNL", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/TS_MNL_Beta", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/UCB-MNL", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Structured_Bandit", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single-Item Recommendation", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/Epsilon Greedy", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/LinTS", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/LinUCB", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/Multi-Task", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/MultiTask/MTTS", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/MultiTask/Meta-TS", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/TS", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/UCB1", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Slate Recommendation", "4_Causal_Policy_Learning/Scenario5/OnlineRL_Markov", "4_Causal_Policy_Learning/Scenario6/OnlineRL_non_Markov", "5_Case_Study/MIMIC3/Case_Study_1", "5_Case_Study/MIMIC3/Create_DTR_RL_MIMIC_Data_V2", "5_Case_Study/MIMIC3/Infinite_Horizon", "5_Case_Study/MIMIC3/Longitudinal", "5_Case_Study/MIMIC3/MIMIC3-Demo", "5_Case_Study/MIMIC3/MIMIC3-Demo-Ver2", "5_Case_Study/MIMIC3/MIMIC3_intro", "5_Case_Study/MIMIC3/Single_Stage", "5_Case_Study/MovieLens/Data_Preprocessing", "5_Case_Study/MovieLens/MovieLens", "5_Case_Study/MovieLens/MovieLens_simulation", "How to Compile", "Intro", "Overview", "README", "Summarization_Table", "_old files(to delete)/Map"], "filenames": ["0_Learner Template.ipynb", "0_Motivating_Examples\\CEL.ipynb", "0_Motivating_Examples\\CPL.ipynb", "0_Motivating_Examples\\CSL.ipynb", "1_Preliminary\\(old) Causal Inference 101.ipynb", "1_Preliminary\\Causal Inference 101_old.md", "1_Preliminary\\Causal Inference Preliminary.ipynb", "1_Preliminary\\Policy Evaluation and Optimization.md", "1_Preliminary\\Preliminary.md", "2_Causal_Structure_Learning\\Causal Discovery.ipynb", "2_Causal_Structure_Learning\\Causal Mediation Analysis.ipynb", "2_Causal_Structure_Learning\\Functional-based Learner.ipynb", "2_Causal_Structure_Learning\\Preliminaries of Causal Graphs.ipynb", "2_Causal_Structure_Learning\\Score-based Learner.ipynb", "2_Causal_Structure_Learning\\Testing-based Learner.ipynb", "3_Causal_Effect_Learning\\Scenario 1\\ATE.ipynb", "3_Causal_Effect_Learning\\Scenario 1\\DR-Learner.ipynb", "3_Causal_Effect_Learning\\Scenario 1\\Dragonnet.ipynb", "3_Causal_Effect_Learning\\Scenario 1\\GRF.ipynb", "3_Causal_Effect_Learning\\Scenario 1\\HTE.ipynb", "3_Causal_Effect_Learning\\Scenario 1\\Lp-R-Learner.ipynb", "3_Causal_Effect_Learning\\Scenario 1\\Mediation Analysis.ipynb", "3_Causal_Effect_Learning\\Scenario 1\\Meta Learners.ipynb", "3_Causal_Effect_Learning\\Scenario 1\\Other Approaches.ipynb", "3_Causal_Effect_Learning\\Scenario 1\\R-Learner.ipynb", "3_Causal_Effect_Learning\\Scenario 1\\R-Learner, DR-Learner, Lp-R-Learner.ipynb", "3_Causal_Effect_Learning\\Scenario 1\\S-learner.ipynb", "3_Causal_Effect_Learning\\Scenario 1\\Single Stage.ipynb", "3_Causal_Effect_Learning\\Scenario 1\\T-learner.ipynb", "3_Causal_Effect_Learning\\Scenario 1\\X-learner.ipynb", "3_Causal_Effect_Learning\\Scenario 2\\ATE.md", "3_Causal_Effect_Learning\\Scenario 2\\HTE.md", "3_Causal_Effect_Learning\\Scenario 2\\underMDP.md", "3_Causal_Effect_Learning\\Scenario 3\\DiD.ipynb", "3_Causal_Effect_Learning\\Scenario 3\\Extensions.md", "3_Causal_Effect_Learning\\Scenario 3\\H1SL_H2SL.ipynb", "3_Causal_Effect_Learning\\Scenario 3\\Matrix Completion.ipynb", "3_Causal_Effect_Learning\\Scenario 3\\MediatedQ-learning_Multiple.ipynb", "3_Causal_Effect_Learning\\Scenario 3\\Panel Data.md", "3_Causal_Effect_Learning\\Scenario 3\\R-DiD.ipynb", "3_Causal_Effect_Learning\\Scenario 3\\Synthetic Control.ipynb", "3_Causal_Effect_Learning\\Scenario 3\\Synthetic DiD.ipynb", "3_Causal_Effect_Learning\\Scenario 3\\Synthetic Learner.ipynb", "3_Causal_Effect_Learning\\Scenario 3\\Synthetic X-Learner.ipynb", "3_Causal_Effect_Learning\\Scenario 4\\Miscellaneous.md", "4_Causal_Policy_Learning\\Scenario1\\A-learning_Single.ipynb", "4_Causal_Policy_Learning\\Scenario1\\Classification.md", "4_Causal_Policy_Learning\\Scenario1\\Classification\\O-Learning.ipynb", "4_Causal_Policy_Learning\\Scenario1\\Continuous.md", "4_Causal_Policy_Learning\\Scenario1\\Continuous\\Deep Jump Learner.ipynb", "4_Causal_Policy_Learning\\Scenario1\\Continuous\\Kernel-Based Learner.md", "4_Causal_Policy_Learning\\Scenario1\\Continuous\\Outcome Learning.md", "4_Causal_Policy_Learning\\Scenario1\\Discrete.md", "4_Causal_Policy_Learning\\Scenario1\\Micellaneous\\Adaptively Collected Data.ipynb", "4_Causal_Policy_Learning\\Scenario1\\Micellaneous\\Concordance.ipynb", "4_Causal_Policy_Learning\\Scenario1\\Micellaneous\\Policy Search.ipynb", "4_Causal_Policy_Learning\\Scenario1\\Micellaneous\\Survival.ipynb", "4_Causal_Policy_Learning\\Scenario1\\PlanToDo.md", "4_Causal_Policy_Learning\\Scenario1\\Q-learning_Single.ipynb", "4_Causal_Policy_Learning\\Scenario1\\Quantile\\QuantileOTR_test.ipynb", "4_Causal_Policy_Learning\\Scenario1\\Single Stage.md", "4_Causal_Policy_Learning\\Scenario1\\Test\\A_Q test.ipynb", "4_Causal_Policy_Learning\\Scenario2\\DR_Infinite.ipynb", "4_Causal_Policy_Learning\\Scenario2\\Deeply_Debiased.ipynb", "4_Causal_Policy_Learning\\Scenario2\\Evaluation.md", "4_Causal_Policy_Learning\\Scenario2\\FQE.ipynb", "4_Causal_Policy_Learning\\Scenario2\\FQI.ipynb", "4_Causal_Policy_Learning\\Scenario2\\IPW_Infinite.ipynb", "4_Causal_Policy_Learning\\Scenario2\\Inference.ipynb", "4_Causal_Policy_Learning\\Scenario2\\MediationRL.ipynb", "4_Causal_Policy_Learning\\Scenario2\\Model_based_Infinite.ipynb", "4_Causal_Policy_Learning\\Scenario2\\Optimization.md", "4_Causal_Policy_Learning\\Scenario2\\Spatial_temporal_DR.ipynb", "4_Causal_Policy_Learning\\Scenario2\\archive\\archive_preliminary_MDP.ipynb", "4_Causal_Policy_Learning\\Scenario2\\preliminary_MDP-potential-outcome.ipynb", "4_Causal_Policy_Learning\\Scenario3\\A-learning_Multiple.ipynb", "4_Causal_Policy_Learning\\Scenario3\\Multi Stage.md", "4_Causal_Policy_Learning\\Scenario3\\Q-learning_Multiple.ipynb", "4_Causal_Policy_Learning\\Scenario4\\Bandits.md", "4_Causal_Policy_Learning\\Scenario4\\Contextual_Bandits\\Contextual_Bandits.ipynb", "4_Causal_Policy_Learning\\Scenario4\\Contextual_Bandits\\LinTS.ipynb", "4_Causal_Policy_Learning\\Scenario4\\Contextual_Bandits\\LinUCB.ipynb", "4_Causal_Policy_Learning\\Scenario4\\MAB\\Epsilon_Greedy.ipynb", "4_Causal_Policy_Learning\\Scenario4\\MAB\\MAB.ipynb", "4_Causal_Policy_Learning\\Scenario4\\MAB\\TS.ipynb", "4_Causal_Policy_Learning\\Scenario4\\MAB\\UCB.ipynb", "4_Causal_Policy_Learning\\Scenario4\\Meta_Bandits\\MTTS.ipynb", "4_Causal_Policy_Learning\\Scenario4\\Meta_Bandits\\Meta_Bandits.ipynb", "4_Causal_Policy_Learning\\Scenario4\\Meta_Bandits\\Meta_TS.ipynb", "4_Causal_Policy_Learning\\Scenario4\\OnlineEval\\Direct Online Policy Evaluator.ipynb", "4_Causal_Policy_Learning\\Scenario4\\OnlineEval\\Doubly Robust Online Policy Evaluator.ipynb", "4_Causal_Policy_Learning\\Scenario4\\OnlineEval\\Inverse Probability Weighted Online Policy Evaluator.ipynb", "4_Causal_Policy_Learning\\Scenario4\\OnlineEval\\Online Policy Evaluation.md", "4_Causal_Policy_Learning\\Scenario4\\Structured_Bandits\\Cascade\\CascadeLinTS.ipynb", "4_Causal_Policy_Learning\\Scenario4\\Structured_Bandits\\Cascade\\Learning to rank.ipynb", "4_Causal_Policy_Learning\\Scenario4\\Structured_Bandits\\Cascade\\MTSS_Cascade.ipynb", "4_Causal_Policy_Learning\\Scenario4\\Structured_Bandits\\Cascade\\TS_Cascade.ipynb", "4_Causal_Policy_Learning\\Scenario4\\Structured_Bandits\\Combinatorial-Semi\\CombLinTS.ipynb", "4_Causal_Policy_Learning\\Scenario4\\Structured_Bandits\\Combinatorial-Semi\\CombTS.ipynb", "4_Causal_Policy_Learning\\Scenario4\\Structured_Bandits\\Combinatorial-Semi\\Combinatorial Optimization.ipynb", "4_Causal_Policy_Learning\\Scenario4\\Structured_Bandits\\Combinatorial-Semi\\MTSS_Comb.ipynb", "4_Causal_Policy_Learning\\Scenario4\\Structured_Bandits\\MNL\\Assortment Optimization.ipynb", "4_Causal_Policy_Learning\\Scenario4\\Structured_Bandits\\MNL\\MTSS_MNL.ipynb", "4_Causal_Policy_Learning\\Scenario4\\Structured_Bandits\\MNL\\TS_Contextual_MNL.ipynb", "4_Causal_Policy_Learning\\Scenario4\\Structured_Bandits\\MNL\\TS_MNL_Beta.ipynb", "4_Causal_Policy_Learning\\Scenario4\\Structured_Bandits\\MNL\\UCB-MNL.ipynb", "4_Causal_Policy_Learning\\Scenario4\\Structured_Bandits\\Structured_Bandit.ipynb", "4_Causal_Policy_Learning\\Scenario4\\_old_docs(to delete)\\Single-Item Recommendation.ipynb", "4_Causal_Policy_Learning\\Scenario4\\_old_docs(to delete)\\Single\\Epsilon Greedy.ipynb", "4_Causal_Policy_Learning\\Scenario4\\_old_docs(to delete)\\Single\\LinTS.ipynb", "4_Causal_Policy_Learning\\Scenario4\\_old_docs(to delete)\\Single\\LinUCB.md", "4_Causal_Policy_Learning\\Scenario4\\_old_docs(to delete)\\Single\\Multi-Task.md", "4_Causal_Policy_Learning\\Scenario4\\_old_docs(to delete)\\Single\\MultiTask\\MTTS.md", "4_Causal_Policy_Learning\\Scenario4\\_old_docs(to delete)\\Single\\MultiTask\\Meta-TS.md", "4_Causal_Policy_Learning\\Scenario4\\_old_docs(to delete)\\Single\\TS.ipynb", "4_Causal_Policy_Learning\\Scenario4\\_old_docs(to delete)\\Single\\UCB1.ipynb", "4_Causal_Policy_Learning\\Scenario4\\_old_docs(to delete)\\Slate Recommendation.ipynb", "4_Causal_Policy_Learning\\Scenario5\\OnlineRL_Markov.ipynb", "4_Causal_Policy_Learning\\Scenario6\\OnlineRL_non_Markov.ipynb", "5_Case_Study\\MIMIC3\\Case_Study_1.md", "5_Case_Study\\MIMIC3\\Create_DTR_RL_MIMIC_Data_V2.ipynb", "5_Case_Study\\MIMIC3\\Infinite_Horizon.ipynb", "5_Case_Study\\MIMIC3\\Longitudinal.ipynb", "5_Case_Study\\MIMIC3\\MIMIC3-Demo.ipynb", "5_Case_Study\\MIMIC3\\MIMIC3-Demo-Ver2.ipynb", "5_Case_Study\\MIMIC3\\MIMIC3_intro.ipynb", "5_Case_Study\\MIMIC3\\Single_Stage.ipynb", "5_Case_Study\\MovieLens\\Data_Preprocessing.ipynb", "5_Case_Study\\MovieLens\\MovieLens.ipynb", "5_Case_Study\\MovieLens\\MovieLens_simulation.ipynb", "How to Compile.md", "Intro.md", "Overview.md", "README.md", "Summarization_Table.md", "_old files(to delete)\\Map.md"], "titles": ["Learner Name (Single/Multiple Stages/Infinite Horizon)", "Causal Effect Learning (CEL)", "Causal Policy Learning (CPL)", "Causal Structure Learning (CSL)", "Causal Inference 101", "Causal Inference 101", "Causal Inference Preliminary", "Policy Evaluation and Optimization", "Preliminary", "Causal Discovery", "Causal Mediation Analysis", "Functional-based Learner", "Preliminaries of Causal Graphs", "Score-based Learner", "Testing-based Learner", "ATE Estimation", "<strong>5. DR-learner</strong>", "<strong>8. Dragon Net</strong>", "<strong>7. Generalized Random Forest</strong>", "HTE Estimation", "<strong>6. Lp-R-learner</strong>", "Mediation Analysis", "<strong>Meta Learners</strong>", "<strong>Other Approaches</strong>", "<strong>4. R learner</strong>", "<strong>R-Learner, DR-Learner, and Lp-R-Learner</strong>", "<strong>1. S-learner</strong>", "<strong>Single Stage \u2013 Paradigm 1</strong>", "<strong>2. T-learner</strong>", "<strong>3. X-learner</strong>", "ATE", "HTE", "Markov Decision Processes \u2013 Paradigm 2", "<strong>Difference in Difference</strong>", "Extensions", "<strong>H1SL and H2SL</strong>", "<strong>Matrix Completion</strong>", "MediatedQ-Learning (Multiple Stages)", "Panel Data  \u2013 Paradigm 3", "<strong>R-DiD</strong>", "<strong>Synthetic Control</strong>", "<strong>Synthetic DiD</strong>", "<strong>Synthetic Learner</strong>", "<strong>Synthetic X-Learner</strong>", "Miscellaneous", "A-Learning", "Reduction to Classification Problems", "Outcome Weighted Learning", "Continuous Action Space", "Deep Jump Learner for Continuous Actions", "Kernel-Based Learner", "Outcome Learning", "Discrete Action Space", "Adaptively Collected Data", "Concordance-assisted learning", "Policy Search", "Time-to-Event Data", "Plan To Do", "Q-Learning", "Quantile Optimal Treatment Regime", "Single Stage", "Test A-Learning Single", "Doubly Robust Estimator for Policy Evaluation (Infinite Horizon)", "Deeply-Debiased Off-Policy Evaluation", "Policy Evaluation\u2013Value Estimation", "Fitted-Q Evaluation", "Fitted-Q Iteration", "Importance Sampling for Policy Evaluation (Infinite Horizon)", "Confidence Interval in OPE", "Dynamic Mediation Analysis in Reinforcement Learning", "Q-Learning (Infinite Horizon)", "Policy Optimization", "Infinite Horizon Importance Sampling for Policy Evaluation", "Preliminary: Off-policy Evaluation and Optimization in Markov Decision Processes", "Preliminary: Off-policy Evaluation and Optimization in Markov Decision Processes", "A-Learning", "Multiple Stages (DTR)", "Q-Learning", "Overview: Bandits ALgorithm", "Contextual Bandits", "LinTS", "LinUCB", "<span class=\"math notranslate nohighlight\">\\(\\epsilon\\)</span>-Greedy", "Multi-Armed Bandits (MAB)", "TS", "UCB", "Multi-Task Thompson Sampling (MTTS)", "Meta Bandits", "Meta Thompson Sampling", "Direct Online Policy Evaluator", "Doubly Robust Online Policy Evaluator", "Inverse Probability Weighted Online Policy Evaluator", "Online Policy Evaluation", "CascadeLinTS", "Online Learning to Rank (Cascading Bandit)", "MTSS_Cascade", "TS_Cascade", "CombLinTS", "CombTS", "Online Combinatorial Optimization (Combinatorial Semi-Bandit)", "MTSS_Comb", "Dynamic Assortment Optimization (Multinomial Logit Bandit)", "MTSS_MNL", "TS_Contextual_MNL", "TS_MNL", "UCB_MNL", "Structured Bandit (Slate Recommendation)", "Single-Item Recommendation", "Epsilon_Greedy", "LinTS", "LinUCB", "Multi-Task", "MTTS", "Meta-TS", "TS", "UCB1", "Slate Recommendation", "Online Policy Learning and Evaluation in Markovian Environments", "Ooline Policy Learning in Non-Markovian Environments", "MIMIC III", "Generating 3-stage-DTR dataset", "MIMIC III (Infinite Horizon)", "MIMIC III (3-Stages)", "Mimic3 Demo", "Mimic3 Demo-Ver2", "Mimic3", "MIMIC III (Single-Stage)", "Read in Data", "MovieLens", "Specifying the Simulation Environments", "How to compile", "Introduction", "Overview", "How to contribute?", "&lt;no title&gt;", "&lt;no title&gt;"], "terms": {"an": [0, 1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 22, 23, 25, 27, 28, 29, 32, 33, 45, 47, 48, 49, 58, 59, 60, 63, 64, 65, 66, 67, 68, 69, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 114, 115, 116, 117, 118, 120, 121, 122, 126, 128, 129, 132, 133], "overview": [0, 10, 11, 12, 14], "includ": [0, 2, 5, 9, 27, 32, 38, 40, 58, 60, 69, 74, 75, 76, 77, 78, 79, 83, 84, 87, 89, 90, 91, 93, 95, 97, 98, 99, 100, 102, 103, 104, 106, 107, 108, 109, 114, 115, 116, 117, 121, 122, 123, 124, 125, 128, 129, 131, 132, 133], "brief": [0, 118, 132], "introduct": [0, 5, 29, 32, 73, 74, 79, 82, 83, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 107, 108, 117, 118, 132], "evolut": 0, "i": [0, 1, 2, 4, 6, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 32, 33, 38, 40, 45, 47, 49, 58, 59, 60, 62, 63, 65, 66, 67, 68, 69, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 109, 114, 115, 116, 117, 118, 120, 122, 126, 127, 128, 134], "e": [0, 1, 2, 4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 38, 40, 45, 47, 49, 58, 59, 60, 62, 63, 65, 66, 67, 69, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 84, 86, 87, 88, 89, 90, 91, 93, 95, 96, 97, 98, 100, 101, 102, 103, 104, 107, 109, 114, 115, 117, 118, 126, 129, 132], "when": [0, 2, 4, 5, 6, 10, 12, 13, 14, 15, 17, 19, 21, 22, 27, 28, 32, 38, 40, 47, 49, 59, 62, 63, 65, 67, 72, 73, 74, 80, 84, 86, 88, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 109, 114, 116, 118, 123, 126, 128, 132, 133], "first": [0, 5, 9, 10, 14, 15, 17, 18, 19, 20, 21, 22, 23, 25, 26, 32, 33, 38, 40, 47, 58, 59, 62, 63, 65, 69, 72, 79, 85, 86, 90, 91, 93, 95, 96, 104, 115, 117, 121, 122, 126, 128, 130, 132, 133], "develop": [0, 1, 2, 9, 14, 18, 23, 32, 47, 49, 87, 98, 103, 104, 133], "ani": [0, 4, 5, 6, 9, 10, 11, 13, 15, 19, 21, 22, 23, 26, 28, 29, 32, 33, 40, 49, 59, 62, 63, 67, 72, 73, 74, 76, 78, 79, 85, 87, 93, 94, 95, 96, 106, 116, 117, 118, 122, 126, 127, 132, 133], "altern": [0, 15, 45, 75, 101, 117], "extens": [0, 5, 19, 20, 25, 32, 45, 58, 62, 63, 72, 75, 77, 79, 83, 107, 117, 118, 132], "applic": [0, 1, 2, 3, 9, 10, 12, 32, 37, 38, 47, 49, 62, 65, 67, 69, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 116, 122], "situat": [0, 11, 13, 14, 40, 49, 62, 65, 67, 79, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105], "describ": [0, 6, 10, 27, 106, 123, 124, 125, 133], "data": [0, 2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 19, 22, 23, 25, 32, 33, 36, 40, 45, 47, 49, 58, 62, 63, 64, 67, 72, 73, 74, 75, 77, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91, 105, 117, 121, 122, 123, 124, 125, 126, 128, 129], "structur": [0, 2, 5, 10, 12, 15, 17, 19, 21, 32, 38, 45, 47, 58, 63, 69, 75, 76, 77, 78, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 117, 121, 122, 126, 131, 134], "can": [0, 1, 2, 4, 5, 6, 9, 10, 11, 13, 15, 17, 18, 19, 20, 21, 22, 23, 25, 26, 29, 32, 33, 38, 40, 45, 47, 49, 58, 59, 60, 62, 63, 65, 66, 67, 68, 69, 70, 72, 74, 75, 77, 78, 80, 82, 84, 86, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 114, 115, 116, 117, 121, 123, 124, 126, 127, 128, 130, 132, 133], "analyz": [0, 69, 121, 122, 126], "make": [0, 4, 5, 6, 9, 10, 15, 17, 32, 49, 58, 59, 77, 78, 79, 82, 89, 90, 91, 117, 118, 130, 131, 132, 133], "connect": [0, 12, 74, 117], "between": [0, 1, 2, 4, 6, 9, 14, 15, 19, 22, 29, 32, 33, 40, 45, 49, 58, 61, 67, 72, 74, 75, 81, 84, 86, 90, 91, 95, 96, 102, 103, 104, 107, 132], "real": [0, 2, 3, 9, 17, 18, 19, 20, 23, 25, 32, 33, 38, 45, 49, 58, 75, 77, 78, 89, 90, 91, 93, 98, 105, 128], "mention": [0, 72, 132], "motiv": [0, 2, 4, 15, 58, 62, 63, 65, 66, 72, 73, 77, 79, 83, 87, 93, 94, 99, 101, 117, 123, 124], "exampl": [0, 1, 2, 4, 5, 6, 9, 14, 17, 18, 19, 21, 22, 23, 32, 33, 38, 40, 45, 58, 59, 62, 63, 72, 75, 77, 78, 79, 80, 82, 83, 84, 85, 87, 94, 95, 99, 100, 101, 102, 109, 114, 117, 122, 126, 132], "we": [0, 1, 2, 3, 4, 6, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 38, 40, 45, 47, 48, 49, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 128, 130, 131, 132, 133], "us": [0, 1, 2, 4, 6, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 33, 40, 45, 47, 49, 58, 59, 60, 61, 63, 64, 66, 67, 69, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 100, 102, 103, 104, 105, 106, 107, 108, 109, 114, 115, 116, 117, 118, 120, 121, 122, 123, 124, 126, 128, 131, 132, 133], "advantag": [0, 11, 13, 14, 45, 49, 59, 62, 63, 65, 67, 68, 75, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 107, 128, 133, 134], "descript": [0, 116], "clear": [0, 128], "definit": [0, 10, 27, 45, 63, 65, 73, 74, 75, 94, 123, 124, 125], "concept": [0, 19, 74, 94], "abstract": 0, "pseudo": [0, 16, 25, 59, 75, 77, 133], "In": [0, 1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 32, 33, 38, 40, 45, 47, 48, 49, 52, 58, 59, 61, 62, 63, 67, 68, 70, 72, 73, 74, 75, 77, 78, 79, 80, 81, 83, 84, 87, 88, 89, 90, 91, 93, 94, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 114, 115, 116, 117, 118, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132], "follow": [0, 2, 3, 4, 5, 9, 10, 11, 13, 14, 15, 19, 22, 24, 25, 27, 29, 33, 38, 40, 45, 47, 49, 58, 59, 60, 62, 63, 65, 66, 67, 68, 69, 72, 73, 74, 75, 77, 78, 79, 83, 89, 90, 91, 95, 96, 100, 102, 105, 106, 107, 116, 117, 122, 123, 124, 125, 126, 128, 132], "exhibit": [0, 45, 49, 58, 75, 77, 105], "how": [0, 1, 2, 3, 9, 12, 17, 22, 27, 40, 45, 47, 49, 58, 59, 60, 61, 62, 69, 72, 75, 77, 78, 79, 87, 105, 106, 116, 117], "appli": [0, 10, 11, 16, 17, 19, 20, 25, 45, 49, 58, 59, 62, 63, 67, 72, 75, 77, 83, 86, 88, 105, 107, 117, 118, 120, 122, 126, 129, 131, 132], "do": [0, 5, 10, 12, 15, 21, 24, 25, 32, 45, 47, 49, 58, 59, 75, 77, 81, 85, 96, 98, 104, 115, 117, 122, 126, 132], "respect": [0, 4, 6, 9, 13, 45, 49, 58, 59, 62, 65, 67, 72, 73, 74, 75, 77, 90, 91, 117], "import": [0, 1, 2, 3, 10, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 40, 45, 47, 49, 58, 59, 60, 61, 62, 63, 68, 70, 74, 75, 77, 105, 108, 109, 114, 115, 118, 120, 121, 122, 123, 124, 126, 127, 128, 129], "from": [0, 1, 2, 3, 4, 6, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 40, 45, 47, 49, 58, 59, 60, 61, 62, 63, 67, 69, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 114, 115, 116, 117, 118, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 131, 132], "causaldm": [0, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 45, 47, 49, 58, 59, 60, 61, 68, 69, 70, 72, 75, 77, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115, 121, 122, 126, 128, 129, 130, 133], "alearn": [0, 45, 61, 75], "test": [0, 1, 9, 10, 11, 12, 13, 16, 20, 24, 25, 27, 40, 45, 47, 58, 75, 77, 123, 124, 125, 126, 128, 132], "shared_simul": [0, 47, 61, 75, 77], "numpi": [0, 10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 33, 40, 45, 47, 61, 69, 75, 77, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115, 120, 121, 122, 123, 124, 126, 127, 128], "np": [0, 10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 40, 45, 47, 49, 59, 61, 69, 75, 77, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115, 120, 121, 122, 123, 124, 126, 127, 128, 129], "importerror": [0, 21, 33, 61, 105], "traceback": [0, 10, 11, 13, 14, 17, 21, 22, 23, 25, 33, 49, 59, 61, 68, 70, 72, 105, 108, 109, 114, 115, 120, 126, 127, 129], "most": [0, 2, 5, 9, 10, 11, 12, 13, 14, 17, 21, 22, 23, 25, 26, 32, 33, 47, 49, 59, 61, 62, 65, 68, 70, 72, 73, 74, 79, 82, 83, 86, 87, 88, 93, 97, 98, 99, 100, 101, 105, 106, 107, 108, 109, 114, 115, 116, 117, 120, 123, 124, 126, 127, 128, 129, 132], "recent": [0, 2, 3, 9, 10, 11, 12, 13, 14, 17, 21, 22, 23, 25, 32, 33, 45, 49, 59, 61, 62, 63, 68, 70, 72, 75, 78, 79, 87, 96, 98, 103, 104, 105, 107, 108, 109, 114, 115, 118, 120, 126, 127, 129, 133], "call": [0, 4, 5, 9, 10, 11, 12, 13, 14, 15, 17, 21, 22, 23, 25, 28, 33, 47, 49, 59, 61, 65, 68, 70, 72, 105, 108, 109, 114, 115, 120, 126, 127, 129, 130], "last": [0, 9, 10, 11, 13, 14, 15, 17, 21, 22, 23, 25, 27, 33, 49, 59, 60, 61, 68, 70, 72, 73, 90, 91, 105, 108, 109, 114, 115, 120, 126, 127, 128, 129, 132], "input": [0, 5, 10, 11, 13, 14, 17, 21, 22, 23, 25, 27, 33, 49, 59, 61, 68, 69, 70, 72, 105, 108, 109, 114, 115, 120, 121, 122, 123, 124, 125, 126, 127, 129, 132], "cell": [0, 3, 5, 10, 11, 13, 14, 17, 21, 22, 23, 25, 33, 49, 59, 61, 68, 70, 72, 105, 108, 109, 114, 115, 120, 126, 127, 129], "line": [0, 5, 10, 11, 13, 14, 17, 19, 21, 22, 23, 25, 33, 49, 59, 61, 62, 68, 70, 72, 105, 108, 109, 114, 115, 120, 126, 127, 129, 130], "3": [0, 1, 5, 10, 16, 17, 18, 20, 23, 24, 25, 26, 27, 28, 33, 40, 45, 47, 49, 58, 59, 61, 69, 75, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 114, 115, 116, 117, 118, 121, 123, 124, 125, 126, 127, 128, 129, 133], "4": [0, 3, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 29, 33, 40, 45, 47, 49, 58, 59, 61, 63, 69, 72, 75, 77, 78, 79, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 94, 95, 99, 100, 101, 102, 105, 106, 107, 108, 109, 114, 115, 116, 117, 120, 121, 122, 123, 124, 126, 127, 128, 129], "cannot": [0, 2, 4, 6, 11, 14, 15, 21, 33, 61, 63, 74, 105, 118], "d": [0, 2, 5, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 32, 33, 45, 49, 52, 58, 59, 61, 63, 67, 69, 72, 73, 74, 75, 77, 78, 79, 83, 84, 87, 88, 94, 101, 105, 106, 107, 114, 115, 116, 117, 120, 121, 126, 127, 129], "anaconda3": [0, 10, 11, 17, 18, 21, 22, 23, 33, 49, 59, 61, 105, 120, 126, 127], "lib": [0, 10, 11, 17, 18, 21, 22, 23, 33, 49, 59, 61, 105, 120, 126, 127], "site": [0, 2, 10, 11, 17, 18, 21, 22, 23, 33, 49, 59, 61, 105, 120, 126, 127, 131], "packag": [0, 9, 10, 11, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 47, 49, 59, 60, 61, 69, 75, 95, 102, 105, 120, 123, 124, 126, 127, 130, 133], "__init__": [0, 21, 33, 59, 61, 105, 126, 127, 129], "py": [0, 9, 10, 11, 14, 17, 21, 22, 23, 33, 49, 59, 61, 105, 120, 123, 126, 127, 129], "find": [0, 2, 4, 6, 9, 14, 15, 27, 33, 45, 49, 58, 59, 69, 75, 77, 78, 79, 83, 84, 87, 89, 90, 91, 94, 97, 98, 99, 100, 101, 106, 107, 109, 114, 117, 121, 122, 126, 128, 133], "optim": [0, 2, 5, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 25, 45, 47, 49, 58, 61, 62, 63, 65, 66, 67, 72, 75, 77, 78, 79, 83, 84, 87, 89, 90, 91, 94, 95, 97, 98, 100, 102, 104, 105, 106, 107, 108, 109, 114, 115, 116, 118, 121, 128, 132, 133, 134], "regim": [0, 2, 15, 19, 45, 49, 58, 61, 75, 77, 108, 109, 114, 115, 122, 126, 129, 132], "appropri": [0, 11, 59, 62, 65, 67, 72, 86, 95, 98, 102, 133], "interpret": [0, 3, 10, 13, 45, 49, 58, 69, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 108, 109, 114, 115, 127], "A": [0, 1, 2, 3, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 32, 33, 40, 47, 49, 52, 58, 59, 60, 62, 63, 69, 72, 73, 74, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 114, 115, 116, 117, 120, 121, 122, 123, 124, 126, 127, 128, 129, 134], "sentenc": [0, 108, 109, 114, 115, 133], "analysi": [0, 3, 9, 11, 13, 14, 27, 33, 37, 38, 49, 82, 85, 95, 101, 107, 108, 109, 114, 115, 116, 123, 124, 125, 132], "result": [0, 2, 4, 5, 10, 15, 17, 18, 19, 20, 21, 22, 23, 25, 27, 28, 29, 45, 49, 58, 61, 62, 63, 65, 67, 69, 72, 75, 77, 93, 95, 96, 99, 108, 109, 114, 115, 121, 123, 124, 125, 126, 129, 132], "estim": [0, 1, 2, 5, 6, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 32, 38, 40, 45, 47, 49, 58, 59, 61, 63, 65, 66, 67, 68, 72, 73, 74, 75, 77, 81, 82, 85, 89, 90, 91, 95, 96, 98, 105, 107, 108, 109, 114, 115, 117, 118, 121, 122, 123, 124, 126, 129, 132], "fix": [0, 45, 58, 59, 65, 66, 69, 75, 77, 79, 82, 89, 90, 91, 108, 117, 118, 121, 122, 126], "valu": [0, 2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 20, 21, 22, 23, 25, 27, 32, 40, 45, 47, 49, 58, 59, 60, 61, 62, 63, 65, 66, 67, 72, 74, 75, 77, 79, 82, 83, 87, 89, 90, 91, 94, 107, 108, 120, 121, 122, 123, 124, 125, 126, 128, 129], "subfield": 1, "infer": [1, 2, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 25, 26, 27, 32, 37, 38, 40, 59, 63, 74, 89, 90, 91, 101, 104, 117, 118, 122, 132], "aim": [1, 2, 6, 11, 13, 14, 15, 17, 18, 19, 21, 22, 23, 28, 32, 33, 40, 45, 58, 60, 65, 66, 74, 75, 77, 79, 83, 87, 94, 99, 101, 106, 116, 117, 128, 132], "identifi": [1, 3, 9, 10, 11, 13, 14, 15, 17, 18, 21, 22, 23, 26, 33, 38, 69, 126], "conduct": [1, 27, 38, 59, 121, 122, 126, 128], "statist": [1, 2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 16, 18, 19, 20, 21, 23, 25, 33, 35, 36, 39, 40, 41, 42, 43, 45, 47, 49, 59, 62, 63, 67, 68, 69, 72, 75, 79, 80, 81, 87, 89, 90, 91, 93, 94, 96, 98, 107, 109, 117, 118, 121, 126, 129, 132], "specif": [1, 2, 3, 4, 5, 6, 10, 15, 17, 18, 19, 21, 22, 23, 26, 27, 32, 33, 38, 40, 45, 58, 59, 62, 63, 66, 67, 68, 69, 72, 73, 74, 77, 78, 80, 82, 84, 86, 87, 88, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 106, 107, 108, 109, 114, 116, 121, 124, 126, 128, 132], "intervent": [1, 2, 4, 6, 10, 12, 15, 27, 33], "system": [1, 5, 9, 10, 11, 12, 13, 14, 17, 19, 49, 67, 72, 73, 78, 79, 83, 86, 87, 88, 94, 95, 98, 100, 101, 102, 103, 106, 107, 118], "It": [1, 2, 4, 5, 19, 25, 32, 40, 65, 66, 67, 72, 74, 80, 81, 82, 84, 85, 86, 93, 95, 96, 97, 98, 99, 100, 102, 103, 107, 109, 114, 117, 118], "tri": 1, "answer": [1, 2, 17, 33], "question": [1, 2, 17, 33, 62, 72, 133], "what": [1, 2, 32, 33, 75, 77, 78, 101], "have": [1, 2, 3, 4, 6, 10, 12, 15, 27, 32, 33, 40, 47, 59, 60, 62, 67, 72, 73, 74, 76, 78, 79, 86, 87, 88, 93, 103, 106, 107, 116, 117, 123, 124, 125, 128, 130, 132, 133], "done": [1, 117], "someth": [1, 61], "differ": [1, 2, 3, 4, 5, 6, 12, 15, 22, 28, 32, 38, 40, 45, 58, 59, 60, 61, 67, 72, 73, 74, 75, 77, 79, 80, 83, 84, 86, 87, 88, 90, 91, 95, 96, 98, 99, 100, 102, 103, 106, 107, 109, 114, 117, 118, 127, 128, 132], "s": [1, 2, 3, 5, 6, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 27, 28, 29, 32, 33, 38, 40, 45, 58, 59, 60, 62, 63, 65, 66, 67, 69, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 86, 87, 88, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 117, 122, 124, 126, 127, 128, 129, 132, 133], "consequ": [1, 4, 15, 49, 62, 72], "excecut": 1, "polici": [1, 5, 15, 19, 21, 22, 23, 25, 32, 33, 47, 48, 52, 61, 65, 66, 68, 79, 82, 121, 128, 131, 133], "quantifi": [1, 2, 3, 10, 40, 69, 85, 90, 91, 94, 123, 124], "etc": [1, 2, 17, 19, 32, 38, 45, 58, 79, 99, 106, 116], "suppos": [1, 9, 10, 11, 12, 13, 14, 19, 33, 38, 40, 45, 60, 75, 76, 79, 80, 81, 82, 83, 84, 85, 94, 99, 101, 108, 109, 114, 115, 117], "you": [1, 5, 45, 47, 58, 59, 77, 96, 122, 126, 127, 128, 130, 133], "ar": [1, 2, 3, 4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 28, 29, 32, 33, 38, 40, 45, 47, 52, 59, 60, 62, 63, 65, 67, 69, 72, 73, 74, 75, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 106, 107, 108, 109, 114, 115, 116, 117, 120, 121, 122, 123, 124, 126, 127, 128, 130, 131, 132, 133], "medic": [1, 15], "research": [1, 2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 21, 32, 33, 62, 66, 72, 98, 101, 104, 105, 131], "who": [1, 2, 4, 6, 15, 27, 33, 60, 80, 81, 86, 87, 123, 124, 125], "just": [1, 10, 18, 20, 22, 23, 25, 28, 32, 40, 117], "fictiti": 1, "hopefulli": 1, "allevi": 1, "patient": [1, 2, 27, 32, 49, 59, 87, 122, 123, 124, 125, 126], "symptom": 1, "hypertens": 1, "sinc": [1, 4, 10, 15, 21, 32, 60, 63, 67, 78, 79, 83, 89, 90, 91, 101, 107, 114, 117, 118, 132], "thi": [1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 15, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 32, 33, 38, 40, 47, 48, 49, 52, 59, 60, 62, 63, 64, 65, 67, 68, 70, 71, 72, 73, 74, 78, 79, 82, 83, 85, 87, 94, 99, 100, 101, 102, 106, 107, 108, 109, 114, 115, 116, 117, 118, 121, 122, 123, 124, 126, 127, 128, 130, 131, 132, 133], "newli": [1, 49, 69, 133], "drug": [1, 3], "must": [1, 2, 5, 133], "go": [1, 33, 130], "through": [1, 2, 5, 9, 10, 11, 12, 14, 15, 17, 21, 33, 74, 79, 83, 86, 87, 94, 101, 104, 106, 107, 116, 117, 123, 124, 128], "preclin": 1, "bitro": 1, "vivo": 1, "three": [1, 6, 9, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 24, 25, 26, 28, 29, 32, 33, 59, 69, 78, 79, 80, 81, 82, 84, 85, 88, 89, 90, 91, 93, 95, 96, 97, 100, 102, 103, 104, 106, 107, 116, 117, 118, 122, 132, 133], "phase": 1, "final": [1, 2, 17, 19, 20, 21, 22, 25, 28, 29, 58, 59, 62, 63, 65, 66, 72, 73, 75, 77, 79, 80, 81, 84, 95, 102, 103, 104, 109, 114, 117, 121, 122, 126, 128, 132], "approv": 1, "confirm": [1, 4, 6, 15], "potenti": [1, 2, 15, 19, 21, 22, 28, 29, 32, 33, 45, 58, 59, 63, 65, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 94, 96, 97, 98, 99, 100, 101, 106, 117, 123, 124, 132], "side": [1, 65, 66, 117], "dure": [1, 2, 3, 10, 60], "procedur": [1, 6, 11, 15, 16, 17, 19, 25, 59, 63, 68], "usual": [1, 2, 15, 59, 67, 72], "evalu": [1, 5, 10, 11, 13, 14, 15, 18, 21, 22, 23, 27, 32, 33, 40, 66, 68, 69, 79, 107, 121, 132, 134], "mesur": 1, "well": [1, 9, 11, 13, 19, 22, 27, 32, 38, 47, 59, 65, 67, 72, 73, 74, 82, 83, 93, 97, 99, 100, 107, 108, 117, 118, 132, 133], "perform": [1, 9, 13, 17, 18, 19, 20, 22, 23, 25, 28, 47, 59, 62, 65, 66, 67, 72, 79, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91, 107, 108, 117, 128], "compar": [1, 3, 15, 16, 18, 20, 22, 23, 25, 40, 62, 69, 72, 82, 88, 117, 121, 122, 126, 128, 132], "placebo": 1, "other": [1, 2, 3, 4, 5, 6, 9, 10, 13, 15, 17, 19, 21, 22, 25, 27, 28, 40, 45, 49, 58, 63, 72, 73, 74, 75, 77, 78, 79, 80, 83, 87, 93, 96, 97, 98, 99, 100, 103, 104, 106, 107, 116, 117, 126, 127, 128, 129, 132], "exist": [1, 2, 4, 5, 6, 9, 10, 11, 12, 13, 17, 19, 21, 32, 45, 49, 58, 62, 69, 74, 94, 101, 106, 116, 117, 132], "treatment": [1, 2, 4, 9, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 38, 40, 45, 47, 49, 58, 60, 63, 64, 69, 71, 74, 75, 77, 78, 87, 107, 117, 121, 122, 123, 124, 126, 129, 132, 134], "method": [1, 2, 5, 10, 12, 13, 17, 19, 21, 22, 28, 29, 32, 33, 36, 38, 40, 45, 49, 58, 59, 62, 63, 64, 65, 66, 67, 68, 69, 71, 72, 75, 77, 88, 89, 90, 91, 117, 118, 121, 126, 129, 132], "experiment": [1, 4, 6, 15, 33, 132], "design": [1, 17, 18, 19, 23, 62, 63, 72, 95, 100, 102, 117], "wide": [1, 2, 9, 15, 19, 32, 33, 62, 67, 72, 78, 79, 82, 83, 87, 93, 95, 99, 100, 102, 106, 107, 108, 128, 132], "known": [1, 2, 3, 9, 12, 15, 21, 22, 26, 32, 45, 67, 72, 73, 74, 75, 78, 83, 84, 86, 87, 88, 89, 90, 91, 94, 95, 99, 100, 101, 102, 107, 109, 114, 117, 118, 132], "b": [1, 2, 9, 10, 11, 13, 14, 15, 16, 18, 19, 20, 22, 23, 25, 26, 28, 29, 45, 47, 49, 52, 58, 59, 62, 67, 72, 73, 74, 75, 77, 78, 79, 80, 84, 86, 87, 88, 93, 94, 97, 99, 100, 106, 107, 109, 114, 115, 116, 127, 129], "randomli": [1, 2, 4, 6, 16, 17, 18, 20, 24, 26, 28, 29, 82, 108], "assign": [1, 2, 4, 6, 12, 15, 19, 22, 23, 32, 33, 38, 47, 58, 69, 74, 77], "one": [1, 2, 4, 5, 6, 15, 19, 21, 22, 26, 32, 33, 40, 45, 47, 59, 62, 63, 65, 67, 72, 74, 75, 79, 83, 84, 87, 93, 94, 95, 96, 101, 102, 103, 104, 106, 107, 109, 114, 117, 122, 126, 128], "two": [1, 2, 3, 4, 5, 6, 10, 14, 15, 16, 17, 21, 22, 25, 26, 28, 29, 32, 33, 40, 59, 60, 62, 63, 67, 72, 74, 78, 79, 83, 84, 87, 89, 90, 91, 95, 100, 102, 107, 114, 117, 122, 123, 124, 126, 130, 132], "group": [1, 2, 4, 6, 15, 19, 22, 28, 29, 33, 38, 40, 45, 59, 75, 83, 99, 107, 123, 124, 126, 132], "receiv": [1, 2, 4, 6, 15, 32, 33, 40, 58, 60, 73, 74, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 114, 115, 116, 122, 126, 128, 132, 133], "measur": [1, 3, 4, 6, 9, 10, 11, 12, 13, 14, 15, 19, 33, 38, 63, 67, 69, 74, 117, 132], "sbp": 1, "systol": 1, "blood": 1, "pressur": [1, 27, 123, 124, 125], "each": [1, 2, 3, 4, 6, 9, 10, 11, 13, 14, 18, 19, 20, 21, 22, 23, 25, 28, 32, 33, 40, 45, 49, 58, 60, 67, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 108, 109, 114, 115, 116, 121, 122, 123, 124, 126, 128, 132], "both": [1, 4, 5, 6, 10, 11, 13, 14, 15, 17, 22, 28, 49, 59, 62, 63, 67, 69, 72, 74, 82, 86, 88, 95, 100, 102, 108, 114, 117, 122, 126, 128, 132], "befor": [1, 10, 11, 15, 16, 22, 23, 25, 33, 38, 88, 133], "after": [1, 2, 3, 10, 11, 13, 14, 15, 17, 24, 25, 27, 33, 38, 40, 60, 67, 68, 70, 72, 73, 77, 80, 82, 84, 85, 96, 108, 109, 114, 115, 117, 123, 124, 125], "By": [1, 17, 19, 45, 58, 60, 63, 73, 74, 77, 82, 86, 106, 108], "analys": 1, "abl": [1, 4, 6, 15, 17, 19, 33, 84, 86, 123, 124], "determin": [1, 9, 12, 14, 71, 82, 86, 95, 100, 101, 102, 103, 104, 106, 116, 133], "treat": [1, 17, 27, 33, 38, 40, 106, 123, 124, 132], "shop": [1, 19], "websit": [1, 2, 19, 27, 76, 79, 83, 87, 106, 107, 128, 130], "seller": 1, "often": [1, 4, 6, 17, 22, 28, 32, 40, 59, 132], "veri": [1, 3, 5, 19, 22, 26, 28, 33, 38, 59, 132], "cautiou": 1, "about": [1, 2, 4, 5, 6, 15, 17, 18, 20, 22, 23, 25, 29, 32, 40, 59, 60, 79, 84, 87, 88, 126], "custom": [1, 2, 19, 59, 60, 86, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 127], "purchas": [1, 2, 60, 101, 102, 103, 104, 105], "experi": [1, 4, 6, 15, 19, 47, 74, 79, 83, 87, 89, 90, 91, 106, 107, 128], "whenev": [1, 2, 79, 83, 94, 101], "consum": [1, 10, 33], "satisfi": [1, 9, 15, 17, 18, 23, 24, 25, 62, 63, 67, 72, 79, 83, 87, 97, 98, 99, 100, 106, 107, 116, 117, 128], "item": [1, 2, 78, 79, 80, 82, 83, 84, 85, 86, 87, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 108, 109, 115, 116, 127, 134], "thei": [1, 2, 4, 5, 6, 32, 33, 67, 72, 74, 79, 83, 87, 106, 107, 128], "bought": 1, "order": [1, 2, 9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 23, 25, 32, 59, 63, 86, 87, 88, 93, 94, 95, 96, 97, 98, 100, 102, 103, 104, 106, 116, 123, 124], "wrong": [1, 61], "size": [1, 22, 23, 25, 45, 49, 58, 61, 69, 97, 98, 99, 100, 121, 128, 129, 132], "cloth": [1, 19], "broken": 1, "miss": [1, 5, 74], "sever": [1, 2, 16, 17, 19, 21, 24, 25, 27, 32, 38, 106, 123, 124, 125, 132, 133], "option": [1, 10, 18, 20, 23, 25, 45, 49, 58, 61, 75, 77, 79, 80, 81, 82, 84, 85, 108, 109, 114, 115, 127, 133], "provid": [1, 2, 12, 14, 15, 19, 27, 28, 29, 32, 40, 45, 58, 61, 63, 69, 72, 74, 75, 77, 82, 86, 89, 90, 91, 103, 108, 117, 118, 121, 122, 126, 132, 133], "address": [1, 2, 17, 19, 32, 49, 82, 86, 117, 132], "problem": [1, 2, 3, 10, 17, 18, 19, 23, 24, 25, 32, 33, 38, 47, 58, 59, 62, 63, 65, 66, 67, 72, 77, 78, 82, 84, 85, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 115, 117, 118, 123, 124, 126, 132, 133], "For": [1, 2, 3, 4, 5, 6, 10, 17, 19, 20, 22, 25, 27, 29, 32, 33, 38, 45, 58, 59, 60, 62, 67, 72, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 114, 115, 117, 123, 124, 125, 128, 132], "mai": [1, 2, 3, 4, 6, 10, 15, 18, 19, 21, 23, 32, 47, 59, 74, 79, 80, 87, 109, 123, 124, 130], "offer": [1, 2, 63, 82, 101, 102, 103, 104, 105, 106, 116], "1": [1, 4, 5, 6, 10, 16, 18, 19, 20, 23, 24, 25, 28, 29, 32, 33, 38, 40, 47, 52, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 72, 73, 74, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 114, 115, 116, 117, 118, 120, 121, 122, 123, 124, 126, 127, 128, 129], "fulli": [1, 79, 83, 86, 87, 107, 117, 128], "refund": 1, "without": [1, 10, 22, 40, 73, 74, 91, 132], "return": [1, 2, 10, 21, 22, 23, 45, 49, 58, 59, 61, 69, 75, 77, 117, 120, 121, 123, 126, 127, 129], "2": [1, 10, 16, 18, 19, 20, 23, 24, 25, 26, 29, 33, 35, 37, 39, 40, 41, 42, 43, 47, 59, 60, 61, 62, 63, 65, 66, 68, 69, 72, 73, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 114, 115, 116, 117, 118, 121, 122, 123, 124, 126, 127, 128, 129, 133], "discount": [1, 63, 72, 73, 74, 117], "next": [1, 10, 15, 19, 22, 29, 38, 59, 67, 72, 73, 74, 90, 91, 123, 124, 130], "compens": 1, "level": [1, 3, 4, 5, 6, 19, 59, 117, 123, 124, 132], "vari": [1, 37, 79, 122], "accord": [1, 2, 4, 6, 12, 17, 27, 32, 33, 63, 65, 67, 69, 74, 84, 86, 104, 107, 109, 114, 123, 132], "primari": [1, 3, 17, 60, 78, 132], "goal": [1, 2, 3, 17, 27, 40, 47, 59, 63, 73, 74, 79, 83, 87, 89, 90, 91, 99, 101, 106, 107, 128, 132, 133], "outcom": [1, 2, 3, 10, 12, 15, 16, 17, 19, 20, 21, 22, 24, 25, 28, 29, 32, 33, 37, 38, 40, 45, 49, 58, 59, 60, 69, 75, 77, 78, 86, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 117, 122, 126, 132, 134], "so": [1, 2, 4, 5, 9, 10, 11, 13, 15, 17, 24, 25, 27, 59, 73, 74, 77, 82, 85, 107, 108, 115, 123, 124], "examin": [1, 94, 122, 126, 132], "which": [1, 2, 3, 4, 5, 6, 10, 12, 15, 17, 18, 19, 21, 22, 23, 24, 25, 27, 28, 29, 32, 33, 38, 40, 45, 47, 49, 52, 58, 59, 62, 66, 67, 69, 72, 73, 74, 75, 77, 78, 79, 80, 83, 84, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 108, 109, 114, 116, 117, 118, 121, 123, 124, 125, 126, 128, 132, 133], "take": [1, 11, 13, 14, 22, 29, 32, 33, 47, 59, 63, 69, 73, 77, 79, 82, 83, 84, 86, 87, 88, 93, 95, 97, 98, 99, 100, 102, 103, 104, 105, 107, 108, 120, 121, 128, 132, 133], "histori": [1, 2, 27, 45, 58, 59, 60, 74, 82, 89, 90, 91, 107, 108, 117, 118, 132], "maxim": [1, 2, 27, 47, 49, 58, 59, 77, 78, 79, 83, 87, 94, 106, 107, 117, 122, 126], "profit": [1, 2, 101, 106, 116], "asid": [1, 19, 33, 59], "abov": [1, 4, 6, 9, 10, 11, 15, 16, 17, 18, 19, 21, 22, 23, 25, 29, 32, 33, 40, 49, 101, 117, 122, 123, 126, 130], "idea": [1, 17, 20, 22, 24, 25, 26, 33, 40, 117, 131, 133], "fundament": 1, "ha": [1, 2, 3, 5, 9, 10, 13, 18, 19, 21, 23, 33, 38, 47, 49, 59, 62, 63, 67, 68, 69, 72, 76, 80, 83, 84, 85, 86, 87, 95, 98, 99, 101, 102, 106, 107, 109, 114, 115, 117, 121, 126, 128, 132], "broad": [1, 38], "our": [1, 2, 4, 6, 15, 17, 18, 23, 32, 33, 38, 40, 49, 52, 59, 63, 67, 68, 69, 72, 74, 77, 87, 89, 90, 91, 117], "daili": 1, "live": 1, "leverag": [1, 14, 18, 20, 23, 25, 49, 88, 117], "studi": [1, 2, 3, 4, 5, 6, 9, 13, 15, 19, 21, 27, 32, 40, 59, 60, 62, 65, 72, 79, 83, 87, 106, 107, 118, 122, 126, 128, 132], "new": [1, 2, 4, 6, 17, 32, 33, 45, 59, 60, 75, 77, 79, 86, 87, 88, 99, 106, 107, 116, 117, 127, 128, 132], "catalyst": 1, "rate": [1, 2, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 24, 25, 26, 27, 28, 29, 49, 62, 63, 72, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 94, 106, 107, 108, 117, 122, 123, 124, 126, 127, 128], "chemic": 1, "reaction": 1, "smoke": [1, 40], "risk": [1, 124], "lung": 1, "cancer": 1, "ad": [1, 4, 6, 19, 45, 75, 89, 90, 91, 99, 106, 116, 133], "exposur": [1, 2, 3, 10, 19, 37, 40, 69, 122], "convers": [1, 2, 19], "bui": [1, 102, 103, 104], "product": [1, 2, 33, 101, 106, 116, 128], "extracurricular": 1, "remedi": 1, "class": [1, 4, 9, 10, 24, 25, 49, 59, 62, 63, 65, 72, 78, 79, 85, 87, 95, 100, 102, 106, 107, 115, 116, 118, 129, 132], "improv": [1, 2, 5, 16, 17, 18, 19, 20, 24, 26, 28, 29, 59, 93, 117, 118, 133], "student": [1, 15, 16, 17, 18, 20, 24, 26, 27, 28, 29, 79, 80, 81, 86, 87, 107, 127, 128, 129], "grade": 1, "cdot": [1, 4, 6, 9, 10, 11, 12, 13, 14, 15, 18, 20, 21, 23, 24, 25, 33, 45, 49, 60, 62, 63, 65, 66, 67, 69, 72, 73, 74, 75, 76, 77, 78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 93, 95, 96, 97, 98, 100, 101, 102, 103, 104, 105, 108, 109, 114, 115, 117, 132], "social": [1, 132], "phenomena": 1, "natur": [1, 2, 5, 10, 12, 21, 24, 25, 47, 59, 69, 117, 121, 122, 123, 126, 128], "quantif": 1, "allow": [1, 2, 4, 5, 6, 10, 47, 49, 58, 59, 63, 74, 77, 132], "understand": [1, 10, 19, 58, 77, 82, 117], "relationship": [1, 3, 4, 6, 9, 10, 11, 12, 13, 14, 40, 47, 58, 67, 80, 95, 102, 104, 109, 117, 132], "methodolog": [1, 9, 12, 38, 45, 69, 75, 132], "onli": [1, 2, 4, 5, 6, 10, 12, 15, 17, 26, 33, 38, 40, 59, 60, 62, 63, 67, 68, 72, 73, 74, 78, 88, 93, 94, 95, 96, 101, 102, 103, 104, 117, 130, 132], "scientif": [1, 4, 6], "also": [1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 19, 21, 22, 24, 25, 26, 33, 45, 58, 59, 61, 62, 65, 66, 67, 69, 72, 74, 75, 77, 84, 86, 87, 95, 96, 97, 98, 99, 100, 101, 102, 104, 107, 109, 114, 118, 123, 124, 128, 132], "practic": [1, 2, 49, 58, 63, 77, 79, 80, 82, 83, 84, 86, 89, 90, 91, 93, 95, 96, 97, 98, 100, 102, 103, 104, 107, 108, 109, 114, 117], "where": [1, 2, 4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 38, 40, 45, 47, 49, 58, 59, 60, 62, 63, 65, 67, 68, 69, 72, 73, 74, 75, 77, 78, 79, 80, 82, 83, 84, 86, 87, 88, 89, 90, 91, 94, 95, 97, 99, 100, 101, 102, 106, 107, 108, 116, 117, 121, 122, 123, 124, 126, 127, 128, 132, 133], "seek": 1, "user": [2, 4, 6, 15, 16, 17, 18, 20, 24, 26, 27, 28, 29, 45, 47, 58, 59, 75, 77, 79, 80, 81, 82, 83, 86, 87, 88, 94, 97, 98, 100, 101, 102, 103, 104, 106, 107, 108, 116, 120, 123, 128], "growth": 2, "engag": 2, "critic": [2, 5, 27, 40, 62, 72, 74, 123, 124, 125], "fast": [2, 9, 10, 11, 12, 13, 14, 33, 62, 134], "chang": [2, 22, 27, 32, 33, 38, 49, 67, 75, 97, 122, 123, 124, 126, 130, 132, 133], "market": [2, 33, 127], "campaign": [2, 60], "internet": 2, "compani": [2, 19, 33], "encourag": [2, 47], "The": [2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 35, 38, 39, 40, 41, 42, 43, 45, 47, 49, 58, 59, 60, 62, 63, 65, 66, 67, 69, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 108, 109, 114, 115, 116, 117, 118, 121, 122, 123, 124, 125, 126, 128, 130, 132, 133], "posit": [2, 4, 6, 10, 11, 13, 14, 15, 21, 22, 26, 32, 33, 45, 58, 69, 75, 77, 87, 106, 116, 128], "effect": [2, 3, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 28, 29, 32, 33, 38, 40, 47, 60, 63, 77, 101, 106, 116, 121, 122, 126, 131], "desir": [2, 3, 59], "busi": 2, "lead": [2, 19, 63], "surplu": 2, "oper": [2, 10, 12, 15, 63, 101, 104, 105], "cost": [2, 25, 47, 104], "increas": [2, 49, 63, 78, 82, 89, 90, 91, 107, 122, 123, 124, 126], "impel": 2, "carri": 2, "out": [2, 10, 16, 17, 18, 19, 20, 24, 26, 28, 29, 74, 126], "more": [2, 3, 4, 5, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 25, 26, 28, 29, 32, 45, 49, 59, 60, 63, 67, 68, 70, 72, 74, 75, 79, 81, 82, 88, 97, 98, 100, 103, 104, 107, 108, 109, 114, 115, 117, 126, 130, 133], "refin": 2, "strategi": 2, "acquisit": 2, "retent": 2, "associ": [2, 4, 5, 6, 9, 11, 13, 21, 36, 40, 47, 49, 59, 74, 78, 89, 90, 91, 118, 123, 124, 126, 132], "massiv": [2, 19], "scale": [2, 9, 20, 25, 40, 49, 65, 78, 93, 94, 95, 97, 99, 100, 102, 103, 107, 132], "promot": 2, "balanc": [2, 73, 84, 107], "increment": [2, 33, 117], "sustain": 2, "invest": [2, 45, 58, 75, 77], "roi": [2, 84, 106, 107, 114, 115, 116], "requir": [2, 9, 11, 14, 17, 18, 23, 32, 45, 47, 49, 62, 63, 72, 74, 75, 77, 87, 117, 132], "predict": [2, 5, 15, 18, 21, 22, 23, 26, 28, 29, 40, 49, 58, 77, 117, 123, 124, 128], "caus": [2, 4, 6, 9, 11, 12, 13, 14, 19, 21, 32, 33, 47, 59, 123, 124], "action": [2, 4, 6, 10, 15, 16, 17, 18, 19, 20, 21, 24, 26, 27, 28, 29, 32, 33, 45, 47, 58, 60, 61, 62, 63, 65, 66, 67, 69, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 114, 115, 116, 117, 118, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132], "uplift": [2, 59, 60], "model": [2, 6, 10, 12, 15, 17, 21, 22, 24, 25, 26, 28, 29, 36, 45, 49, 58, 59, 61, 62, 63, 65, 72, 73, 74, 75, 77, 78, 80, 81, 86, 87, 89, 90, 91, 93, 94, 95, 97, 100, 101, 102, 103, 104, 106, 107, 109, 116, 122, 124, 126, 132], "heterogen": [2, 9, 15, 16, 18, 19, 20, 22, 23, 24, 25, 26, 28, 29, 33, 38, 86, 94, 95, 99, 100, 101, 102, 132, 134], "attent": [2, 3, 9, 11, 12, 13, 14, 32, 49, 78, 89, 90, 91, 107, 123, 124, 132], "literatur": [2, 9, 15, 19, 21, 32, 49, 59, 62, 68, 69, 72, 74, 87, 104, 117, 118, 121, 129, 132, 133], "book": [2, 5, 77, 117, 130, 132, 133], "sampl": [2, 4, 6, 16, 17, 18, 20, 22, 23, 25, 32, 45, 47, 49, 58, 59, 62, 63, 68, 73, 79, 80, 82, 83, 84, 87, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 108, 109, 114, 115, 116, 117, 128, 132], "code": [2, 9, 10, 17, 18, 23, 33, 47, 61, 116, 122, 126, 133], "relat": [2, 9, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 40, 45, 67, 73, 74, 75, 78, 79, 87, 107, 117, 123, 124, 125, 128, 132, 133], "under": [2, 3, 4, 5, 6, 9, 10, 15, 16, 17, 19, 20, 21, 22, 25, 26, 28, 29, 32, 33, 45, 47, 49, 58, 62, 63, 64, 65, 67, 69, 72, 79, 86, 88, 89, 90, 91, 95, 100, 101, 102, 103, 104, 107, 122, 123, 124, 126, 128, 132, 133], "set": [2, 3, 5, 9, 10, 11, 12, 13, 14, 18, 21, 23, 27, 32, 49, 59, 61, 63, 67, 69, 72, 73, 74, 77, 82, 88, 89, 90, 91, 93, 95, 96, 97, 98, 100, 102, 103, 104, 108, 117, 118, 120, 121, 122, 123, 124, 126, 128, 129, 130, 132], "point": [2, 15, 16, 17, 18, 20, 23, 24, 26, 28, 29, 32, 33, 47, 49, 58, 60, 65, 66, 67, 68, 73, 74, 75, 77, 83, 87, 117, 118, 128], "interest": [2, 3, 4, 6, 10, 12, 17, 18, 19, 21, 23, 32, 33, 38, 45, 49, 58, 59, 60, 69, 72, 75, 77, 93, 94, 95, 96, 117, 121, 122, 123, 124, 126, 128, 132], "dataset": [2, 3, 15, 19, 26, 27, 33, 40, 45, 49, 58, 60, 73, 74, 76, 77, 79, 83, 87, 93, 95, 96, 97, 98, 100, 102, 103, 104, 106, 107, 116, 117, 123, 124, 125, 126, 128], "space": [2, 9, 21, 27, 45, 49, 58, 60, 62, 67, 72, 73, 74, 75, 77, 80, 81, 82, 84, 85, 87, 88, 89, 90, 91, 97, 98, 100, 106, 108, 109, 114, 115, 116], "should": [2, 10, 12, 17, 75, 77, 80, 93, 95, 96, 97, 98, 100, 102, 103, 130], "variou": [2, 3, 11, 13, 38, 58, 62, 72, 77, 88, 97, 106, 132], "email": [2, 45, 58], "sent": 2, "total": [2, 10, 12, 15, 19, 21, 33, 38, 40, 49, 59, 60, 69, 75, 79, 82, 83, 85, 86, 93, 95, 96, 97, 98, 100, 102, 103, 104, 106, 107, 108, 115, 116, 121, 126, 128, 132], "amount": [2, 17, 32, 94, 123], "spent": [2, 49, 60], "fetch_hillstrom": [2, 59, 60], "discret": [2, 4, 5, 6, 27, 45, 49, 59, 73, 74, 75, 80, 81, 82, 84, 85, 122, 123, 124, 126, 134], "q": [2, 5, 9, 17, 32, 45, 49, 59, 61, 62, 63, 72, 73, 74, 75, 78, 82, 84, 86, 88, 95, 100, 102, 104, 107, 108, 117, 122, 126, 129, 132, 134], "much": [2, 3, 19], "spend": [2, 45, 58, 59, 60], "averag": [2, 9, 12, 15, 16, 17, 19, 20, 22, 25, 29, 33, 38, 40, 45, 58, 63, 67, 68, 69, 75, 77, 82, 85, 108, 115, 117, 121, 123, 124, 128, 129, 132], "add": [2, 5, 10, 45, 58, 86, 129, 130, 133], "quantil": [2, 68, 134], "continu": [2, 4, 6, 9, 10, 11, 12, 13, 14, 45, 58, 59, 67, 72, 73, 75, 77, 82, 84, 85, 86, 88, 97, 98, 99, 100, 123, 124, 126, 128, 130, 134], "owl": [2, 134], "john": [2, 5, 73, 74, 117], "wanamak": 2, "onc": [2, 5, 86, 88, 94, 133], "phrase": 2, "half": 2, "monei": [2, 60], "advertis": [2, 19, 33, 97, 98, 99, 100], "wast": 2, "troubl": 2, "don": [2, 10, 59, 102, 103, 104], "t": [2, 4, 5, 6, 10, 11, 15, 17, 18, 19, 20, 21, 23, 25, 29, 32, 33, 38, 40, 45, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 114, 115, 116, 117, 122, 123, 124, 126, 128, 129, 132], "know": [2, 19, 59], "indic": [2, 4, 6, 11, 13, 14, 15, 27, 33, 49, 82, 90, 91, 94, 101, 102, 103, 104, 106, 123, 124, 126], "high": [2, 3, 4, 9, 10, 11, 12, 13, 14, 15, 32, 40, 45, 75, 117, 123, 124, 129], "intent": 2, "convert": [2, 4, 6, 10, 11, 13, 14, 128], "todai": 2, "digit": 2, "techniqu": [2, 40, 62, 72, 132], "enabl": [2, 9, 10, 12, 95, 100, 102], "lift": 2, "via": [2, 3, 4, 9, 10, 11, 12, 13, 14, 15, 40, 59, 62, 63, 65, 72, 73, 86, 89, 90, 91, 95, 100, 101, 102, 117, 118, 133], "random": [2, 4, 6, 9, 11, 12, 13, 14, 15, 16, 19, 20, 21, 24, 26, 35, 39, 41, 42, 43, 59, 61, 68, 69, 73, 74, 79, 80, 81, 82, 83, 84, 86, 87, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 107, 108, 109, 121, 123, 124, 126, 129], "control": [2, 3, 4, 5, 6, 9, 12, 15, 16, 19, 20, 21, 22, 24, 25, 27, 28, 29, 32, 33, 38, 45, 75, 117, 121, 122, 123, 124, 126, 132], "select": [2, 10, 26, 40, 47, 49, 60, 73, 78, 79, 80, 81, 82, 83, 84, 85, 87, 93, 95, 96, 97, 98, 100, 101, 102, 104, 105, 107, 108, 109, 114, 115, 117, 118, 123, 124, 125, 128], "form": [2, 10, 11, 15, 62, 66, 72, 73, 80, 84, 86, 88, 95, 102, 117], "interven": [2, 4, 6, 9, 12, 33], "base": [2, 4, 5, 9, 10, 12, 15, 17, 18, 19, 21, 22, 23, 27, 32, 33, 45, 47, 49, 58, 62, 63, 65, 66, 67, 69, 72, 74, 75, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 93, 95, 96, 97, 98, 100, 101, 102, 103, 104, 105, 107, 108, 109, 114, 115, 118, 120, 122, 123, 124, 126, 128, 132, 134], "collect": [2, 3, 4, 6, 17, 19, 23, 27, 40, 59, 73, 74, 79, 83, 87, 101, 106, 107, 117, 123, 124, 125, 128, 132], "converion": 2, "even": [2, 15, 32, 40, 118, 132], "win": 2, "impress": [2, 19], "those": [2, 5, 47, 74, 80, 81, 82, 84, 85, 86, 88], "With": [2, 45, 47, 67, 95, 102, 106, 122, 126], "wearabl": 2, "devic": 2, "easili": [2, 22, 28, 80, 84, 89, 95, 96, 98, 102, 103, 109, 114], "keep": [2, 6, 10, 12, 101, 104], "track": [2, 9], "own": [2, 87, 132], "meanwhil": [2, 73], "util": [2, 10, 11, 13, 14, 17, 33, 58, 59, 62, 63, 67, 68, 72, 77, 79, 80, 81, 86, 87, 93, 95, 101, 102, 103, 104, 106, 117, 118, 123, 124, 125, 126, 127, 128], "manag": [2, 130], "increasingli": 2, "hot": 2, "topic": [2, 32, 117], "among": [2, 4, 9, 10, 11, 12, 13, 14, 40, 59, 65, 72, 78, 79, 83, 86, 87, 95, 100, 102, 107, 126, 128, 132], "them": [2, 6, 15, 21, 22, 28, 32, 59, 72, 83, 94, 101, 103, 107, 126], "decid": [2, 18, 23, 93, 95, 96, 97, 98, 99, 100], "biggest": 2, "challeng": [2, 3, 10, 40, 63, 68, 117, 118], "given": [2, 4, 6, 11, 13, 14, 15, 16, 17, 21, 22, 24, 25, 26, 27, 29, 32, 33, 45, 49, 58, 59, 62, 63, 65, 68, 72, 73, 74, 75, 77, 78, 80, 81, 89, 90, 91, 95, 100, 102, 117, 132], "activ": 2, "suggest": [2, 4, 45, 65, 78, 85, 106, 107, 115, 131, 133], "help": [2, 10, 27, 77, 79, 83, 87, 106, 107, 128], "regul": [2, 3, 10, 12, 21], "psycholog": [2, 21], "howev": [2, 4, 6, 9, 12, 15, 18, 19, 21, 22, 23, 25, 28, 32, 40, 45, 62, 63, 67, 68, 72, 75, 77, 84, 107, 109, 114, 117, 118], "send": [2, 45, 58, 97, 98, 100], "written": [2, 5, 9, 14, 15, 19, 20, 21, 25, 32], "intuit": [2, 47, 79, 82, 107, 108], "asleep": 2, "intens": [2, 19], "workout": 2, "rare": [2, 68], "exercis": 2, "would": [2, 4, 19, 21, 22, 26, 32, 33, 38, 45, 47, 58, 59, 60, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 87, 88, 89, 90, 91, 94, 99, 101, 106, 107, 109, 114, 116, 117, 118, 122, 126, 132, 133], "decreas": [2, 3, 63, 82, 107, 108, 123, 124], "To": [2, 13, 15, 17, 18, 22, 23, 33, 40, 49, 59, 62, 63, 67, 69, 72, 73, 82, 88, 94, 95, 102, 117, 128, 130, 133], "number": [2, 4, 9, 11, 13, 14, 22, 23, 25, 27, 33, 40, 45, 47, 49, 59, 67, 69, 75, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 108, 115, 116, 123, 124, 126, 128, 132], "formal": [2, 3, 4, 15, 17, 24, 25, 72, 74, 94, 99], "reinforc": [2, 5, 9, 10, 11, 12, 13, 14, 58, 65, 66, 67, 72, 73, 74, 77, 82, 107, 108, 117, 118, 121], "mdp": [2, 32, 62, 67, 69, 72, 73, 74, 117, 118], "seri": [2, 5, 9, 18, 23, 45, 67, 72, 75], "stage": [2, 16, 17, 25, 32, 33, 48, 52, 75, 121, 128, 132, 134], "condit": [2, 4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 25, 32, 33, 45, 49, 59, 62, 63, 74, 75, 86, 89, 90, 91, 95, 100, 102, 106, 117, 118, 126], "affect": [2, 3, 4, 6, 12, 15, 21, 33, 47, 132], "previou": [2, 17, 19, 74, 79, 85, 87, 89, 90, 91, 95, 100, 102, 106, 107, 116, 128, 132], "delai": [2, 69, 77, 121], "current": [2, 3, 59, 69, 73, 74, 78, 89, 90, 91, 117, 132], "decis": [2, 5, 9, 10, 15, 33, 45, 49, 58, 59, 60, 69, 75, 77, 78, 87, 89, 90, 91, 101, 117, 118, 126, 130, 131, 132, 133], "subsequ": [2, 4, 6, 106], "regard": [2, 19, 63, 65, 67, 72, 79, 132], "cumul": [2, 67, 73, 74, 78, 79, 83, 87, 95, 100, 102, 106, 107, 117, 128], "sequenc": [2, 76, 78, 87, 106, 116, 118, 126], "longitudin": [2, 32, 37, 38, 122], "subject": [2, 4, 6, 15, 19, 22, 33, 45, 58, 75, 77], "experienc": 2, "entir": [2, 5, 17, 32, 95, 100, 102, 123, 132], "formul": [2, 9, 13, 74, 100, 132], "illustr": [2, 17, 18, 21, 23, 27, 40, 59, 63, 69, 78, 83, 89, 90, 91, 107, 117, 123, 124, 125, 132, 133], "context": [2, 10, 21, 33, 38, 49, 78, 79, 89, 90, 91, 132], "hiv": 2, "infect": [2, 3], "time": [2, 5, 9, 10, 11, 13, 14, 19, 21, 25, 32, 37, 38, 40, 45, 49, 59, 63, 67, 69, 72, 73, 74, 75, 79, 82, 83, 85, 86, 87, 89, 90, 91, 106, 107, 108, 115, 117, 118, 121, 122, 123, 124, 126, 128, 132], "datamdp": [2, 75, 76, 77], "cd4": 2, "count": [2, 10, 82, 85, 108, 115, 127], "wa": [2, 4, 9, 10, 13, 15, 21, 24, 25, 27, 32, 33, 40, 47, 58, 59, 75, 77, 118, 128], "all": [2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 24, 25, 26, 27, 28, 29, 32, 33, 38, 40, 45, 47, 58, 59, 63, 69, 72, 74, 75, 76, 77, 79, 86, 87, 89, 90, 91, 94, 97, 98, 99, 100, 103, 105, 106, 107, 116, 117, 118, 121, 122, 123, 124, 126, 128, 132], "interact": [2, 20, 25, 87, 106, 116], "same": [2, 4, 5, 6, 10, 15, 18, 19, 21, 22, 23, 28, 29, 33, 45, 47, 58, 63, 74, 75, 77, 88, 97, 98, 101, 102, 103, 104, 106, 117], "possibl": [2, 4, 6, 9, 13, 22, 29, 40, 63, 97, 98, 100, 128, 132], "style": [2, 14, 105], "mani": [2, 3, 5, 9, 10, 12, 47, 65, 72, 73, 74, 89, 90, 91, 95, 100, 102, 106, 116, 117], "channel": [2, 59], "distribut": [2, 4, 6, 9, 14, 21, 22, 23, 25, 47, 59, 60, 63, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 109, 114, 117, 118, 128, 132], "credit": 2, "correspond": [2, 4, 6, 10, 12, 32, 40, 45, 47, 49, 58, 59, 62, 63, 67, 68, 69, 72, 74, 75, 77, 79, 82, 83, 84, 85, 86, 87, 88, 94, 95, 98, 101, 102, 103, 104, 106, 107, 108, 109, 114, 115, 116, 117, 118, 132], "contribut": [2, 3, 10, 131], "becom": [2, 15, 24, 25, 32, 40, 63, 67, 118], "rule": [2, 47, 49, 98], "simpl": [2, 18, 23, 33, 65, 66, 67, 78, 82, 87, 100, 107, 108, 129, 134], "been": [2, 4, 6, 9, 13, 15, 18, 23, 27, 32, 33, 49, 59, 62, 67, 68, 72, 78, 83, 84, 86, 87, 98, 103, 107, 109, 114, 123, 124, 125, 132], "long": [2, 32, 62, 67, 69, 72, 101, 132], "ever": 2, "enhanc": [2, 131], "capabl": 2, "driven": 2, "attempt": 2, "popular": [2, 49, 66, 94, 95, 101, 104, 106, 107, 116, 117, 127, 128], "framework": [2, 4, 6, 15, 69, 79, 80, 86, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 116, 121, 131], "classic": [2, 4, 6, 9, 14, 21, 22, 24, 25, 32, 49, 58, 65, 77, 79, 83, 84, 107, 114, 118, 132, 133], "bandit": [2, 5, 89, 90, 91, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 115, 116, 118, 128, 134], "prefer": [2, 19, 22, 28], "click": [2, 19, 94, 102, 103, 104, 106], "overal": [2, 19, 21, 22, 23, 25, 33, 45, 58, 59, 75, 77, 79, 83, 94, 95, 99, 100, 101, 102, 107, 123, 124, 132], "repres": [2, 4, 6, 9, 10, 11, 12, 13, 14, 15, 27, 38, 49, 117, 123, 124, 125, 132], "movi": [2, 26, 79, 82, 83, 87, 102, 103, 104, 106, 107, 116, 128], "youtub": 2, "netflix": 2, "agent": [2, 59, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 109, 114, 116, 117, 128], "list": [2, 10, 11, 13, 14, 32, 40, 61, 75, 88, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 106, 116, 120, 123, 124, 127, 128, 132], "video": [2, 59], "visit": [2, 32, 49, 63, 67, 79, 83, 87, 94, 101, 106, 107, 117, 128], "either": [2, 4, 6, 15, 27, 45, 52, 58, 60, 62, 65, 66, 72, 75, 77, 79, 82, 84, 85, 86, 88, 90, 93, 95, 96, 97, 98, 100, 101, 102, 103, 104, 106, 107, 108, 115, 117, 118, 132, 133], "leav": [2, 3, 32, 83, 87, 94, 106, 132], "typic": [2, 40, 62, 67, 68, 72, 78, 79, 83, 99, 100, 117, 132], "larg": [2, 17, 19, 27, 40, 47, 61, 62, 63, 65, 67, 69, 72, 74, 78, 82, 84, 85, 86, 87, 88, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 107, 115, 123, 124, 125, 126], "avail": [2, 4, 6, 9, 10, 13, 14, 17, 33, 60, 74, 79, 83, 87, 93, 94, 100, 101, 106, 107, 116, 123, 124, 125, 128], "therefor": [2, 17, 32, 40, 45, 58, 63, 65, 66, 67, 79, 83, 84, 87, 88, 94, 97, 98, 100, 107, 109, 114, 117, 122, 126, 128, 132], "explor": [2, 22, 32, 59, 68, 70, 71, 72, 77, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 93, 96, 107, 108, 109, 114, 115, 117, 128], "exploit": [2, 19, 82, 83, 84, 85, 89, 90, 91, 96, 107, 108, 109, 114, 115], "inform": [2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 17, 19, 22, 27, 29, 33, 40, 45, 49, 60, 67, 72, 75, 76, 78, 79, 80, 81, 84, 86, 87, 88, 90, 91, 93, 94, 95, 97, 98, 100, 101, 102, 103, 106, 107, 109, 114, 116, 118, 121, 122, 126, 129, 130, 132, 133], "far": [2, 82, 85, 107, 108], "approach": [2, 3, 4, 6, 15, 16, 17, 18, 21, 22, 25, 32, 33, 45, 47, 58, 62, 63, 65, 66, 67, 68, 72, 75, 77, 78, 79, 101, 103, 104, 105, 107, 117, 118, 132], "As": [2, 15, 20, 22, 25, 26, 29, 32, 40, 62, 63, 65, 69, 72, 73, 74, 78, 80, 81, 85, 86, 88, 93, 95, 96, 107, 109, 115, 117, 121, 122, 123, 124, 126, 132], "chapter": [2, 60, 74, 79, 83, 87, 93, 95, 96, 97, 98, 100, 102, 103, 104, 106, 107, 116, 117, 118, 132, 133], "genr": [2, 26, 79, 83, 87, 106, 107, 128], "five": [2, 102, 103, 104, 106, 128], "whose": [2, 3, 74, 132], "unknown": [2, 9, 12, 13, 64, 67, 72, 78, 79, 83, 84, 86, 88, 89, 90, 91, 95, 100, 102, 107, 109, 114, 126, 132], "over": [2, 3, 15, 22, 33, 38, 49, 62, 63, 67, 69, 72, 88, 89, 90, 91, 104, 107, 117, 123, 127, 132], "satisfact": [2, 27, 79, 83, 87, 106, 107, 128], "movielen": [2, 15, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 102, 103, 104, 106, 107, 116, 127], "arm": [2, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 98, 99, 106, 107, 108, 115, 116, 127, 128, 134], "contextu": [2, 40, 78, 80, 81, 83, 89, 90, 91, 101, 102, 103, 107, 109, 128, 132, 134], "meta": [2, 19, 29, 78, 86, 94, 95, 99, 100, 101, 102, 106, 134], "multipl": [2, 9, 10, 11, 12, 13, 14, 32, 45, 47, 59, 61, 75, 78, 88, 118, 126, 132, 134], "million": [2, 3, 9, 10, 11, 12, 13, 14], "try": [2, 10, 16, 21, 25, 27, 107, 120, 123, 126, 130], "assort": [2, 102, 104, 105, 106, 116, 134], "rank": [2, 93, 95, 96, 106, 116, 134], "top": [2, 9, 10, 11, 12, 13, 14, 40, 74, 79, 83, 87, 93, 94, 95, 96, 104, 106, 107, 117, 123, 124], "restaur": [2, 33, 93, 94, 95, 96], "true": [2, 3, 10, 11, 13, 14, 17, 18, 21, 22, 23, 25, 45, 47, 58, 59, 60, 61, 63, 65, 69, 75, 77, 80, 81, 82, 84, 86, 88, 90, 102, 104, 105, 106, 107, 108, 109, 114, 115, 120, 121, 122, 123, 126, 128], "expect": [2, 15, 16, 17, 18, 20, 22, 23, 24, 25, 26, 28, 29, 32, 38, 45, 47, 49, 58, 62, 67, 69, 72, 73, 74, 75, 77, 79, 80, 81, 84, 86, 87, 88, 90, 91, 96, 98, 107, 122, 123, 124, 126, 128], "yelp": [2, 93, 95, 96], "discuss": [2, 9, 32, 67, 72, 73, 74, 88, 117, 132, 133], "offlin": [2, 27, 32, 49, 59, 64, 90, 117, 118, 132], "prevent": 2, "unnecessari": [2, 123, 124], "essenti": [2, 3, 72, 86, 118], "variant": [2, 3, 67, 82, 107, 108, 117, 127], "frequent": [2, 40], "commerci": 2, "googl": [2, 131], "displai": [2, 5, 17, 21, 33, 93, 94, 95, 96], "twitter": 2, "view": [2, 3, 21, 72, 90, 91, 120, 123, 131], "bipartit": 2, "match": [2, 33, 62, 67, 90, 91, 99, 102, 103, 104, 106, 116, 127], "need": [2, 10, 20, 25, 33, 45, 49, 59, 67, 75, 79, 83, 84, 85, 87, 88, 94, 99, 101, 106, 107, 109, 114, 116, 117, 118, 121, 130, 133], "show": [2, 4, 10, 15, 19, 40, 59, 62, 72, 74, 82, 90, 93, 95, 96, 99, 101, 107, 108, 128], "like": [2, 5, 19, 21, 22, 26, 27, 28, 38, 45, 47, 58, 59, 63, 77, 79, 83, 87, 106, 107, 122, 126, 128, 133], "attract": [2, 3, 4, 9, 11, 12, 13, 14, 15, 22, 59, 89, 90, 91, 94, 95, 96, 97, 98, 99, 100, 106], "while": [2, 6, 10, 12, 22, 28, 32, 33, 38, 45, 47, 59, 69, 75, 78, 79, 88, 95, 100, 102, 103, 121, 128, 132], "adher": 2, "budget": 2, "constraint": [2, 5, 9, 10, 13, 40, 65, 97, 98, 99, 100, 106, 116], "feedback": [2, 78, 79, 80, 83, 87, 89, 90, 91, 95, 99, 100, 102, 106, 107, 109, 114, 116], "achiev": [2, 17, 19, 20, 25, 33, 47, 62, 63, 72, 84, 88], "whom": 2, "its": [2, 5, 9, 11, 13, 17, 19, 20, 22, 25, 47, 49, 59, 62, 63, 66, 67, 72, 73, 74, 79, 84, 86, 87, 90, 93, 107, 109, 114, 117, 130, 132], "chanc": 2, "accept": [2, 5, 120], "adult": [2, 97, 98, 100], "combinatori": [2, 95, 97, 98, 100, 102, 105, 106, 116, 134], "world": [2, 78, 79, 83, 87, 93, 98, 107], "across": [2, 38, 86, 87, 97], "retail": 2, "adjust": [2, 21, 88], "period": [2, 11, 32, 33, 40, 123, 132], "rideshar": 2, "servic": [2, 94, 127], "weather": 2, "occur": [2, 10, 74, 117], "outsid": [2, 3, 10, 21, 32], "airlin": 2, "rais": [2, 10, 21, 33, 69, 120, 121, 126], "ticket": 2, "farewel": 2, "date": [2, 86, 88, 126], "rise": [2, 15], "low": [2, 5, 62, 67, 72, 104, 106, 118, 123, 124, 129], "evalut": 2, "section": [2, 4, 6, 15, 17, 19, 20, 21, 22, 25, 32, 33, 38, 48, 52, 64, 67, 68, 71, 72, 74, 117, 121, 123, 124, 126, 128, 130, 132], "harper": 2, "f": [2, 10, 62, 72, 88, 94, 95, 100, 102, 106, 116, 120, 126, 127, 130], "m": [2, 5, 10, 12, 15, 16, 17, 19, 20, 21, 24, 25, 33, 37, 38, 45, 49, 58, 59, 62, 63, 65, 73, 75, 77, 79, 80, 86, 87, 88, 89, 90, 91, 93, 94, 98, 101, 102, 103, 107, 109, 122, 126, 127, 129, 132], "konstan": 2, "j": [2, 9, 11, 13, 14, 15, 16, 17, 19, 20, 21, 22, 25, 26, 28, 29, 40, 45, 59, 63, 69, 72, 74, 75, 78, 79, 86, 87, 88, 89, 90, 91, 95, 101, 102, 103, 104, 105, 107, 114, 115, 117, 121, 126, 129], "acm": [2, 49], "transact": 2, "intellig": [2, 5, 19, 49, 78, 79, 80, 81, 87, 93, 94, 96, 107, 109, 117, 118], "tii": 2, "19": [2, 5, 10, 21, 40, 45, 49, 59, 61, 62, 120, 123], "2015": [2, 5, 47, 58, 67, 72, 77, 78, 94, 97, 99, 107, 117], "asghar": 2, "n": [2, 4, 6, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 38, 40, 45, 47, 49, 58, 59, 60, 61, 62, 63, 65, 66, 67, 72, 73, 74, 75, 76, 77, 79, 80, 82, 83, 84, 85, 86, 87, 88, 93, 94, 95, 97, 99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 115, 116, 117, 122, 123, 124, 126, 127, 128, 130, 132], "review": [2, 9, 12, 17, 19, 45, 49, 67, 68, 72, 75, 83, 95, 100, 102, 106, 107, 129, 133], "arxiv": [2, 5, 9, 10, 11, 12, 13, 14, 16, 19, 20, 25, 49, 59, 62, 65, 69, 79, 83, 84, 89, 90, 91, 93, 94, 95, 99, 100, 101, 102, 103, 106, 107, 116, 117, 118, 121], "preprint": [2, 5, 9, 10, 11, 12, 13, 14, 16, 19, 20, 25, 49, 59, 62, 65, 69, 79, 83, 84, 89, 90, 91, 93, 94, 95, 99, 100, 101, 102, 103, 106, 107, 116, 117, 118, 121], "1605": 2, "05362": 2, "2016": [2, 5, 62, 67, 72, 93, 94, 95, 99, 102, 117], "asuncion": 2, "newman": 2, "uci": [2, 131], "machin": [2, 5, 9, 10, 11, 12, 13, 14, 15, 17, 19, 22, 26, 28, 29, 62, 63, 66, 67, 68, 72, 78, 79, 80, 82, 85, 87, 88, 94, 97, 98, 99, 104, 106, 107, 108, 109, 114, 115, 116, 117], "repositori": [2, 9, 10, 11, 13, 133], "2007": [2, 9, 10, 11, 12, 13, 14, 79], "tsiati": [2, 15, 45, 75, 129, 132], "davidian": [2, 15, 45, 75, 129, 132], "hollowai": [2, 132], "laber": [2, 15, 45, 75, 129, 132], "2019": [2, 3, 5, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 22, 23, 25, 26, 28, 29, 35, 39, 41, 42, 43, 62, 65, 79, 83, 94, 96, 101, 102, 103, 104, 105, 107, 132], "precis": [2, 19, 80, 84, 86, 88, 95, 102, 132], "medicin": [2, 19, 47, 89, 90, 91, 132], "chapman": [2, 132], "hall": [2, 132], "crc": [2, 132], "era": [3, 10], "revolut": [3, 10], "area": [3, 10, 32, 38, 47, 83, 89, 90, 91, 107, 117], "gener": [3, 4, 6, 10, 19, 21, 22, 27, 32, 35, 39, 40, 41, 42, 43, 47, 49, 58, 59, 62, 65, 67, 68, 72, 73, 74, 77, 78, 79, 83, 87, 89, 90, 91, 99, 106, 107, 109, 115, 116, 127, 128, 130, 132], "graph": [3, 10, 69, 132], "direct": [3, 9, 10, 11, 12, 13, 14, 59, 63, 65, 66, 69, 72, 78, 101, 104, 117, 121, 122, 126], "indirect": [3, 10, 12, 21, 69, 122, 126], "mediat": [3, 9, 11, 13, 14, 32, 37, 74], "intermedi": 3, "variabl": [3, 4, 6, 9, 10, 11, 12, 13, 14, 16, 19, 20, 21, 22, 23, 25, 27, 32, 47, 48, 58, 68, 69, 74, 76, 77, 79, 83, 87, 94, 107, 117, 118, 126, 128, 132], "instanc": [3, 32, 47, 61, 88, 95, 102], "outbreak": 3, "coronaviru": [3, 10], "diseas": 3, "chines": [3, 10, 21], "govern": 3, "taken": [3, 38, 60, 63, 76, 87, 90, 91, 132], "extrem": [3, 22, 28], "stop": [3, 10, 89, 90, 91, 94, 106], "viru": 3, "lock": 3, "wuhan": 3, "down": 3, "jan": [3, 9, 10, 11, 12, 13, 14], "23rd": 3, "2020": [3, 5, 9, 11, 12, 13, 14, 16, 18, 19, 20, 21, 24, 25, 40, 49, 79, 80, 84, 93, 98, 100, 103, 104, 107, 109, 117, 118], "12": [3, 5, 9, 10, 11, 12, 13, 14, 16, 17, 20, 21, 23, 24, 27, 28, 29, 45, 49, 58, 59, 61, 69, 79, 107, 118, 120, 122, 123, 124, 126, 127, 128, 129], "citi": [3, 10, 21], "hubei": [3, 10, 21], "lockdown": [3, 10, 21], "directli": [3, 5, 12, 17, 27, 45, 58, 59, 62, 65, 68, 69, 70, 72, 73, 74, 75, 96, 100, 104, 108, 109, 114, 115, 117, 118, 121, 126], "block": [3, 5, 122, 126], "peopl": [3, 15, 26, 27, 28, 29, 131, 133], "stimul": [3, 59], "quarantin": 3, "further": [3, 10, 12, 20, 25, 33, 59, 63, 69, 95, 97, 98, 100, 102, 106, 116, 121, 122, 126, 128, 131, 132], "migrat": 3, "countrywid": 3, "china": [3, 10, 21], "thu": [3, 9, 12, 15, 17, 18, 20, 23, 25, 38, 49, 59, 74, 87, 89, 90, 91], "indirectli": 3, "reduc": [3, 10, 12, 21, 40, 59, 63], "great": [3, 19, 94], "crisi": 3, "mechan": [3, 10, 74], "individu": [3, 4, 6, 10, 15, 22, 27, 29, 33, 38, 45, 47, 49, 58, 60, 63, 75, 76, 77, 101, 116, 122, 126, 127], "decad": [3, 33], "discoveri": [3, 12, 49], "disentangl": [3, 9, 11, 12, 13, 14], "complex": [3, 5, 9, 11, 12, 13, 14, 22, 28, 32, 49, 63, 97, 98, 100, 104, 118, 132], "field": [3, 45, 75, 78], "5": [3, 9, 10, 11, 12, 13, 14, 15, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 33, 37, 40, 45, 47, 49, 58, 59, 61, 68, 69, 70, 72, 75, 77, 79, 83, 84, 87, 88, 94, 99, 101, 102, 103, 104, 105, 107, 108, 109, 114, 115, 120, 121, 122, 123, 124, 126, 128, 129], "singl": [3, 22, 26, 28, 32, 40, 48, 49, 52, 58, 62, 69, 72, 75, 77, 108, 109, 114, 115, 123, 124, 125, 132, 134], "nucleotid": 3, "polymorph": 3, "snp": 3, "person": [3, 9, 32, 45, 49, 58, 75, 77, 79, 107, 130], "genom": 3, "fewer": [3, 132], "non": [3, 9, 10, 12, 13, 14, 17, 19, 21, 27, 45, 47, 58, 59, 75, 77, 90, 91, 126], "spuriou": 3, "protein": 3, "systemat": [3, 133], "phenotyp": 3, "focu": [3, 4, 6, 12, 16, 17, 18, 19, 20, 24, 26, 28, 29, 45, 52, 65, 75, 78, 79, 83, 87, 89, 90, 91, 100, 101, 102, 107, 117, 128, 132], "brem": 3, "kruglyak": 3, "2005": [3, 5, 10, 58, 66, 77, 118], "discov": [3, 106], "featur": [3, 4, 6, 12, 15, 27, 47, 49, 60, 69, 79, 80, 81, 86, 87, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 109, 116, 117, 121, 123, 124, 125, 128, 132, 134], "explain": 3, "104": [3, 10, 21, 40, 83], "segreg": 3, "simul": [3, 6, 10, 12, 17, 27, 79, 83, 87, 106, 128], "genet": 3, "divers": [3, 58, 77, 132], "strain": 3, "by4716": 3, "rm11": 3, "1a": [3, 20, 25], "contain": [3, 4, 6, 9, 11, 12, 13, 14, 15, 17, 19, 27, 33, 40, 49, 60, 76, 88, 89, 90, 91, 94, 106, 116, 128, 132, 133], "thousand": [3, 127], "genotyp": 3, "rich": 3, "influenc": [3, 10, 12, 21, 40, 63, 132], "target": [3, 10, 22, 23, 25, 32, 49, 58, 59, 62, 65, 67, 72, 73, 74, 77, 90, 99, 121, 122, 126, 132], "herit": 3, "due": [3, 14, 32, 40, 62, 63, 65, 66, 67, 68, 69, 104, 117, 118, 121, 123, 124, 125, 128, 132], "dimension": [3, 4, 9, 10, 11, 12, 13, 14, 15, 18, 23, 40, 45, 63, 75, 87, 106, 116, 118, 132], "name": [3, 5, 9, 10, 11, 13, 14, 17, 21, 25, 32, 33, 45, 49, 59, 61, 62, 65, 72, 78, 83, 85, 87, 99, 105, 107, 115, 117, 120, 127, 129], "quantit": 3, "loci": 3, "qtl": 3, "involv": [3, 52, 78, 117], "parsimoni": 3, "reveal": 3, "necessari": [3, 4, 6, 80, 95, 96, 97, 98, 102, 103], "depend": [3, 5, 49, 59, 63, 67, 72, 74, 78, 79, 89, 90, 91, 99, 100, 101, 104, 106, 116, 117, 118, 132], "present": [3, 10, 63, 73, 93, 95, 96, 97, 98, 100, 102, 103, 104, 132], "toward": [3, 63, 94, 95, 99, 100, 101, 102, 106], "yer124c": 3, "daughter": 3, "particip": 3, "pathwai": 3, "wall": 3, "metabol": 3, "delet": [3, 11, 13, 14], "separ": [3, 15, 19, 21, 22, 28, 29, 62, 72, 99, 127], "divis": 3, "sensit": [3, 21, 45, 47, 75, 126], "against": [3, 63, 124], "consid": [4, 6, 9, 11, 12, 13, 14, 19, 26, 32, 33, 45, 58, 59, 60, 62, 63, 65, 66, 67, 69, 72, 73, 74, 75, 77, 79, 80, 83, 84, 86, 87, 88, 93, 94, 95, 97, 98, 100, 101, 102, 103, 106, 109, 114, 116, 121, 122, 126, 129, 132], "popul": [4, 6, 15, 33], "doe": [4, 6, 9, 11, 12, 13, 14, 79, 93, 95, 96, 118, 120, 122, 126, 127, 132], "y": [4, 6, 10, 12, 16, 17, 19, 20, 21, 25, 40, 47, 49, 58, 59, 61, 75, 77, 78, 79, 89, 90, 91, 94, 95, 98, 99, 100, 101, 102, 104, 106, 107, 116, 126, 128, 129, 132], "establish": [4, 6, 14, 40, 58, 63, 77], "respons": [4, 5, 6, 15, 22, 26, 28, 101, 102, 103, 104, 118], "advoc": [4, 6], "neyman": [4, 6], "rubin": [4, 6], "robin": [4, 6, 15, 17, 45, 75, 126], "denot": [4, 6, 9, 11, 13, 19, 20, 21, 22, 25, 27, 28, 32, 33, 38, 40, 49, 59, 62, 63, 65, 66, 67, 69, 72, 73, 74, 78, 79, 83, 86, 87, 89, 90, 91, 94, 99, 101, 106, 107, 116, 117, 123, 124, 132], "vector": [4, 6, 9, 11, 12, 13, 14, 20, 25, 74, 79, 80, 84, 87, 94, 95, 100, 101, 102, 106, 109, 114, 116, 117, 118, 132], "simplic": [4, 6, 22, 67, 97, 98, 100, 124, 132], "simplest": [4, 5, 6, 59], "case": [4, 6, 9, 11, 13, 14, 15, 19, 22, 24, 25, 28, 32, 40, 45, 47, 59, 75, 77, 85, 114, 116, 129, 132, 133], "binari": [4, 6, 21, 27, 45, 47, 52, 58, 60, 75, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 93, 94, 95, 96, 99, 101, 102, 103, 104, 107, 122, 123, 124, 126, 127, 128, 134], "0": [4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 38, 40, 45, 47, 49, 52, 58, 59, 60, 61, 62, 63, 65, 66, 67, 69, 72, 73, 74, 75, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 114, 115, 117, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132], "sai": [4, 6, 9, 11, 13, 14], "versu": [4, 6, 17, 21, 27, 32, 120, 123, 132], "acquir": [4, 6], "app": [4, 6], "download": [4, 6, 17, 23], "baselin": [4, 6, 11, 13, 14, 15, 22, 27, 67, 72, 79, 86, 87, 107, 128], "observ": [4, 5, 6, 9, 11, 13, 15, 17, 19, 20, 21, 22, 23, 25, 26, 32, 33, 38, 40, 47, 49, 58, 60, 62, 63, 65, 67, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 102, 105, 106, 107, 108, 115, 116, 117, 118, 121, 122, 126, 128, 132], "summar": [4, 6, 9, 10, 17, 19, 22, 26, 28, 29, 59, 69, 83, 118, 121, 122, 126, 128, 132], "z_i": [4, 6, 9, 11, 12, 13, 14, 20, 25], "x_i": [4, 15, 47, 49, 59], "t_i": [4, 33, 73, 74], "y_i": [4, 33, 47, 49, 59], "th": [4, 6, 15, 18, 23, 40, 63, 67, 68, 69, 73, 74, 87, 94, 121], "covari": [4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 25, 33, 86, 88, 97, 98, 100, 123, 124, 126], "prior": [4, 6, 11, 78, 79, 80, 84, 86, 87, 88, 95, 96, 97, 98, 100, 102, 103, 104, 107, 109, 114, 121, 128], "assum": [4, 6, 9, 10, 11, 13, 24, 25, 45, 47, 58, 67, 73, 74, 75, 77, 78, 79, 80, 81, 83, 84, 86, 87, 88, 93, 95, 96, 97, 98, 100, 101, 102, 103, 104, 106, 107, 109, 114, 116, 118, 126, 128, 132], "chosen": [4, 6, 16, 17, 18, 19, 20, 24, 26, 28, 29, 65, 74, 79, 90, 91, 94, 95, 99, 101, 102, 103, 104], "henc": [4, 6, 10, 15, 27, 47, 62, 67, 72, 79, 83, 87, 95, 102, 107, 117, 118, 128], "sometim": [4, 6, 117], "refer": [4, 5, 6, 130], "counterfactu": [4, 6, 33, 40, 74, 117, 132], "becaus": [4, 6, 127], "realiti": [4, 6], "hypothet": [4, 6], "contrari": [4, 6, 128], "fact": [4, 6, 62, 63, 65, 66, 72, 73, 79, 117], "actual": [4, 6, 15, 118], "than": [4, 6, 10, 15, 19, 22, 25, 26, 28, 29, 49, 62, 63, 67, 68, 72, 74, 79, 81, 83, 87, 107, 124, 128], "notion": [4, 6], "defin": [4, 5, 6, 10, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 32, 33, 38, 45, 49, 58, 59, 62, 63, 67, 68, 72, 73, 74, 75, 77, 82, 89, 90, 91, 94, 99, 106, 107, 108, 116, 122, 126, 132], "now": [4, 6, 22, 40, 59, 106, 117, 129], "deduc": [4, 6], "x": [4, 6, 15, 17, 18, 19, 21, 23, 24, 25, 40, 47, 49, 59, 61, 78, 80, 81, 86, 88, 89, 90, 91, 96, 97, 107, 109, 116, 120, 126, 128, 129], "sutva": [4, 6, 15, 32, 33, 74], "stabl": [4, 6, 15, 21, 120, 123], "unit": [4, 6, 15, 33, 38, 40, 132], "begin": [4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 32, 33, 40, 45, 47, 49, 58, 59, 62, 63, 65, 66, 67, 68, 69, 72, 73, 74, 75, 77, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91, 93, 94, 95, 97, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 115, 116, 117, 122, 126, 132, 133], "align": [4, 6, 15, 17, 21, 24, 25, 32, 33, 40, 45, 47, 58, 62, 63, 67, 69, 72, 73, 75, 77, 80, 81, 82, 84, 85, 104, 108, 109, 115, 117, 122, 126], "end": [4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 32, 33, 40, 45, 47, 49, 58, 59, 62, 63, 65, 66, 67, 68, 69, 72, 73, 74, 75, 77, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91, 93, 94, 95, 97, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 114, 115, 116, 117, 122, 126, 132], "That": [4, 6, 15, 19, 24, 25, 26, 33, 59], "regardless": [4, 6, 15], "interfer": [4, 6, 15, 32], "No": [4, 6, 9, 11, 13, 14, 15, 17, 21, 25, 33, 45, 49, 58, 59, 69, 86, 87, 88, 101, 121, 126, 127, 128, 129, 132], "unmeasur": [4, 6, 9, 11, 13, 14, 15, 21, 22, 26, 32, 74, 118], "confound": [4, 5, 6, 9, 11, 12, 13, 14, 15, 21, 22, 26, 32, 74, 118, 121, 122, 126, 132], "strong": [4, 6, 14, 15, 18, 23, 32, 67, 72, 126], "ignor": [4, 6, 15, 16, 17, 20, 24, 59, 67, 72, 89, 90, 91, 127, 128, 130], "perp": [4, 6, 15, 21, 74], "refut": [4, 6, 15], "believ": [4, 6, 15, 132], "relev": [4, 6, 15, 67], "reason": [4, 6, 9, 12, 14, 15, 19], "p": [4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 17, 19, 20, 21, 22, 25, 26, 28, 29, 32, 45, 47, 49, 61, 69, 72, 73, 74, 75, 79, 80, 81, 82, 85, 86, 88, 93, 95, 97, 98, 99, 100, 102, 103, 105, 107, 108, 109, 114, 115, 117, 121, 126, 127, 128, 129, 130, 132], "ensur": [4, 6, 9, 15, 74], "similar": [4, 5, 6, 10, 15, 21, 33, 47, 62, 63, 66, 67, 72, 74, 75, 78, 80, 81, 82, 84, 85, 86, 87, 88, 93, 94, 109, 117, 132], "vice": [4, 6, 15], "versa": [4, 6, 15], "text": [4, 5, 6, 10, 12, 15, 16, 17, 19, 21, 22, 25, 26, 28, 29, 32, 33, 40, 47, 58, 60, 62, 65, 66, 73, 77, 85, 86, 88, 95, 100, 102, 103, 117], "ATE": [4, 6, 12, 17, 19, 21, 26, 32, 38, 69, 121, 128], "There": [4, 5, 6, 19, 38, 40, 59, 60, 85, 117, 133], "deriv": [4, 6, 18, 21, 22, 23, 29, 32, 45, 49, 63, 68, 69, 77, 100, 121], "confoun": 4, "come": [4, 33, 97, 98, 132], "consider": 4, "e_x": 4, "quad": [4, 15, 18, 22, 23, 29, 45, 75, 86, 88, 89, 90, 91, 95, 100, 102], "similarli": [4, 10, 15, 33, 45, 62, 63, 72, 73, 74, 75, 86, 88, 99, 100, 106, 121, 123, 124], "mu": [4, 15, 16, 21, 22, 25, 26, 80, 84, 86, 87, 88, 89, 90, 91, 93, 95, 100, 102, 122], "gamma": [4, 15, 17, 20, 25, 32, 45, 62, 63, 65, 66, 67, 72, 73, 74, 75, 80, 81, 86, 88, 93, 95, 97, 100, 102, 103, 109, 117], "paramet": [4, 9, 10, 11, 15, 17, 18, 20, 23, 25, 49, 59, 80, 82, 85, 86, 88, 95, 100, 101, 102, 104, 107, 108, 109, 121, 126], "mle": 4, "least": [4, 15, 20, 22, 25, 79, 83, 87, 101, 106, 107, 126, 128], "squar": [4, 15, 20, 25, 126], "Then": [4, 9, 10, 11, 12, 13, 14, 15, 18, 23, 68, 69, 75, 77, 79, 83, 85, 87, 89, 90, 91, 95, 100, 102, 106, 107, 115, 116, 117, 128, 130], "hat": [4, 15, 16, 17, 18, 20, 22, 23, 24, 25, 26, 28, 29, 33, 40, 45, 58, 59, 62, 65, 67, 72, 73, 74, 75, 77, 81, 82, 86, 93, 97, 105, 117, 128], "sum_": [4, 15, 17, 18, 21, 23, 32, 33, 40, 45, 49, 58, 59, 62, 63, 65, 66, 67, 68, 69, 72, 73, 74, 75, 79, 83, 85, 87, 89, 90, 91, 93, 94, 95, 99, 100, 101, 102, 103, 104, 105, 107, 115, 117], "anoth": [4, 5, 9, 10, 17, 19, 40, 59, 67, 68, 72, 117, 122, 126, 128], "pi": [4, 15, 16, 20, 25, 32, 47, 58, 59, 62, 63, 65, 66, 67, 68, 69, 72, 73, 74, 77, 89, 90, 91, 117], "get": [4, 15, 16, 17, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 33, 38, 45, 58, 60, 61, 75, 77, 80, 81, 82, 83, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 116, 122, 126, 127, 128, 129], "function": [4, 5, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 45, 47, 49, 58, 59, 62, 63, 65, 66, 67, 72, 74, 75, 79, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91, 93, 95, 96, 97, 98, 100, 101, 102, 103, 104, 106, 107, 108, 116, 117, 128, 132], "One": [4, 15, 62, 72, 117, 126, 127, 130], "difficult": [4, 15, 82], "build": [4, 5, 69, 72, 79, 121, 126, 130, 132], "simpli": [4, 59, 87, 97], "stratifi": 4, "choos": [4, 10, 16, 17, 18, 20, 24, 26, 27, 28, 29, 62, 63, 72, 78, 79, 83, 85, 87, 89, 90, 91, 95, 99, 100, 101, 102, 106, 107, 115, 116, 128, 133], "cutoff": 4, "c_0": 4, "c_1": 4, "c_k": 4, "belong": [4, 27, 40, 65, 132, 133], "k": [4, 5, 9, 10, 11, 12, 13, 14, 20, 25, 40, 49, 59, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 114, 115, 116, 117, 127, 128, 129], "c_": [4, 45, 75, 82, 85, 108, 115], "le": [4, 5, 49, 62, 63, 65, 66, 73, 74, 94], "bar": [4, 18, 23, 32, 67, 74, 76, 77, 117], "_": [4, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 28, 29, 32, 40, 45, 47, 49, 58, 59, 60, 62, 63, 65, 66, 67, 68, 72, 73, 74, 75, 76, 77, 80, 84, 86, 87, 88, 89, 90, 91, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 106, 107, 109, 114, 115, 116, 117, 120, 123, 124, 132], "1k": 4, "0k": 4, "n_k": 4, "theoret": [4, 19, 63, 74, 88, 101, 116], "justif": 4, "semiparametr": [4, 16, 19, 20, 21, 24, 25, 62, 63, 72, 126], "theori": [4, 17, 19, 20, 21, 25, 45, 47, 63, 75, 79, 101, 102, 104, 106, 126], "augment": [4, 15, 47, 63], "ipw": [4, 15, 59, 69, 126], "probabl": [4, 15, 21, 47, 49, 59, 62, 63, 67, 72, 73, 82, 83, 88, 101, 106, 107, 108, 126], "everi": [4, 15, 62, 67, 72, 79, 83, 86, 87, 88, 93, 95, 100, 102, 103, 107, 117, 128], "themselv": [4, 15], "did": [4, 15, 33, 38, 40, 75, 77, 132], "frac": [4, 15, 16, 17, 18, 20, 21, 23, 25, 33, 45, 47, 49, 58, 59, 62, 63, 67, 69, 72, 75, 82, 85, 101, 102, 103, 104, 105, 107, 108, 115], "ty": 4, "unbias": [4, 15, 67], "left": [4, 15, 18, 20, 23, 24, 25, 49, 59, 62, 72, 75, 89, 90, 91, 128, 129, 132], "right": [4, 9, 12, 15, 18, 20, 23, 24, 25, 49, 59, 62, 65, 66, 72, 75, 89, 90, 91, 117, 132], "t_iy_i": 4, "combin": [4, 15, 20, 21, 22, 25, 28, 29, 59, 62, 63, 72, 85, 87, 117, 128], "obtain": [4, 9, 11, 13, 15, 17, 18, 20, 21, 22, 23, 24, 25, 28, 29, 32, 59, 63, 67, 77, 98, 99, 117, 128, 132], "whether": [5, 33, 90, 91, 102, 103, 104, 123, 124, 127], "write": [5, 15, 18, 23], "content": [5, 20, 25, 32, 132, 133], "jupyt": [5, 130], "notebook": [5, 121, 122, 126], "ipynb": [5, 9, 14, 133], "regular": [5, 10, 49, 72, 86], "md": 5, "ll": [5, 27, 128], "flavor": 5, "stand": [5, 45, 75, 101], "markedli": 5, "slight": 5, "variat": [5, 9, 33], "commonmark": 5, "small": [5, 47, 123, 124], "syntax": 5, "sphinx": 5, "ecosystem": 5, "power": [5, 20, 25, 130], "tool": [5, 15], "kind": [5, 32, 68], "markup": 5, "languag": [5, 78], "serv": [5, 15, 17, 27, 74, 128], "purpos": [5, 15, 27, 33, 38, 123, 124, 125], "wherea": [5, 69, 74, 121], "span": 5, "being": [5, 82, 85, 87, 88, 94, 95, 100, 101, 102, 104, 106, 108, 115, 123, 124, 125, 128], "At": [5, 73, 75, 77, 79, 80, 82, 84, 85, 94, 95, 97, 100, 102, 107, 108, 109, 114, 115, 122], "insert": [5, 128], "mydirectivenam": 5, "my": [5, 19], "work": [5, 9, 13, 17, 21, 32, 45, 59, 63, 69, 75, 77], "alreadi": [5, 18, 23, 133], "doesn": [5, 32, 132], "pre": [5, 11, 21, 33, 40, 74, 82, 106, 107, 108], "note": [5, 10, 11, 13, 14, 17, 19, 22, 29, 32, 38, 40, 45, 47, 58, 59, 60, 73, 74, 75, 77, 80, 82, 84, 85, 86, 87, 88, 93, 95, 96, 97, 98, 100, 101, 102, 103, 106, 109, 114, 116, 118, 126], "box": 5, "here": [5, 9, 10, 11, 12, 13, 14, 17, 18, 19, 23, 45, 47, 49, 63, 73, 75, 77, 80, 81, 82, 84, 85, 86, 87, 88, 90, 91, 93, 95, 96, 97, 98, 100, 102, 103, 104, 106, 107, 108, 114, 116, 121, 122, 126, 128], "built": [5, 47, 72], "see": [5, 9, 10, 11, 13, 14, 20, 21, 22, 25, 26, 40, 63, 72, 79, 83, 88, 106, 107, 120, 123, 124, 132, 133], "document": [5, 10, 16, 17, 21, 27, 59, 120, 123, 130, 133], "less": [5, 19, 45, 49, 75, 117], "pattern": [5, 122, 126], "some": [5, 15, 16, 19, 21, 22, 25, 28, 32, 33, 38, 45, 49, 59, 62, 63, 72, 74, 75, 88, 89, 90, 91, 95, 106, 116, 123, 124, 132], "rolenam": 5, "again": [5, 77, 122, 126], "valid": [5, 63, 68, 74, 117], "doc": [5, 21, 120, 123], "page": [5, 16, 19, 20, 24, 25, 67, 78, 99, 106, 107, 116, 118, 130], "rel": [5, 22, 28, 67, 72, 87, 132], "path": [5, 10, 21, 69], "intro": 5, "cite": [5, 72], "store": [5, 90], "bibtex": 5, "holdgraf_evidence_2014": 5, "render": 5, "moreov": [5, 15, 19, 32, 62, 63, 72], "bibliographi": 5, "properli": [5, 9], "bib": 5, "look": [5, 19, 23, 33, 63], "egw05": [5, 66], "damien": [5, 66], "ernst": [5, 66], "pierr": [5, 66], "geurt": [5, 66], "loui": [5, 66], "wehenkel": [5, 66], "tree": [5, 18, 19, 23, 38, 59, 66, 126], "batch": [5, 65, 66, 95, 100, 102, 117], "mode": [5, 10, 66, 95, 100, 102, 127], "learn": [5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 25, 26, 28, 29, 32, 38, 40, 48, 52, 59, 63, 65, 66, 67, 68, 72, 73, 74, 78, 79, 80, 82, 83, 85, 86, 87, 88, 89, 90, 91, 93, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 114, 115, 116, 121, 122, 126, 129, 131, 133, 134], "journal": [5, 9, 10, 11, 12, 13, 14, 16, 19, 20, 21, 24, 25, 33, 36, 37, 40, 45, 47, 59, 66, 74, 75, 79, 89, 90, 91, 101, 118, 122, 129], "hzal18": [5, 117], "tuoma": [5, 117], "haarnoja": [5, 117], "aurick": [5, 117], "zhou": [5, 49, 59, 62, 67, 78, 104, 107, 117], "pieter": [5, 117], "abbeel": [5, 117], "sergei": [5, 117], "levin": [5, 117], "soft": [5, 117], "actor": 5, "off": [5, 49, 62, 65, 67, 68, 69, 72, 83, 89, 90, 91, 96, 107, 117, 118, 133], "maximum": [5, 59, 75, 77, 81, 82, 85, 86, 99, 106, 108, 115, 116, 117], "entropi": [5, 15, 117], "deep": [5, 17, 19, 45, 59, 69, 75, 117, 118, 121, 132, 134], "stochast": [5, 62, 72, 73, 74, 78, 79, 83, 87, 89, 90, 91, 106, 107, 116, 117], "intern": [5, 9, 10, 11, 12, 13, 14, 16, 19, 20, 25, 49, 62, 63, 67, 68, 72, 78, 79, 80, 81, 87, 88, 93, 94, 96, 97, 98, 99, 104, 106, 107, 109, 116, 117, 118, 130], "confer": [5, 9, 10, 11, 12, 13, 14, 17, 19, 49, 62, 63, 67, 68, 72, 78, 79, 80, 81, 87, 88, 93, 94, 96, 97, 98, 99, 101, 102, 104, 106, 107, 109, 116, 117, 118], "1861": [5, 10, 117], "1870": [5, 117], "pmlr": [5, 19, 49, 62, 63, 67, 68, 72, 78, 79, 80, 87, 88, 93, 94, 96, 97, 98, 99, 101, 102, 104, 106, 107, 109, 116, 117], "2018": [5, 9, 10, 11, 12, 14, 15, 17, 45, 47, 49, 59, 67, 72, 73, 74, 75, 78, 82, 99, 101, 103, 107, 108, 114, 115, 117], "hk20": [5, 118], "yichun": [5, 10, 21, 118], "hu": [5, 118], "nathan": [5, 62, 118], "kallu": [5, 49, 62, 118], "dtr": [5, 77, 118, 132], "adapt": [5, 17, 18, 19, 20, 23, 25, 47, 49, 58, 74, 77, 78, 82, 95, 96, 98, 100, 102, 103, 105, 107, 108, 117, 118], "regret": [5, 45, 73, 74, 75, 78, 83, 86, 87, 88, 95, 97, 100, 102, 107, 118], "02791": [5, 118], "jl16": [5, 62, 67], "nan": [5, 10, 21, 62, 65, 67, 126], "jiang": [5, 62, 65, 67, 72, 78, 107], "lihong": [5, 62, 67], "li": [5, 15, 33, 40, 49, 62, 67, 72, 79, 80, 81, 89, 90, 91, 93, 101, 103, 104, 107, 109, 117, 118], "doubli": [5, 6, 16, 19, 20, 25, 45, 49, 59, 63, 67, 72, 75, 89, 91], "robust": [5, 16, 19, 20, 25, 32, 45, 49, 59, 63, 67, 69, 72, 75, 86, 89, 91, 94, 95, 99, 100, 101, 102, 106, 121, 126, 134], "652": [5, 62, 67, 72], "661": [5, 62, 67, 72, 79, 107], "ku19": [5, 62], "masatoshi": [5, 62], "uehara": [5, 62], "effici": [5, 15, 16, 19, 21, 22, 25, 29, 62, 63, 68, 70, 72, 81, 86, 87, 88, 93, 95, 97, 98, 99, 100, 101, 102, 104, 108, 109, 114, 115, 117, 126, 128], "break": [5, 62, 72], "curs": [5, 18, 23, 62, 63, 72], "horizon": [5, 32, 63, 69, 73, 74, 97, 98, 100, 117, 118, 132, 134], "doubl": [5, 15, 17, 20, 25, 32, 72, 90, 117], "1909": [5, 62], "05850": [5, 62], "lvy19": [5, 65], "hoang": [5, 62, 65], "cameron": [5, 62, 65], "voloshin": [5, 62, 65], "yisong": [5, 62, 65], "yue": [5, 9, 10, 11, 12, 13, 14, 59, 62, 65], "1903": [5, 65], "08738": [5, 65], "lltz18": [5, 67], "qiang": [5, 62, 67], "liu": [5, 47, 62, 67, 72], "ziyang": [5, 62, 67], "tang": [5, 62, 67, 72], "dengyong": [5, 62, 67], "infinit": [5, 32, 63, 69, 73, 74, 79, 117, 118, 132, 134], "advanc": [5, 9, 10, 11, 12, 13, 14, 19, 22, 49, 67, 72, 86, 87, 88, 98, 101, 102, 103, 133], "neural": [5, 9, 10, 11, 12, 13, 14, 17, 19, 49, 67, 72, 78, 86, 87, 88, 98, 101, 102, 103, 107], "process": [5, 9, 10, 11, 12, 13, 14, 17, 19, 38, 49, 62, 67, 72, 78, 86, 87, 88, 97, 98, 100, 101, 102, 103, 106, 107, 117, 118, 121, 132], "5356": [5, 67], "5366": [5, 67], "mgkulic21": [5, 118], "lingheng": [5, 118], "meng": [5, 118], "rob": [5, 118], "gorbet": [5, 118], "dana": [5, 118], "kuli": [5, 118], "\u0107": [5, 118], "memori": [5, 118, 128], "pomdp": [5, 32, 118, 132], "2021": [5, 9, 13, 16, 18, 19, 20, 24, 25, 33, 36, 49, 63, 68, 86, 87, 88, 89, 90, 91, 118], "ieee": [5, 118], "rsj": [5, 118], "robot": [5, 118], "iro": [5, 118], "5619": [5, 118], "5626": [5, 22, 118], "mbm": [5, 117], "16": [5, 10, 18, 21, 49, 59, 61, 117, 120, 123, 124, 126, 128, 129], "volodymyr": [5, 117], "mnih": [5, 117], "adria": [5, 117], "puigdomenech": [5, 117], "badia": [5, 117], "mehdi": [5, 117], "mirza": [5, 117], "alex": [5, 117], "grave": [5, 117], "timothi": [5, 117], "lillicrap": [5, 117], "tim": [5, 117], "harlei": [5, 117], "david": [5, 9, 10, 11, 12, 13, 14, 17, 19, 117], "silver": [5, 117], "korai": [5, 117], "kavukcuoglu": [5, 117], "asynchron": [5, 117], "1928": [5, 117], "1937": [5, 117], "mk": [5, 117], "15": [5, 10, 18, 21, 23, 27, 40, 58, 59, 61, 117, 123, 127, 128, 129], "andrei": [5, 117], "rusu": [5, 117], "joel": [5, 117], "veness": [5, 117], "marc": [5, 117], "g": [5, 9, 10, 11, 12, 13, 14, 17, 22, 27, 29, 45, 59, 62, 63, 65, 67, 69, 72, 73, 74, 78, 82, 86, 88, 95, 100, 101, 102, 103, 107, 108, 117, 118, 126, 132], "bellemar": [5, 117], "martin": [5, 74, 117], "riedmil": [5, 117], "andrea": [5, 117], "fidjeland": [5, 117], "georg": [5, 117], "ostrovski": [5, 117], "human": [5, 117], "518": [5, 117], "7540": [5, 117], "529": [5, 117], "533": [5, 89, 90, 91, 117], "pre00": [5, 67], "doina": [5, 67], "precup": [5, 67, 72], "elig": [5, 67, 72, 117], "trace": [5, 67, 72, 117], "comput": [5, 9, 13, 19, 67, 72, 79, 86, 95, 101, 102, 103, 104, 117], "scienc": [5, 9, 10, 11, 12, 13, 14, 15, 19, 22, 26, 28, 29, 45, 67, 72, 75, 95, 102, 129, 132], "depart": [5, 67, 72], "faculti": [5, 67, 72], "public": [5, 23, 67, 72], "80": [5, 45, 59, 61, 67, 72, 75], "2000": [5, 9, 10, 11, 12, 13, 14, 40, 58, 67, 72, 77, 108, 109, 114, 115], "put14": [5, 74], "l": [5, 24, 25, 49, 59, 62, 69, 72, 73, 74, 78, 79, 80, 81, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 109, 121], "puterman": [5, 73, 74], "markov": [5, 9, 11, 13, 14, 67, 94, 117, 118, 132], "dynam": [5, 9, 15, 45, 47, 49, 58, 73, 74, 75, 77, 102, 104, 105, 106, 116, 117, 118, 121, 129, 132], "program": [5, 40, 73, 74, 95, 101, 102, 104], "wilei": [5, 73, 74], "son": [5, 73, 74], "2014": [5, 9, 10, 11, 12, 13, 14, 45, 59, 73, 74, 75, 129], "sla": [5, 117], "schulman": [5, 117], "michael": [5, 33, 117], "jordan": [5, 117], "philipp": [5, 117], "moritz": [5, 117], "trust": [5, 117], "region": [5, 117], "1889": [5, 117], "1897": [5, 117], "swd": [5, 117], "17": [5, 10, 21, 49, 59, 61, 117, 120, 123, 126, 127, 128], "filip": [5, 117], "wolski": [5, 117], "prafulla": [5, 117], "dhariw": [5, 117], "alec": [5, 117], "radford": [5, 117], "oleg": [5, 117], "klimov": [5, 117], "proxim": [5, 69, 117], "algorithm": [5, 9, 10, 12, 19, 20, 22, 25, 26, 28, 29, 47, 62, 66, 73, 74, 79, 80, 83, 86, 87, 88, 89, 90, 91, 93, 96, 97, 98, 103, 104, 117, 122, 126, 128, 132, 133, 134], "1707": [5, 84, 106, 107, 116, 117], "06347": [5, 117], "2017": [5, 9, 10, 11, 12, 13, 14, 16, 19, 20, 23, 25, 37, 78, 84, 101, 102, 104, 106, 107, 116, 117, 118, 122], "swcs21": [5, 63], "chengchun": [5, 63, 117, 118], "shi": [5, 17, 19, 45, 49, 59, 63, 68, 69, 74, 75, 117, 118, 121], "runzh": [5, 63, 131], "wan": [5, 63, 68, 86, 87, 94, 95, 99, 100, 101, 102, 106, 131], "victor": [5, 17, 19, 63], "chernozhukov": [5, 15, 17, 63, 68], "rui": [5, 9, 10, 11, 12, 13, 14, 47, 59, 63, 117, 118, 131, 133], "song": [5, 9, 10, 11, 12, 13, 14, 45, 47, 49, 58, 59, 63, 69, 75, 77, 86, 87, 89, 90, 91, 94, 95, 99, 100, 101, 102, 106, 117, 118, 121, 131, 133], "deepli": [5, 68], "debias": [5, 15, 17, 68], "interv": [5, 18, 23, 49, 59, 63, 73, 74, 89, 90, 91, 117, 118], "9580": [5, 63, 68], "9591": [5, 63, 68], "swl": [5, 74], "20": [5, 9, 10, 14, 18, 21, 23, 33, 45, 49, 58, 59, 61, 74, 100, 102, 103, 120, 123, 128, 129], "shi2020reinforc": [5, 74], "szls20": [5, 117], "sheng": [5, 117], "zhang": [5, 15, 78, 104, 107, 117], "wenbin": [5, 9, 10, 11, 12, 13, 14, 117], "lu": [5, 9, 10, 11, 12, 13, 14, 45, 49, 75, 89, 90, 91, 107, 117], "2001": [5, 27, 117, 123, 124, 125], "04515": [5, 117], "szy": [5, 118], "22": [5, 10, 21, 23, 45, 58, 61, 117, 118], "jin": [5, 101, 103, 118], "zhu": [5, 9, 10, 11, 12, 13, 14, 49, 101, 103, 118], "shen": [5, 78, 89, 90, 91, 107, 118], "ye": [5, 9, 118, 132], "shikai": [5, 118, 131], "luo": [5, 59, 118, 131], "hongtu": [5, 118], "confid": [5, 16, 19, 20, 25, 81, 83, 85, 89, 90, 91, 105, 115, 117, 118], "american": [5, 21, 36, 40, 47, 59, 89, 90, 91, 118, 126], "2022": [5, 21, 23, 59, 87, 94, 95, 99, 100, 101, 102, 106, 118], "ss96": [5, 117], "satind": [5, 117], "singh": [5, 117], "richard": [5, 9, 10, 11, 12, 13, 14, 74, 117], "sutton": [5, 73, 74, 82, 107, 108, 117], "replac": [5, 10, 12, 45, 49, 59, 63, 67, 72, 117, 128], "123": [5, 40, 117, 120, 122, 123, 124, 126], "158": [5, 21, 75, 77, 117], "1996": [5, 117], "spa12": [5, 118], "matthij": [5, 118], "tj": [5, 75, 118], "spaan": [5, 118], "partial": [5, 10, 12, 24, 25, 27, 32, 45, 75, 97, 98, 100, 118, 123, 124, 125, 132], "state": [5, 6, 11, 13, 14, 19, 21, 22, 27, 28, 32, 33, 40, 59, 62, 63, 65, 66, 67, 69, 72, 73, 74, 117, 118, 120, 121, 122, 126, 128, 131], "art": [5, 11, 13, 14, 19, 59, 62, 72, 118, 132], "387": [5, 21, 118], "414": [5, 118], "2012": [5, 21, 27, 47, 78, 101, 116, 118, 123, 124, 125, 126], "sut88": [5, 117], "tempor": [5, 9, 10, 67, 72, 117], "9": [5, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 21, 23, 24, 26, 27, 28, 29, 33, 40, 45, 58, 59, 61, 69, 72, 75, 107, 109, 114, 117, 120, 121, 122, 123, 126, 127, 128, 129], "44": [5, 18, 59, 61, 117, 123], "1988": [5, 16, 19, 20, 24, 25, 40, 95, 117], "sb18": [5, 74, 117], "andrew": [5, 33, 74, 117], "barto": [5, 73, 74, 82, 107, 108, 117], "mit": [5, 73, 74, 82, 107, 108, 117], "press": [5, 73, 74, 82, 84, 107, 108, 117], "tfl": [5, 62], "yihao": [5, 62], "feng": [5, 62], "bia": [5, 15, 21, 22, 23, 25, 32, 47, 49, 59, 62, 63, 65, 67, 72, 118, 123, 124, 132], "reduct": [5, 62, 118], "represent": [5, 9, 10, 11, 12, 13, 14, 47, 62], "tb16": [5, 62], "philip": [5, 62, 67], "thoma": [5, 62, 67, 72], "emma": [5, 62], "brunskil": [5, 62], "2139": [5, 62], "2148": [5, 62], "tho15": [5, 67], "safe": [5, 67, 72], "doctor": [5, 12, 32, 67, 127], "dissert": [5, 67], "univers": [5, 67, 84, 107, 131], "massachusett": [5, 67], "amherst": [5, 67], "uhj19": [5, 62], "jiawei": [5, 62], "huang": [5, 62], "minimax": [5, 62, 63], "weight": [5, 9, 10, 11, 12, 13, 14, 15, 17, 18, 20, 21, 22, 23, 25, 29, 40, 62, 63, 67, 72, 99, 106, 116, 126, 132], "1910": [5, 62], "12809": [5, 62], "vhgs16": [5, 117], "hado": [5, 117], "van": [5, 16, 19, 20, 25, 37, 84, 100, 106, 107, 114, 115, 116, 117, 122], "hasselt": [5, 117], "arthur": [5, 117], "guez": [5, 117], "proceed": [5, 19, 21, 22, 26, 28, 29, 45, 49, 75, 79, 81, 107, 117, 126], "aaai": [5, 117], "artifici": [5, 19, 49, 78, 79, 80, 81, 87, 93, 94, 96, 107, 109, 117], "volum": [5, 117], "30": [5, 10, 21, 27, 40, 61, 117], "vljy19": [5, 62, 65], "empir": [5, 62, 65, 67, 74, 79, 83, 107], "1911": [5, 62, 65], "06854": [5, 62, 65], "zlpm17": [5, 118], "pengfei": [5, 118], "xin": [5, 118], "pascal": [5, 118], "poupart": [5, 118], "guanghui": [5, 118], "miao": [5, 118], "On": [5, 33, 47, 49, 118, 128], "1704": [5, 118], "07978": [5, 118], "If": [5, 10, 15, 58, 75, 77, 86, 87, 93, 97, 100, 106, 116, 126, 130, 133], "insid": 5, "jupytext": 5, "metadata": [5, 23, 86, 87], "run": [5, 10, 14, 117], "command": [5, 130], "init": 5, "print": [5, 10, 11, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 40, 45, 58, 61, 75, 77, 122, 123, 124, 126, 128, 129], "default": [5, 9, 10, 11, 58, 59, 86, 88, 93, 117, 127, 129, 130], "kernel": [5, 18, 19, 20, 23, 25, 32, 47, 49, 62, 72, 73, 74, 117, 134], "output": [5, 11, 17, 49, 128], "rest": [5, 6, 10, 12, 17, 38, 40, 79, 87, 89, 90, 91, 123, 124, 128], "nb": 5, "r": [6, 10, 12, 15, 16, 17, 18, 19, 21, 22, 23, 26, 28, 29, 32, 33, 38, 45, 49, 58, 59, 60, 62, 67, 68, 69, 72, 73, 74, 75, 76, 77, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 114, 115, 116, 117, 120, 121, 122, 123, 126, 128, 129, 132], "s_i": [6, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 29, 33, 38, 132], "a_i": [6, 15, 17, 18, 19, 20, 21, 23, 24, 25, 47, 49, 59, 60, 89, 90, 91, 132], "r_i": [6, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 29, 45, 60, 75, 76, 89, 90, 91, 132], "equival": [6, 9, 10, 11, 12, 13, 14, 47, 63, 78, 83, 107], "pearl": [6, 9, 10, 11, 12, 13, 14, 21], "spirt": [6, 9, 10, 11, 12, 13, 14], "mathemat": [6, 10, 12, 45, 75, 99, 106, 116, 129], "physic": [6, 10, 12, 21, 132], "hold": [6, 10, 12, 21, 32, 67, 72, 73, 74], "constant": [6, 10, 12, 22, 28, 47], "unchang": [6, 10, 12], "regress": [6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 22, 24, 25, 28, 29, 40, 45, 58, 59, 65, 67, 72, 75, 77, 95, 122, 126], "propens": [6, 12, 15, 16, 17, 20, 21, 22, 24, 25, 29, 33, 45, 49, 59, 67, 72, 75], "score": [6, 9, 12, 15, 16, 17, 20, 21, 22, 24, 25, 27, 29, 33, 45, 49, 59, 67, 72, 75, 123, 124, 125, 126, 128, 132], "roust": 6, "introduc": [6, 15, 17, 18, 19, 20, 21, 22, 23, 25, 26, 29, 33, 38, 45, 62, 63, 67, 68, 69, 72, 73, 74, 75, 77, 78, 79, 85, 86, 88, 89, 90, 91, 94, 101, 104, 107, 115, 117, 118, 132, 133], "cel": [6, 15, 16, 17, 18, 20, 21, 24, 26, 28, 29, 32, 33, 69, 128, 131, 133], "detail": [6, 10, 12, 15, 16, 17, 19, 20, 22, 25, 29, 32, 38, 40, 60, 63, 83, 107, 126, 130, 132], "hte": [6, 15, 16, 17, 18, 20, 22, 23, 24, 25, 26, 28, 29, 32, 38, 123, 124, 128], "captur": [6, 9, 17, 18, 22, 23, 49, 69, 90, 91], "heterogenieti": 6, "quit": [6, 17, 19, 22, 67, 72, 132], "few": [6, 19, 62, 72, 74, 79, 83, 87, 99, 107, 132], "deal": [6, 32, 40, 95, 96, 100, 102, 105, 132], "reli": [9, 12, 13, 62, 72], "locat": [9, 12], "reward": [9, 12, 15, 19, 21, 22, 23, 25, 27, 32, 40, 47, 58, 59, 60, 67, 69, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 114, 115, 116, 117, 120, 121, 122, 126, 127, 128, 129, 132, 134], "conveni": [9, 12], "violat": [9, 12, 32, 63], "emerg": [9, 12], "basic": [9, 15, 16, 22, 25, 26, 40, 45, 97, 98, 100, 132], "wai": [9, 22, 24, 25, 29, 59, 68, 69, 70, 72, 77, 108, 109, 114, 115, 117, 133], "mathcal": [9, 10, 11, 12, 13, 14, 21, 32, 33, 45, 49, 62, 63, 67, 72, 73, 74, 75, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 114, 115, 116, 117, 128, 132], "mathbf": [9, 10, 11, 12, 13, 14], "z": [9, 10, 11, 12, 13, 14, 16, 17, 19, 25, 69, 72, 84, 93, 94, 96, 97, 99, 106, 107, 114, 115, 116, 121], "node": [9, 11, 12, 13, 14, 132], "edg": [9, 10, 11, 12, 13, 14], "said": [9, 11, 12, 13, 14], "parent": [9, 11, 12, 13, 14, 130], "z_j": [9, 11, 12, 13, 14], "let": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 28, 29, 49, 58, 62, 63, 67, 69, 72, 73, 74, 76, 79, 83, 87, 94, 99, 101, 106, 107, 116, 117], "pa_": [9, 11, 12, 13, 14], "cycl": [9, 11, 12, 13, 14], "acycl": [9, 10, 11, 12, 13, 14], "dag": [9, 10, 11, 12, 13, 14, 123, 124], "character": [9, 10, 11, 12, 13, 14, 66, 73, 90, 91, 93, 95, 101, 106, 116], "z_1": [9, 11, 12, 13, 14], "z_2": [9, 11, 12, 13, 14], "z_d": [9, 11, 12, 13, 14], "rightarrow": [9, 11, 12, 13, 14, 20, 21, 25, 32], "mean": [9, 11, 12, 13, 14, 19, 32, 49, 59, 61, 62, 67, 72, 74, 75, 77, 80, 82, 84, 85, 86, 88, 89, 90, 91, 95, 97, 98, 99, 100, 102, 103, 107, 108, 109, 114, 115, 117, 120, 123, 128, 134], "propos": [9, 10, 13, 14, 17, 21, 32, 47, 49, 59, 62, 63, 67, 68, 69, 72, 75, 89, 90, 91, 93, 121, 122, 126, 132], "plusibl": 9, "up": [9, 13, 18, 20, 23, 25, 74, 78, 86, 88, 117, 132], "markovian": 9, "unless": [9, 10, 14], "certain": [9, 17, 59, 74, 118], "assumpt": [9, 11, 13, 14, 16, 17, 19, 21, 22, 25, 26, 32, 40, 47, 63, 67, 69, 72, 74, 78, 79, 90, 94, 95, 100, 102, 117, 118, 132], "specifi": [9, 10, 11, 15, 18, 23, 24, 25, 45, 47, 58, 60, 63, 74, 75, 77, 90, 107, 108, 109, 114, 122, 126, 127], "type": [9, 10, 15, 32, 38, 60, 62, 63, 65, 66, 67, 68, 72, 79, 83, 84, 87, 89, 90, 101, 102, 103, 104, 105, 107, 126, 127, 130, 132, 134], "focus": [9, 19, 32, 59, 67, 83, 94, 106, 107, 116, 117, 131, 132], "local": [9, 10, 14, 18, 19, 20, 22, 23, 25, 120, 123, 127, 129, 130], "independ": [9, 10, 11, 12, 13, 14, 15, 20, 21, 25, 32, 59, 60, 74, 97, 117], "skeleton": [9, 132], "orient": [9, 10, 14], "pc": [9, 10, 11, 12, 13, 132], "et": [9, 11, 12, 14, 15, 16, 21, 25, 36, 47, 59, 62, 63, 67, 68, 72, 74, 82, 85, 89, 90, 91, 93, 97, 107, 108, 115, 117], "al": [9, 11, 12, 14, 15, 16, 21, 25, 36, 47, 59, 62, 63, 67, 68, 72, 74, 82, 85, 89, 90, 91, 93, 97, 107, 108, 115, 117], "kalisch": [9, 10, 11, 12, 13, 14], "b\u00fchlmann": [9, 10, 11, 12, 13, 14], "easi": [9, 14, 19, 22, 24, 25, 26, 58, 65, 67, 77, 82, 101], "shah": [9, 10, 11, 12, 13, 14], "peter": [9, 10, 11, 12, 13, 14, 16, 19, 20, 24, 25], "second": [9, 15, 21, 22, 28, 45, 49, 63, 75, 93, 95, 96, 117, 128, 132], "ica": [9, 13, 14], "lingam": [9, 13, 14, 132], "shimizu": [9, 10, 11, 12, 13, 14], "2006": [9, 10, 11, 12, 13, 14, 16, 19, 20, 25, 96], "cam": [9, 10, 11, 12, 13, 14], "greedi": [9, 10, 11, 12, 13, 14, 83, 89, 90, 91, 108, 117, 129, 134], "search": [9, 10, 11, 12, 13, 14, 94, 117], "ge": [9, 32, 62, 63, 67, 69, 72, 73, 74, 86, 87, 94, 95, 99, 100, 101, 102, 106, 117, 121, 131, 133], "chicker": [9, 10, 11, 12, 13, 14], "2002": [9, 10, 11, 12, 13, 14, 79, 82, 85, 107, 108, 115], "fge": 9, "ramsei": [9, 10, 11, 12, 13, 14], "bayesian": [9, 10, 11, 12, 13, 14, 86, 87, 95, 96, 98, 100, 102], "zheng": [9, 10, 11, 12, 14, 37, 122], "open": [9, 10, 27, 69, 120, 121, 122, 123, 124, 125, 127, 133], "construct": [9, 10, 11, 12, 13, 14, 16, 20, 21, 22, 25, 26, 33, 62, 63, 65, 67, 68, 69, 72, 86, 117], "notear": [9, 11, 14, 123, 124, 132], "vae": [9, 13], "parameter": [9, 13, 86, 88, 95, 100, 102, 117], "network": [9, 10, 11, 12, 13, 14, 17, 19, 49, 59], "yu": [9, 10, 11, 12, 13, 14, 19, 22, 26, 28, 29, 47, 59], "friendli": [9, 13], "gnn": [9, 10, 11, 12, 13, 14], "chen": [9, 10, 11, 12, 13, 14, 89, 90, 91, 98, 99, 106, 116], "cai": [9, 11, 12, 13, 14, 49, 89, 90, 91, 131, 133], "cut": [9, 13], "support": [9, 20, 25, 69, 74, 79, 84, 85, 88, 117, 127, 132], "train": [9, 10, 16, 17, 18, 19, 20, 23, 24, 25, 45, 47, 58, 61, 75, 77, 80, 81, 93, 122, 126, 128, 129, 132], "free": [9, 65, 131, 132], "gaussian": [9, 10, 12, 13, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 97, 98, 100, 109, 114, 129, 132, 134], "o": [9, 10, 11, 12, 13, 14, 15, 17, 132], "max": [9, 49, 58, 59, 62, 72, 77, 127, 128, 132], "adjac": [9, 10, 11, 13, 14, 132], "b_": [9, 11, 13, 14], "leq": [9, 11, 13, 14, 32, 33, 40, 89, 90, 91, 99, 101, 132], "matrix": [9, 10, 11, 13, 14, 21, 40, 69, 80, 84, 86, 95, 97, 98, 100, 102, 103, 106, 121, 123, 124, 126], "otherwis": [9, 11, 13, 14, 58, 60, 77, 82, 88, 94, 108, 130], "nest": [9, 11, 13, 14, 45, 75, 127], "faith": [9, 11, 13, 14], "suffici": [9, 11, 13, 14, 17, 62, 67], "pair": [9, 11, 13, 14, 62, 63, 67, 72, 74, 80, 84, 95, 96, 98, 102, 103, 104, 109, 114], "epsilon": [9, 11, 13, 14, 17, 24, 25, 83, 89, 90, 91, 108, 117, 134], "label": [9, 10, 11, 13, 14, 40, 47, 49, 62, 63, 65, 67, 68, 72, 73, 74, 86, 89, 90, 91, 94, 95, 100, 101, 102, 106, 116, 117, 126], "lsem_x": [9, 11, 13, 14], "jointli": [9, 11, 13, 14, 45, 75], "error": [9, 10, 11, 13, 14, 19, 45, 58, 75, 77, 122, 126, 127], "plu": [9, 11, 13], "n_i": [9, 11, 13], "anm": [9, 11, 13], "f_i": [9, 11, 13], "special": [9, 11, 13, 32, 132], "handl": [9, 10, 11, 13, 14, 19, 22, 49, 59, 67, 72, 107, 120, 123, 127, 132], "version": [9, 11, 13, 18, 23, 62, 63, 67, 72, 79, 82, 83, 101, 107, 108, 118], "f_2": [9, 13], "f_1": [9, 13], "nonlinear": [9, 13, 22, 28], "transform": [9, 13, 45], "fisher": [9, 14], "implement": [9, 11, 13, 14, 15, 18, 19, 22, 23, 26, 27, 40, 47, 49, 58, 59, 65, 67, 77, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91, 93, 95, 96, 97, 98, 100, 102, 103, 104, 128, 133, 134], "http": [9, 10, 11, 13, 14, 17, 21, 23, 27, 33, 40, 60, 120, 123, 130, 131], "github": [9, 10, 11, 13, 14, 17, 40, 129, 130, 133], "com": [9, 10, 11, 13, 14, 17, 27, 33, 40, 60, 130, 131], "bd2kccd": [9, 14], "highli": [9, 14], "java": [9, 14], "blob": [9, 14, 40], "20pc": [9, 14], "20in": [9, 14], "20action": [9, 14], "recov": [9, 11], "hyper": [9, 11, 85, 121], "cdt15": [9, 11], "xunzheng": [9, 13], "incorpor": [9, 10, 19, 82, 84, 107, 108], "auto": [9, 128], "encod": [9, 127], "modifi": [9, 12, 17, 80, 84, 95, 96, 97, 98, 100, 102, 103, 109, 114, 121], "smooth": [9, 49], "evid": 9, "lower": [9, 11, 13, 14, 59, 62, 67, 72, 90, 97, 122, 126], "bound": [9, 19, 20, 21, 25, 62, 63, 72, 73, 74, 81, 83, 85, 88, 89, 90, 91, 97, 105, 115, 126], "loss": [9, 17, 19, 40, 73, 74, 132], "fishmoon1234": 9, "pytorch": 9, "paszk": 9, "anoc": [9, 11, 12, 13, 14], "cvae": 9, "constrain": [9, 10, 11, 12, 13, 14], "novel": [9, 10, 17, 69, 72], "identif": [9, 10, 11, 12, 13, 14, 130, 132], "publicli": [9, 10, 123, 124, 125], "anonym": [9, 10, 27, 123, 124, 125], "granger": 9, "1969": [9, 10], "entner": 9, "hoyer": [9, 10, 11, 12, 13, 14], "2010": [9, 21, 40, 79, 107, 126], "momentari": 9, "mci": 9, "rung": 9, "autoregress": 9, "var": [9, 21, 120], "hyv\u00e4rinen": [9, 10, 11, 12, 13, 14], "timino": 9, "2013": [9, 11, 13, 14, 15, 22, 79, 80, 98, 99, 106, 107, 109, 116], "dynotear": 9, "pamfil": 9, "contemporan": 9, "intra": [9, 86], "slice": [9, 21, 120, 123], "lag": [9, 118, 120, 123], "interslic": 9, "nt": [9, 21, 62, 63, 68, 69, 72, 121, 126], "sun": [9, 59, 126], "nonparametr": [9, 19, 72], "along": [9, 33, 69, 78, 132], "properti": [9, 19, 59, 104, 114], "judea": [9, 10, 11, 12, 13, 14, 21], "survei": [9, 10, 11, 12, 13, 14, 79, 83, 99, 101, 107, 133], "96": [9, 10, 11, 12, 13, 14, 40, 61, 69, 114, 115, 120, 121, 123], "146": [9, 10, 11, 12, 13, 14, 40, 83, 120, 122, 127], "2009": [9, 10, 11, 12, 13, 14], "pater": [9, 10, 11, 12, 13, 14], "clark": [9, 10, 11, 12, 13, 14], "glymour": [9, 10, 11, 12, 13, 14], "schein": [9, 10, 11, 12, 13, 14], "stuart": [9, 10, 11, 12, 13, 14], "kauffman": [9, 10, 11, 12, 13, 14], "valerio": [9, 10, 11, 12, 13, 14], "aimal": [9, 10, 11, 12, 13, 14], "frank": [9, 10, 11, 12, 13, 14], "wimberli": [9, 10, 11, 12, 13, 14], "gene": [9, 10, 11, 12, 13, 14], "express": [9, 10, 11, 12, 13, 14, 18, 22, 23, 33, 62, 72, 78, 84], "microarrai": [9, 10, 11, 12, 13, 14], "marku": [9, 10, 11, 12, 13, 14], "8": [9, 10, 11, 12, 13, 14, 15, 18, 19, 21, 22, 24, 25, 26, 28, 29, 40, 49, 59, 61, 69, 77, 79, 107, 109, 114, 120, 121, 122, 123, 126, 127, 129], "mar": [9, 10, 11, 12, 13, 14], "613": [9, 10, 11, 12, 13, 14], "636": [9, 10, 11, 12, 13, 14], "rajen": [9, 10, 11, 12, 13, 14], "jona": [9, 10, 11, 12, 13, 14], "hard": [9, 10, 11, 12, 13, 14], "generalis": [9, 10, 11, 12, 13, 14], "1804": [9, 10, 11, 12, 13, 14], "07203": [9, 10, 11, 12, 13, 14], "shohei": [9, 10, 11, 12, 13, 14], "patrik": [9, 10, 11, 12, 13, 14], "aapo": [9, 10, 11, 12, 13, 14], "antti": [9, 10, 11, 12, 13, 14], "kerminen": [9, 10, 11, 12, 13, 14], "7": [9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 40, 45, 49, 58, 59, 61, 68, 69, 70, 72, 79, 94, 101, 107, 108, 120, 121, 122, 123, 124, 126, 127, 129], "oct": [9, 10, 11, 12, 13, 14], "2003": [9, 10, 11, 12, 13, 14, 45, 75], "2030": [9, 10, 11, 12, 13, 14], "6": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 26, 27, 28, 29, 33, 40, 47, 49, 59, 61, 63, 68, 69, 70, 72, 79, 101, 106, 107, 108, 109, 114, 115, 120, 121, 122, 123, 124, 126, 127, 128, 129], "ernest": [9, 10, 11, 12, 13, 14], "penal": [9, 10, 11, 12, 13, 14, 19, 47, 58, 77], "annal": [9, 10, 11, 12, 13, 14, 18, 19, 21, 23, 35, 39, 41, 42, 43, 45, 75, 126], "42": [9, 10, 11, 12, 13, 14, 59, 61, 80, 81, 82, 84, 85, 86, 88, 108, 109, 114, 115, 129], "2526": [9, 10, 11, 12, 13, 14], "2556": [9, 10, 11, 12, 13, 14], "maxwel": [9, 10, 11, 12, 13, 14], "nov": [9, 10, 11, 12, 13, 14, 33], "507": [9, 10, 11, 12, 13, 14, 96], "554": [9, 10, 11, 12, 13, 14], "joseph": [9, 10, 11, 12, 13, 14], "madelyn": [9, 10, 11, 12, 13, 14], "ruben": [9, 10, 11, 12, 13, 14], "sanchez": [9, 10, 11, 12, 13, 14], "romero": [9, 10, 11, 12, 13, 14], "magnet": [9, 10, 11, 12, 13, 14], "reson": [9, 10, 11, 12, 13, 14], "imag": [9, 10, 11, 12, 13, 14, 17, 21, 33], "analyt": [9, 10, 11, 12, 13, 14, 60], "121": [9, 10, 11, 12, 13, 14, 27, 40], "129": [9, 10, 11, 12, 13, 14, 40, 120, 122, 123, 124, 126], "xun": [9, 10, 11, 12, 13, 14], "bryon": [9, 10, 11, 12, 13, 14], "aragam": [9, 10, 11, 12, 13, 14], "pradeep": [9, 10, 11, 12, 13, 14], "ravikumar": [9, 10, 11, 12, 13, 14], "eric": [9, 10, 11, 12, 13, 14, 21], "xing": [9, 10, 11, 12, 13, 14], "tear": [9, 10, 11, 12, 13, 14], "pp": [9, 10, 11, 12, 13, 14, 21, 45, 49, 75, 78, 79, 80, 81, 87, 88, 93, 94, 96, 97, 98, 99, 101, 102, 104, 106, 109, 126], "9472": [9, 10, 11, 12, 13, 14], "9483": [9, 10, 11, 12, 13, 14], "10": [9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 21, 22, 23, 24, 25, 26, 28, 29, 45, 47, 49, 58, 59, 61, 69, 81, 95, 97, 98, 100, 102, 107, 120, 121, 122, 123, 126, 127, 129], "jie": [9, 10, 11, 12, 13, 14], "tian": [9, 10, 11, 12, 13, 14], "gao": [9, 10, 11, 12, 13, 14], "mo": [9, 10, 11, 12, 13, 14], "1904": [9, 10, 11, 12, 13, 14, 79, 83, 107], "10098": [9, 10, 11, 12, 13, 14], "11": [9, 10, 11, 12, 13, 14, 15, 17, 21, 24, 26, 27, 28, 29, 45, 58, 59, 61, 72, 107, 114, 115, 120, 122, 123, 126, 128, 129], "shengyu": [9, 10, 11, 12, 13, 14], "zhitang": [9, 10, 11, 12, 13, 14], "1906": [9, 10, 11, 12, 13, 14], "04477": [9, 10, 11, 12, 13, 14], "hengrui": [9, 10, 11, 12, 13, 14, 131, 133], "demand": [10, 40], "kei": [10, 17, 27, 33, 47, 49, 67, 94, 120, 127, 128, 131, 132, 133], "factor": [10, 67, 73, 74, 94, 95, 96, 97, 98, 100, 101, 106], "guid": [10, 81, 84, 86, 88, 107, 109, 114, 117], "downstream": 10, "task": [10, 63, 65, 67, 72, 74, 78, 83, 87, 88, 107, 127], "m_1": [10, 12, 69], "m_2": [10, 12], "m_p": [10, 12], "dimens": [10, 12, 118], "give": [10, 15, 18, 23, 26, 28, 29, 73, 79, 83, 87, 107, 122, 126, 128], "te": [10, 12, 21, 69, 121, 122, 126], "de": [10, 12, 21, 63, 78, 107], "ie": [10, 12, 21], "equat": [10, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 32, 33, 40, 49, 59, 62, 63, 65, 66, 67, 68, 72, 73, 75, 86, 88, 89, 90, 91, 93, 94, 95, 97, 99, 100, 101, 102, 103, 104, 105, 106, 107, 115, 116, 117], "split": [10, 12, 15, 18, 23, 33, 62, 63, 72, 93, 94, 95, 99, 100, 102, 106, 116, 117, 123, 124, 127, 128], "remov": [10, 11, 12, 15, 26, 47, 128], "citet": [10, 68, 72], "pearl2009caus": 10, "dm": [10, 15, 21, 62, 65, 72], "dm_i": 10, "big": [10, 15, 16, 17, 18, 20, 21, 23, 25, 32, 33, 45, 47, 49, 62, 63, 65, 66, 67, 72, 73, 75, 86, 90, 93, 102, 117], "m_i": [10, 21], "_i": [10, 22, 29, 40, 45, 59, 60, 80, 89, 90, 91, 95, 100, 102, 106, 109, 116, 128], "omega_i": 10, "setminu": 10, "except": [10, 40, 75, 128], "im": [10, 69, 121], "def_im": 10, "im_i": 10, "firstli": [10, 85, 107, 115], "sourc": [10, 133], "degre": [10, 11, 13, 14, 19, 20, 25, 40, 93], "freedom": 10, "smaller": [10, 22, 25, 123, 124], "decompos": [10, 63, 69, 95, 100, 102, 121], "compon": [10, 11, 58, 62, 72, 73, 121, 122, 126, 132], "row": [10, 15, 16, 17, 18, 20, 21, 22, 24, 26, 27, 28, 29, 33, 40, 59, 78, 120, 123, 127, 128, 129], "compos": 10, "investig": [10, 33, 64, 79], "spread": [10, 21], "major": [10, 21, 58, 69, 79, 84, 95, 100, 102, 107, 109, 114, 117, 121], "panda": [10, 11, 15, 16, 17, 18, 20, 21, 23, 24, 26, 27, 28, 29, 33, 40, 61, 69, 75, 77, 120, 121, 122, 123, 124, 126, 127, 128], "pd": [10, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 33, 40, 45, 58, 59, 61, 69, 75, 77, 120, 121, 122, 123, 124, 126, 127, 128, 129], "os": [10, 11, 13, 14, 15, 16, 17, 21, 27, 49, 59, 68, 70, 72, 108, 109, 114, 115, 123, 124, 129], "pickl": [10, 27, 49, 69, 120, 121, 122, 123, 124, 127], "data_typ": 10, "realdata": 10, "real_data_fil": 10, "covid19": [10, 33], "pkl": 10, "epoch": [10, 101, 102, 103, 104, 105], "100": [10, 15, 40, 45, 49, 59, 61, 69, 75, 86, 100, 102, 103, 107, 120, 121, 123, 124, 126, 129], "node_numb": 10, "32": [10, 16, 19, 20, 21, 25, 40, 61, 79, 101, 102, 103, 123], "sample_s": 10, "38": [10, 18, 21, 23, 33, 40, 59, 61], "batch_siz": [10, 17], "rep_numb": 10, "usag": 10, "h": [10, 16, 19, 20, 25, 45, 49, 78, 86, 87, 88, 89, 90, 91, 93, 94, 95, 97, 100, 101, 102, 103, 106, 107, 115, 116], "create_new": 10, "simu_g_fil": 10, "graph_degre": 10, "a_typ": [10, 11, 13, 14], "seed": [10, 11, 13, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 47, 49, 59, 61, 69, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 107, 108, 109, 114, 115, 121, 123, 124, 126, 128, 129], "k_max_it": 10, "original_lr": 10, "argument": [10, 11, 13, 63, 127], "invalid": 10, "choic": [10, 17, 21, 52, 69, 78, 94, 95, 101, 107, 116, 121, 126], "argumenterror": 10, "file": [10, 17, 22, 23, 49, 59, 69, 120, 121, 122, 126, 127, 128, 129, 130], "argpars": [10, 17], "1857": 10, "argumentpars": 10, "parse_known_arg": 10, "self": [10, 59, 62, 67, 72, 120, 126, 127, 129], "arg": [10, 17, 20, 24, 25, 40, 45, 47, 58, 59, 62, 65, 66, 73, 74, 75, 77, 80, 81, 84, 85, 93, 95, 96, 97, 98, 100, 101, 102, 103, 104, 115, 117, 127], "namespac": 10, "1856": 10, "_parse_known_arg": 10, "1858": 10, "2066": [10, 79, 80, 93, 107, 109], "arg_str": 10, "2065": 10, "start_index": 10, "consume_opt": 10, "2068": [10, 40, 122], "option_str": 10, "action_tupl": 10, "take_act": [10, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115, 128, 129], "1918": 10, "argument_str": 10, "1917": 10, "seen_act": 10, "argument_valu": 10, "_get_valu": 10, "1920": 10, "previous": [10, 75, 80, 81, 82, 84, 85, 86, 88], "1921": 10, "seen": 10, "1922": 10, "realli": 10, "2450": 10, "2449": 10, "_check_valu": 10, "2452": 10, "remaind": 10, "check": [10, 17, 32, 127], "none": [10, 18, 21, 23, 27, 40, 61, 69, 82, 86, 94, 108, 114, 120, 121, 126, 127, 128, 129], "2506": 10, "2505": 10, "msg": [10, 127], "systemexit": 10, "ipython": [10, 17, 21, 33], "core": [10, 17, 69, 120], "interactiveshel": 10, "2727": 10, "safe_execfil": 10, "fname": 10, "exit_ignor": 10, "raise_except": 10, "shell_futur": 10, "2726": 10, "glob": [10, 17], "loc": [10, 120, 123, 124, 128, 129], "py3compat": 10, "execfil": 10, "2728": 10, "2729": 10, "compil": 10, "els": [10, 21, 45, 58, 69, 120, 121, 122, 126, 127], "2730": 10, "statu": [10, 19, 21, 27, 32, 59, 90, 91, 123, 124, 125], "2731": 10, "made": [10, 32, 67, 78], "exit": 10, "sy": 10, "2732": 10, "bother": 10, "2738": 10, "2739": 10, "explicitli": [10, 68, 90, 91, 95, 100, 102], "silenc": 10, "short": [10, 62, 67, 69, 118], "55": [10, 18, 61, 95, 102, 123, 128], "54": [10, 59, 61], "exec": 10, "read": [10, 128], "2_causal_structure_learn": 10, "62": [10, 11, 13, 14, 27, 61, 75, 126], "modul": [10, 11, 13, 14, 17, 25, 49, 59, 129], "60": [10, 61, 126, 129], "parser": [10, 127], "add_argu": 10, "float": [10, 127], "3e": 10, "initi": [10, 27, 45, 47, 49, 58, 59, 61, 63, 65, 66, 67, 72, 73, 74, 77, 81, 82, 85, 105, 108, 115, 117, 122, 126, 128, 129], "parse_arg": 10, "63": [10, 61, 126], "1824": 10, "1823": 10, "def": [10, 21, 49, 59, 61, 69, 121, 126, 127, 129], "argv": 10, "1825": 10, "1860": 10, "1859": 10, "err": [10, 126], "_sy": 10, "exc_info": 10, "str": [10, 40, 120, 127], "2581": 10, "messag": [10, 59], "2580": 10, "prog": 10, "2568": 10, "2567": 10, "_print_messag": 10, "stderr": 10, "assertionerror": 10, "get_ipython": 10, "run_line_mag": 10, "2294": 10, "magic_nam": 10, "_stack_depth": 10, "2292": 10, "kwarg": [10, 127, 129], "local_n": 10, "get_local_scop": 10, "stack_depth": 10, "2293": [10, 23], "builtin_trap": 10, "fn": 10, "2295": 10, "magic": 10, "execut": [10, 19, 32, 33, 40, 79, 87, 107, 127, 128, 129], "829": 10, "executionmag": 10, "parameter_": 10, "runner": 10, "file_find": 10, "826": 10, "_run_with_tim": 10, "nrun": 10, "827": 10, "828": 10, "831": 10, "opt": [10, 11, 45, 58, 61, 75, 77, 122, 126, 129], "832": 10, "shell": 10, "user_n": 10, "__name__": 10, "__name__sav": 10, "814": 10, "813": 10, "filenam": [10, 127], "prog_n": 10, "815": 10, "2744": 10, "2742": 10, "2743": 10, "showtraceback": 10, "exception_onli": 10, "2745": [10, 22], "2746": 10, "1972": [10, 40], "exc_tupl": 10, "tb_offset": 10, "running_compiled_cod": 10, "1970": [10, 40], "stb": 10, "tb": [10, 20, 25], "1971": [10, 40], "full": [10, 95, 100, 132], "extend": [10, 16, 25, 47, 67, 72, 133], "interactivetb": 10, "get_exception_onli": 10, "etyp": 10, "1973": [10, 40], "1974": [10, 40], "1975": [10, 127], "1976": 10, "customis": 10, "1977": 10, "parallel": [10, 33, 40], "1978": 10, "engin": [10, 15, 16, 17, 18, 20, 24, 26, 27, 28, 29, 79, 87, 107, 127, 128], "string": 10, "ultratb": 10, "585": 10, "listtb": 10, "577": [10, 127], "578": [10, 59, 60, 127, 128], "579": 10, "580": 10, "583": [10, 21], "584": [10, 25], "structured_traceback": 10, "443": 10, "etb": 10, "440": [10, 21], "chained_exc_id": 10, "id": [10, 69, 102, 103, 104, 120], "441": 10, "chained_exceptions_tb_offset": 10, "442": 10, "out_list": 10, "444": [10, 21], "445": 10, "446": 10, "chained_exception_messag": 10, "447": [10, 27, 94, 96], "449": 10, "1118": [10, 47], "autoformattedtb": 10, "number_of_lines_of_context": 10, "1116": 10, "1117": 10, "formattedtb": 10, "1119": [10, 61], "1012": 10, "1009": 10, "1010": 10, "verbose_mod": 10, "1011": 10, "verbos": [10, 18, 23, 127], "verbosetb": 10, "1013": 10, "1014": 10, "1015": 10, "elif": [10, 127], "minim": [10, 17, 19, 62, 63, 72, 73, 74, 78, 83, 95, 100, 102, 107], "1016": 10, "865": 10, "856": 10, "857": 10, "858": 10, "862": 10, "int": [10, 21, 40, 61, 127, 128], "863": 10, "864": [10, 104], "nice": [10, 104, 114], "formatted_except": 10, "format_exception_as_a_whol": 10, "866": 10, "868": 10, "color": 10, "shorthand": 10, "quicker": 10, "lookup": 10, "869": [10, 22], "colorsnorm": 10, "normal": [10, 14, 17, 61, 62, 67, 68, 72, 86, 90, 98, 99], "lot": [10, 19, 59, 73], "799": 10, "796": [10, 127], "assert": [10, 127], "isinst": [10, 120, 127], "797": [10, 127], "head": [10, 17, 27, 33, 40, 61, 75, 120, 122, 123, 124, 126, 127], "prepare_head": 10, "long_head": 10, "798": [10, 127], "record": [10, 27, 33, 60, 128], "get_record": 10, "800": [10, 21], "802": 10, "frame": [10, 120], "803": 10, "skip": 10, "854": [10, 21], "848": 10, "formatt": 10, "849": 10, "stack_data": 10, "850": 10, "851": 10, "852": 10, "pygments_formatt": 10, "853": 10, "frameinfo": 10, "546": 10, "cl": 10, "frame_or_tb": 10, "collapse_repeated_fram": 10, "530": 10, "classmethod": 10, "531": 10, "532": [10, 27, 123, 124, 125], "536": [10, 21, 25, 36, 59], "bool": [10, 120, 127], "537": 10, "iter": [10, 59, 63, 65, 75, 77, 86, 95, 100, 102, 117, 127], "union": [10, 49, 127], "repeatedfram": 10, "538": 10, "539": [10, 120, 123, 124], "object": [10, 17, 21, 24, 47, 59, 79, 83, 84, 94, 106, 107, 109, 114, 117, 123], "540": [10, 27], "stack": 10, "consecut": 10, "collaps": 10, "544": 10, "configur": 10, "545": 10, "iter_stack": 10, "548": 10, "revers": [10, 11, 13, 14, 123, 124], "549": 10, "550": [10, 77], "bottom": [10, 94, 106], "551": [10, 25], "is_fram": 10, "98": [10, 21, 61], "97": [10, 61, 103, 123], "yield": [10, 16, 17, 22, 25, 28, 32, 33, 49, 59, 62, 63, 67, 72], "99": [10, 40, 59, 61, 120], "f_back": 10, "91": [10, 59, 61, 69, 120, 121, 122, 123], "90": [10, 59, 61], "frametyp": 10, "tracebacktyp": 10, "assert_": 10, "92": [10, 40, 61], "172": [10, 97, 120, 122, 123], "170": [10, 21, 83, 120, 122], "171": [10, 77], "seaborn": [10, 128, 129], "sn": [10, 128, 129], "matplotlib": [10, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 40, 123, 124, 127, 128], "pyplot": [10, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 40, 123, 124, 127, 128], "plt": [10, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 40, 59, 120, 123, 124, 127, 128, 129], "load": [10, 27, 33, 40, 121, 122, 127], "join": [10, 59], "anoce_result": 10, "rb": [10, 69, 121, 122, 127], "calcul": [10, 17, 19, 33, 40, 62, 65, 72, 75, 77, 80, 81, 82, 85, 86, 88, 102, 104, 107, 108, 109, 115, 121, 122, 126, 128], "calculate_effect": 10, "plot": [10, 11, 13, 14, 40, 123, 124], "covid": [10, 21], "matshow": 10, "cmap": 10, "bwr": 10, "vmin": 10, "vmax": 10, "fig1": 10, "gcf": 10, "colorbar": 10, "df": [10, 11, 13, 14, 21, 126], "datafram": [10, 14, 21, 22, 23, 45, 58, 59, 61, 75, 77, 120, 122, 123, 126, 127, 128, 129], "arrai": [10, 15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 45, 47, 49, 59, 61, 69, 75, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115, 120, 121, 122, 123, 124, 126, 127, 128, 129, 132], "read_csv": [10, 16, 17, 21, 27, 40, 69, 75, 77, 120, 121, 122, 123, 124, 126, 127, 128], "csv": [10, 16, 17, 21, 27, 40, 69, 120, 121, 122, 123, 124, 126, 128], "column": [10, 14, 15, 16, 17, 18, 20, 21, 22, 24, 26, 27, 28, 29, 33, 40, 45, 59, 61, 93, 95, 97, 100, 102, 103, 120, 122, 123, 126, 127, 128, 129], "31": [10, 11, 13, 21, 40, 61, 72], "round": [10, 11, 13, 14, 16, 17, 18, 20, 21, 24, 26, 28, 29, 33, 45, 58, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 108, 109, 114, 115, 116, 128], "reshap": [10, 11, 13, 14, 17, 21, 22, 26, 49, 69, 120, 121, 124, 126, 129], "shenzhen": [10, 21], "212": 10, "026": 10, "guangzhou": [10, 21], "107": [10, 47, 120], "068": 10, "beij": [10, 21], "039": [10, 16, 128], "043": 10, "chengdu": [10, 21], "084": 10, "018": [10, 24], "shanghai": [10, 21], "072": 10, "dongguan": [10, 21], "027": 10, "suzhou": [10, 21], "113": [10, 27, 59, 123], "xian": [10, 21], "055": 10, "045": [10, 83, 128], "hangzhou": [10, 21], "097": 10, "zhengzhou": [10, 21], "070": 10, "chongq": [10, 21], "132": [10, 40, 120, 122], "029": [10, 24, 128], "changsha": [10, 21], "079": 10, "nanj": [10, 21], "101": [10, 11, 13, 14, 21, 40, 59], "047": 10, "13": [10, 11, 13, 14, 18, 21, 23, 27, 61, 107, 122, 123, 126, 128, 129], "kunm": [10, 21], "006": [10, 61], "046": 10, "14": [10, 11, 13, 14, 21, 23, 27, 49, 61, 120, 123, 126, 128, 129], "tianjin": [10, 21], "081": [10, 21, 83], "058": [10, 21], "hefei": [10, 21], "024": [10, 24], "076": [10, 83], "009": 10, "056": [10, 21], "wenzhou": [10, 21], "319": [10, 16, 19, 20, 24, 25], "033": [10, 49, 104], "18": [10, 21, 40, 59, 61, 79, 87, 107, 120, 126, 127, 128], "nanchang": [10, 21], "052": 10, "001": [10, 21, 126, 128], "zhoukou": [10, 21], "014": 10, "fuyang": [10, 21], "021": 10, "21": [10, 18, 21, 23, 33, 45, 58, 59, 61, 95], "shangqiu": [10, 21], "008": [10, 128], "023": [10, 128], "yueyang": [10, 21], "002": [10, 21, 102, 126], "23": [10, 21, 23, 33, 45, 58, 61, 122], "zhumadian": [10, 21], "24": [10, 21, 58, 61, 127], "changd": [10, 21], "25": [10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 23, 24, 26, 27, 28, 29, 33, 58, 59, 61, 77, 80, 81, 86, 123, 127, 128, 129], "nanyang": [10, 21], "025": [10, 21, 126], "26": [10, 21, 47, 61], "032": [10, 21], "27": [10, 18, 21, 61, 126], "xinyang": [10, 21], "034": 10, "28": [10, 21, 33, 59, 61, 98, 120, 127], "anq": [10, 21], "010": [10, 128], "005": [10, 45, 126], "29": [10, 21, 40, 45, 59, 61, 75, 126, 129], "jiujiang": [10, 21], "042": 10, "020": [10, 24], "mt_data": 10, "zero": [10, 11, 13, 14, 15, 21, 22, 26, 27, 45, 49, 59, 62, 72, 75, 80, 86, 93, 95, 96, 97, 98, 100, 105, 108, 109, 114, 115, 124, 127, 128, 129], "fig": [10, 132], "figur": [10, 17, 33, 40, 129, 132], "figsiz": [10, 40], "ax": [10, 129], "add_subplot": 10, "cax": 10, "shrink": 10, "horizont": 10, "cities_nam": 10, "set_xtick": 10, "arang": [10, 20], "len": [10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 24, 26, 28, 29, 33, 40, 45, 47, 49, 58, 59, 69, 75, 77, 79, 83, 87, 88, 106, 107, 120, 121, 122, 123, 124, 126, 127, 128, 129], "set_ytick": 10, "set_xticklabel": 10, "rotat": 10, "set_yticklabel": 10, "linear": [10, 12, 19, 24, 25, 47, 79, 80, 81, 89, 90, 91, 93, 97, 100, 101, 102, 103, 104, 107, 109, 122, 126], "addit": [10, 12, 14, 22, 62, 63, 67, 68, 72, 73, 74, 88, 128], "graphic": [10, 12], "uniqu": [11, 13, 14, 49, 65, 66, 73, 74, 117, 120, 127], "invari": [11, 13, 14, 132], "trasform": [11, 13, 14], "disadvantag": [11, 13, 14, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104], "knowledg": [11, 49, 79, 80, 84, 87, 88, 109, 114], "realiz": [11, 13, 14, 67, 84, 128], "underli": [11, 13, 14, 17, 19, 73, 74, 89, 118], "lsem": [11, 14, 123, 124], "g_j": [11, 13], "differenti": [11, 13], "corollari": [11, 13], "threshold": 11, "synthetic_dataset": [11, 13, 14], "1234": [11, 13, 14], "300": [11, 13, 14, 18, 20, 49, 83, 128], "ground_truth_g": [11, 13, 14], "simulate_random_dag": [11, 13, 14], "graph_typ": [11, 13, 14], "erdo": [11, 13, 14], "renyi": [11, 13, 14], "w_rang": [11, 13, 14], "c": [11, 13, 14, 15, 17, 18, 23, 27, 45, 47, 49, 52, 58, 59, 68, 69, 72, 75, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 93, 94, 95, 96, 97, 98, 100, 102, 103, 104, 105, 106, 107, 108, 109, 115, 116, 120, 121, 123, 127, 128, 129, 134], "ones": [11, 13, 14, 15, 21, 22, 26, 45, 47, 59, 61, 69, 75, 84, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 114, 121, 124, 126, 128, 129], "simulate_lsem": [11, 13, 14], "plot_net": [11, 13, 14, 123, 124], "nx": [11, 13, 14, 123, 124], "to_numpy_arrai": [11, 13, 14], "labels_nam": [11, 13, 14, 123, 124], "rang": [11, 13, 14, 21, 49, 61, 69, 75, 99, 121, 126, 127, 128, 129, 132], "modulenotfounderror": [11, 13, 14, 17, 25, 49, 129], "pip": [11, 14, 18, 23, 59, 130], "instal": [11, 14, 18, 23, 59, 130], "igraph": 11, "factor_analyz": 11, "directlingam": 11, "fit": [11, 15, 17, 18, 20, 21, 22, 23, 25, 26, 28, 29, 32, 40, 45, 58, 59, 61, 75, 77, 122, 123, 124, 126, 129], "adjacency_matrix_": 11, "ica_r": 11, "ab": [11, 13, 14, 129], "fdr": [11, 13, 14], "tpr": [11, 13, 14], "shd": [11, 13, 14], "count_accuraci": [11, 13, 14], "digraph": [11, 13, 14, 123, 124], "python3": [11, 23], "statsmodel": [11, 18, 23, 45, 58, 59, 75, 77, 129], "tsa": 11, "tsa_model": 11, "futurewarn": [11, 127], "int64index": 11, "deprec": [11, 126], "futur": [11, 32, 73, 74], "index": [11, 14, 17, 18, 21, 23, 24, 40, 49, 58, 67, 77, 87, 94, 120, 122, 123, 126, 127, 129, 130], "dtype": [11, 21, 24, 45, 58, 61, 77, 93, 95, 96, 97, 98, 100, 102, 103, 120, 122, 123, 126, 127, 129], "instead": [11, 16, 17, 18, 20, 22, 23, 24, 26, 28, 29, 32, 58, 62, 67, 72, 75, 77, 79, 86, 95, 100, 102, 117, 120, 123, 130], "to_datetim": 11, "datetimeindex": 11, "float64index": 11, "67": [11, 13, 14, 40, 61, 78, 101, 104, 105, 107, 126], "prune": [11, 13, 14], "metric": [11, 13, 14, 47], "fals": [11, 13, 14, 18, 21, 23, 45, 58, 69, 80, 81, 86, 88, 102, 103, 104, 105, 108, 120, 121, 122, 123, 126, 127, 128, 129], "ham": [11, 13, 14], "distanc": [11, 13, 14], "smallest": [11, 13, 14, 22, 49], "account": [11, 13, 14, 21, 69, 77, 84, 86, 94, 95, 99, 100, 101, 102, 121, 132, 134], "neg": [11, 13, 14, 21, 45, 47, 58, 69, 75, 77, 121, 123, 124, 126], "better": [11, 13, 14, 17, 18, 22, 23, 28, 29, 45, 58, 60, 62, 75, 77, 82, 85, 122, 123, 124, 126], "00": [11, 13, 14, 23, 45, 58, 59, 61, 75, 122, 126, 129], "50": [11, 13, 14, 21, 27, 49, 61, 69, 121, 126, 127, 128], "daggnn": [11, 13, 14], "equal": [11, 13, 14, 49, 62, 63, 67, 72, 73, 94, 97, 98, 100, 101, 124], "varianc": [11, 13, 14, 22, 23, 25, 49, 62, 63, 67, 68, 72, 80, 84, 109, 114, 117], "biometrika": [11, 13, 14, 15, 16, 19, 20, 24, 25], "219": [11, 13, 14], "228": [11, 13, 14, 22, 23], "mooij": [11, 13, 14], "janz": [11, 13, 14], "sch\u00f6lkopf": [11, 13, 14], "cma": 12, "dissect": 12, "transmit": 12, "comprehens": [12, 27, 123, 124, 125], "cate": [12, 19], "moder": 13, "sem": 13, "good": [13, 22, 65, 66, 74, 84, 107, 117, 132], "analysis": 13, "contrain": 13, "notears_linear": [13, 123, 124], "lambda1": [13, 123, 124], "loss_typ": [13, 123, 124], "l2": [13, 123, 124], "notears_r": 13, "author": [14, 17, 133], "nois": [14, 86, 97, 98, 132], "sparsiti": [14, 47, 79], "teat": 14, "pydot": 14, "git": [14, 130], "pycaus": 14, "start_vm": 14, "tetrad": 14, "tetradrunn": 14, "new_df": 14, "map": [14, 65, 66, 74, 78, 89, 90, 91, 117, 132, 133], "02": [14, 45, 58, 61, 75, 122, 126, 128, 129], "format": [14, 75, 128], "algoid": 14, "testid": 14, "gettetradgraph": 14, "getnod": 14, "dot_str": 14, "tetradgraphtodot": 14, "graph_from_dot_data": 14, "node_a": 14, "fill": 14, "fillcolor": 14, "red": 14, "add_nod": 14, "nx_pydot": 14, "from_pydot": 14, "pc_re": 14, "trial": [15, 32, 33, 78, 107], "ve": [15, 19, 132, 133], "preliminari": [15, 38], "notat": [15, 33, 74, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 133], "rl": [15, 63, 73, 74, 117, 118, 132], "main": [15, 20, 24, 25, 40, 117, 130, 131, 132, 133], "mathbb": [15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 32, 33, 38, 45, 47, 49, 59, 62, 63, 65, 66, 67, 72, 73, 74, 75, 89, 90, 91, 117, 132], "common": [15, 19, 22, 26, 97, 99, 127, 132], "causal": [15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 28, 32, 33, 36, 37, 38, 40, 69, 117, 118, 121, 122, 126, 130, 131, 133], "consist": [15, 16, 17, 19, 20, 21, 22, 24, 25, 26, 27, 32, 47, 59, 62, 65, 67, 68, 69, 72, 73, 74, 90, 99, 106, 116, 123, 124, 125, 128], "These": [15, 19, 22, 62, 63, 72, 74], "nuc": [15, 21, 22, 26, 32], "remark": [15, 82, 86, 88, 108], "commonli": [15, 19, 21, 65, 66, 67, 68, 72, 73, 79, 80, 89, 90, 91, 109], "impos": [15, 65, 74], "automat": [15, 67, 72, 74, 88], "behavior": [15, 22, 23, 25, 59, 64, 67, 73, 74, 90, 94, 101, 116], "strictli": [15, 67, 72], "re": [15, 87], "shown": [15, 17, 33, 84, 86, 94, 107, 109, 114], "below": [15, 16, 17, 21, 22, 24, 25, 26, 28, 69, 75, 77, 79, 83, 87, 107, 118, 121, 122, 123, 126, 128, 132], "_s": 15, "_x": [], "e_": [15, 94, 95], "rh": [15, 117], "rid": 15, "pure": [15, 117], "categori": [15, 62, 65, 72, 107, 132], "IS": [15, 21, 62, 67, 72], "dr": [15, 19, 20, 21, 49, 62, 67, 72, 131], "widehat": [15, 16, 17, 21, 25, 49, 62, 63, 65, 66, 68, 72, 89, 90, 91, 117], "later": [15, 27, 32, 45, 68, 70, 72, 75, 108, 109, 114, 115], "learner": [15, 17, 18, 19, 21, 23, 27, 33, 45, 47, 58, 59, 61, 75, 77, 105, 108, 109, 114, 115, 121, 122, 123, 124, 126, 128, 129, 132, 133, 134], "elabor": [15, 32], "sklearn": [15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 40, 47, 123, 124, 126, 128], "ensembl": [15, 16, 17, 18, 20, 21, 24, 26, 28, 29, 123, 124], "gradientboostingregressor": [15, 16, 17, 18, 20, 21, 24, 26, 28, 29], "linear_model": [15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 40, 58, 77, 123, 124, 128], "linearregress": [15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 123, 124, 128], "chdir": [16, 17, 59, 68, 70, 72, 108, 109, 114, 115, 129], "alinaxu": [16, 17, 27, 59], "cdm": [16, 17, 27, 59, 131, 133], "movielens_cel": [15, 16, 17, 18, 20, 24, 26, 27, 28, 29], "pop": [15, 16, 17, 18, 20, 24, 26, 28, 29], "filenotfounderror": [68, 70, 72, 108, 109, 114, 115, 127], "winerror": [68, 70, 72, 108, 109, 114, 115], "\u7cfb\u7edf\u627e\u4e0d\u5230\u6307\u5b9a\u7684\u8def\u5f84": [108, 109, 114, 115], "userinfo_index": [15, 16, 17, 18, 21, 24, 26, 27, 28, 29, 123, 124, 128], "sanda": [15, 17, 18, 21, 22, 26, 27, 28, 29, 124], "iloc": [15, 17, 18, 20, 21, 22, 23, 26, 27, 28, 29, 40, 49, 69, 120, 121, 122, 123, 124, 126, 127, 128, 129], "s_learner": [15, 21, 22, 26, 124], "max_depth": [15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 69, 121, 123, 124, 126, 128], "sanda_all1": [15, 21, 26, 124], "copi": [15, 21, 26, 59, 69, 120, 121, 123, 124, 126, 127, 128], "sanda_all0": [15, 21, 26, 124], "ate_dm": [15, 21], "sum": [15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 33, 59, 61, 63, 85, 106, 107, 115, 123, 124, 127, 128], "14529621186817238": [], "inclin": [15, 26, 28, 29, 123, 124], "higher": [15, 19, 26, 28, 29, 40, 63, 79, 83, 87, 107, 123, 124, 128], "drama": [15, 16, 17, 18, 20, 24, 26, 27, 28, 29, 79, 83, 87, 88, 106, 107, 127, 128, 129], "fiction": [15, 26, 28, 29], "145": [40, 120, 123, 124, 126], "invers": [15, 21, 59, 67, 72], "aipw": [15, 59], "proce": [15, 74], "bigg": [15, 17, 21, 40], "flip": 15, "role": [15, 89, 90, 91], "a_ir_i": 15, "logisticregress": [15, 16, 18, 20, 21, 22, 23, 24, 25, 29, 123, 124], "ps_model": [15, 16, 21, 24, 25], "pi_": [15, 21, 77, 117], "predict_proba": [15, 21, 22, 29, 123, 124], "ate_i": [15, 21], "3556423779577757": [], "watch": [15, 26, 27, 59, 82], "356": 15, "sci": [15, 16, 17, 18, 20, 24, 26, 27, 28, 29, 79, 81, 83, 84, 87, 107, 127, 128], "fi": [15, 16, 17, 18, 20, 24, 26, 27, 28, 29, 79, 81, 83, 84, 87, 107, 127, 128], "third": [15, 62, 72, 93, 95, 96], "misspecif": [15, 45, 63, 75, 80, 93, 97, 103], "term": [15, 20, 25, 62, 63, 67, 69, 72, 77, 79, 86, 90, 91], "correct": [15, 32], "correctli": [15, 63, 90, 126], "prove": [15, 16, 20, 21, 25, 47, 62, 63, 68], "mild": [15, 16, 19, 25, 62], "semi": [15, 97, 98, 100, 105, 106, 116], "parametr": [15, 17, 72], "converg": [15, 17, 19, 20, 25, 49, 62, 63, 65, 66, 72, 134], "found": [15, 45, 60, 75, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 128, 130, 132], "15559049518872164": [], "ate_dr": [15, 21], "010294283320549269": [], "slightli": [15, 22, 32, 72, 74, 118, 128], "sequenti": [15, 32, 45, 59, 69, 74, 75, 78, 83, 86, 88, 89, 90, 91, 99, 107], "681": 15, "694": 15, "v": [15, 16, 17, 18, 19, 20, 23, 24, 25, 32, 47, 49, 58, 62, 68, 72, 73, 74, 81, 89, 90, 91, 94, 95, 96, 98, 101, 102, 103, 104, 105, 106, 117], "chetverikov": [15, 17], "demir": [15, 17], "duflo": [15, 17], "hansen": [15, 17], "w": [15, 17, 22, 37, 38, 45, 49, 58, 74, 75, 76, 77, 78, 79, 81, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 106, 107, 116, 117, 122], "newei": [15, 17], "kennedi": [16, 19, 20, 25], "oracl": [16, 19, 20, 24, 25], "theorem": [16, 17, 25, 72, 100, 117], "step": [16, 17, 20, 22, 24, 25, 26, 28, 29, 40, 47, 59, 61, 62, 63, 67, 72, 76, 89, 90, 91, 117, 128, 133], "nuisanc": [16, 18, 20, 23, 25, 59, 62, 63, 67, 72], "i_": [16, 20, 25, 63], "mu_a": [16, 25], "phi": [16, 25, 45, 75, 80, 84, 86, 88, 93, 95, 97, 100, 102, 103, 109, 127, 129], "_a": [16, 20, 25, 81], "_1": [16, 25, 59, 63, 69, 122], "_0": [16, 25, 59], "i_2": [16, 20, 25, 63], "tau": [16, 18, 19, 20, 22, 23, 24, 25, 26, 28, 29, 33, 38, 59, 63, 117], "_n": [16, 20, 24, 25, 59], "single_stag": [15, 16, 17, 18, 20, 24, 25, 26, 28, 29], "_env_getdata_cel": [15, 16, 17, 18, 20, 24, 26, 28, 29], "drlearner": [16, 25], "warn": [16, 17, 20, 24, 27, 45, 49, 58, 59, 61, 75, 77, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 126, 127, 128], "filterwarn": [16, 17, 20, 24, 59, 128], "get_movielens_cel": [15, 16, 17, 18, 20, 24, 26, 28, 29], "drop": [15, 16, 17, 20, 24, 26, 27, 28, 29, 59, 77, 120, 127, 128], "comedi": [15, 16, 17, 18, 20, 24, 26, 27, 28, 29, 79, 82, 83, 85, 86, 87, 106, 107, 127, 128, 129], "thriller": [15, 16, 17, 18, 20, 24, 26, 27, 28, 29, 79, 80, 81, 82, 83, 84, 86, 87, 88, 106, 107, 127, 128, 129], "user_id": [15, 16, 17, 18, 20, 24, 26, 27, 28, 29, 127, 128], "movie_id": [15, 16, 17, 18, 20, 24, 26, 27, 28, 29, 127, 128], "ag": [15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 68, 70, 72, 79, 87, 107, 108, 109, 114, 115, 127, 128, 129], "gender_m": [15, 16, 17, 18, 20, 24, 26, 27, 28, 29, 127, 128], "occupation_academ": [15, 16, 17, 18, 20, 24, 26, 27, 28, 29, 127, 128], "educ": [15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 79, 87, 107, 127, 128, 129], "occupation_colleg": [15, 16, 17, 18, 20, 24, 26, 27, 28, 29, 127, 128], "grad": [15, 16, 17, 18, 20, 24, 26, 27, 28, 29, 79, 80, 81, 86, 87, 107, 127, 128], "occupation_execut": [15, 16, 17, 18, 20, 24, 26, 27, 28, 29, 127, 128], "manageri": [15, 16, 17, 18, 20, 24, 26, 27, 28, 29, 79, 87, 107, 127, 128], "occupation_oth": [15, 16, 17, 18, 20, 24, 26, 27, 28, 29, 128], "occupation_technician": [15, 16, 17, 18, 20, 24, 26, 27, 28, 29, 127, 128], "48": [15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 61, 79, 123, 124, 125, 128], "1193": [15, 16, 17, 18, 20, 24, 26, 27, 28, 29, 127], "919": [15, 16, 17, 18, 20, 24, 26, 27, 28, 29], "527": [15, 16, 17, 18, 20, 24, 26, 27, 28, 29], "1721": [15, 16, 17, 18, 20, 24, 26, 27, 28, 29], "150": [15, 16, 17, 18, 20, 24, 26, 27, 28, 29, 61], "65637": [15, 16, 17, 18, 20, 24, 26, 28, 29], "5878": [15, 16, 17, 18, 20, 24, 26, 27, 28, 29, 128], "3300": [15, 16, 17, 18, 20, 24, 26, 27, 28, 29], "65638": [15, 16, 17, 18, 20, 24, 26, 28, 29], "1391": [15, 16, 17, 18, 20, 24, 26, 27, 28, 29], "65639": [15, 16, 17, 18, 20, 24, 26, 28, 29], "185": [15, 16, 17, 18, 20, 24, 26, 27, 28, 29], "65640": [15, 16, 17, 18, 20, 24, 26, 28, 29], "2232": [15, 16, 17, 18, 20, 24, 26, 27, 28, 29], "65641": [15, 16, 17, 18, 20, 24, 26, 28, 29], "426": [15, 16, 17, 18, 20, 24, 26, 27, 28, 29, 128], "65642": [15, 16, 17, 18, 20, 24, 26, 27, 28, 29], "n_fold": [16, 20, 24, 25], "y_model": [16, 20, 24, 25], "rlearner_model": [16, 24, 25], "hte_dr_learn": [16, 25], "to_numpi": [16, 17, 22, 23, 24, 25, 26, 124, 128], "fold": [16, 24, 25, 59], "r2": [16, 24, 25], "baselearn": [16, 25], "036": 16, "pslearner": [16, 25], "735": 16, "038": 16, "037": [16, 21], "734": [16, 24], "1000": [16, 17, 20, 22, 24, 26, 28, 29, 47, 59, 61, 95, 102, 103, 105, 106, 128, 129], "5000": [16, 17, 24, 26, 27, 28, 29, 128], "05672212": 16, "73726057": 16, "09360586": 16, "ate_dr_learn": 16, "3541": 16, "conclus": [16, 17, 18, 20, 22, 24, 25, 26, 28, 29, 123, 124, 128], "xinkun": [16, 19, 20, 24, 25], "nie": [16, 19, 20, 24, 25, 122, 126], "stefan": [16, 18, 19, 20, 23, 24, 25, 35, 39, 41, 42, 43], "wager": [16, 18, 19, 20, 23, 24, 25, 35, 39, 41, 42, 43], "quasi": [16, 19, 20, 24, 25, 33], "108": [16, 19, 20, 24, 25, 27, 40, 120], "299": [16, 19, 20, 24, 25], "robinson": [16, 19, 20, 24, 25], "root": [16, 19, 20, 24, 25], "econometrica": [16, 19, 20, 24, 25], "econometr": [16, 19, 20, 24, 25, 33], "societi": [16, 19, 20, 24, 25, 45, 75], "931": [16, 19, 20, 24, 25], "954": [16, 19, 20, 24, 25], "edward": [16, 19, 20, 25], "2004": [16, 19, 20, 25, 45, 75], "14497": [16, 19, 20, 25], "der": [16, 19, 20, 25, 37, 122], "laan": [16, 19, 20, 25, 37, 122], "biostatist": [16, 19, 20, 25, 45, 75], "lee": [16, 19, 20, 25], "okui": [16, 19, 20, 25], "whang": [16, 19, 20, 25], "uniform": [16, 19, 20, 25, 59], "band": [16, 19, 20, 25], "1207": [16, 19, 20, 25], "1225": [16, 19, 20, 25, 127], "foster": [16, 19, 20, 25], "syrgkani": [16, 19, 20, 25], "orthogon": [16, 19, 20, 25, 78, 107], "1901": [16, 19, 20, 25], "09036": [16, 19, 20, 25], "guarante": [17, 19, 33, 74, 132], "asymptot": [17, 47, 59, 62, 63, 72, 90, 117], "dml": [17, 18, 23], "plug": [17, 21, 22, 26, 49, 62, 63, 65, 72], "att": 17, "despit": [17, 49, 123, 124], "versatil": 17, "ml": 17, "seem": [17, 123, 124], "criteria": [17, 27, 123, 124, 125], "best": [17, 21, 49, 58, 69, 77, 79, 106, 121, 126, 128], "qualiti": [17, 19], "angl": 17, "innov": 17, "discard": 17, "irrelev": [15, 17, 26], "start": [17, 24, 25, 32, 40, 73, 77, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 108, 109, 114, 115, 123, 124, 128], "minimum": [17, 33], "tmle": 17, "imporv": 17, "finit": [17, 47, 58, 63, 67, 72, 77, 82, 85, 88, 107, 108, 115, 126], "stabil": [17, 132], "amd": 17, "word": [17, 45, 58, 73, 74, 75, 77, 79, 83, 87, 106, 107, 116, 128], "archetectur": 17, "singlestag": 17, "png": [17, 21, 33, 129], "width": 17, "500": [17, 21, 59, 83, 87, 97, 98, 100, 105, 122], "layer": 17, "resourc": [17, 33], "theta": [17, 20, 25, 80, 82, 84, 86, 93, 94, 95, 96, 97, 98, 100, 102, 103, 104, 106, 108, 109, 114, 116, 117, 122], "min_": [17, 20, 24, 25, 40, 59, 62, 65, 66, 117], "nn": [17, 118], "alpha": [17, 18, 23, 40, 59, 63, 68, 73, 74, 80, 81, 86, 88, 93, 96, 104, 109, 117, 129], "crossentropi": 17, "hyperparamet": 17, "tild": [17, 22, 29, 63, 75, 77, 80, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 109, 114], "extra": [17, 128], "beta": [17, 18, 23, 24, 25, 45, 58, 59, 69, 77, 80, 84, 86, 88, 95, 96, 102, 104, 114, 121, 122, 126, 134], "solut": [17, 18, 23, 47, 49, 65, 66, 73, 117, 133], "claudiashi57": 17, "test_output": 17, "train_output": 17, "train_and_predict_dragon": 17, "targeted_regular": 17, "output_dir": 17, "master": [17, 40], "knob_loss": 17, "dragonnet_loss_binarycross": 17, "ratio": [17, 21, 27, 62, 63, 67, 72, 123, 124, 125, 126], "val_split": 17, "64": [17, 18, 23, 61, 126], "am": 17, "elapsed_tim": 17, "285": 17, "40207719802856": 17, "2031": 17, "2s": 17, "898u": 17, "964u": 17, "7404845356941223": 17, "untreat": [17, 33, 38], "7264252305030823": 17, "dict_kei": [17, 27, 128], "q_t0": 17, "q_t1": 17, "ep": 17, "hte_dragonnet": 17, "34005857": 17, "33967185": 17, "46262145": 17, "aaverag": 17, "ate_dragonnet": 17, "3526": 17, "claudia": [17, 19], "blei": [17, 19], "veitch": [17, 19], "33rd": 17, "neurip": 17, "susan": [18, 19, 23, 35, 36, 39, 41, 42, 43], "athei": [18, 19, 23, 35, 36, 39, 41, 42, 43], "juli": [18, 19, 23, 35, 39, 41, 42, 43, 87, 88, 99], "tibshirani": [18, 19, 23, 35, 39, 41, 42, 43], "moment": [18, 23], "psi_": [18, 23, 45, 62, 63, 68, 72, 75], "nu": [18, 23], "o_i": [18, 23, 49], "care": [18, 23, 27, 123, 124, 125, 127], "xi": [18, 23, 62, 72], "induc": [18, 23], "solv": [18, 23, 24, 25, 45, 47, 49, 58, 62, 63, 65, 66, 67, 72, 73, 74, 75, 84, 98, 101, 106, 107, 109, 114, 116, 117], "alpha_i": [18, 23], "otim": [18, 23], "vv": [18, 23], "notic": [18, 23, 80, 96, 97, 104, 109], "formula": [18, 23, 59, 129, 133], "ordinari": [18, 23], "prone": [18, 23], "grf": [18, 19, 23], "quantiti": [18, 23, 38], "grow": [18, 23, 69, 72, 118], "dot": [18, 23, 40, 45, 59, 62, 67, 72, 75, 79, 83, 87, 94, 101, 106, 107, 116, 127, 128, 129, 132], "l_b": [18, 23], "fall": [18, 23, 32, 127], "leaf": [18, 23], "frequenc": [18, 23, 80, 81, 93, 95, 100, 102, 103], "alpha_": [18, 23, 88], "bi": [18, 23], "boldsymbol": [18, 23, 45, 58, 60, 75, 76, 77, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 106, 108, 109, 115, 116, 122, 126], "x_0": [18, 23], "flexibl": [18, 23, 49, 59, 63, 89, 90, 91, 134], "causal_effect_learn": [21, 25], "lprlearner": [18, 20, 25], "_util_causaldm": [18, 22, 23, 25, 45, 58, 59, 60, 129], "econml": [18, 23], "python": [18, 23, 33, 95, 102, 127, 133], "cp39": [], "macosx_10_9_x86_64": [], "whl": 23, "mb": 23, "2k": 23, "90m": 23, "0m": 23, "32m1": [], "31m2": [], "eta": [20, 21, 23, 24, 25, 59, 62, 63, 65, 67, 68, 72, 73, 74, 95, 100, 101, 102, 106, 116], "36m0": 23, "0m00": [], "01": [45, 58, 59, 61, 75, 122, 126, 129], "25hcollect": [], "shap": [18, 23], "41": [23, 58, 61, 124, 128], "40": [21, 23, 40, 59, 61, 75, 120, 123, 126, 129], "433": [], "kb": 23, "32m433": [], "31m3": [], "25hrequir": 23, "scikit": [18, 23, 59, 60], "scipi": [18, 23, 127, 129], "lightgbm": [18, 23, 25, 123, 124, 128], "spars": [18, 23], "py2": 23, "py3": 23, "32m81": [], "81": 61, "joblib": [18, 23], "threadpoolctl": [18, 23], "numba": [18, 23], "slicer": [18, 23], "tqdm": [18, 23, 123, 124], "cloudpickl": [18, 23], "patsi": [18, 23], "dateutil": [18, 23], "pytz": [18, 23], "wheel": 23, "35": [21, 40, 59, 61, 127, 128, 129], "llvmlite": [18, 23], "39": [18, 23, 40, 45, 59, 61, 127], "0rc1": 18, "setuptool": [18, 23], "pypars": 18, "six": [18, 23, 132, 133], "successfulli": [23, 59], "demo": [18, 23, 61, 133], "causalforest": [18, 23], "causalivforest": [18, 23], "regressionforest": [18, 23], "causalforestdml": [18, 23], "est": [18, 23], "criterion": [18, 23], "het": [18, 23], "n_estim": [18, 23], "400": [18, 21, 23, 61], "min_samples_leaf": [18, 23], "min_var_fraction_leaf": [18, 23], "min_var_leaf_on_v": [18, 23], "min_impurity_decreas": [18, 23], "max_sampl": [18, 23], "45": [18, 23, 59, 61, 128, 129], "min_balancedness_tol": [18, 23], "warm_start": [18, 23], "fit_intercept": [18, 23, 47], "subforest_s": [18, 23], "honest": [18, 23], "n_job": [18, 23, 47, 126], "random_st": [18, 23, 126], "1235": [18, 23], "hte_grf": [18, 23], "05": [18, 23, 33, 59, 122, 126], "flatten": [18, 21, 23, 69, 121, 126], "900": [18, 20, 126], "3605": [], "3783": [], "3646": [], "ate_grf": 18, "358": 18, "47": [18, 19, 23, 27, 33, 35, 39, 41, 42, 43, 61, 82, 85, 107, 108, 115, 123, 124, 125, 126], "1148": [18, 19, 23, 35, 39, 41, 42, 43], "1178": [18, 19, 23, 35, 39, 41, 42, 43], "setup": [19, 24, 25, 47, 61, 62, 63, 101, 117, 118, 132], "triplet": [19, 73, 74, 132], "trajectori": [19, 40, 67, 72, 73, 74, 117, 132], "imagin": 19, "terminolog": 19, "recommend": [19, 27, 45, 47, 49, 58, 61, 75, 77, 78, 79, 83, 87, 94, 99, 101, 122, 126, 128, 129], "adversit": 19, "impact": [19, 33, 69, 123, 124, 126], "annual": [19, 38, 40], "incom": [19, 101, 102, 103, 104, 128], "expos": [19, 26, 33, 40], "pictur": [19, 59], "dress": 19, "femal": [19, 21, 79, 128], "male": [19, 79, 80, 81, 86, 87, 107, 128], "clearli": [19, 132], "granular": 19, "averg": 19, "characsterist": 19, "subsect": [19, 27, 38, 72], "briefli": [19, 38, 78, 107], "lp": 19, "forest": [19, 35, 39, 41, 42, 43], "dragonnet": 19, "paper": [19, 20, 25, 117], "pleas": [19, 20, 22, 25, 29, 133], "easiest": [19, 22, 24, 25, 59], "apporach": 19, "enough": [19, 63, 128, 130], "complic": [19, 22, 28, 63], "worth": [19, 32, 40, 100], "sensibl": 19, "trend": [19, 22, 33, 40, 79, 114, 115, 132], "cancel": 19, "tend": [19, 22, 40], "particularli": [19, 45, 58, 75, 77], "larger": [19, 28, 40, 45, 58, 60, 63, 72, 75, 77], "part": [19, 33, 40, 59, 63, 69, 117, 121, 130, 132], "boost": [19, 59], "acheiv": 19, "alwai": [19, 45, 58, 63, 79, 83, 84, 87, 96, 98, 104, 107, 109, 114, 126], "faster": [19, 49, 63, 72], "might": [19, 61, 62, 123, 126], "computation": [19, 68, 95, 100, 102, 104, 118], "polynomi": [19, 20, 25], "tradeoff": [19, 63], "inherit": 19, "dragon": 19, "net": 19, "outperform": [19, 80, 93, 96, 97, 98, 103, 104, 128], "kunzel": [19, 22, 26, 28, 29], "sekhon": [19, 22, 26, 28, 29], "bickel": [19, 22, 26, 28, 29], "metalearn": [19, 22, 26, 28, 29], "nation": [19, 22, 26, 28, 29], "academi": [19, 22, 26, 28, 29], "116": [19, 22, 26, 28, 29, 36, 40, 45, 58, 89, 90, 91, 120, 122], "4156": [19, 22, 26, 28, 29], "4165": [19, 22, 26, 28, 29], "alicia": 19, "curth": 19, "mihaela": 19, "schaar": 19, "1810": 19, "1818": 19, "residu": [20, 24, 25, 126], "cross": [20, 25, 59], "relax": [20, 25, 32, 63, 132], "breviti": [20, 25], "1b": [20, 25], "basi": [20, 25, 62, 69, 72, 86, 121], "k_": [20, 25], "hs": [20, 25], "bandwidth": [20, 25, 49], "mu_1": [20, 22, 25, 28, 29], "mu_0": [20, 22, 25, 28, 29], "estimt": [20, 25], "_b": [20, 25], "_r": [20, 25], "s_0": [20, 25, 32, 63, 73, 74, 117], "repeat": [20, 25, 77, 107, 117], "twice": [20, 25], "n_": [20, 25, 40], "samplem": [20, 25], "tradit": [20, 25, 33, 67], "milder": [20, 25, 63], "ps_model_a": [20, 25], "ps_model_b": [20, 25], "lprlearner_model": [20, 25], "sample_index": 20, "tolist": [20, 120, 123, 124, 127, 128, 129], "hte_lp_r_learn": [20, 25], "42175269": [], "52461763": [], "13400663": [], "ate_lp_r_learn": 20, "2182": [], "influnc": 21, "treamtent": 21, "borrow": 21, "necess": 21, "birth": 21, "pill": 21, "incid": 21, "thrombosi": 21, "pregnanc": 21, "want": [21, 58, 59, 75, 77, 96, 130, 133], "sens": [21, 62, 63, 72], "marit": 21, "reliabl": [21, 45, 58, 61, 75, 77], "iid": 21, "treament": 21, "a_0": [21, 63, 69, 74, 117], "a_1": [21, 69, 74, 117, 122, 126], "m_a": 21, "r_": [21, 32, 58, 60, 62, 63, 65, 66, 67, 72, 73, 74, 75, 79, 81, 83, 85, 86, 87, 88, 93, 95, 97, 100, 106, 107, 115, 116, 132], "m_": 21, "imai": 21, "m_0": [21, 24, 25, 69], "suffic": 21, "rho": [21, 59, 62, 67, 72], "p_a": 21, "shift": [21, 47, 117, 132], "tchetgen": [21, 126], "shpitser": [21, 126], "aurora_cel": 21, "survey_r": [], "hispan": 21, "white": 21, "trauma": 21, "health": [21, 32, 69, 123, 124, 127], "mental": 21, "chronic": 21, "percept": 21, "stress": 21, "neurotic": 21, "childhood": 21, "insomnia": 21, "cont": [21, 49], "peritraumat": 21, "distress": 21, "w2": 21, "acut": 21, "disord": 21, "ptsd": 21, "depress": 21, "month": [21, 60], "hist": [21, 59, 120, 123], "bin": [21, 59, 128], "326": [21, 45, 75], "274": 21, "242": 21, "187": [21, 27, 69, 120, 121], "148": [21, 120, 123], "109": [21, 40, 105], "55287818": 21, "75287818": 21, "95287818": 21, "15287818": 21, "64712182": 21, "44712182": 21, "24712182": 21, "04712182": 21, "84712182": 21, "barcontain": [21, 123], "artist": [21, 123, 127], "aurora_cel_md": 21, "folder": [21, 130, 133], "9j": 21, "vb5nb4rd5bx0gr1q5ytx9q600000gn": 21, "ipykernel_35787": 21, "2568975421": 21, "settingwithcopywarn": [21, 120, 123], "caveat": [21, 120, 123], "pydata": [21, 120, 123], "org": [21, 23, 120, 123], "user_guid": [21, 120, 123], "html": [21, 60, 120, 123, 130], "mediation_analysi": 21, "me_singl": [21, 126], "control_polici": [21, 69, 121, 126], "dim_stat": [21, 69, 121, 122, 126], "get_a": [21, 69, 121, 126], "action_valu": [21, 69, 121, 126], "shape": [21, 40, 61, 69, 75, 121, 126, 127], "target_polici": [21, 69, 121, 126], "pa": [21, 33, 69, 121, 126], "prob_arr": [21, 69, 121, 126], "valueerror": [21, 69, 121, 126], "problearner_paramet": [21, 69, 121, 126], "splitter": [21, 69, 121, 126], "direct_est": [21, 126], "r_model": [21, 69, 121, 126], "ol": [21, 58, 69, 121, 126], "truncat": [21, 67, 69, 72, 121, 126], "dim_medi": [21, 69, 121, 122, 126], "expectation_mcmc_it": 21, "nature_decomp": [21, 69, 121, 126], "estimate_de_m": [21, 69, 121, 126], "est_d": [21, 126], "est_m": [21, 126], "est_t": [21, 126], "5699712042262648": 21, "35390067425173": 21, "923871878477995": 21, "ipw_est": [21, 126], "1833766092547435": 21, "0830496488123182": 21, "266426258067062": 21, "robust_est": [21, 69, 121, 126], "082810672178048": 21, "6367679712306544": 21, "7195786434087026": 21, "robust_d": 21, "robust_i": 21, "robust_t": 21, "mediator_1d": 21, "aurora_cel_1d": 21, "mediators_index": 21, "append": [21, 49, 61, 127, 128, 129], "four": [21, 69, 78, 79, 86, 87, 95, 98, 100, 102, 121, 128], "083": 21, "637": 21, "720": [21, 61], "262": 21, "234": 21, "496": 21, "017": [21, 24], "435": [21, 128], "452": 21, "699": 21, "465": 21, "748": [21, 120, 123], "214": [21, 22, 75, 79, 81], "131861": 21, "151941": 21, "741954": 21, "476881": 21, "776439": 21, "879518": 21, "062249": 21, "868139": 21, "848059": 21, "081954": 21, "706881": 21, "223561": 21, "937751": 21, "718046": 21, "393119": 21, "418046": 21, "323119": 21, "241954": 21, "483119": 21, "1489": 21, "641954": 21, "506881": 21, "120482": 21, "1490": 21, "321954": 21, "656881": 21, "1491": 21, "841954": 21, "146881": 21, "1492": [21, 22], "231954": 21, "216881": 21, "1493": 21, "441954": 21, "333119": 21, "1494": 21, "3238214724070896": 21, "583008488326464": 21, "6766993378439592": 21, "0005208102510488": 21, "636768": 21, "719579": 21, "324": [21, 78], "covid19_cel": 21, "292852": 21, "637413": 21, "913318": 21, "513904": 21, "951952": 21, "795226": 21, "010544": 21, "147116": 21, "071851": 21, "266743": 21, "045451": 21, "026626": 21, "794902": 21, "157263": 21, "012273": 21, "940021": 21, "693004": 21, "797915": 21, "500000": [21, 27, 120, 122, 123], "427091": 21, "792291": 21, "098134": 21, "176879": 21, "740606": 21, "069790": 21, "111048": 21, "927152": 21, "917465": 21, "264442": 21, "065442": 21, "042891": 21, "762210": 21, "123276": 21, "971190": 21, "944849": 21, "717563": 21, "782914": 21, "095238": 21, "760591": 21, "172900": 21, "868353": 21, "536234": 21, "939283": 21, "098691": 21, "088660": 21, "262078": 21, "735539": 21, "208682": 21, "955573": 21, "069427": 21, "698803": 21, "084979": 21, "902696": 21, "899230": 21, "633096": 21, "769921": 21, "477273": 21, "454398": 21, "250654": 21, "939562": 21, "149566": 21, "784729": 21, "779052": 21, "719391": 21, "173107": 21, "448533": 21, "226761": 21, "964872": 21, "125997": 21, "729486": 21, "135069": 21, "921326": 21, "925182": 21, "662126": 21, "828047": 21, "400000": [21, 120, 122], "140390": 21, "108600": 21, "047156": 21, "815548": 21, "533363": 21, "173536": 21, "308488": 21, "199351": 21, "838208": 21, "107659": 21, "944363": 21, "028927": 21, "715424": 21, "018883": 21, "925700": 21, "820400": 21, "639058": 21, "878947": 21, "807692": 21, "062158": 21, "586850": 21, "469484": 21, "326334": 21, "479242": 21, "650710": 21, "264352": 21, "682694": 21, "736854": 21, "204114": 21, "037254": 21, "075291": 21, "779771": 21, "060582": 21, "021507": 21, "796522": 21, "680173": 21, "951977": 21, "294326": 21, "530267": 21, "571570": 21, "428835": 21, "473093": 21, "179841": 21, "077723": 21, "149741": 21, "637036": 21, "281233": 21, "046941": 21, "168571": 21, "811361": 21, "052676": 21, "972389": 21, "864756": 21, "701395": 21, "995490": 21, "109589": 21, "897320": 21, "382069": 21, "289806": 21, "041032": 21, "683110": 21, "672166": 21, "529203": 21, "909618": 21, "029841": 21, "250219": 21, "108112": 21, "210270": 21, "863557": 21, "155546": 21, "055981": 21, "000739": 21, "749153": 21, "995393": 21, "192593": 21, "482535": 21, "164017": 21, "656821": 21, "651928": 21, "708246": 21, "588910": 21, "148011": 21, "490420": 21, "440770": 21, "347127": 21, "144951": 21, "270242": 21, "921650": 21, "215292": 21, "102442": 21, "982433": 21, "801220": 21, "037740": 21, "287785": 21, "171677": 21, "030898": 21, "854759": 21, "128409": 21, "576126": 21, "770616": 21, "191284": 21, "435813": 21, "084196": 21, "605906": 21, "307340": 21, "474589": 21, "099494": 21, "373177": 21, "253232": 21, "124960": 21, "867672": 21, "146863": 21, "136656": 21, "894203": 21, "635793": 21, "820545": 21, "845285": 21, "278246": 21, "950636": 21, "930212": 21, "173367": 21, "965229": 21, "370520": 21, "184868": 21, "296518": 21, "052125": 21, "178420": 21, "140642": 21, "001873": 21, "828338": 21, "050149": 21, "080622": 21, "782546": 21, "214282": 21, "914472": 21, "644101": 21, "630285": 21, "992847": 21, "822527": 21, "474421": 21, "188018": 21, "345831": 21, "115597": 21, "228738": 21, "996008": 21, "097064": 21, "981428": 21, "926802": 21, "829375": 21, "990533": 21, "013089": 21, "192243": 21, "280890": 21, "643705": 21, "702932": 21, "017906": 21, "253913": 21, "882940": 21, "059254": 21, "509737": 21, "164002": 21, "993222": 21, "934286": 21, "946955": 21, "993287": 21, "844765": 21, "716947": 21, "736582": 21, "871981": 21, "112732": 21, "649070": 21, "621102": 21, "116686": 21, "858802": 21, "429514": 21, "851297": 21, "776376": 21, "181538": 21, "740580": 21, "935064": 21, "719345": 21, "759164": 21, "641585": 21, "651791": 21, "540918": 21, "933250": 21, "507287": 21, "469476": 21, "082212": 21, "603982": 21, "724633": 21, "303232": 21, "312939": 21, "179535": 21, "980677": 21, "236501": 21, "528457": 21, "656411": 21, "327752": 21, "076134": 21, "299791": 21, "936846": 21, "181952": 21, "839581": 21, "539065": 21, "909695": 21, "693490": 21, "226519": 21, "528723": 21, "417358": 21, "668425": 21, "043352": 21, "848219": 21, "364526": 21, "062001": 21, "410301": 21, "871230": 21, "475528": 21, "144627": 21, "231135": 21, "126969": 21, "357398": 21, "983761": 21, "193422": 21, "097615": 21, "838285": 21, "171171": 21, "876705": 21, "463145": 21, "434180": 21, "511868": 21, "921547": 21, "050862": 21, "366664": 21, "753326": 21, "281971": 21, "309997": 21, "980845": 21, "002650": 21, "022058": 21, "032005": 21, "805918": 21, "060452": 21, "125673": 21, "747338": 21, "035326": 21, "606716": 21, "988680": 21, "813622": 21, "686867": 21, "432760": 21, "928552": 21, "074092": 21, "395144": 21, "947214": 21, "112098": 21, "881150": 21, "896476": 21, "002845": 21, "916207": 21, "701719": 21, "867089": 21, "964613": 21, "667084": 21, "028169": 21, "524647": 21, "808017": 21, "606230": 21, "339734": 21, "215940": 21, "950746": 21, "921715": 21, "220864": 21, "834689": 21, "039230": 21, "792536": 21, "855976": 21, "924145": 21, "838933": 21, "679882": 21, "776855": 21, "864724": 21, "625158": 21, "194203": 21, "376806": 21, "638014": 21, "428127": 21, "903468": 21, "053162": 21, "893333": 21, "826913": 21, "059934": 21, "711601": 21, "905191": 21, "597521": 21, "799891": 21, "754369": 21, "733082": 21, "605912": 21, "650462": 21, "715133": 21, "540011": 21, "086331": 21, "324318": 21, "604902": 21, "240240": 21, "678514": 21, "941771": 21, "853870": 21, "713999": 21, "979322": 21, "616151": 21, "712055": 21, "463547": 21, "557215": 21, "588222": 21, "473332": 21, "490730": 21, "426028": 21, "610805": 21, "424375": 21, "129921": 21, "425470": 21, "787702": 21, "371460": 21, "939302": 21, "995036": 21, "940572": 21, "799697": 21, "127974": 21, "644533": 21, "808024": 21, "487328": 21, "679655": 21, "636077": 21, "505732": 21, "551934": 21, "427194": 21, "720673": 21, "465912": 21, "119910": 21, "512886": 21, "614200": 21, "222873": 21, "902820": 21, "931370": 21, "935323": 21, "742122": 21, "076328": 21, "511175": 21, "659210": 21, "398034": 21, "508583": 21, "481010": 21, "334271": 21, "442130": 21, "314993": 21, "574808": 21, "323708": 21, "012853": 21, "231297": 21, "336565": 21, "064632": 21, "691572": 21, "771898": 21, "755795": 21, "555790": 21, "826524": 21, "377654": 21, "463709": 21, "298825": 21, "384718": 21, "390226": 21, "231304": 21, "293252": 21, "237298": 21, "407236": 21, "208753": 21, "187500": 21, "095703": 21, "326748": 21, "995069": 21, "561226": 21, "689310": 21, "758128": 21, "536836": 21, "751842": 21, "328633": 21, "442843": 21, "317066": 21, "344704": 21, "432572": 21, "222232": 21, "263768": 21, "236682": 21, "413294": 21, "201139": 21, "134615": 21, "112065": 21, "308668": 21, "848588": 21, "496653": 21, "631476": 21, "753268": 21, "488916": 21, "658012": 21, "287518": 21, "452855": 21, "368485": 21, "305532": 21, "549990": 21, "226249": 21, "283597": 21, "255247": 21, "420746": 21, "231887": 21, "174074": 21, "123373": 21, "341781": 21, "936619": 21, "448701": 21, "607144": 21, "780030": 21, "488851": 21, "602057": 21, "247115": 21, "512957": 21, "437562": 21, "307703": 21, "774619": 21, "272419": 21, "290434": 21, "297724": 21, "444755": 21, "256219": 21, "255605": 21, "095412": 21, "440439": 21, "013504": 21, "414357": 21, "610546": 21, "890255": 21, "512341": 21, "571795": 21, "249934": 21, "600437": 21, "716202": 21, "380214": 21, "153991": 21, "348203": 21, "350406": 21, "359122": 21, "605135": 21, "347911": 21, "289157": 21, "086858": 21, "482754": 21, "947506": 21, "316801": 21, "626033": 21, "920290": 21, "583686": 21, "558284": 21, "269568": 21, "595220": 21, "123405": 21, "366314": 21, "195333": 21, "334984": 21, "400108": 21, "395086": 21, "606463": 21, "410411": 21, "271186": 21, "437782": 21, "738454": 21, "033301": 21, "221707": 21, "695304": 21, "084946": 21, "659016": 21, "564570": 21, "292928": 21, "551027": 21, "872629": 21, "374933": 21, "788778": 21, "311137": 21, "351248": 21, "413392": 21, "450814": 21, "372341": 21, "360465": 21, "015837": 21, "396958": 21, "901724": 21, "952949": 21, "620428": 21, "857758": 21, "526792": 21, "436590": 21, "248962": 21, "437627": 21, "522839": 21, "301417": 21, "502103": 21, "274428": 21, "232308": 21, "308740": 21, "295520": 21, "225860": 21, "090909": [21, 123, 124, 126], "995587": 21, "330279": 21, "886270": 21, "834527": 21, "656683": 21, "879530": 21, "525366": 21, "432540": 21, "286967": 21, "518789": 21, "455188": 21, "322412": 21, "449485": 21, "348494": 21, "236520": 21, "295650": 21, "286870": 21, "214488": 21, "873563": 21, "957841": 21, "388632": 21, "875351": 21, "830671": 21, "674438": 21, "940637": 21, "531976": 21, "439182": 21, "316094": 21, "531587": 21, "445144": 21, "340297": 21, "448254": 21, "360742": 21, "249350": 21, "296428": 21, "302875": 21, "213581": 21, "424242": 21, "33": [21, 27, 40, 61, 98], "025266": 21, "409206": 21, "826394": 21, "816610": 21, "645473": 21, "057374": 21, "544352": 21, "409633": 21, "348300": 21, "458590": 21, "384232": 21, "315997": 21, "400205": 21, "328763": 21, "280001": 21, "247244": 21, "280584": 21, "213905": 21, "052632": 21, "34": [21, 40, 49, 59, 61, 86, 87, 88], "847292": 21, "199707": 21, "807311": 21, "791759": 21, "614239": 21, "896800": 21, "520700": 21, "434322": 21, "364986": 21, "516326": 21, "421654": 21, "294775": 21, "432475": 21, "319950": 21, "318913": 21, "210438": 21, "269082": 21, "239209": 21, "000000": [21, 27, 69, 120, 121, 122, 123, 124, 126], "419055": 21, "741241": 21, "908431": 21, "955282": 21, "779803": 21, "225012": 21, "722066": 21, "528898": 21, "528379": 21, "663617": 21, "538099": 21, "322801": 21, "482760": 21, "354683": 21, "398066": 21, "240667": 21, "335632": 21, "288036": 21, "444444": [21, 27], "36": [21, 40, 59, 61, 97], "159110": 21, "644332": 21, "912514": 21, "006085": 21, "814860": 21, "225400": 21, "734929": 21, "505570": 21, "716072": 21, "881734": 21, "582487": 21, "436298": 21, "607565": 21, "509652": 21, "551902": 21, "411350": 21, "418997": 21, "459529": 21, "645161": 21, "37": [21, 40, 45, 47, 59, 61, 123], "304294": 21, "796126": 21, "914522": 21, "095768": 21, "906228": 21, "343434": 21, "856688": 21, "531166": 21, "808380": 21, "997596": 21, "624607": 21, "522742": 21, "600113": 21, "597650": 21, "659275": 21, "439279": 21, "510786": 21, "363636": [21, 120, 123, 124, 126], "movielens_cel_md": 21, "730690894257576": 21, "13369489173373478": 21, "5969960025238406": 21, "143298762540704": 21, "5474864933099358": 21, "595812269230768": 21, "592741884817156": 21, "001726777600432909": 21, "594468662417588": 21, "438": [21, 94, 96], "918": 21, "521": 21, "709": 21, "842": 21, "867": 21, "922": 21, "248": [21, 61], "453": 21, "053": 21, "216": 21, "969": [21, 126], "247": [21, 120], "952": 21, "367": 21, "586": 21, "989": 21, "235": [21, 82, 85, 107, 108, 115, 128], "619": 21, "516": [21, 47], "016": 21, "311": [21, 83, 127], "924": [21, 126], "731": [21, 22, 23, 25], "812": 21, "421": [21, 83, 102, 103], "679": 21, "742": 21, "251": 21, "134": [21, 40], "117": [21, 40, 45, 58, 59, 128], "399": 21, "136": [21, 27, 123, 126], "263": 21, "593": 21, "594": 21, "771": 21, "163": [21, 120, 122, 131], "608": 21, "629": 21, "323": 21, "306": [21, 127], "717": 21, "192": [21, 27, 126], "909": 21, "197": [21, 126], "141": [21, 40, 120, 126], "416": [21, 126], "153": [21, 61, 83, 128], "570": 21, "485": 21, "543": 21, "408": [21, 97], "512": 21, "404": 21, "437": 21, "154": [21, 40, 59, 120, 122], "598": 21, "165": [21, 33], "149": [21, 40, 59, 128], "473": 21, "062": [21, 128], "176": [21, 83], "241": [21, 75], "103": [21, 40, 120, 123], "493": [21, 40], "510": 21, "hick": 21, "raymond": 21, "dustin": 21, "tinglei": 21, "2011": [21, 33, 79, 81, 89, 90, 91, 103], "stata": 21, "605": 21, "hong": [21, 87, 126], "guanglei": 21, "biometr": [21, 47, 126], "alexandria": 21, "va": 21, "usa": 21, "2401": [21, 126], "2415": [21, 126], "kosuk": 21, "luke": 21, "keel": 21, "309": [21, 33, 83, 101, 127], "probabilist": [21, 94, 95, 102], "373": 21, "392": 21, "ilya": 21, "1816": [21, 98, 126], "foundament": [22, 26], "esitm": [22, 26], "supervis": [22, 26, 28, 29], "n0": [22, 23, 25, 59], "mc": [22, 23, 25, 59, 117], "223": [22, 23, 25, 59, 128], "data_behavior": [22, 23, 25], "get_data_simul": [22, 23, 25, 59], "data_target": [22, 23, 25], "hte_tru": [22, 23, 25], "unboundlocalerror": [22, 23], "229": [], "226": [], "s1": [22, 23, 25, 59, 61, 126], "s_1": [22, 23, 69, 74, 117], "s2": [22, 23, 25, 59, 61, 126], "s_2": [22, 23], "227": [22, 23, 120, 122], "referenc": [22, 23], "034775": [22, 59], "453145": [22, 59], "167637": 22, "084880": [22, 59], "234459": [22, 59], "553798": 22, "144626": [22, 59], "040543": [22, 59], "956732": 22, "148426": [22, 59], "021139": [22, 59], "095578": 22, "120852": [22, 59], "377594": [22, 59], "323133": 22, "995": [22, 59], "022440": [22, 59], "887551": [22, 59], "797542": 22, "996": [22, 59], "411179": [22, 59], "655833": [22, 59], "722846": 22, "997": [22, 59], "155706": [22, 59], "992197": [22, 59], "140100": 22, "998": [22, 59], "510241": [22, 59], "828438": [22, 59], "167118": 22, "999": [22, 59, 102, 104], "744187": [22, 59], "857147": [22, 59], "458481": 22, "lgbmregressor": [22, 25, 123, 124, 128], "hstack": [22, 26, 45, 61, 75, 120, 124], "hte_s_learn": [22, 26, 124], "1687": 22, "589": 22, "0319": 22, "8354": 22, "5843": 22, "4577": 22, "0791": [22, 98], "2961": [22, 23, 25], "4475": [22, 23, 25], "2863": [22, 23, 25], "4471": [22, 23, 25], "1839": [22, 23, 25], "3869": [22, 23, 25, 128], "238": [22, 23, 25], "bias_s_learn": 22, "variance_s_learn": 22, "2857192464627009": 22, "079505077680185": 22, "toi": 22, "although": [22, 32, 63, 68, 123, 124], "cover": [22, 32], "mu0": [22, 28, 29, 123, 124], "mu1": [22, 28, 29, 61, 123, 124], "hte_t_learn": [22, 28, 123, 124], "glanc": 22, "8733": 22, "6596": 22, "3087": 22, "2298": 22, "5598": 22, "8211": 22, "bias_t_learn": 22, "variance_t_learn": 22, "29138198450323705": 22, "810391408711312": 22, "overfit": [22, 28], "provabl": [22, 29, 107], "imput": [22, 29], "delta": [22, 29, 33, 86, 88], "tau_1": [22, 29, 33], "tau_0": [22, 29, 33], "s_t0": [22, 29], "s_t1": [22, 29], "r_t0": [22, 29], "r_t1": [22, 29], "unobserv": [22, 29, 118, 132], "origin": [22, 27, 29, 45, 58, 59, 60, 88, 117, 123, 124, 125], "n_t0": [22, 29], "n_t1": [22, 29], "delta0": [22, 29], "delta1": [22, 29], "tau0": [22, 29], "tau1": [22, 29], "hte_x_learn": [22, 29], "9341": 22, "9235": 22, "2944": 22, "4147": 22, "5443": 22, "roughli": [22, 62, 63, 132], "catch": 22, "synthet": [22, 38, 132], "bias_x_learn": 22, "variance_x_learn": 22, "2827518068171628": 22, "7686646616779012": 22, "worst": 22, "pypi": 23, "pkg": 23, "dev": 23, "colab": 23, "cp38": 23, "manylinux_2_17_x86_64": 23, "manylinux2014_x86_64": 23, "32m3": 23, "31m96": 23, "usr": 23, "dist": 23, "77": [23, 59, 61, 79], "32m77": 23, "31m12": 23, "manylinux2010_x86_64": 23, "571": 23, "32m571": 23, "31m58": 23, "56": [23, 49, 61, 79, 87, 107, 127, 128], "importlib": 23, "0dev0": 23, "57": [23, 59, 61, 126], "zipp": 23, "2344": 23, "612": 23, "7801": 23, "6886": 23, "6297": 23, "4417": 23, "819": 23, "okai": 23, "bias_grf": 23, "variance_grf": 23, "706857912147952": 23, "198946462195667": 23, "came": [24, 25], "g_0": [24, 25], "u": [24, 25, 63, 85, 115, 128, 130], "manipul": [24, 25], "l_0": [24, 25], "rlearner": [24, 25], "hte_r_learn": [24, 25], "y_learner": [24, 25], "019": 24, "ps_learner": [24, 25], "015": [24, 129], "739": 24, "740": 24, "736": 24, "725": [24, 27], "028": [24, 128], "031": 24, "030": 24, "05127254": 24, "08881288": 24, "10304225": 24, "ate_r_learn": 24, "0755": 24, "942": [25, 126], "943": [25, 98, 126], "958": 25, "966": 25, "951": 25, "948": 25, "957": 25, "932": [25, 127], "950": 25, "944": [25, 126], "683": [25, 69], "659": 25, "705": 25, "677": [25, 127], "667": [25, 127], "642": [25, 27], "669": 25, "4971": 25, "0231": 25, "0514": 25, "0037": 25, "0943": 25, "4128": 25, "1436": 25, "4714": 25, "bias_r_learn": 25, "variance_r_learn": 25, "010664510462813687": 25, "3201771635462656": 25, "amaz": 25, "significantli": [25, 69, 121], "980": [25, 59], "978": 25, "947": 25, "975": [25, 126], "946": 25, "940": [25, 126], "2566": 25, "0408": 25, "8131": 25, "0906": 25, "5665": 25, "7341": 25, "6459": 25, "272": [25, 126], "bias_dr_learn": 25, "variance_dr_learn": 25, "29436318987432813": 25, "011818461500106": 25, "lp_r": 25, "0353": 25, "2368": 25, "0444": 25, "0884": 25, "6845": 25, "6876": 25, "6223": 25, "85": [25, 61], "bias_lp_r_learn": 25, "variance_lp_r_learn": 25, "2909913487561472": 25, "1822936738050482": 25, "incred": 25, "cc": [], "comparison": [26, 45, 67, 75, 118], "13686218": [], "52931381": [], "10841595": [], "ate_s_learn": 26, "1453": [101, 104, 105], "dislik": 27, "scope": [27, 32], "getcwd": [68, 70, 72, 108, 109, 114, 115, 129], "onlin": [74, 79, 83, 87, 95, 100, 102, 103, 106, 107, 108, 109, 114, 115, 116, 118, 130, 132, 133], "cmab": [27, 80, 81, 128, 129], "_env_realcmab": [27, 80, 81, 128], "env": [80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115, 128, 129], "get_movielen": 27, "xs": [27, 86, 95, 100, 102, 103, 127], "mean_ri": [27, 127], "standardized_x": [27, 127], "data_ml": 27, "users_index": 27, "movie_gener": [27, 128], "data_cel": 27, "concat": [27, 59, 120, 127, 128], "complet": [27, 45, 69, 75, 86, 88, 127], "4220": 27, "2355": 27, "14400": 27, "2918": 27, "16752": 27, "2791": 27, "20195": 27, "2797": 27, "21689": 27, "2321": 27, "393463": 27, "3299": 27, "395410": 27, "892": [27, 126], "396058": 27, "574": [27, 127], "397794": 27, "1812": 27, "400719": 27, "3830": 27, "49563": 27, "data_cel_al": 27, "to_csv": [27, 120, 123, 128], "11057": 27, "25871": 27, "31166": 27, "40383": 27, "303406": 27, "320275": 27, "332011": 27, "382221": 27, "397209": 27, "65": [27, 40, 45, 49, 59, 61, 75, 129], "175": [27, 69, 83, 87, 120, 121, 123], "save": [27, 67, 86, 128, 130], "www": [27, 33], "kaggl": [27, 33, 123, 124, 125], "asjad99": 27, "mimiciii": 27, "access": [27, 123, 124, 125, 130], "center": [27, 123, 124, 125], "databas": [27, 123, 124, 125], "clinic": [27, 32, 33, 78, 107, 123, 124, 125], "61": [27, 58, 59, 61, 123, 124, 125], "admiss": [27, 123, 124, 125], "boston": [27, 123, 124, 125], "teach": [27, 123, 124, 125], "hospit": [27, 123, 124, 125], "demograph": [27, 123, 124, 125], "vital": [27, 89, 90, 91, 123, 124, 125], "lab": [27, 123, 124, 125], "cohort": [27, 123, 124, 125], "sepsi": [27, 123, 124, 125], "meet": [27, 123, 124, 125], "ventil": 27, "particular": [27, 59, 62, 72, 117, 128, 132], "characterist": [27, 132], "physiolog": 27, "whole": [27, 59], "mimic3_sepsis_data": 27, "mimic3_data": [27, 120, 123, 124], "bloc": [27, 69, 120, 121], "icustayid": [27, 69, 120, 121, 123, 124, 126], "charttim": 27, "gender": [27, 79, 87, 107, 128, 129], "elixhaus": 27, "re_admiss": 27, "died_in_hosp": 27, "died_within_48h_of_out_tim": [27, 120, 123, 124, 125], "mortality_90d": 27, "input_tot": 27, "input_4hourli": 27, "output_tot": 27, "output_4hourli": 27, "cumulated_bal": 27, "sofa": [27, 69, 120, 121, 122, 125, 126], "sir": 27, "vaso_input": 27, "iv_input": [27, 69, 120, 121, 122, 123, 124, 126], "7245486000": 27, "17639": 27, "826435": 27, "6527": 27, "0000": [27, 126], "13617": 27, "520": 27, "7090": 27, "884898": 27, "6898241400": 27, "30766": 27, "069028": 27, "383136": 27, "5805732000": 27, "12049": 27, "217303": 27, "976040": 27, "4264269300": 27, "30946": 27, "970000": 27, "1300": 27, "340": 27, "160": [27, 83], "960": [27, 105], "125000": [27, 123, 124, 126], "5707825200": 27, "19793": 27, "588912": 27, "9552": 27, "6830": 27, "2722": 27, "457625": 27, "7214122800": 27, "24524": 27, "747419": 27, "10661": 27, "0483": 27, "5746": 27, "360": 27, "4915": 27, "049099": 27, "glucos": [27, 69, 120, 121, 122, 123, 124, 125, 126], "pao2": [27, 120, 123, 124, 125, 126], "pao2_fio2": [27, 69, 120, 121, 122, 123, 124, 125, 126], "mimic3_data_select": 27, "84": [27, 58, 59, 61], "168": [27, 120, 122, 123], "122": [27, 40], "59": [27, 47, 61, 123, 126], "198": 27, "148148": 27, "125": [27, 40, 120, 122], "690": 27, "647482": 27, "110": [27, 40, 120, 123], "727273": 27, "179": [27, 126], "499993": 27, "347": 27, "222222": 27, "4995": 27, "375000": 27, "787683": 27, "206": [27, 69, 120, 121, 123, 126], "005547": 27, "965110": 27, "4996": 27, "333333": [27, 120], "143": [27, 40, 83, 126], "846153": 27, "025000": 27, "4997": 27, "106": [27, 40, 120, 123, 124, 126], "258": 27, "923": 27, "214286": 27, "402531": 27, "4998": 27, "144": [27, 69, 120, 121], "376": [27, 45], "752": [27, 120, 123], "172130": 27, "4999": 27, "269": 27, "999996": 27, "data_cel_select": [27, 123, 124], "oxygen": [27, 123, 124, 125], "fraction": [27, 123, 124, 125], "deliv": [27, 123, 124, 125], "fio2": [27, 123, 124, 125], "organ": [27, 123, 124, 125], "failur": [27, 123, 124, 125, 126], "assess": [27, 60, 123, 124, 125], "dysfunct": [27, 123, 124, 125], "iv": [27, 69, 120, 121, 122, 123, 124, 125, 126], "volumn": [27, 123, 124, 125], "fluid": [27, 123, 124, 125], "administ": [27, 123, 124, 125], "addition": 27, "creat": [27, 127, 133], "aspect": 27, "3598282": 28, "34648075": 28, "35533324": 28, "ate_t_learn": 28, "3571": 28, "estiamt": 28, "33630057": 29, "31723622": 29, "37261498": 29, "ate_x_learn": 29, "3566": 29, "move": [32, 73], "encount": [32, 80, 81], "scenario": [32, 99, 132], "substanti": [32, 40], "transit": [32, 67, 73, 74, 117, 118], "easier": 32, "ma": [21, 32, 69, 74, 117, 118, 121, 122, 126], "subseteq": [32, 74, 99, 101, 117], "s_": [32, 62, 63, 65, 66, 67, 72, 73, 74, 105, 117, 132], "w_t": [32, 74, 76, 93, 95, 96, 117], "_t": [32, 67, 69, 74, 75, 76, 77, 79, 89, 90, 91, 94, 95, 100, 101, 102, 106, 116, 117], "a_t": [32, 62, 63, 65, 66, 69, 72, 73, 74, 75, 78, 79, 80, 81, 82, 83, 84, 85, 87, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 106, 107, 108, 109, 114, 115, 116, 117, 128, 132], "s_t": [32, 62, 63, 65, 66, 67, 69, 72, 73, 74, 117, 132], "cmia": [32, 74, 117, 118], "y_t": [32, 33, 74, 117], "w_": [32, 74, 94, 95, 117], "tupl": [32, 62, 63, 72, 73, 78, 87, 106, 116, 117, 118], "a_": [32, 45, 60, 62, 63, 65, 66, 67, 72, 73, 74, 75, 76, 77, 82, 85, 86, 87, 88, 93, 95, 97, 98, 100, 101, 106, 107, 108, 115, 116, 117, 132], "equiv": [32, 62, 63, 72, 86, 89, 90, 91, 94], "limit": [32, 40, 49, 59, 63, 67, 69, 72, 85, 115, 117], "pai": [32, 123, 124], "r_t": [32, 62, 65, 66, 69, 72, 73, 78, 79, 80, 82, 83, 84, 85, 87, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 115, 116, 117, 128, 132], "cpl": [32, 131, 133], "restrict": 32, "talk": 32, "cima": 32, "especi": [32, 84, 86, 101, 106, 116, 128, 132], "signific": [32, 40, 62, 69, 121, 123, 124], "effort": 32, "instrument": 32, "proxi": 32, "emploi": [32, 40, 82, 101, 106, 127], "trim": 32, "strict": [32, 127], "ideal": [32, 82, 117], "greater": [32, 124], "depth": 32, "past": [33, 60, 69, 74, 82], "econom": [33, 89, 90, 91, 132], "maker": 33, "sale": [33, 40, 127], "post": [33, 40, 120], "green": 33, "purpl": 33, "orang": 33, "dash": 33, "essens": 33, "remain": 33, "panel": [33, 36], "att_t": 33, "tau_t": 33, "shortli": 33, "tricki": 33, "diff": 33, "never": 33, "transfer": 33, "dy_t": 33, "foral": [33, 40, 49, 73, 74, 89, 90, 91, 94, 95, 99, 100, 101, 102, 104], "exogen": 33, "won": 33, "nept": 33, "y_1": 33, "y_0": [33, 74, 117], "card": 33, "krueger": 33, "1994": 33, "wage": 33, "employ": 33, "harrywang": 33, "parulpandei": 33, "sandhyakrishnan02": 33, "downloa": 33, "384": 33, "food": 33, "jersei": 33, "pennsylvania": 33, "april": [33, 79, 94, 96], "1992": [33, 126], "stai": [33, 38, 47], "employe": 33, "febuarari": 33, "novemb": [33, 78, 104], "data_employ": 33, "total_emp_feb": 33, "total_emp_nov": 33, "75": [33, 40, 59, 61, 123], "n_pa": 33, "n_nj": 33, "y_pa_feb": 33, "y_pa_nov": 33, "y_nj_feb": 33, "y_nj_nov": 33, "43": [18, 33, 59, 61, 126], "nj": 33, "feb": 33, "g_i": 33, "t_0": [33, 38, 40, 132], "t_1": [33, 63, 73, 74, 132], "g_it_i": 33, "d_": [33, 77], "tr": [33, 40, 63], "y_": [33, 38, 40, 86, 88, 94, 95, 98, 99, 100, 101, 102, 104], "co": [33, 40], "subtract": [33, 132], "lechner": 33, "foundat": [33, 47, 73, 79, 114, 115], "224": 33, "goodman": 33, "bacon": 33, "225": 33, "254": 33, "277": [33, 120, 122], "1716": [36, 40], "1730": 36, "surviv": [37, 59, 122, 126], "dive": [38, 69, 121], "life": 38, "length": [38, 73, 74, 94, 97, 98, 100, 101], "gdp": 38, "countri": [38, 59], "stock": 38, "price": [38, 49, 101, 102, 103, 104], "firm": 38, "chronolog": 38, "aris": 38, "estimand": [38, 67, 72], "ITE": 38, "delta_": 38, "treatement": [38, 122, 126], "ITEs": 38, "stationari": [38, 63, 72, 73, 74, 78], "sc": [38, 132], "unlik": [40, 49, 118], "imbal": 40, "fulfil": 40, "issu": [40, 67, 82, 117, 133], "fund": 40, "reweight": [40, 67], "perspect": [40, 87, 96, 98, 117], "conterfactu": 40, "omega": [40, 45, 62, 63, 67, 72, 75], "sdid": 40, "i0": 40, "ij": 40, "jt": 40, "qquad": 40, "omega_": [40, 75], "abadi": 40, "diamond": 40, "hainmuel": 40, "california": 40, "proposit": 40, "tobacco": 40, "consumpt": 40, "susanathei": 40, "mcpanel": 40, "examples_from_pap": 40, "smok_outcom": 40, "smoke_x": 40, "smoke_covari": 40, "header": [40, 120, 123, 127], "smoke_a": 40, "smoke_treat": 40, "smoke_r": 40, "smoke_outcom": 40, "linspac": [40, 49, 128], "astyp": [40, 61, 127, 128], "renam": [40, 120, 122, 126], "preriod": 40, "element": [40, 78, 94], "t0": [40, 75], "pre_expo_r_ctl": 40, "pre_expo_r_trt": 40, "post_expo_r_ctl": 40, "post_expo_r_trt": 40, "lasso": 40, "clf": [40, 47], "coef_": [40, 128], "intercept_": [40, 128], "03980357": 40, "07157998": 40, "22667637": 40, "02990258": 40, "00037257": 40, "02313041": 40, "09714507": 40, "16905554": 40, "19878875": 40, "06427401": 40, "09209638": 40, "05463154": 40, "post_expo_r_trt_counterfactu": 40, "vline": 40, "ymin": 40, "ymax": 40, "130": 40, "linestyl": 40, "ylabel": [40, 59, 128, 129], "per": [40, 62, 72, 80, 81, 86], "capita": 40, "cigarett": 40, "pack": [40, 68, 70, 72, 108, 109, 114, 115], "legend": [40, 128, 129], "effectli": 40, "longer": [40, 118], "105": [40, 59, 120, 123], "505": 40, "2069": 40, "2070": 40, "2071": [40, 107], "esti": 40, "mate": 40, "statisticalassoci": 40, "115": [40, 94, 120, 122], "2083": 40, "contrast": [45, 61, 67, 75, 90, 91, 106, 132], "incent": [45, 58, 75, 77], "mainli": [45, 58, 65, 66, 75, 77, 79, 83, 87, 95, 100, 102, 107, 118, 128, 132], "convent": [45, 74, 75, 101], "soon": [45, 67, 75], "multinomi": [45, 52, 58, 60, 75, 77, 102, 103, 104, 106, 116, 129], "constrast": [45, 75], "furthermor": [45, 75, 79, 83, 86, 87, 95, 100, 102, 107], "c_j": 45, "blip": [45, 75], "max_": [45, 59, 66, 73, 74, 75, 77, 80, 81, 84, 85, 93, 95, 96, 97, 98, 100, 101, 102, 103, 104, 115, 117], "psi": [45, 49, 75, 86], "hand": [45, 49, 58, 65, 66, 77, 117, 128], "logist": [45, 59, 67, 72, 80, 81, 86, 93, 95, 102, 103, 109], "substitut": [45, 101, 106, 116], "euqat": 45, "appendix": 45, "bootstrap": [45, 58, 61, 68, 75, 77, 122], "utilz": [45, 75], "boostrap": [45, 58, 75], "resampl": [45, 58, 75, 77], "standard": [45, 58, 61, 62, 63, 67, 68, 72, 75, 77, 80, 84, 86, 88, 90, 96, 97, 98, 101, 103, 104, 105, 109, 122, 126, 132], "cpl13": [45, 47, 49, 58, 59, 75, 77, 122, 126, 129], "disc": [45, 47, 58, 59, 75, 77, 122, 126, 129], "get_data": [45, 58, 60], "target_col": [45, 58, 59, 60], "binary_trt": [45, 58, 60], "2d": 45, "intercept": [45, 58, 59, 61, 77, 93, 95, 97, 100, 102, 103, 126, 128, 129], "newaxi": [45, 61], "model_info": [45, 58, 61, 75, 77, 122, 126, 129], "x_prop": [45, 61, 75], "recenc": [45, 58, 59, 60], "x_q0": [45, 61, 75], "x_c": [45, 61, 75], "action_spac": [45, 58, 61, 75, 77, 122, 126, 129], "phi_": 45, "exp": [45, 61, 86], "gamma_": 45, "j0": 45, "j1": 45, "j2": 45, "prop": [45, 61, 75], "discrete_model": [45, 75], "multinomialresultswrapp": [45, 75], "0x14a13a92ac0": [], "q0": [45, 61, 75, 77, 122, 126], "3997e": 45, "4189e": 45, "7181e": 45, "03": [45, 60, 75, 122, 126, 129], "3389e": 45, "0295e": 45, "3272e": 45, "1025e": 45, "7135e": [45, 59], "7582e": 45, "opt_d": [45, 58, 61, 75, 77, 122, 126, 129], "recommend_act": [45, 47, 58, 75, 77, 122, 126, 129], "value_count": [45, 58, 77, 120, 122, 126, 127, 129], "v_hat": [45, 58, 61, 75, 77, 122, 126, 129], "predict_valu": [45, 58, 75, 77, 122, 126, 129], "fitted_model": [45, 58, 61, 75, 77, 122, 126, 129], "202": [45, 126], "int64": [45, 58, 61, 77, 93, 95, 96, 97, 98, 100, 102, 103, 120, 122, 123, 126, 127, 129], "126": [40, 45, 58, 61, 120, 122], "18615811062617": 45, "71": [40, 45, 61, 123, 124], "003": [45, 126], "mail": [45, 58, 59, 60], "women": [45, 58, 59, 60, 128], "men": [45, 58, 59, 60, 128], "deviaiton": [45, 58, 61, 75, 77], "amai": [45, 58, 61, 75, 77], "n_b": [45, 58, 61, 75, 77, 122], "fitted_param": [45, 58, 61, 75, 77], "fitted_valu": [45, 58, 61, 75, 77], "value_avg": [45, 58, 61, 75, 77], "value_std": [45, 58, 61, 75, 77], "param": [45, 58, 61, 75, 77, 129], "predict_value_boot": [45, 58, 75, 77], "value_hat": [45, 58, 61, 75, 77], "keyboardinterrupt": [], "88": [45, 59, 61, 75, 123, 124, 126], "true_prop": [], "86": [61, 120], "87": 61, "regime_sampl": [], "_fit": [], "x_sampl": [], "a_sampl": [], "y_sampl": [], "89": [40, 61], "boot": [], "estimate_v0": [], "102": [40, 126], "_fit_model": [], "pseudo_y_prev": [], "_get_pseudo_i": [], "177": [], "tmp_mul": [], "contrast_model": [], "diag": [], "fitted_prop": [], "178": [], "new_psi": [], "linalg": [127, 129], "inv": [], "old_psi": [], "__array_function__": [], "200": [45, 58, 59, 61, 75, 77, 126, 129], "replic": [45, 58, 128], "37488160184644": 45, "std": [45, 58, 61, 75, 77, 120, 126, 127, 128], "37346454667266": [], "739458412078504": [], "correspod": [45, 58], "placehold": [], "schult": [45, 75, 129], "institut": [45, 75, 129], "640": [45, 75, 129], "seattl": [45, 75], "symposium": [45, 75], "189": [45, 75, 126], "springer": [45, 75, 78, 79, 107], "york": [45, 75], "ny": [45, 75], "murphi": [45, 58, 75, 77], "royal": [45, 75], "331": [45, 75, 78], "355": [45, 75], "liang": [45, 75, 78, 107], "fan": [45, 75], "46": [45, 61, 75, 100], "925": [45, 75, 126], "close": [47, 62, 67, 72, 84, 117], "behaviour": [47, 67, 72, 101], "share": [47, 63, 67, 72, 86, 87, 95, 100, 102, 117, 130], "min": [47, 49, 59, 82, 127, 128], "neq": 47, "classif": [47, 65, 67, 72], "classifi": [47, 60, 126], "impli": [47, 62, 73, 74, 122, 126], "opposit": 47, "why": 47, "w_i": 47, "though": 47, "instabl": 47, "svm": 47, "tbd": [], "owl_simu": 47, "generate_test_cas": [47, 61], "case1": 47, "sigma": [47, 62, 63, 68, 72, 80, 84, 86, 88, 95, 97, 98, 100, 102, 109, 114, 115, 129], "xai": [47, 61], "outcomeweightedlearn": 47, "linearsvc": 47, "svc": 47, "model_select": [17, 47, 126], "gridsearchcv": [47, 126], "cross_val_scor": 47, "cs": [47, 95, 102], "logspac": 47, "param_grid": 47, "dict": [47, 75, 127], "assignment_prob": 47, "your": [47, 59, 130, 131], "notabl": [47, 79], "meantim": [47, 90], "zhao": 47, "yingqi": 47, "499": [47, 79], "1106": 47, "ying": 47, "regimen": [47, 58, 77], "3776": 47, "3788": 47, "lou": 47, "zhilan": 47, "jun": 47, "shao": 47, "menggang": 47, "74": [47, 59, 61], "506": 47, "stat": 47, "68": [18, 47, 61], "sim": [47, 62, 63, 65, 67, 72, 73, 74, 80, 84, 86, 88, 89, 90, 91, 93, 94, 95, 97, 99, 100, 101, 102, 103, 104, 106, 116, 117, 128], "const": 47, "concentr": [48, 68, 69, 99], "emphasi": 48, "dosag": 48, "insulin": 48, "paid": [49, 132], "domain": [49, 106, 116], "dose": 49, "contin": 49, "discontinu": 49, "i2dr": 49, "idr": 49, "ingredi": 49, "multi": [49, 60, 75, 78, 79, 87, 88, 98, 99, 106, 107, 116, 128, 134], "detect": 49, "overcom": 49, "bullet": [49, 63], "densiti": [49, 59, 62, 63, 67, 72, 73], "eqnarrai": [49, 62, 63, 65, 66, 72, 73, 74, 117], "eqn": [49, 62, 63, 65, 67, 68, 72, 73, 74, 86, 94, 95, 100, 102, 106, 116, 117], "almost": [49, 74], "sure": [49, 74], "naiv": 49, "concern": [49, 123, 124, 125], "psi_h": 49, "trade": [49, 67, 74, 83, 89, 90, 91, 96, 107], "decai": [49, 63], "yet": [49, 118, 133], "q_": [49, 59, 75, 77], "dnn": 49, "argmin_": [49, 72], "substack": [49, 65, 66], "gamma_n": 49, "argmax_": [49, 86, 88, 89, 90, 91, 101, 102, 103, 104, 105, 107, 109, 114, 115], "argmax": [49, 128, 129], "value_djq": 49, "warfarin": 49, "deep_jump_learn": 49, "djl_opt": 49, "data_gen": 49, "data_gener": 49, "realdatagener": 49, "file_nam": [49, 123, 124], "real_envir": 49, "djl_partit": 49, "djl_agent": 49, "djlearn_opt": 49, "2333": 49, "mlp_max_it": 49, "attributeerror": 49, "attribut": [49, 69, 121], "partit": [49, 126], "067": 49, "133": [49, 120, 123], "167": [49, 77], "333": 49, "minut": 49, "opt_polici": 49, "train_data": 49, "xt": 49, "3333333333333333": 49, "0th": 49, "djl_eval": 49, "pi_evalu": 49, "act_list": 49, "x_max": 49, "org_data": 49, "x_min": 49, "val": 49, "act": [49, 127], "regr_mean": 49, "djlearn_ev": 49, "datetim": [49, 123, 124], "djl": 49, "environ": [49, 65, 78, 79, 83, 87, 89, 90, 91, 106, 107, 116, 123, 124, 128], "omp_num_thread": [49, 123, 124], "calibr": 49, "2111": 49, "08885": 49, "kosorok": [49, 58, 77], "august": 49, "assist": [49, 131], "26th": 49, "sigkdd": 49, "mine": 49, "march": 49, "1243": [49, 59], "1251": 49, "earli": [58, 77, 89, 90, 91, 128], "kept": [58, 77], "evolv": [58, 77], "hope": [58, 77], "straightforward": [58, 63, 65, 77, 84, 114, 117], "qlearn": [58, 61, 77, 122, 126, 129], "beta_": [58, 88, 122, 126], "regressionresultswrapp": [58, 77], "0x229d617dc70": [], "94": [58, 59, 61, 120, 122], "202956": 58, "239801": 58, "611375": 58, "526133": 58, "152892": 58, "843148": 58, "000549": 58, "007584": 58, "000416": 58, "float64": [58, 77, 122, 129], "371": 58, "207": [58, 59], "48792828230197": 58, "53": [58, 59, 61, 126, 128], "0005": [58, 122], "0076": 58, "0004histori": 58, "49": [58, 59, 61], "05211088055782": [], "1075901567830195": [], "shold": 58, "set_index": [58, 77, 122, 126], "40675465960962": 58, "11527665835263": [], "196176682684333": [], "sandwich": [], "project": 131, "ci": [63, 73, 74, 128, 129], "wang": [58, 59, 69, 77, 78, 98, 99, 106, 107, 116, 121, 131, 133], "zeng": [58, 77], "statistica": [58, 77, 95], "sinica": [58, 77], "901": [58, 77, 126], "extendour": 59, "satisfactori": 59, "prolong": 59, "platform": 59, "tail": 59, "preval": 59, "heavi": [59, 117, 133], "unstabl": [59, 67], "skew": [59, 126], "median": 59, "moodi": 59, "invert": 59, "cummul": 59, "qunatil": 59, "year": [59, 60, 80, 81, 86, 118], "feasibl": [59, 61, 63, 77, 99, 103, 117, 118], "misspecifi": 59, "pretain": 59, "c_i": 59, "rho_": 59, "beta_1": 59, "fine": 59, "grid": 59, "beta_0": 59, "u_": [59, 85, 107, 115], "1n": 59, "0n": 59, "1i": [59, 75, 76, 77], "0i": 59, "proper": 59, "nelder": 59, "mead": 59, "data_sim": 59, "383222": [], "837005": [], "823949": [], "548747": [], "626713": [], "967657": [], "558539": [], "067276": [], "875451": [], "851840": [], "482248": [], "916466": [], "050466": [], "379659": [], "838442": [], "706367": [], "419095": [], "860056": [], "801635": [], "609076": [], "419511": [], "430254": [], "167251": [], "520525": [], "452121": [], "159374": [], "128552": [], "347347": [], "205922": [], "954332": [], "dr_quantileotr": 59, "quantile_otr": 59, "quantileotr": 59, "x1": 59, "x2": 59, "mocondquant_0": 59, "x_1": [], "x_2": [], "mocondquant_1": 59, "coeffici": [59, 80], "coef_original_scal": 59, "q_est": [59, 61], "dr_qopt": 59, "mopropen": 59, "notbinaryrandom": 59, "termin": [59, 89, 90, 91, 130], "129150": 59, "gradient": [59, 62, 72, 89, 90, 91], "final_simplex": 59, "0401e": 59, "04": [59, 122], "0062e": 59, "3241e": 59, "9385e": 59, "9699e": 59, "9649e": 59, "9516e": 59, "0098e": 59, "7645e": 59, "9178e": 59, "9988e": 59, "6791e": 59, "1197": 59, "fun": 59, "119701027689532": 59, "nfev": 59, "nit": 59, "success": 59, "0000e": 59, "3468e": 59, "7854e": 59, "06": [59, 98, 122], "sklift": 59, "return_x_y_t": 59, "raw": 59, "history_seg": 59, "zip_cod": [59, 60, 127], "newbi": [59, 60], "142": [59, 120, 123], "surburban": 59, "phone": [59, 60], "350": [59, 83], "329": 59, "08": [59, 122], "rural": [59, 60], "web": [59, 60, 79, 94, 106, 107, 116], "180": 59, "750": [59, 120, 123], "675": 59, "83": [59, 61, 128], "urban": [59, 60], "63995": 59, "63996": 59, "63997": 59, "63998": 59, "552": 59, "multichannel": [59, 60], "63999": 59, "472": 59, "82": [59, 61, 78, 107], "64000": 59, "inplac": [59, 120, 122, 126], "get_dummi": [59, 127], "prefix": [59, 127], "axi": [59, 61, 120, 127, 128, 129, 132], "anymor": 59, "zip_code_rur": 59, "channel_multichannel": 59, "data_r": 59, "zip_code_surburban": [59, 60], "zip_code_urban": [59, 60], "channel_phon": [59, 60], "channel_web": [59, 60], "217": 59, "267": [59, 128], "297": 59, "264": 59, "66": [59, 61, 123, 126], "332": 59, "451": [59, 83], "265": 59, "459": 59, "63466": 59, "63552": 59, "63743": 59, "210": [59, 120, 122], "63876": 59, "215": 59, "63883": 59, "239": 59, "70": [59, 61], "exceed": 59, "502953": 59, "1895e": [], "7227e": [], "4110e": [], "8883e": [], "3248e": [], "6189e": [], "4630e": [], "8951e": [], "8789e": [], "1688e": [], "1876e": [], "7185e": [], "4111e": [], "9113e": [], "3260e": [], "6160e": [], "5493e": [], "8964e": [], "8975e": [], "1777e": [], "1816e": [], "7171e": [], "4095e": [], "8872e": [], "3259e": [], "6174e": [], "7327e": [], "8731e": [], "9187e": [], "1762e": [], "1882e": [], "7222e": [], "4113e": [], "8993e": [], "3252e": [], "6171e": [], "6759e": [], "9012e": [], "9038e": [], "1803e": [], "1924e": [], "7234e": [], "4088e": [], "8863e": [], "3250e": [], "6158e": [], "4646e": [], "9095e": [], "8690e": [], "2013e": [], "1900e": [], "7211e": [], "4096e": [], "8999e": [], "3246e": [], "6178e": [], "3607e": [], "9148e": [], "9045e": [], "1516e": [], "1880e": [], "9149e": [], "6187e": [], "4407e": [], "9451e": [], "8686e": [], "1759e": [], "1875e": [], "7196e": [], "4083e": [], "9025e": [], "6157e": [], "5918e": [], "9206e": [], "8949e": [], "1680e": [], "1872e": [], "7252e": [], "4081e": [], "8846e": [], "3243e": [], "6168e": [], "4315e": [], "8960e": [], "8996e": [], "1701e": [], "1925e": [], "7192e": [], "4085e": [], "8711e": [], "3264e": [], "6172e": [], "5903e": [], "9406e": [], "8946e": [], "1745e": [], "1889e": [], "7195e": 59, "4101e": [], "8838e": [], "3258e": [], "6177e": [], "4543e": [], "9190e": [], "8917e": [], "181": 126, "5661e": [], "6834e": [], "patch": 59, "facecolor": 59, "blue": 59, "xlabel": 59, "r1": 59, "titl": 59, "histogram": [59, 123], "xlim": 59, "ylim": [59, 128], "face": 59, "xu": [59, 78, 107, 131], "op": [59, 62, 65, 67, 69, 72, 73, 74, 132], "were": 59, "_c": 59, "_j": [59, 63, 86, 87, 88], "qdr_qope": 59, "mixtur": 59, "mdn": 59, "gbdt": 59, "futher": 59, "quanatil": 59, "dr_quantileop": 59, "quantileop": 59, "qope_est": 59, "927600463556344": 59, "nameerror": 59, "5961404868027": 59, "lan": 59, "ben": 59, "sherwood": 59, "523": 59, "1254": 59, "erica": 59, "em": 59, "nema": 59, "dean": 59, "ru": 59, "bioscienc": 59, "243": 59, "2212": 59, "14466": 59, "week": 60, "merchandis": 60, "compris": [60, 132], "nine": 60, "dollar": 60, "suburban": 60, "ident": [60, 69, 80, 84, 86, 95, 97, 100, 102, 103, 105, 108, 109, 114, 115, 121, 128, 129], "flase": 60, "blog": 60, "minethatdata": 60, "2008": [60, 101], "phi1": 61, "phi2": 61, "psi1": 61, "psi2": 61, "random_binari": 61, "450": [61, 77], "a1": [61, 75, 77, 122], "binomi": [61, 95, 129], "a2": [61, 75, 77, 122], "mu2": 61, "y_opt": 61, "opt_tru": 61, "optimal_a": 61, "optimal_v": 61, "004": [61, 126, 128], "250": 61, "95": [40, 61, 102, 128, 129], "1108": 61, "575955081366": 61, "todo": [61, 70, 77, 108, 109, 114, 115, 116, 134], "estimate_value_boot": 61, "estimated_contrast": [61, 75], "estimated_prop": 61, "estimate_valu": 61, "a0": 61, "232": 61, "8969": 61, "9788": 61, "s1a1": 61, "del": 61, "1102": 61, "524126394967": 61, "554474056899934": 61, "379": 61, "334892": 61, "318229": 61, "628596": 61, "027810": 61, "313279": 61, "716134": 61, "729627": 61, "050612": 61, "335": 61, "294202": 61, "253088": 61, "460437": 61, "091607": 61, "664498": 61, "409741": 61, "410791": 61, "090007": 61, "200070": 61, "071281": 61, "474": 61, "508450": 61, "375403": 61, "517774": 61, "092061": 61, "114": [40, 61, 83, 128], "a_est": 61, "c0": 61, "c1": 61, "vhat": 61, "q1": [61, 77, 122], "opt_v": 61, "rep": [61, 128, 129], "51": [61, 126], "52": [61, 123], "58": [61, 75], "69": [61, 123], "72": [40, 61], "73": [61, 123], "76": [61, 101, 102, 104, 106, 123], "78": [61, 101, 102, 104, 106], "79": [61, 123], "93": 61, "2674": 61, "9966": 61, "718": 61, "432": 61, "9964": 61, "7158350462053": 61, "366": [61, 105], "5116": 61, "157": 61, "1218": [61, 127], "7812": 61, "0755e": 61, "4913e": 61, "3333e": 61, "8864e": 61, "1197e": 61, "0288e": 61, "5741e": 61, "1112": [61, 77], "2353635304949": 61, "1120": 61, "4987706735005": 61, "10000": [61, 84], "decent": 62, "fqe": [62, 65, 66, 72], "integr": [62, 72, 128, 131], "bellman": [62, 65, 66, 72, 73, 117], "bellman_q": [62, 65, 72, 73, 117], "wise": [62, 67, 72, 128], "stepi": [62, 67, 72], "stepdr": [62, 72], "i_t": [62, 67, 72, 94], "besid": [62, 65, 66, 67, 72, 117], "recurs": [62, 72, 73], "debia": [62, 63, 72], "reflect": [62, 67, 72, 74, 79, 83, 87, 107, 128], "mi": [62, 63, 72], "suffer": [62, 72, 123, 124], "huge": [62, 72, 117], "avoid": [62, 63, 67, 72, 127], "widetild": [62, 67, 72], "drl": [62, 63, 72], "margin": [62, 63, 67, 72], "infti": [62, 63, 65, 66, 67, 69, 72, 73], "p_t": [62, 63, 67, 72], "p_b": [62, 67, 72], "recal": [62, 63, 67, 68, 72, 117, 118], "manner": [62, 72], "tini": [62, 63, 72], "textrm": [62, 63, 68, 69, 72, 122, 126], "sqrt": [62, 72, 81, 85, 105, 115], "weakli": [62, 67, 72], "lower_bound": [62, 68, 72], "proven": [62, 72], "speak": [62, 63, 72], "publish": [68, 70, 72, 108, 109, 114, 115, 133], "hide": [68, 70, 72, 108, 109, 114, 115], "\u7cfb\u7edf\u627e\u4e0d\u5230\u6307\u5b9a\u7684\u6587\u4ef6": [68, 70, 72], "eqn_omega": [62, 72], "mini": [62, 72], "solvel": [62, 72], "sup_": [62, 72], "simplifi": [62, 72, 73, 89, 90, 91], "reproduc": [62, 72], "hilbert": [62, 72], "rkh": [62, 72], "outer": [62, 72], "descent": [62, 72, 89, 90, 91, 117], "approxim": [62, 67, 72, 86, 88, 93, 95, 97, 102, 103, 132], "still": [63, 67, 72, 86, 118], "slow": 63, "wald": [63, 68, 89, 90], "nomin": 63, "coverag": 63, "weaker": 63, "deeper": 63, "new_drl_term": 63, "dirac": 63, "p_": [63, 72, 89, 90, 91], "event": 63, "numer": [63, 65, 66, 79, 83, 87, 106, 107, 116, 126, 128], "debiasterm": 63, "protect": [63, 90], "tripli": 63, "ci_tr": 63, "z_": [63, 68], "nuisans": 63, "i_1": 63, "t_": 63, "disjoint": 63, "t_2": 63, "counterpart": [63, 67], "arbitrari": 63, "breakthrough": 63, "spirit": 63, "uncorrel": 63, "hoeffd": 63, "decomposit": [63, 69], "degener": 63, "gather": 64, "conceptu": [65, 67], "contract": [65, 66, 117], "ell": [65, 66, 117], "until": [65, 66, 67, 86, 88, 101, 102, 103, 104, 105, 117], "fqi": [66, 117], "vanilla": 67, "prod_": 67, "immedi": [67, 69, 73, 74, 121], "bias": 67, "exponenti": 67, "forward": 67, "stationar": [67, 73], "sa": [67, 72], "rather": [67, 74], "understood": 67, "trick": [67, 75], "omit": 67, "principl": [67, 72], "neglig": [67, 69, 72, 121], "harri": [67, 72], "ergod": [67, 72], "chain": [67, 72], "eventu": [67, 72, 128], "mix": [67, 72, 100], "ref": [68, 72], "sec": [68, 72], "adopt": [68, 95], "tighter": 68, "inequ": 68, "curse_horizon": [68, 72], "kallus2019effici": [68, 72], "eqref": [68, 72], "ci_drl": 68, "upper": [68, 81, 83, 85, 89, 90, 91, 105, 115, 128, 129], "mobil": [69, 78], "devis": 69, "encompass": 69, "multipli": [69, 121], "pi_e": 69, "pi_0": 69, "dento": 69, "lim_": 69, "dde": [69, 121], "dme": [69, 121], "ii": [69, 74, 107, 118], "m_t": [69, 75], "iii": [69, 107], "r_1": 69, "depict": [69, 132], "mimic3_mrl_data_dict_v2": [69, 120, 121], "mimic3_mrl": [69, 121], "mrl_df": [69, 120, 121], "mimic3_mrl_df_v2": [69, 120, 121], "died_within_48h": [69, 120, 121, 122, 126], "1006": [69, 120, 121, 123, 124, 126], "next_glucos": [69, 120, 121], "next_pao2_fio2": [69, 120, 121], "682": 69, "684": 69, "173913": [69, 120, 121, 123], "685": 69, "686": [69, 100], "687": 69, "234036": [69, 120, 121], "me_mdp": [69, 121], "mcmc": [69, 121, 126], "ratio_ndim": [69, 121], "scaler": [69, 121], "q_set": [69, 121], "product_tensor": [69, 121], "include_intercept": [69, 121], "penalti": [69, 121], "min_l": [69, 121], "t_dependent_q": [69, 121], "l2penalti": [69, 121], "spline": [69, 121], "dimems": [69, 121], "est_id": [69, 121], "01810020554867914": 69, "006066387156687134": 69, "004866328022066192": 69, "00018158807389352197": 69, "017081734487951722": 69, "ide_s": [69, 121], "ime_s": [69, 121], "dde_s": [69, 121], "dme_s": [69, 121], "te_s": [69, 121, 122], "0058689011135968135": 69, "002110278954293422": 69, "002770561709572756": 69, "0010678186846614852": 69, "005821662648181514": 69, "dierct": [69, 121], "ind": [69, 120, 121, 127], "inm": [69, 121], "dnde": [69, 121], "nddnme": 69, "tabl": [69, 83, 121, 122, 126, 133], "dnme": [69, 121], "0181": 69, "0059": 69, "0061": 69, "0021": 69, "0049": 69, "0028": 69, "0002": [69, 122], "0011": 69, "0171": 69, "0058": 69, "insignific": [69, 121], "conclud": [69, 121], "wu": [69, 121], "2023": [69, 121], "2301": [69, 121], "13348": [69, 121], "dedic": 71, "textit": 72, "citep": 72, "jiang2016doubl": 72, "farajtabar2018mor": 72, "uehara2019minimax": 72, "rotnitzky1995semiparametr": 72, "carefulli": [72, 85, 117], "thomas2016data": 72, "our_method": 72, "superior": [72, 86], "gain": [72, 128], "tang2019doubl": 72, "upon": [72, 79, 132], "vspace": 72, "1cm": 72, "worthi": 72, "denomin": 72, "modif": 72, "throw": 72, "awai": [72, 91], "geometr": [72, 95, 101, 102, 104], "2cm": 72, "mean_": 72, "proof": 72, "cramer": 72, "rao": 72, "bickel1993effici": 72, "van2000asymptot": 72, "liu2018break": 72, "ineffici": [72, 84, 85, 88], "mass": 73, "enter": 73, "throughout": [73, 123], "report": 73, "readi": 73, "t_n": [73, 74], "uniformli": [73, 74], "def_valu": [73, 74], "benefit": [73, 74], "_l": [73, 74], "_u": [73, 74], "opo": [73, 74], "repeatedli": [74, 87], "perspectii": 74, "implicitli": 74, "writ": 74, "ground": [74, 117], "literautr": 74, "subset": [74, 94, 97, 98, 99, 100, 101, 106, 116, 117, 123, 124, 125], "had": [74, 117], "cup_": [74, 117], "determinist": [74, 86, 89, 90, 91, 95, 100, 101, 102, 106, 116], "homogen": 74, "central": [74, 78, 83, 107], "statioanri": 74, "shall": 74, "wors": 74, "ca": 74, "sra": 74, "s_j": 74, "a_j": 74, "y_j": 74, "markovobserv": 74, "robserv": 74, "interchang": 74, "h_": [75, 76, 77, 132], "ti": [75, 76, 77], "till": [75, 76, 77], "q_t": [75, 117], "h_t": 75, "v_": [75, 101, 102, 105], "d_t": 75, "backward": [75, 77], "eqaut": 75, "accordingli": [75, 80, 84, 85, 96, 98, 104, 109, 114, 115], "m_k": 75, "h_ti": 75, "datamdp_feas": [75, 77], "txt": [75, 77, 127], "sep": [75, 77, 126, 127], "cd4_0": [75, 77], "cd4_6": [75, 77], "cd4_12": [75, 77], "a3": [75, 77, 122], "0x19213166910": [], "0x192193bb190": [], "0x192193bb8b0": [], "8924": 75, "1455": 75, "5109": 75, "1229": 75, "0503": 75, "9351": 75, "595": [75, 97], "7725": 75, "0474": 75, "5872e": 75, "0493e": 75, "9347e": 75, "2010e": 75, "568": 75, "1057": 75, "8412e": 75, "2479e": 75, "1162": 75, "4662578531563": 75, "4662578531918": [], "3966192806022": [], "626837283714682": [], "omega_t": 75, "w_1": 76, "w_2": 76, "multistag": 77, "prepar": [77, 106], "reset": 77, "reset_index": [77, 120, 123], "0x1c5312fdf10": [], "0x1c531306eb0": [], "0x1c5380e7e80": [], "q2": 77, "898024": 77, "102009": 77, "116478": 77, "002859": 77, "676661": 77, "454044": 77, "288382": 77, "921595": 77, "015938": 77, "553900": 77, "477566": 77, "551396": 77, "334465": 77, "182": [77, 120, 123, 126, 128], "312429": 77, "703112": 77, "1113": [77, 97, 99], "3004201781755": 77, "9473745874627": [], "502235932374479": [], "BE": 77, "THE": 77, "AS": 77, "THAT": 77, "OF": 77, "979": 77, "4518636939476": 77, "financ": [78, 83, 107, 132], "slot": 78, "casino": 78, "gambler": 78, "plai": [78, 79, 83, 85, 87, 89, 90, 91, 99], "earn": 78, "payout": 78, "produc": 78, "divid": [78, 132], "adversari": 78, "pacakg": 78, "distinct": 78, "laern": 78, "durand": [78, 107], "achilleo": [78, 107], "iacovid": [78, 107], "strati": [78, 107], "mitsi": [78, 107], "pineau": [78, 107], "mous": [78, 107], "novo": [78, 107], "carcinogenesi": [78, 107], "healthcar": [78, 83, 87, 107], "zha": [78, 107], "portfolio": [78, 107], "twenti": [78, 107], "fourth": [78, 107], "joint": [78, 107], "811": [78, 107], "821": [78, 107], "bouneffouf": [78, 79, 83, 107], "bouzeghoub": 78, "gan\u00e7arski": 78, "awar": 78, "berlin": [78, 79], "heidelberg": [78, 79], "primarili": 79, "profil": 79, "occup": [79, 87, 107, 128, 129], "season": 79, "temperatur": 79, "aid": 79, "mab": [79, 82, 84, 85, 87, 107], "tast": 79, "film": [79, 127], "ultim": [79, 83, 87, 94, 99, 101, 106, 107, 128], "lipschitz": 79, "linucb": [79, 107, 129, 134], "lint": [79, 107, 128, 129, 134], "static": [79, 86, 95, 100, 130], "nonstationari": 79, "1m": [79, 83, 87, 106, 107, 128], "highest": [79, 82, 83, 84, 85, 87, 94, 95, 96, 97, 98, 100, 106, 107, 108, 109, 114, 115, 128], "colleg": [79, 80, 81, 86, 87, 107, 127, 128], "technician": [79, 87, 107, 127, 128, 129], "academ": [79, 87, 107, 127, 128], "bernoulli": [79, 83, 87, 94, 95, 96, 99, 100, 109, 114], "chu": [79, 81, 107], "reyzin": [79, 81], "schapir": [79, 81, 107], "june": [79, 80, 81, 93, 94, 97, 99, 101, 102, 104, 106, 109], "payoff": [79, 80, 81, 107, 109], "fourteenth": [79, 81], "208": [79, 81, 120, 122], "jmlr": [79, 81], "workshop": [79, 81], "agraw": [79, 80, 101, 102, 103, 104, 105, 106, 107, 109], "goyal": [79, 80, 101, 102, 104, 105, 106, 107, 109], "thompson": [79, 80, 83, 84, 87, 89, 90, 91, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 106, 109, 114, 115, 116, 134], "127": [79, 80, 107, 109, 123, 124, 126], "135": [79, 80, 83, 107, 109], "kveton": [79, 80, 86, 87, 88, 93, 94, 97, 99, 106, 107, 109, 116], "zaheer": [79, 80, 86, 87, 88, 93, 107, 109], "szepesvari": [79, 80, 87, 88, 93, 94, 106, 107, 109, 116], "ghavamzadeh": [79, 80, 87, 93, 107, 109], "boutili": [79, 80, 87, 88, 93, 107, 109], "2076": [79, 80, 93, 107, 109], "rish": [79, 83, 107], "10040": [79, 83, 107], "slivkin": [79, 83, 107], "286": 79, "hazan": 79, "megiddo": 79, "513": 79, "langford": [79, 89, 90, 91, 107], "articl": [79, 107], "19th": [79, 107], "670": [79, 107], "auer": [79, 82, 85, 107, 108, 115], "cesa": [79, 82, 85, 107, 108, 115], "bianchi": [79, 82, 85, 107, 108, 115], "freund": 79, "nonstochast": 79, "multiarm": [79, 82, 85, 107, 108, 115], "siam": 79, "scalabl": [80, 81, 86, 88, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 134], "ucb": [80, 81, 83, 89, 90, 91, 93, 96, 97, 98, 103, 104, 105, 107, 115, 129], "suscept": [80, 93, 97, 103], "avial": [80, 106, 109, 116], "consdier": [80, 109], "ts": [80, 81, 83, 86, 87, 88, 89, 90, 91, 95, 96, 98, 100, 102, 103, 104, 107, 109, 129, 134], "domian": [80, 84, 109, 114], "thecorrespond": [80, 109], "posterior": [80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 107, 109, 114, 128], "greatest": [80, 84, 96, 109, 114], "updat": [80, 81, 82, 84, 85, 86, 88, 90, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115, 117, 127, 130, 132, 133], "distirbut": [80, 84, 96, 98, 104, 109, 114], "rewad": [80, 84, 96, 98, 104, 109, 114], "cpl4": [27, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 128, 129], "theano": [27, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 128], "tensor": [27, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 128], "bla": [27, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 128], "api": [27, 59, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 128, 129, 133], "imit": [80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104], "_env": [27, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 128], "single_contextual_env": [80, 81, 128], "deviat": [80, 84, 86, 88, 97, 98], "prior_theta_u": [80, 109, 128, 129], "prior_theta_cov": [80, 109, 128, 129], "covarainc": [80, 84], "lints_gaussian_ag": [80, 88, 109], "lints_gaussian": [80, 109, 128, 129], "get_phi": [80, 81, 86, 128, 129], "get_reward": [80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115, 128, 129], "receive_reward": [80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115, 128, 129], "feature_info": [80, 81, 86, 128], "old": [80, 81, 86], "retrain_freq": [80, 81, 93, 109], "glm": [80, 81, 107, 134], "lints_glm_ag": 80, "lints_glm": 80, "specifci": 81, "gaussain": 81, "theta_a": [81, 82, 84, 108], "u_a": [81, 85, 115], "theta_": [81, 82, 84, 93, 94, 95, 96, 97, 99, 101, 104, 108, 109, 114, 122], "exploration_t": [81, 129], "linucb_gaussian_ag": 81, "linucb_gaussian": [81, 129], "linucb_glm_ag": 81, "linucb_glm": 81, "domin": [82, 126], "eploit": 82, "epsilon_t": [82, 108], "epsilon_": [82, 86, 88, 107, 108], "pull": [82, 85, 86, 108, 115, 128, 133], "c_a": [82, 85, 108, 115], "decrease_ep": [82, 108], "specfi": [82, 108], "epsilon_greedi": 82, "_env_realmab": [82, 84, 85], "single_gaussian_env": [82, 84, 85, 108, 109, 114, 115, 129], "greedy_ag": [82, 108], "single_bernoulli_env": [82, 84, 85, 109, 114], "fischer": [82, 85, 107, 108, 115], "256": [82, 85, 107, 108, 115], "satisf": [83, 94], "tackl": [83, 107], "preprocess": [17, 83, 87], "288": 83, "204": [75, 83, 126], "096": 83, "312": 83, "287": [83, 120, 128], "313": 83, "305": [83, 127], "278": 83, "455": 83, "553": 83, "420": 83, "07272": [83, 107], "Be": 84, "uncertainti": [84, 85], "dilemma": [84, 107, 109, 114], "greedili": [84, 85, 95, 100, 102, 107, 109, 114, 115, 128], "nearli": [84, 107, 109, 114], "manual": [84, 114, 130], "r_0": 84, "reward_typ": [84, 114, 129], "u_prior_mean": [84, 98, 114, 129], "u_prior_cov": [84, 114, 129], "ts_gaussian_ag": [84, 114], "prior_phi_beta": [84, 114], "ts_bernoulli_ag": [84, 114], "russo": [84, 106, 107, 114, 115, 116], "kazerouni": [84, 106, 107, 114, 115, 116], "osband": [84, 106, 107, 114, 115, 116], "wen": [84, 93, 94, 97, 99, 106, 107, 114, 115, 116], "tutori": [84, 94, 99, 100, 101, 102, 106, 107, 114, 115, 116, 128, 133], "0203": [84, 107], "lattimor": [84, 107], "szepesv": [84, 107], "ari": [84, 107], "cambridg": [84, 107], "radiu": [85, 107, 115], "2log": 85, "ucb1": [85, 107, 129, 134], "log": [85, 115, 117, 126, 128], "ucb_ag": [85, 105, 115], "hierarch": [86, 87, 95, 100, 102], "alignedat": [86, 88, 95, 100, 102], "inter": [86, 94, 95, 99, 100, 101, 102, 134], "mu_": [86, 87, 88, 122], "hierachical_model": 86, "explicit": [86, 88, 95, 102], "pymc3": [86, 88, 95, 102, 103], "mathmet": 86, "simultan": [86, 95, 100, 102], "meta_bandit": [86, 88], "mtts_gaussian": 86, "_env_realmultitask": [86, 88], "multitask_env": [86, 88], "episod": [86, 88], "schedul": [86, 88, 102, 105], "preced": [86, 88], "concurr": 86, "theta_prior_mean": 86, "theta_prior_cov": 86, "delta_cov": 86, "approximate_solut": 86, "finish": [86, 88, 133], "update_freq": [86, 88, 95, 100, 102, 103, 105], "mtts_gaussian_ag": 86, "mtts_agent": 86, "posterior_u": [86, 88, 114], "posterior_cov_diag": [86, 88], "mtts_binari": 86, "phi_beta": [86, 88, 95, 102, 105, 108, 109, 114], "mtts_binary_ag": 86, "posterior_alpha": [86, 88, 114], "posterior_beta": [86, 88, 114], "29655": [86, 87], "29668": [86, 87], "basu": [86, 87, 88], "szepesv\u00e1ri": [86, 87, 88], "28029": [86, 87, 88], "28041": [86, 87, 88], "acceler": 87, "arbitrati": 87, "decsion": 87, "lack": [87, 132], "integ": [87, 106, 116], "a_k": 87, "r_k": 87, "konobeev": [87, 88], "hsu": [87, 88], "mladenov": [87, 88], "5884": [87, 88], "5893": [87, 88], "7724": 87, "7741": 87, "maintain": [88, 117], "demonstr": 88, "categor": [88, 132], "accommod": [88, 97], "meta_ts_gaussian": 88, "sigma_0": 88, "sigma_q": 88, "meta_ts_gaussian_ag": 88, "meta_ts_ag": 88, "episode_finish": 88, "meta_post": 88, "candid": [88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 131], "candi_mean": 88, "entri": [88, 94], "meta_ts_binari": 88, "meta_ts_binary_ag": 88, "ongo": [89, 90, 91], "crucial": [89, 90, 91], "instruct": [89, 90, 91], "exposit": [89, 90, 91], "link": [89, 90, 91, 130], "dud\u00edk": [89, 90, 91], "suvta": [89, 90, 91], "dr_est": [89, 90, 91], "2110": [89, 90, 91], "15501": [89, 90, 91], "240": [89, 90, 91, 120], "255": [89, 90, 91], "534": [89, 90, 91], "708": [89, 90, 91], "719": [89, 90, 91], "1103": [89, 90, 91], "4601": [89, 90, 91], "dream": 90, "architectur": [90, 118], "tripl": 90, "x_t": 90, "buffer": [90, 117], "pi_b": 90, "pi_t": 90, "histor": [90, 91, 118], "kappa_t": [90, 91], "pr": [90, 91], "kappa": [90, 91], "overlap": 91, "zong": [93, 94], "laplac": 93, "mid": [93, 95, 96, 97, 98, 100, 101, 102, 103, 104, 107, 115], "inroduct": [93, 95, 96, 97, 98, 100, 102, 103, 104], "cascad": [93, 95, 96, 106, 116, 134], "structured_bandit": [93, 95, 96, 97, 98, 100, 102, 103, 104, 105], "_env_realcascad": [93, 95, 96], "cascading_env": [93, 95, 96], "itm": [93, 95, 96, 97, 98, 100, 102, 103, 104], "considerd": [93, 97, 100], "lints_ag": [93, 97, 103], "fisrt": [93, 97, 100], "restatur": [93, 95, 96, 97, 98, 100, 102, 103, 104], "1301": 93, "2087": 93, "1123": 93, "unfortun": [93, 95, 96], "ni": [93, 94], "sung": [93, 94], "ke": [93, 94], "1603": [93, 94], "05359": [93, 94], "sort": [94, 120], "slate": [94, 99, 101, 104], "f_r": [94, 95, 100, 102, 106, 116], "she": 94, "latent": 94, "visibl": 94, "theta_i": [94, 95, 96, 98, 99, 100, 101, 102, 103, 104], "mathmat": 94, "model_cascad": [94, 95], "permut": 94, "ts_cascad": 94, "cascadelint": [94, 134], "mtss_cascad": 94, "chuklin": 94, "rijk": 94, "synthesi": 94, "lectur": 94, "retriev": [94, 106, 128], "2202": [94, 95, 99, 100, 101, 102, 106], "13227": [94, 95, 99, 100, 101, 102, 106], "ashkan": [94, 97, 99, 106, 116], "767": [94, 106, 116], "776": [94, 104, 106, 116], "cheung": [94, 96], "tan": [94, 96], "zhong": [94, 96], "22nd": [94, 96], "mtss": [95, 100, 102, 134], "general_hierach": [95, 100, 102], "mtt": [95, 100, 102], "subsum": [95, 100, 102, 106, 116], "enjoi": [95, 102], "conjug": [95, 96, 102, 104, 114], "facilit": [95, 100, 102], "deploy": [95, 100, 102], "gamma_prior_mean": [95, 100, 102, 103], "gamma_prior_cov": [95, 100, 102, 103], "coverainc": [95, 102, 103], "n_init": [95, 102, 103, 105], "draw": [95, 102, 103], "mtss_agent": [95, 100, 102], "2189": 95, "1610": 95, "1206": 95, "forcina": 95, "franconi": 95, "rivista": 95, "di": [95, 120, 121, 123, 124, 126], "applicata": 95, "salvati": [95, 102], "wiecki": [95, 102], "fonnesbeck": [95, 102], "peerj": [95, 102], "e55": [95, 102], "doi": [95, 102], "7717": [95, 102], "u_prior_alpha": [96, 104], "u_prior_beta": [96, 104], "ts_agent": [96, 98, 104], "2690": 96, "reach": 97, "kalman": 97, "filter": 97, "exact": 97, "Of": [97, 98, 100], "cours": [97, 98, 100], "welcom": [97, 98, 100, 131, 133], "combinatorial_semi": [97, 98, 100], "_env_realcomb": [97, 98, 100], "combsemi_env": [97, 98, 100], "prior_gamma_mu": 97, "prior_gamma_cov": [97, 100], "lints_semi": 97, "tot_r": [97, 98, 100], "480": 97, "1895": 97, "1700": 97, "2219": 97, "2807": 97, "1593": 97, "2784": 97, "2831": 97, "1523": [97, 100], "8214": 97, "2055": 97, "0487": 97, "8551": 97, "1778": 97, "9068": 97, "6194": 97, "9444": [97, 100], "3574891974648375": 97, "1122": [97, 99], "began": 98, "famili": 98, "sub": [98, 117], "bay": [98, 100], "u_prior_cov_diag": 98, "diagon": 98, "ts_semi": 98, "1054": 98, "2060": 98, "494": 98, "1488": 98, "1351": 98, "898": 98, "1587": 98, "1114": [98, 100], "321": 98, "8094": 98, "8462": 98, "8306": 98, "6929": 98, "6706": 98, "6444": 98, "5902": 98, "5764": [98, 100], "0607550383245": 98, "yuan": [98, 99, 106, 116], "februari": 98, "151": [40, 98, 99, 106, 116, 128], "159": [40, 98, 99, 106, 116], "perrault": 98, "boursier": 98, "valko": 98, "perchet": 98, "5429": 98, "5440": 98, "alloc": [99, 106, 116], "pali": 99, "sigma_2": [99, 100], "combt": [99, 134], "comblint": [99, 134], "mtss_comb": 99, "sankararaman": 99, "5114": 99, "5122": 99, "lmm": 100, "sigma_1": 100, "prior_gamma_mean": 100, "mtss_semi": 100, "2132": [100, 126], "689": 100, "1645": 100, "1733": 100, "2671": 100, "1611": 100, "2099": 100, "1668": 100, "9462": 100, "4307": 100, "9867": 100, "846": 100, "504": 100, "3613": 100, "6928": 100, "45535406270607": 100, "pari": 100, "golrezaei": 100, "ssrn": 100, "3651397": 100, "mnl": [101, 102, 103, 104, 105, 106, 134], "arguabl": 101, "eta_0": 101, "eta_1": 101, "eta_": [101, 102, 103, 104, 105], "eta_k": 101, "revenu": [101, 102, 103, 104], "convention": 101, "v_i": 101, "mnldist": 101, "cup": 101, "v_0": 101, "intract": [101, 104], "appear": [101, 102, 103, 104, 105], "matter": 101, "ts_mnl": 101, "ts_contextual_mnl": 101, "mtss_mnl": 101, "pentico": 101, "european": 101, "190": [101, 120, 123, 126], "295": 101, "luce": [101, 116], "courier": [101, 116], "corpor": [101, 116], "avadhanula": [101, 102, 103, 104, 105, 106], "zeevi": [101, 102, 104, 105, 106], "oh": [101, 102, 103], "iyengar": [101, 102, 103], "1485": [101, 104, 105], "ou": [101, 103], "1805": [101, 103], "02971": [101, 103], "concret": 102, "eqn1": 102, "logit": [102, 103, 104, 106, 116], "_env_realmnl": [102, 103, 104], "mnl_env": [102, 103, 104, 105], "same_reward": [102, 103, 104, 105], "clip": [102, 104], "275": 102, "448": [102, 103], "836": [102, 103], "9493188224156814": 102, "framwork": 103, "realtionship": 103, "mnl_ts_contextu": 103, "298": 103, "9729194890231303": 103, "tulabandhula": 103, "tractabl": [103, 104], "14033": 103, "multinomila": 104, "ts_mnl_beta": 104, "mnl_t": 104, "394": [104, 120, 123, 124], "911": 104, "430": [104, 120, 123, 124], "03330462654669619": 104, "dong": 104, "switch": [104, 124, 130], "2607": 104, "2615": 104, "48log": 105, "_env_mnl": 105, "20000": [105, 128], "update_freq_linear": 105, "with_intercept": [105, 108, 109, 114, 115, 129], "x_mu": [105, 108, 109, 114, 115], "x_sigma": [105, 108, 109, 114, 115], "sigma_gamma": [105, 108, 109, 114, 115], "mu_gamma": 105, "exp_r": 105, "519": 105, "906": 105, "main_raw_model": [106, 116], "cardin": [106, 116], "exclud": [106, 116], "appeal": 106, "brows": 106, "02038": [106, 116], "2015a": [106, 116], "strike": 107, "unfamiliar": [107, 133], "guaasian": [107, 134], "glmt": 107, "guassian": [107, 134], "writer": [107, 127], "2080": 107, "na": [108, 109, 114, 115], "longleaf": [108, 109, 114, 115], "home": [108, 109, 114, 115], "lge": [108, 109, 114, 115, 131], "sigma_theta": [108, 109, 114, 115], "mu_theta": [108, 109, 114, 115], "specifii": 108, "cnt": [108, 109], "rewrit": 109, "lints_bernoulli_ag": 109, "lints_bernoulli": 109, "breward": 114, "4375": 114, "rs": 115, "1249": 115, "cook": 116, "vast": 117, "disucss": 117, "hear": 117, "reader": [117, 127], "materi": 117, "recap": 117, "appraoch": 117, "mont": 117, "carlo": 117, "td": 117, "wait": 117, "paradigm": [117, 118, 133], "trasit": 117, "schema": 117, "trpo": 117, "ppo": 117, "simplist": 117, "descient": 117, "around": [117, 123], "fortun": [117, 118], "bigtriangledown_": 117, "abil": 117, "dqn": 117, "replai": 117, "scratch": 117, "Such": 117, "q_0": 117, "effiic": 117, "a2c": 117, "sac": 117, "a3c": 117, "pomdp_comparison": 118, "valuabl": 118, "infeas": 118, "horiozn": 118, "quickli": 118, "belief": 118, "mimic3": 120, "subset_rl_data_final_cont": [120, 123], "mimic3_bas": [120, 123], "lambda": [120, 129], "vivia": [18, 120, 123, 127], "appdata": [18, 120, 123, 127], "temp": [120, 123, 127], "ipykernel_2056": [], "4058168275": 120, "row_index": [120, 123], "col_index": [120, 123], "98685": [120, 123], "120": [40, 120, 122, 123], "142857": [120, 123], "749": [120, 123], "200000": [120, 122, 123, 124, 126], "751": [120, 123], "545455": [120, 123], "030303": [120, 123, 124], "196": [120, 123, 126], "666667": [120, 122, 123], "753": 120, "mimic_fin": [120, 123], "692": [120, 123], "selected_id": 120, "dtr_data": 120, "concaten": [120, 128, 129], "varnam": 120, "varname_format": 120, "bloc_1": 120, "bloc_2": 120, "bloc_3": 120, "died_within_48h_1": 120, "died_within_48h_2": 120, "icustayid_2": 120, "icustayid_3": 120, "died_within_48h_3": 120, "mimic3_dtr_3stage_v2": 120, "iv_input_3": [120, 122], "icustayid_1": 120, "glucose_1": [120, 122], "pao2_fio2_1": [120, 122], "iv_input_1": [120, 122], "sofa_1": [120, 122], "glucose_2": [120, 122], "pao2_fio2_2": [120, 122], "iv_input_2": [120, 122], "sofa_2": [120, 122], "glucose_3": [120, 122], "pao2_fio2_3": [120, 122], "sofa_3": [120, 122], "31005": 120, "833333": [120, 122], "364": [120, 122], "439": [120, 122], "310339": [120, 122], "10989": 120, "714286": [120, 122], "164": [120, 122, 126], "174": [120, 122, 123, 124, 126], "4132": [120, 123, 124, 126], "266": [120, 122], "600000": [120, 122, 123, 124, 126], "388889": [120, 122], "37528": 120, "260": [120, 122], "777778": [120, 122], "257": [120, 122], "857143": [120, 122], "191": [120, 122, 126, 128], "935482": [120, 122], "86428": 120, "mrl_data": 120, "mdtr_data": [120, 122], "mimic3_mdtr_data_dict_3stage_v2": [120, 122], "wb": [120, 123, 127], "dump": [120, 123, 127], "mdtr_df": 120, "mimic3_mdtr_3stage_v2": [120, 122], "next_stat": 120, "s0": 120, "time_idx": 120, "vstack": 120, "keyerror": 120, "listcomp": 120, "3511": 120, "__getitem__": 120, "3509": 120, "is_iter": 120, "3510": 120, "_get_indexer_strict": 120, "3513": 120, "boolean": 120, "3514": 120, "getattr": 120, "5782": 120, "axis_nam": 120, "5779": 120, "5780": 120, "keyarr": 120, "new_index": 120, "_reindex_non_uniqu": 120, "_raise_if_miss": 120, "5784": 120, "5785": 120, "5786": 120, "gh": [120, 130], "42790": 120, "preserv": 120, "5845": 120, "5842": 120, "5844": 120, "not_found": 120, "ensure_index": 120, "missing_mask": 120, "nonzero": 120, "next_pao2": 120, "next_sofa": 120, "rl_df": 120, "mimic3_rl_df": 120, "499996": 120, "427": 120, "630": 120, "631": 120, "632": 120, "633": 120, "634": [120, 126], "97782": 120, "201": 120, "635": 120, "within": [120, 121, 123, 124, 126, 130], "48h": [120, 121, 123, 124, 126], "mimic3_multi_stag": [120, 123], "lag_k": [120, 123], "new_sofa": [120, 123], "mimic3_sampl": [120, 123], "groupbi": [120, 123, 127], "mimic3_single_stag": [120, 123, 124, 126], "111": 40, "112": 40, "data_num": [], "_q_term": [], "er_sa0": [], "er_sa": [], "_er_sa0_sa": [], "rho_sam": [], "qlearner": [], "pmlearner": [], "rewardlearn": 126, "218": [], "est_q1": [], "est_q2": [], "qlearner_linear": [], "sigma_control": [], "_sigma": [], "sigma_target": [], "sigma_g": [], "er_sam_pi": [], "_er_sam_pi": [], "policy_nam": [], "matmul": [], "_xi": [], "include_eta": [], "301": [], "302": [], "303": [], "ridg": [], "304": [], "252": [120, 123, 124], "s_next": [], "pa_star": [], "target_pa_next": [], "a_star": [], "sample_phi": [], "mcmc_em_phi": [], "253": [], "282": [], "280": [], "update_exp": [], "281": [], "283": [], "prod": [], "func": [127, 129], "zip": 127, "bspline": [], "220": [], "221": [], "para_dim": [], "interpol": [], "_bspline": [], "339": [], "__call__": [], "extrapol": [], "337": [], "empti": [], "338": [], "_ensure_c_contigu": [], "_evalu": [], "x_shape": [], "341": [], "342": [], "transpos": [], "349": [], "xp": [], "348": [], "_bspl": [], "evaluate_splin": [], "mimic3_mdtr": 122, "parenthesi": 122, "nde": [122, 126], "213": 122, "695": 122, "156": [40, 122], "647": 122, "057": 122, "284": 122, "mediated_qlearn": 122, "mediatedqlearn": 122, "regime_control": 122, "regime_target": 122, "est_nde_ni": 122, "155758": 122, "212838": 122, "05708": 122, "_predict_value_boot": 122, "nie_s": 122, "nde_s": 122, "6474": 122, "6946": 122, "2835": 122, "q_1": 122, "q_2": 122, "a_2": 122, "_2": 122, "q_3": 122, "a_3": 122, "07": 122, "_3": 122, "polic": [122, 126], "policy1": [122, 126], "8991": 122, "policy2": [122, 126], "8246": 122, "0745": 122, "mortal": [122, 123, 124, 125, 126], "s1_1": 122, "s1_2": 122, "s1_3": 122, "s3_1": 122, "s3_2": 122, "s3_3": 122, "s4_1": 122, "s4_2": 122, "s4_3": 122, "mimic3_clip": [122, 126], "8990981941216631": 122, "8246053645689122": 122, "0001": 122, "0012": [121, 122, 126], "0551": 122, "00001": 122, "0070": 122, "0721": 122, "0008": 122, "0114": 122, "appl": [122, 126], "9637": 122, "summari": [122, 126, 132], "9637185597953717": 122, "privaci": [123, 124, 125], "he": [123, 124, 125], "hour": [123, 124, 125], "diagram": [123, 124, 133], "load_ext": [123, 124], "autoreload": [123, 124], "randn": [123, 124, 129], "rseed": [123, 124], "npseed": [123, 124], "math": [123, 124], "multiprocess": [123, 124], "pool": [123, 124], "functool": [123, 124], "ipykernel_11428": [], "1368811484": 123, "000": [123, 126, 128], "625": 123, "428571": 123, "758782": 123, "140": [40, 123], "818182": [123, 124, 126], "118": [40, 123, 124, 126], "2718509362": 123, "152": [123, 124, 126], "137": [40, 123, 124], "081590": [123, 124], "800000": [120, 123, 124, 126], "1204": [120, 123, 124, 126], "138": [40, 120, 123, 124, 126], "794872": [120, 123, 124, 126], "782051": [123, 124, 126], "668956": [120, 123, 124], "153846": [120, 123, 124, 126], "364286": [120, 123, 124, 126], "956461": [123, 124, 126], "883864": [120, 123, 124], "4201": [120, 123, 124, 126], "580087": [120, 123, 124, 126], "083333": [123, 124, 126], "065657": [120, 123, 124], "5170": [120, 123, 124, 126], "525000": [120, 123, 124, 126], "147": [123, 124, 126], "350198": [123, 124, 126], "616727": [120, 123, 124], "437500": [120, 123, 124, 126], "6504": [120, 123, 124, 126], "081169": [120, 123, 124, 126], "836364": [123, 124, 126], "423": [120, 123, 124], "mimic3_data_fin": [123, 124], "smaple_demo": 123, "est_mt": [123, 124], "w_threshold": [123, 124], "refit": [123, 124], "demo_res_net": [123, 124], "topo_list": [123, 124], "topological_sort": [123, 124], "topolog": [123, 124], "buttom": [123, 124], "administrait": 123, "35384615": 123, "70769231": 123, "06153846": 123, "41538462": 123, "76923077": 123, "12307692": 123, "47692308": 123, "83076923": 123, "18461538": 123, "53846154": 123, "gap": 123, "intak": [123, 124], "death": [123, 124], "administr": [123, 124], "gradientboostingclassifi": [123, 124], "42850795": 123, "04122985": 123, "37054069": 123, "0055272": 123, "10384686": 123, "01457029": 123, "16909439": 123, "28221447": 123, "05764574": 123, "008193": 123, "30211856": 123, "0551675": 123, "01006845": 123, "09689565": 123, "10600407": 123, "18238777": 123, "44978522": 123, "19716563": 123, "289073": 123, "03827421": 123, "22619666": 123, "1875545": 123, "23778146": 123, "20841167": 123, "73958005": 123, "11909299": 123, "09661241": 123, "15624675": 123, "3466977": 123, "42682439": 123, "353852": 123, "12244475": 123, "53581201": 123, "38763738": 123, "00624024": 123, "02708992": 123, "08227609": 123, "09644005": 123, "19550407": 123, "30207966": 123, "03525717": 123, "34339108": 123, "30668368": 123, "11740263": 123, "23538089": 123, "41147115": 123, "46029296": 123, "10346963": 123, "51161134": 123, "04498817": 123, "18302802": 123, "21907476": 123, "54002382": 123, "23518752": 123, "06635588": 123, "83090637": 123, "3999141": 123, "counterintuit": [123, 124], "remind": [123, 124], "20399937380853927": 123, "49003107": 123, "50057977": 123, "20914573": 123, "66345884": 123, "23977303": 123, "0794276": 123, "34455499": 123, "36109094": 123, "19848057": 123, "58006391": 123, "11359767": 123, "23537098": 123, "18899855": 123, "64967052": 123, "63723815": 123, "05042186": 123, "26366224": 123, "00872736": 123, "32914701": 123, "51474347": 123, "41667122": 123, "54158338": 123, "71321121": 123, "26489405": 123, "0774718": 123, "52229178": 123, "61766863": 123, "57557176": 123, "94774448": 123, "55186488": 123, "29666119": 123, "35960446": 123, "20136832": 123, "77408578": 123, "19227108": 123, "11463203": 123, "35932623": 123, "29545405": 123, "86337085": 123, "95171379": 123, "61272862": 123, "00475441": 123, "06064992": 123, "64206127": 123, "75432718": 123, "20535944": 123, "37009124": 123, "35431129": 123, "78816905": 123, "76940612": 123, "68175408": 123, "74628053": 123, "10881984": 123, "17531085": 123, "07151351": 123, "82140618": 123, "01038676": 123, "bad": [123, 124], "08642818615808659": 123, "086": 123, "sample_demo": 124, "692308": 120, "636364": 120, "625000": 120, "45322357": [], "12551825": [], "31095315": [], "06658004": [], "14936954": [], "13404695": [], "32144405": [], "41540906": [], "11657287": [], "0605553": [], "41204992": [], "350003": [], "07587157": [], "1937542": [], "29406602": [], "27231197": [], "44362365": [], "08949383": [], "4349184": [], "13355717": [], "16845723": [], "0938565": [], "30817118": [], "06978495": [], "50736663": [], "20295236": [], "17239035": [], "27745005": [], "2927717": [], "31615833": [], "3621005": [], "19816815": [], "29745249": [], "31014128": [], "00821821": [], "19483265": [], "16912685": [], "20077837": [], "37305844": [], "24538905": [], "20552501": [], "38095327": [], "38948743": [], "2780394": [], "11502808": [], "45806054": [], "29489358": [], "18854476": [], "06531642": [], "22022294": [], "22806464": [], "31916684": [], "05725299": [], "37429873": [], "16776177": [], "30377136": [], "44658451": [], "harm": [], "21392525739350662": [], "33471421": [], "58750923": [], "69769602": [], "50468707": [], "04119141": [], "08032529": [], "24677671": [], "46879497": [], "14228685": [], "40913012": [], "26967209": [], "10424795": [], "15469547": [], "86680554": [], "01699509": [], "50534554": [], "50120394": [], "0832772": [], "4053538": [], "61938348": [], "63167011": [], "53840976": [], "10602297": [], "04338229": [], "18159866": [], "77996324": [], "7988097": [], "94550731": [], "28227784": [], "9895861": [], "34582444": [], "63707457": [], "67745798": [], "16396444": [], "3173255": [], "41720785": [], "66927895": [], "09861153": [], "9408872": [], "21402004": [], "85013445": [], "61804279": [], "67352783": [], "06219661": [], "78217875": [], "87809129": [], "81120382": [], "61344813": [], "6384825": [], "26478542": [], "95845848": [], "14744284": [], "86349984": [], "74704598": [], "2168899": [], "97526792": [], "68596023": [], "4460136626503026": [], "single_data": 126, "single_dataset": 126, "2133": [], "0030": 126, "2104": [], "2332": 126, "2276": [], "0164": [], "2440": [], "_valid": 126, "372": 126, "fitfailedwarn": 126, "490": 126, "fail": [126, 130], "debug": 126, "error_scor": 126, "680": [126, 127], "_fit_and_scor": 126, "x_train": 126, "y_train": 126, "fit_param": 126, "_class": 126, "937": 126, "super": 126, "203": 126, "check_classification_target": 126, "multiclass": 126, "y_type": 126, "some_fits_failed_messag": 126, "_search": 126, "userwarn": 126, "palearn": 126, "pie_a": 126, "i_a": 126, "problearn": 126, "regressor": 126, "decisiontreeclassifi": 126, "183": 126, "best_param": 126, "best_params_": 126, "184": 126, "926": 126, "basesearchcv": 126, "refit_start_tim": 126, "best_estimator_": 126, "927": 126, "928": 126, "sample_weight": 126, "check_input": 126, "x_idx_sort": 126, "899": 126, "902": 126, "903": 126, "904": 126, "934": 126, "935": 126, "938": 126, "939": 126, "941": 126, "basedecisiontre": 126, "n_outputs_": 126, "is_classif": 126, "classes_": 126, "type_of_target": 126, "195": 126, "multilabel": 126, "23320671819000469": 126, "22762835456807218": [], "01638548320515956": [], "24401383777323174": [], "9999": 126, "7646": 126, "2353": 126, "9999999999999999": [], "764561656518231": [], "0004": [], "5510": [], "greenland": 126, "exchang": 126, "epidemiolog": [126, 132], "155": [40, 126], "dat": 127, "latin": 127, "cleric": 127, "admin": 127, "farmer": 127, "homemak": 127, "lawyer": 127, "programm": 127, "retir": 127, "scientist": [127, 131], "tradesman": 127, "craftsman": 127, "unemploi": 127, "ipykernel_37388": [], "407324603": 127, "parserwarn": 127, "back": 127, "regex": 127, "char": 127, "_decor": 127, "deprecate_nonkeyword_argu": 127, "decor": 127, "wrapper": 127, "num_allow_arg": 127, "307": 127, "308": 127, "stacklevel": 127, "310": 127, "io": [127, 130], "filepath_or_buff": 127, "delimit": 127, "index_col": 127, "usecol": 127, "squeez": 127, "mangle_dupe_col": 127, "true_valu": 127, "false_valu": 127, "skipinitialspac": 127, "skiprow": 127, "skipfoot": 127, "nrow": 127, "na_valu": 127, "keep_default_na": 127, "na_filt": 127, "skip_blank_lin": 127, "parse_d": 127, "infer_datetime_format": 127, "keep_date_col": 127, "date_pars": 127, "dayfirst": 127, "cache_d": 127, "chunksiz": 127, "compress": 127, "decim": 127, "linetermin": 127, "quotechar": 127, "quot": 127, "doublequot": 127, "escapechar": 127, "comment": [127, 131], "encoding_error": 127, "dialect": 127, "error_bad_lin": 127, "warn_bad_lin": 127, "on_bad_lin": 127, "delim_whitespac": 127, "low_memori": 127, "memory_map": 127, "float_precis": 127, "storage_opt": 127, "665": 127, "kwds_default": 127, "_refine_defaults_read": 127, "666": 127, "676": 127, "678": 127, "kwd": 127, "_read": 127, "575": 127, "572": 127, "_validate_nam": 127, "textfileread": 127, "933": 127, "930": 127, "has_index_nam": 127, "iohandl": 127, "_engin": 127, "_make_engin": 127, "1217": 127, "1213": 127, "1214": 127, "overload": 127, "get_handl": 127, "1215": 127, "pathlik": 127, "readcsvbuff": 127, "byte": 127, "1216": 127, "1219": 127, "1220": 127, "1221": 127, "1222": 127, "1223": 127, "is_text": 127, "1224": [127, 128], "1226": [127, 128], "1227": 127, "1228": 127, "789": 127, "path_or_buf": 127, "784": 127, "785": 127, "786": 127, "newlin": 127, "787": 127, "ioarg": 127, "788": 127, "790": 127, "791": 127, "792": 127, "793": 127, "794": 127, "795": 127, "errno": 127, "directori": 127, "timestamp": 127, "movie_titl": 127, "adventur": 127, "anim": 127, "children": 127, "crime": 127, "documentari": 127, "fantasi": 127, "noir": 127, "horror": 127, "music": 127, "mysteri": 127, "romanc": 127, "war": 127, "western": 127, "idx_of_genr": 127, "idx": 127, "final_data": 127, "merg": 127, "flew": 127, "cuckoo": 127, "1000209": 127, "movielens_1m": 127, "fp": 127, "popular_genr": 127, "sort_valu": 127, "ascend": 127, "popular_occup": 127, "col": [127, 128], "movielens_1m_popular": 127, "isin": 127, "119103": 127, "96564": 127, "77955": 127, "66745": 127, "54408": 127, "414775": 127, "gender_f": 127, "single_genr": 127, "multi_genr": 127, "nuniqu": 127, "movielens_cleaned_1m": 127, "block_diag": [127, 129], "movielens_bandit": 127, "get_sum_r": 127, "denom": 127, "25182431": 127, "52394863": 127, "20922347": 127, "32501066": 127, "20043842": 127, "deepcopi": 127, "movielens_mtts_1m_gaussian": 127, "19933493": 127, "8245542": 127, "39117662": 127, "67363023": 127, "31367902": 127, "6491084": 127, "movielens_mtts_1m_bernoulli": 127, "iteract": 128, "logged_data": 128, "get_logged_dat": [128, 129], "685706": 128, "2042": 128, "499683": 128, "2424": 128, "694860": 128, "330": 128, "207691": 128, "169": 128, "3671": 128, "425839": 128, "213638": 128, "4140": 128, "242271": 128, "717322": 128, "4411": 128, "910": 128, "345927": 128, "870113": 128, "406": 128, "data_cel_sampl": 128, "1286": 128, "models_cel": 128, "whitespac": 128, "feature_nam": 128, "underlin": 128, "info": 128, "thread": 128, "overhead": 128, "000024": [], "force_row_wis": 128, "And": 128, "force_col_wis": 128, "339901": 128, "inf": 128, "000124": [], "393": 128, "483461": 128, "000203": [], "319149": 128, "000074": [], "319527": 128, "000102": [], "951807": 128, "thev": 128, "age_rang": 128, "itertool": 128, "0439": 128, "7664": 128, "5822": 128, "6663": 128, "6364": 128, "1312": 128, "result_cel_nonlinear": 128, "122379": 128, "576471": 128, "066448": 128, "583382": 128, "133766": 128, "043862": 128, "205939": 128, "232727": 128, "766441": 128, "910281": 128, "336623": 128, "717603": 128, "160268": 128, "687924": 128, "331463": 128, "345233": 128, "377340": 128, "649888": 128, "039056": 128, "923635": 128, "1307": 128, "297553": 128, "090110": 128, "024221": 128, "658442": 128, "151436": 128, "1308": 128, "612166": 128, "695911": 128, "608458": 128, "740830": 128, "1309": 128, "582210": 128, "165707": 128, "552889": 128, "1310": 128, "666311": 128, "283311": 128, "129195": 128, "1311": 128, "636355": 128, "103647": 128, "115987": 128, "te_femal": 128, "500268": 128, "309777": 128, "562432": 128, "605472": 128, "960134": 128, "te_mal": 128, "365749": 128, "321332": 128, "256846": 128, "447365": 128, "schi": 128, "lowest": 128, "models_cel_linear": 128, "result_cel_linear": 128, "323169": 128, "453650": 128, "692167": 128, "482883": 128, "357668": 128, "325782": 128, "098945": 128, "628177": 128, "145705": 128, "886814": 128, "578237": 128, "666234": 128, "464250": 128, "392727": 128, "691633": 128, "580850": 128, "311529": 128, "400261": 128, "055549": 128, "220779": 128, "530090": 128, "566701": 128, "455929": 128, "741310": 128, "570002": 128, "494923": 128, "259652": 128, "899359": 128, "006980": 128, "469963": 128, "444164": 128, "514824": 128, "955027": 128, "692742": 128, "819186": 128, "446776": 128, "160120": 128, "891038": 128, "355564": 128, "348332": 128, "699231": 128, "727408": 128, "727111": 128, "602585": 128, "153151": 128, "701844": 128, "372704": 128, "663122": 128, "265407": 128, "682297": 128, "te_female_linear": 128, "579924": 128, "402675": 128, "282099": 128, "511989": 128, "082199": 128, "te_male_linear": 128, "445089": 128, "423679": 128, "073189": 128, "236301": 128, "957766": 128, "cel_result": 128, "mean_error": 128, "genere_dat": 128, "genere_error": 128, "ddof": 128, "05i": 128, "ran": 128, "sigma1": [128, 129], "cum_reward_inform": 128, "informative_t": 128, "cum_reward_informative_t": 128, "rec_action_informative_t": 128, "cumsum": [128, 129], "cov_inv_last": [], "cov_inv": [], "cov": [], "signatur": [], "iscomplextyp": [], "extobj": [], "get_linalg_error_extobj": [], "_raise_linalgerror_singular": [], "ainv": [], "_umath_linalg": [], "wrap": [], "result_t": [], "1000i": 128, "cum_reward_uninform": 128, "uninformative_t": 128, "cum_reward_uninformative_t": 128, "rec_action_uninformative_t": 128, "sole": 128, "cum_reward_greedi": [128, 129], "cum_reward_greedy_t": [128, 129], "rec_action_greedy_t": 128, "884": 128, "161": [40, 128], "011": 128, "429": 128, "391": 128, "674": 128, "040": 128, "061": 128, "041": 128, "088": 128, "063": 128, "algo": [128, 129], "lineplot": [128, 129], "hue": [128, 129], "n_boot": [128, 129], "linewidth": [128, 129], "marker": [128, 129], "bbox_to_anchor": [128, 129], "borderaxespad": [128, 129], "autoarg": [59, 129], "true_model": 129, "logged_dat": 129, "randint": 129, "user_info": 129, "r_mean": 129, "optimal_action_reward": 129, "rec_genr": 129, "true_model_1": 129, "scifi": 129, "inercept": 129, "to_markdown": 129, "338373e": 129, "553173e": 129, "916054e": 129, "419341e": 129, "574240e": 129, "646757e": 129, "578371e": 129, "303934e": 129, "339018e": 129, "560132e": 129, "625256e": 129, "333319e": [], "835612e": [], "608225e": [], "184398e": 129, "816416e": 129, "784788e": 129, "145633e": 129, "053477e": 129, "396107e": 129, "478043e": 129, "337961e": 129, "061687e": 129, "295411e": 129, "821867e": 129, "000000e": 129, "003925547959648": [], "33837": 129, "0564676": 129, "362526": 129, "81642": 129, "47804": 129, "89155": 129, "0193161": 129, "03163": 129, "85992": 129, "25443": 129, "0739259": 129, "329217": 129, "58364": 129, "58031": 129, "0130774": 129, "23706": 129, "81737": 129, "880949": 129, "0499074": 129, "880965": 129, "87681": 129, "995856": 129, "estimated_gamma": 129, "cum_reward_infolint": 129, "cum_reward_uninfolint": 129, "cum_reward_uninfolinucb": 129, "cum_reward_t": 129, "cum_reward_ucb": 129, "info_lint": [128, 129], "cum_reward_infolints_t": 129, "uninfo_lint": [128, 129], "cum_reward_uninfolints_t": 129, "uninfo_linucb": 129, "cum_reward_uninfolinucb_t": 129, "uninfo_t": 129, "cum_reward_ts_t": 129, "uninfo_ucb": 129, "cum_reward_ucb_t": 129, "tight_layout": 129, "savefig": [128, 129], "movielens_contextu": 129, "432x288": 129, "workflow": 132, "merit": 132, "downsid": 132, "miscellan": 132, "wish": 132, "ccc": 132, "hline": 132, "vdot": 132, "hdashlin": 132, "ct": 132, "bs": 132, "unrel": 132, "correpond": 132, "conjunct": 132, "bowl": 134, "quatil": 134, "otr": 134, "jump": 134, "comb": 134, "practition": 133, "handbook": 133, "complement": 133, "unifi": [131, 133], "desktop": 130, "branch": [130, 133], "visiabl": 130, "_build": 130, "commit": 130, "push": 130, "cd": 130, "password": 130, "reinstal": 130, "credenti": 130, "token": 130, "cname": 130, "ipykernel_50596": [], "261550316": [], "s1_trueg": [], "torch": [], "lr_schedul": [], "elbo": [], "29526717955993453": [], "nll": [], "0023974322189431727": [], "mse": [], "0001498395136839483": [], "ipykernel_50700": [], "2370726509": [], "ipykernel_50716": [], "ipykernel_50724": [], "law": 15, "35633351350901915": 15, "00034335539153089716": [], "35667686890055006": [], "ipykernel_50741": [], "2332491731": [], "ipykernel_50751": [], "1311581033": [], "ipykernel_50768": [], "1061371864": [], "ipykernel_50788": [], "3497684307": [], "ipykernel_50800": [], "604871671": [], "ipykernel_50825": [], "2180662469": [], "ipykernel_50841": [], "ipykernel_50851": [], "778938008": [], "ipykernel_50860": [], "1454775972": [], "36103861": 26, "35479314": 26, "35916424": 26, "3563": 26, "ipykernel_50916": [], "1573112457": [], "124": 40, "139": 40, "128": 40, "131": [40, 45, 58], "119": 40, "ipykernel_51041": [], "15241541": [], "boots_fit": [], "get_pseudo_i": [], "07058862299368": [], "114870661497804": [], "ipykernel_51076": [], "799946913": [], "0x7ff088f97940": [], "48792828230138": [], "ipykernel_51110": [], "3664914869": [], "v1": [], "reward_nam": [], "22558023415299": [], "45840507437804": [], "473336": [], "724067": [], "736866": [], "005787": [], "775420": [], "489403": [], "160543": [], "284184": [], "594114": [], "944133": [], "750790": [], "332135": [], "386872": [], "517143": [], "399555": [], "457515": [], "406177": [], "361293": [], "175896": [], "419406": [], "918524": [], "722485": [], "409496": [], "927478": [], "029262": [], "257666": [], "326091": [], "463442": [], "560685": [], "461035": [], "ipykernel_51119": [], "1796369087": [], "smf": [59, 129], "basepolicylearn": [59, 129], "ipykernel_51131": [], "1171830641": [], "ipykernel_51137": [], "2982377520": [], "ipykernel_51145": [], "3779975037": [], "ipykernel_51151": [], "ipykernel_51159": [], "ipykernel_51165": [], "ipykernel_51170": [], "ipykernel_51203": [], "ipykernel_51208": [], "ipykernel_51234": [], "2644300625": [], "3156513295758": [], "559003921896037": [], "245571": [], "595014": [], "143433": [], "440232": [], "0x7fccf36073a0": [], "0x7fccf1645b50": [], "0x7fccf3617880": [], "3004201781757": [], "ipykernel_51244": [], "2461346363": [], "1558584708713": [], "2312785208211094": [], "ipykernel_51274": [], "3250134418": [], "_base_online_learn": [], "baseonlinelearn": [], "_util_onlin": [], "sgdclassifi": [], "pm": [], "distutil": [], "__config__": [], "blas_opt_info": [], "blas_info": [], "_log": [], "getlogg": [], "runtimeerror": [], "configdefault": [], "config": [], "1838": [], "add_dnn_configvar": [], "add_magma_configvar": [], "1840": [], "add_compile_configvar": [], "1841": [], "gpuarrai": [], "1842": [], "add_tensor_configvar": [], "603": [], "disabl": [], "604": [], "rc": [], "call_subprocess_popen": [], "606": [], "oserror": [], "607": [], "236": [], "null": [], "237": [], "subprocess_popen": [], "returncod": [], "subprocess": [], "timeout": [], "1187": [], "endtim": [], "_time": [], "1188": [], "1189": [], "_wait": [], "1190": [], "1191": [], "bug": [], "issue25942": [], "1915": [], "1916": [], "pid": [], "st": [], "_try_wait": [], "loop": [], "waitpid": [], "1919": [], "wnohang": [], "odd": [], "wait_flag": [], "1873": [], "caller": [], "_waitpid_lock": [], "1874": [], "1875": [], "1876": [], "childprocesserror": [], "1877": [], "happen": [], "sigcld": [], "ipykernel_51297": [], "269298001": [], "_hotfix_theano_print": [], "gp": [], "od": [], "backend": [], "load_trac": [], "save_trac": [], "tracetab": [], "tp": [], "latentkron": [], "marginalkron": [], "marginalspars": [], "draw_valu": [], "licens": [], "shape_util": [], "timeseri": [], "bart": [], "scan": [], "multivari": [], "flat": [], "get_tau_sigma": [], "to_tupl": [], "contextmeta": [], "freerv": [], "cachetool": [], "lrucach": [], "cachedmethod": [], "sharedvari": [], "compat": [], "is_numpy_dev": [], "_is_numpy_dev": [], "_type": [], "np_version_under1p19": [], "noqa": [], "f401": [], "cache_readonli": [], "_lib": [], "tslib": [], "nat": [], "pyx": [], "hashtabl": [], "outofboundstimedelta": [], "localize_pydatetim": [], "tzconvers": [], "_bootstrap": [], "_autoarg": 129, "siev": [], "attr": [], "222": [], "setattr": [], "leave_drama": [], "leave_dram": [], "movielens_mtts_1m": [], "ipykernel_51350": [], "43005494": [], "sm": [59, 129], "iolib": [], "count_model": [], "yule_walk": [], "_test": [], "pytesttest": [], "__all__": [], "emplik": [], "elregress": [], "_elregopt": [], "lazili": [], "__doc__": [], "_predict": [], "predictionresult": [], "_optfunct": [], "_find_and_load": [], "import_": [], "_find_and_load_unlock": [], "_load_unlock": [], "spec": [], "_bootstrap_extern": [], "exec_modul": [], "get_cod": [], "fullnam": [], "_compile_bytecod": [], "bytecode_path": [], "source_path": [], "get_r": [], "true_r": [], "ipykernel_51396": [], "4285146233": [], "arrayord": [], "dicttoarraybiject": [], "imputationwarn": [], "theanof": [], "floatx": [], "hessian": [], "inputvar": [], "get_var_nam": [], "dicttovarbiject": [], "arviz": [], "dill": [], "autocorrplot": [], "plot_autocorr": [], "bpvplot": [], "plot_bpv": [], "compareplot": [], "plot_compar": [], "densityplot": [], "plot_dens": [], "rcparam": [], "_var_nam": [], "plot_util": [], "default_grid": [], "filter_plotters_list": [], "get_plotting_funct": [], "density_util": [], "kde": [], "hdi": [], "diagnost": [], "_calculate_": [], "_numba_var": [], "_stack": [], "_histogram": [], "stats_util": [], "_circular_standard_devi": [], "_sqrt": [], "autocov": [], "_autocov": [], "not_valid": [], "_not_valid": [], "conditional_vect": [], "a_a": [], "b_b": [], "import_modul": [], "_gcd_import": [], "bind": [], "is_win32": [], "startswith": [], "win32": [], "thing": [], "llvm": [], "librari": [], "dylib": [], "executionengin": [], "initfini": [], "ctype": [], "c_void_p": [], "c_char_p": [], "c_bool": [], "pointer": [], "ffi": [], "_encode_str": [], "_lib_path": [], "186": [], "cdll": [], "188": [], "use_errno": [], "use_last_error": [], "winmod": [], "380": [], "381": [], "382": [], "_handl": [], "_dlopen": [], "_name": [], "383": [], "ipykernel_51436": [], "2979947230": [], "export": [], "typeof": [], "ipykernel_51578": [], "1658515725": [], "ipykernel_51653": [], "223052819": [], "coordspec": [], "dimspec": [], "dict_to_dataset": [], "numpy_to_data_arrai": [], "convert_to_dataset": [], "convert_to_inference_data": [], "clear_data_hom": [], "list_dataset": [], "load_arviz_data": [], "inference_data": [], "inferencedata": [], "pkg_resourc": [], "xarrai": [], "xr": [], "load_dataarrai": [], "load_dataset": [], "open_dataarrai": [], "open_dataset": [], "_open_dataset": [], "rasterio_": [], "open_rasterio": [], "_open_rasterio": [], "dataarrai": [], "cfgrib_": [], "cfgribdatastor": [], "abstractdatastor": [], "backendarrai": [], "backendentrypoint": [], "file_manag": [], "cachingfilemanag": [], "dummyfilemanag": [], "filemanag": [], "_normalize_path": [], "serializablelock": [], "ensure_lock": [], "storebackendentrypoint": [], "dask": [], "worri": [], "serial": [], "_version": [], "get_vers": [], "annot": [], "import_requir": [], "weakref": [], "weakvaluedictionari": [], "tlz": [], "toolz": [], "get_dep": [], "_build_tlz": [], "comp": [], "curri": [], "sandbox": [], "functoolz": [], "_sig": [], "create_signature_registri": [], "equalityhashkei": [], "unzip": [], "ipykernel_51726": [], "263006073": [], "io_cmdstan": [], "from_cmdstan": [], "io_cmdstanpi": [], "from_cmdstanpi": [], "netcdf4": [], "nc": 131, "docstr": [], "_netcdf4": [], "underscor": [], "callback": [], "_raw_object_cache_notifi": [], "0x7f86e859af70": [], "tmp": [], "ipykernel_540529": [], "4210367235": [], "ipykernel_51837": [], "812061752": [], "beta_reparameter": [], "w_test": [], "get_yelp": [], "real_data": [], "cascading_realdata_d_10_x_transform_standardize_with_intercept_1": [], "ipykernel_51877": [], "3149151898": [], "lec": [], "prior_theta": [], "ufunc": [], "vec": [], "kw": [], "sig": [], "ftylist": [], "__new__": [], "cach": [], "get_cach": [], "imp": [], "get_target_implement": [], "targetopt": [], "dufunc": [], "py_func": [], "_initi": [], "dispatch": [], "_install_typ": [], "_lower_m": [], "dufunclower": [], "_install_cg": [], "targetctx": [], "_dispatch": [], "targetdescr": [], "target_context": [], "314": [], "_ani": [], "315": [], "_arr": [], "ufuncbuild": [], "cpu_target": [], "registri": [], "_toplevel_target_context": [], "__get__": [], "owner": [], "991": [], "attrnam": [], "_not_found": [], "992": [], "993": [], "994": [], "cpu": [], "cpucontext": [], "typing_context": [], "_target_nam": [], "cached_properti": [], "typingctx": [], "overrid": [], "261": [], "compiler_lock": [], "_acquire_compile_lock": [], "is32bit": [], "machine_bit": [], "_internal_codegen": [], "codegen": [], "jitcpucodegen": [], "abi": [], "libgcc_": [], "module_nam": [], "1166": [], "1167": [], "_data_layout": [], "1168": [], "_llvm_modul": [], "parse_assembl": [], "1169": [], "_create_empty_modul": [], "1170": [], "global_codegen_modul": [], "llvmir": [], "get_global_context": [], "strbuf": [], "globalcontextref": [], "llvmpy_getglobalcontext": [], "_lock": [], "_cfn": [], "ipykernel_51913": [], "546010817": [], "linearsegmentedcolormap": [], "register_cmap": [], "cycler": [], "_api": [], "mpl": [], "cm": [], "contour": [], "ticker": [], "martist": [], "mpatch": [], "1163": [], "1164": [], "1165": [], "polycollect": [], "_collectionwiths": [], "vert": [], "__init_subclass__": [], "__qualname__": [], "_update_set_signature_and_docstr": [], "_properties_excluded_from_set": [], "kwdoc": [], "1747": [], "ai": [], "pprint_setters_rest": [], "leadingspac": [], "1748": [], "hardcopi": [], "1749": [], "pprint_sett": [], "1750": [], "1751": [], "defer": [], "artistinspector": [], "1507": [], "1508": [], "1509": [], "get_sett": [], "1510": [], "get_valid_valu": [], "1511": [], "aliased_nam": [], "1434": [], "callabl": [], "1435": [], "inspect": [], "is_alia": [], "1437": [], "1438": [], "setter": [], "1441": [], "1442": [], "alia": [], "1443": [], "ds": [], "getdoc": [], "1444": [], "1445": [], "622": [], "623": [], "624": [], "cleandoc": [], "626": [], "645": [], "lstrip": [], "646": [], "maxsiz": [], "648": [], "trail": [], "blank": [], "649": [], "ipykernel_51984": [], "3797893370": [], "tt": [], "ipykernel_52056": [], "2686460808": [], "ipykernel_52103": [], "1560890332": [], "mnl_realdata_d_5_x_transform_l2_with_intercept_1": [], "ipykernel_52171": [], "2551634341": [], "backend_bas": [], "figurecanvasbas": [], "mousebutton": [], "figaspect": [], "gridspec": [], "subplotspec": [], "rcparamsdefault": [], "get_backend": [], "rcparamsorig": [], "_blocking_input": [], "allow_raster": [], "_finalize_raster": [], "geo": [], "aitoffax": [], "hammerax": [], "lambertax": [], "mollweideax": [], "polar": [], "polarax": [], "mpl_toolkit": [], "mplot3d": [], "axes3d": [], "triangul": [], "art3d": [], "proj3d": [], "axis3d": [], "ipykernel_52227": [], "3115157464": [], "ipykernel_52247": [], "3636065689": [], "ipykernel_52252": [], "ipykernel_52261": [], "ipykernel_52266": [], "ipykernel_52295": [], "3741024878": [], "3512": [], "5794": [], "5795": [], "5796": [], "5797": [], "5798": [], "5857": [], "5858": [], "5859": [], "5860": [], "5861": [], "ipykernel_52304": [], "1713212044": [], "_u4al": [], "276": 126, "sample_m": [], "279": [], "pm_i": [], "shape_bas": [], "_vhstack_dispatch": [], "tup": [], "_arrays_for_stack_dispatch": [], "hasattr": [], "__iter__": [], "209": [], "pass": 59, "8990981941216672": [], "8246053645689109": [], "9637185597953756": [], "ipykernel_52374": [], "20399937380848096": [], "08642818615808806": [], "ipykernel_52392": [], "2233535502": [], "ipykernel_52413": [], "2289951171": [], "936": [], "205": [], "199": [], "ipykernel_52463": [], "573": [], "576": [], "ipykernel_52474": [], "791222544": [], "000062": 128, "000009": [], "000039": [], "000035": [], "000018": [], "ipykernel_52509": [], "2393233947": [], "893010e": 129, "984154e": 129, "818640e": 129, "0039255479596445": 129, "restart": [], "ipykernel_52516": [], "3830966291": [], "pathlib": [], "data_folder_path": [], "resolv": [], "csv_file_path": [], "project_fold": [], "pers1_fb": [], "posixpath": [], "current_script_dir": [], "dirnam": [], "abspath": [], "__file__": [], "ipykernel_66398": [], "1270737390": [], "data_dir": [], "collabor": 131, "led": 131, "her": 131, "team": 131, "webpag": 131, "contributor": [], "senior": 131, "princip": 131, "amazon": 131, "songrai": 131, "gmail": 131, "professor": 131, "uc": 131, "irvin": 131, "hengrc1": 131, "edu": 131, "lin": [131, 133], "phd": 131, "ncsu": 131, "yang": 131, "yxu63": 131, "byted": 131, "sluo198912": 131, "appreci": [131, 133], "commun": [131, 133], "feel": 131, "contact": [131, 133], "thank": [131, 133], "revis": 133, "xiaodong": [131, 133], "singapor": [], "0x143594c6550": [], "61449870905838": [], "10487587358326": [], "173": [], "old_contrast": [], "q0_model": [], "new_phi": [], "0x24c33e16e80": [], "32585928608": [], "737452705071458": [], "18467665729162": [], "613824004370967": [], "890702": [], "182866": [], "271444": [], "098581": [], "096132": [], "229864": [], "814009": [], "008938": [], "649896": [], "333752": [], "267790": [], "163325": [], "448051": [], "921647": [], "775368": [], "163296": [], "028779": [], "292798": [], "873910": [], "917581": [], "087994": [], "390266": [], "701527": [], "063769": [], "528383": [], "081600": [], "699784": [], "655218": [], "252751": [], "484304": [], "0x26c0e6a0c70": [], "0x26c0f6ab0d0": [], "0x26c0f6ab970": [], "5641123519579": [], "831549961708776": [], "878021": [], "193": [], "491755": [], "106217": [], "430094": [], "0x24c71d49f10": [], "0x24c6baf5a60": [], "0x24c728d7670": [], "8032161821366": [], "280320270143468": [], "5400939625302": [], "5445941159910745": [], "ipykernel_22384": [], "est_q4": [], "est_q5": [], "est_qdiff": [], "q1_diff": [], "eta_pi": [], "q5_diff": [], "eta_a0": [], "q2_diff": [], "q3_diff": [], "q4_diff_1": [], "q4_diff_2": [], "_q_diff": [], "m_sa": [], "out_q1": [], "out_q2": [], "out_q3": [], "out_q5": [], "cal_newq_1235": [], "q1_sam": [], "q2_sam": [], "397": [], "qs": [], "398": 126, "q3": [], "q5": [], "401": [], "ipykernel_30148": [], "ipykernel_28064": [], "000475": [], "000044": [], "000038": [], "000036": 128, "sampled_beta": [], "multivariate_norm": [], "sampled_r": [], "mtrand": [], "4120": [], "randomst": [], "svd": [], "cum_reward_nvgreedi": 128, "cum_reward_nvgreedy_t": 128, "rec_action_nvgreedy_t": 128, "my_figur": 128, "bbox_inch": 128, "tight": 128, "ipykernel_63599": [], "2800271652565482": [], "002233313559525579": [], "00013958209747034868": [], "ipykernel_63659": [], "ipykernel_63674": [], "ipykernel_63679": [], "2024": 126, "685889": [], "tensorflow": 17, "cpu_feature_guard": [], "oneapi": [], "onednn": [], "sse4": [], "rebuild": [], "flag": [], "ipykernel_63697": [], "2268767057": [], "y_unscal": [], "325": [], "yt_train": [], "adam_callback": [], "327": [], "validation_split": [], "328": [], "kera": [], "traceback_util": [], "error_handl": [], "filtered_tb": [], "pylint": [], "_process_traceback_fram": [], "__traceback__": [], "validation_data": [], "shuffl": [], "class_weight": [], "initial_epoch": [], "steps_per_epoch": [], "validation_step": [], "validation_batch_s": [], "validation_freq": [], "max_queue_s": [], "worker": [], "use_multiprocess": [], "1407": [], "1408": [], "on_train_batch_begin": [], "1409": [], "tmp_log": [], "train_funct": [], "1410": [], "data_handl": [], "should_sync": [], "1411": [], "async_wait": [], "eager": [], "def_funct": [], "913": [], "914": [], "optionalxlacontext": [], "_jit_compil": [], "915": [], "_call": [], "916": [], "917": [], "new_tracing_count": [], "experimental_get_tracing_count": [], "945": [], "defun": [], "_stateless_fn": [], "_stateful_fn": [], "949": [], "releas": [], "2451": [], "graph_funct": [], "filtered_flat_arg": [], "_maybe_define_funct": [], "2453": [], "_call_flat": [], "2454": [], "captured_input": [], "2455": [], "cancellation_manag": [], "executing_eagerli": [], "tape": [], "_build_call_output": [], "_inference_funct": [], "ctx": [], "1862": [], "forward_backward": [], "_select_forward_and_backward_funct": [], "495": [], "_interpolatefunctionerror": [], "497": [], "498": [], "num_output": [], "_num_output": [], "quick_execut": [], "op_nam": [], "ensure_initi": [], "pywrap_tf": [], "tfe_py_execut": [], "device_nam": [], "_notokstatusexcept": [], "3588": 18, "7786": 18, "0468": 18, "ipykernel_63730": [], "3012518900": [], "fold1b": [], "ps_learner_b": [], "_logist": [], "1588": [], "1589": [], "fold_coefs_": [], "1590": [], "1591": [], "1041": [], "job": [], "1042": [], "_iter": [], "1043": [], "dispatch_one_batch": [], "1044": [], "_original_iter": [], "1045": [], "859": [], "860": [], "861": [], "777": [], "778": [], "job_idx": [], "_job": [], "779": [], "_backend": [], "apply_async": [], "cb": [], "780": [], "781": [], "_parallel_backend": [], "immediateresult": [], "parallel_backend": [], "_n_job": [], "config_context": [], "_logistic_regression_path": [], "pos_class": [], "max_it": [], "tol": [], "solver": [], "coef": 126, "dual": [], "intercept_sc": [], "multi_class": [], "max_squared_sum": [], "l1_ratio": [], "804": [], "searchsort": [], "805": [], "806": [], "opt_r": [], "807": [], "808": [], "w0": [], "_minim": [], "x0": [], "jac": [], "hess": [], "hessp": [], "621": [], "meth": [], "bfg": [], "_minimize_lbfgsb": [], "tnc": [], "lbfgsb": [], "disp": [], "maxcor": [], "ftol": [], "gtol": [], "maxfun": [], "maxit": [], "iprint": [], "maxl": [], "finite_diff_rel_step": [], "unknown_opt": [], "359": [], "overwrit": [], "func_and_grad": [], "361": 126, "task_str": [], "new_x": [], "362": [], "_differentiable_funct": [], "fun_and_grad": [], "array_equ": [], "_update_x_impl": [], "_update_fun": [], "268": [], "_update_grad": [], "231": [], "f_updat": [], "233": [], "_update_fun_impl": [], "update_fun": [], "fun_wrap": [], "undefin": [], "_compute_if_need": [], "_valu": [], "asarrai": [], "fg": [], "_logistic_loss_and_grad": [], "expit": [], "yz": [], "z0": [], "n_featur": [], "safe_sparse_dot": [], "ipykernel_63741": [], "ipykernel_63750": [], "230": [22, 23], "ipykernel_63755": [], "ipykernel_63760": [], "2628946087": [], "ipykernel_63765": [], "ipykernel_63778": [], "0x7f9c78013d00": [], "17606776208015": [], "061516766866138": [], "ipykernel_63846": [], "3857643488": [], "166": [], "prop_x": [], "old_phi": [], "ipykernel_63873": [], "0x7fd61d4c4580": [], "35843572470768": [], "291777555356988": [], "40675465960682": [], "61049124357007": [], "785361732981682": [], "025941": 59, "121537": 59, "806875": 59, "637488": 59, "363393": 59, "641093": 59, "525509": 59, "381373": 59, "342528": 59, "780761": 59, "ipykernel_63907": [], "ipykernel_63915": [], "ipykernel_63920": [], "ipykernel_63925": [], "ipykernel_63930": [], "ipykernel_63935": [], "ipykernel_63940": [], "ipykernel_63945": [], "ipykernel_63950": [], "2043971912": [], "_er_sa0m": [], "395": [], "396": [], "q_1235": [], "q1_est_beta": [], "q2_est_beta": [], "343": [], "ndim": [], "ipykernel_63978": [], "ipykernel_63983": [], "0x7fdeb50386d0": [], "0x7fdeb223bfa0": [], "0x7fdec0d8b490": [], "4662578531643": [], "8379793733807": [], "9758990176256237": [], "718187": [], "675327": [], "114772": [], "421962": [], "ipykernel_63998": [], "406682526": [], "0x7fc22cdc3d90": [], "0x7fc2386a5ee0": [], "0x7fc238701130": [], "8396121914577": [], "281715389368037": [], "4518636939583": [], "801093573878": [], "850620637679951": [], "ipykernel_64309": [], "sample_gamma": [], "gamma_2_alpha_beta": [], "beta_bernoulli": [], "gamma_temp": [], "mvnormal": [], "alpha_temp": [], "mean_beta": [], "total_s": [], "dim": [], "__getnewargs__": [], "1136": [], "1137": [], "1138": [], "1139": [], "free_rv": [], "1140": [], "1669": [], "1670": [], "1671": [], "logp_elemwiset": [], "logp": [], "1672": [], "minibatch": [], "1673": [], "tensorvari": [], "quaddist": [], "logdet": [], "ok": [], "_quaddist": [], "norm": [], "5908": [], "mvnormallogp": [], "_quaddist_cov": [], "_cov_typ": [], "_quaddist_tau": [], "_quaddist_chol": [], "delta_tran": [], "solve_low": [], "chol_cov": [], "__pow__": [], "pow": [], "notimplementederror": [], "typeerror": [], "notimpl": [], "compute_test_valu": [], "default_output": [], "thunk": [], "make_thunk": [], "storage_map": [], "compute_map": [], "no_recycl": [], "impl": [], "make_c_thunk": [], "methodnotdefin": [], "request": 133, "unsupport": [], "float16": [], "599": [], "600": [], "601": [], "input_storag": [], "node_input_storag": [], "output_storag": [], "node_output_storag": [], "602": [], "1201": [], "1202": [], "init_task": [], "get_init_task": [], "1203": [], "cthunk": [], "in_storag": [], "out_storag": [], "error_storag": [], "__compile__": [], "1205": [], "cthunk_factori": [], "1632": [], "node_ord": [], "1633": [], "prepare_nod": [], "1634": [], "get_module_cach": [], "module_from_kei": [], "lnk": [], "1635": [], "1636": [], "orphan": [], "cmodul": [], "dlimport_workdir": [], "compile_cmodul": [], "1192": [], "1541": [], "1542": [], "_logger": [], "1543": [], "c_compil": [], "compile_str": [], "1544": [], "mod": [], "code_hash": [], "1545": [], "src_code": [], "include_dir": [], "lib_dir": [], "prearg": [], "py_modul": [], "hide_symbol": [], "2494": [], "2495": [], "2496": [], "p_out": [], "output_subprocess_popen": [], "cmd": [], "2497": [], "compile_stderr": [], "decod": [], "2498": [], "deadlock": [], "stdout": [], "pipe": [], "1132": [], "1133": [], "1134": [], "_commun": [], "1135": [], "orig_timeout": [], "timeoutexpir": [], "1979": [], "selector": [], "1980": [], "_check_timeout": [], "1981": [], "415": [], "fd_event_list": [], "_selector": [], "poll": [], "417": [], "interruptederror": [], "418": [], "ipykernel_64633": [], "ipykernel_64650": [], "ipykernel_64655": [], "ipykernel_64662": [], "ipykernel_64668": [], "ipykernel_64691": [], "ipykernel_64696": [], "354": 126, "pie_a_": [], "q1_snext_am_mc": [], "q2_snext_am_mc": [], "q3_snext_am_mc": [], "q4_snext_am_mc": [], "q5_snext_am_mc": [], "q4_s_am_mc": [], "cal_q_am_mc": [], "357": [], "q1_snext_am": [], "pie_a_sprim": [], "update_q1235_snext_am_mc": [], "428": [], "q4_snext_am_mc_astar": [], "update_q4_snext_am_mc_astar": [], "431": [], "update_q4_s_am_mc": [], "m_snext_a_star": [], "action_list": [], "out_q4_a_star": [], "cal_newq_4": [], "454": [], "407": [], "409": [], "q_4": [], "410": [], "q4": [], "411": [], "402": [], "403": [], "405": [], "q4_est_beta": [], "351": [], "ipykernel_64728": [], "ipykernel_64738": [], "ipykernel_64751": [], "ipykernel_64769": [], "ipykernel_64774": [], "2928192091": [], "547": [], "ipykernel_64808": [], "ipykernel_65744": [], "ps_learner_a": [], "fold1a": [], "_gb": [], "monitor": [], "484": [], "486": [], "_validate_data": [], "487": [], "accept_spars": [], "csr": [], "csc": [], "coo": [], "multi_output": [], "488": [], "validate_separ": [], "check_param": [], "check_arrai": [], "check_y_param": [], "581": [], "check_x_i": [], "582": [], "accept_large_spars": [], "force_all_finit": [], "ensure_2d": [], "allow_nd": [], "ensure_min_sampl": [], "ensure_min_featur": [], "y_numer": [], "962": [], "963": [], "964": [], "965": [], "744": [], "cast": [], "unsaf": [], "745": [], "746": [], "747": [], "complexwarn": [], "complex_warn": [], "__array__": [], "2062": [], "2063": [], "npt": [], "dtypelik": [], "ndarrai": [], "2064": [], "__array_wrap__": [], "analogu": [], "extensionarrai": [], "905": [], "_consolidate_inplac": [], "907": [], "mgr": [], "_mgr": [], "5651": [], "consolid": [], "5652": [], "5653": [], "_protect_consolid": [], "5654": [], "5655": [], "5639": [], "5640": [], "blocks_befor": [], "5641": [], "5642": [], "5643": [], "_clear_item_cach": [], "5649": [], "5650": [], "__setattr__": [], "5585": [], "5586": [], "5587": [], "__getattribute__": [], "5588": [], "5589": [], "5116269": [], "16936349": [], "46436953": [], "3796": 20, "09": [], "365676": [], "0x2a7e8097b20": [], "64102945616798": [], "700251079259756": [], "0x2c941a63a60": [], "0642880567614": [], "433980118050489": [], "310089865537": [], "723021866276165": [], "220396": [], "802703": [], "214262": [], "123332": [], "192666": [], "412000": [], "360986": [], "291210": [], "902613": [], "283093": [], "765979": [], "212027": [], "473897": [], "175488": [], "002552": [], "809326": [], "267924": [], "334513": [], "108488": [], "781862": [], "453831": [], "295484": [], "336920": [], "818303": [], "911224": [], "010777": [], "077213": [], "456483": [], "694769": [], "129055": [], "353": [], "pi0_a_": [], "q5_snext_am": [], "pi0_a_sprim": [], "434": [], "unique_act": [], "460": [], "458": [], "m_s_a": [], "out_q4": [], "461": [], "462": [], "0x1ec1a44ce20": [], "0x1ec1a48b130": [], "0x1ec1a48b970": [], "3729840746125": [], "03188949564685": [], "255934": [], "589098": [], "108011": [], "439428": [], "twodim_bas": [], "293": [], "291": [], "292": [], "294": [], "0x27a0967dca0": [], "0x27a034557f0": [], "0x27a0b205670": [], "1723013919952": [], "533775540551028": [], "3928117251199": [], "769146611522496": [], "ipykernel_21624": [], "425": [], "ipykernel_32212": [], "ipykernel_33872": [], "000425": [], "000042": 128, "000030": [], "000029": [], "000016": [], "aaai2024": 131, "aaai24": 131, "casualdm": 133, "csl": [131, 133], "submit": 133, "attach": 133, "upload": 133, "fork": 133, "correspondng": 133, "pythong": 133, "0_learner": 133, "templat": 133, "charg": 133, "0x1f2eb9635e0": [], "20285765375175": [], "029794810665548": [], "0x165d9f41040": [], "95680812775043": [], "256943498969375": [], "59983991207723": [], "093953011550719": [], "055926": [], "826802": [], "386391": [], "833445": [], "338598": [], "741666": [], "994430": [], "396826": [], "082238": [], "566687": [], "866528": [], "308756": [], "373514": [], "992350": [], "288038": [], "473681": [], "325814": [], "311484": [], "580366": [], "130956": [], "171457": [], "533745": [], "411984": [], "630038": [], "492853": [], "368907": [], "594619": [], "804421": [], "831849": [], "640579": [], "scaler_set": [], "normcdf": [], "sm_mean": [], "sm_std": [], "arr": [], "_nx": [], "344": [], "345": [], "0x168d254cdf0": [], "0x168d257c7c0": [], "0x168d257cdf0": [], "4074022525215": [], "3213319966586266": [], "421243": [], "194": [], "996823": [], "064429": [], "431600": [], "0x1f41e8e26a0": [], "0x1f41e8e5a60": [], "0x1f4256c6670": [], "4669195226388": [], "007143566316976": [], "9205551939459": [], "9492924088633736": [], "ipykernel_31632": [], "ipykernel_28920": [], "ipykernel_3596": [], "000537": [], "000049": [], "000061": [], "1660": [], "full_matric": [], "compute_uv": [], "hermitian": [], "1657": [], "gufunc": [], "svd_n_": [], "1659": [], "ddd": [], "vh": [], "1661": [], "1662": [], "_realtyp": [], "_base_policy_learn": 129, "goe": [131, 133], "wonder": [131, 133], "emoji": [131, 133], "runzhestat": [131, 133], "yangxu63": [131, 133], "shadow": [131, 133], "000053": [], "000051": [], "000012": [], "000026": [], "000017": [], "0x1293b2874c0": [], "39743159022507": [], "210770991773556": [], "0x2524e721940": [], "5247281893191": [], "467076442449793": [], "45090054755462": [], "540337667849615": [], "155972": [], "688892": [], "846297": [], "224025": [], "224673": [], "915303": [], "170916": [], "874292": [], "453093": [], "060970": [], "209808": [], "595878": [], "705202": [], "514716": [], "419868": [], "406152": [], "674617": [], "332170": [], "339199": [], "208512": [], "512093": [], "123504": [], "549755": [], "170148": [], "801238": [], "755443": [], "199996": [], "799829": [], "863831": [], "556100": [], "0x17648d0fe50": [], "0x17648d4b130": [], "0x17648d4b9d0": [], "7846098704904": [], "488813901172366": [], "190258": [], "876776": [], "081778": [], "407345": [], "0x2128a04e940": [], "0x2128a0669a0": [], "0x21290e56670": [], "4443212897113": [], "682135193650189": [], "3750883583473": [], "249467182109128": [], "ipykernel_21384": [], "ipykernel_11124": [], "ipykernel_3300": [], "000011": [], "000023": [], "0x192acf476a0": [], "5448501287091": [], "022267000671492": [], "26298977237299": [], "237007377236742": [], "0x14cbbf51f40": [], "96688499524237": [], "011745455100181": [], "58116822978778": [], "563848015107144": [], "331767": [], "256134": [], "129558": [], "575803": [], "523320": [], "447289": [], "577764": [], "674704": [], "434181": [], "394431": [], "961550": [], "602344": [], "098172": [], "097737": [], "843646": [], "474547": [], "577699": [], "624825": [], "464012": [], "359954": [], "289035": [], "809897": [], "559568": [], "776283": [], "042485": [], "129005": [], "542484": [], "922799": [], "546907": [], "667762": [], "0x1d69c2e9fd0": [], "0x1d69d2fb100": [], "0x1d69d2fba00": [], "3539295971796": [], "4353263243676135": [], "095421": [], "931051": [], "117297": [], "423840": [], "1161": [], "8963372456342": [], "702261281487215": [], "0x193273c6580": [], "0x193273c6f70": [], "0x1932e1b5670": [], "1763473425742": [], "367878479365738": [], "0332436142251": [], "806046811218055": [], "ipykernel_13960": [], "ipykernel_31936": [], "ipykernel_17532": [], "000505": [], "000046": [], "ipykernel_69522": [], "2604245517164468": [], "001169236510424758": [], "307728190154737e": [], "099": [], "059": [], "066": [], "064": [], "051": [], "069": [], "073": [], "094": [], "044": [], "075": [], "049": [], "007": [], "050": [], "013": [], "012": [], "022": [], "ipykernel_69599": [], "ipykernel_69616": [], "ipykernel_69624": [], "013373": [], "436": [], "6290810108185": [], "1s": [], "245": [], "491": [], "541": [], "591": 126, "730": [], "773": [], "894": [], "967": [], "1004": [], "1037": [], "1076": [], "1158": [], "0s": [], "1244": [], "1291": [], "1334": [], "1380": [], "1428": [], "1471": [], "1516": [], "1560": [], "1604": [], "1630": [], "1663": [], "1701": [], "1742": [], "1784": [], "1832": [], "1878": [], "1952": [], "1986": [], "3s": [], "457": [], "566": [], "616": [], "664": [], "714": [], "764": [], "888": [], "959": [], "1001": [], "1087": [], "1130": [], "1199": [], "1237": [], "1276": [], "1314": [], "1354": [], "1396": [], "1487": [], "1531": [], "1576": [], "1621": [], "1664": [], "1709": [], "1753": [], "1790": [], "1822": [], "1854": [], "1884": [], "1961": [], "7409491539001465": [], "7258253693580627": [], "41203308": [], "36152625": [], "48624706": [], "3573": [], "62516263": [], "22829592": [], "59547664": [], "4451": [], "ipykernel_70043": [], "ipykernel_70048": [], "ipykernel_70054": [], "ipykernel_70069": [], "0x7fa5c9653b50": [], "99765581782896": [], "21773864116792": [], "28925487374045": [], "755192654070665": [], "ipykernel_70242": [], "0x7fe4c92c2a30": [], "65520914489093": [], "593025218515954": [], "4035997613058": [], "923348720194635": [], "ipykernel_70280": [], "4180678351": [], "ipykernel_70286": [], "ipykernel_70291": [], "ipykernel_70296": [], "ipykernel_70302": [], "ipykernel_70309": [], "ipykernel_70314": [], "ipykernel_70319": [], "018100205548753273": [], "0060663871581336445": [], "0048663280236869826": [], "0001815880748355717": [], "017081734489142183": [], "005868901113603956": [], "0021102789543256586": [], "0027705617093333012": [], "00106781868465062": [], "005821662648177357": [], "ipykernel_70352": [], "ipykernel_70357": [], "0x7fdaf17bf700": [], "0x7fdad0ec3c10": [], "0x7fdaf1b7b220": [], "724763509828": [], "576015382603453": [], "219540": [], "057616": [], "086234": [], "454508": [], "2411941683288": [], "733114904553531": [], "0x7fa3110b68b0": [], "0x7fa30127e700": [], "0x7fa300f14e50": [], "1858992783066": [], "6880019809809124": [], "0533734559239": [], "285407689505127": [], "ipykernel_72090": [], "ipykernel_72109": [], "ipykernel_72114": [], "ipykernel_72120": [], "ipykernel_72125": [], "ipykernel_72145": [], "ipykernel_72191": [], "ipykernel_72203": [], "ipykernel_72215": [], "ipykernel_72233": [], "ipykernel_72677": [], "35564234271940287": 15, "000343355404777341": 15, "3566768689137965": 15, "tf": 17, "standardscal": 17, "train_test_split": 17, "win_amd64": [], "colorama": 18, "roam": 18, "python39": 18, "38914445": [], "34495557": [], "21900331": [], "2875": [], "0x15cdd06d640": [], "2865979908378": [], "607882694404228": [], "9774569321002": [], "631351004175727": [], "0x25eadf82910": [], "06899229590096": [], "135681078585092": [], "48430501187559": [], "160292274985567": [], "ceiling_tau": 59, "tauvec": 59, "0x1936be0afd0": [], "0x1936be4da00": [], "0x1936be4df40": [], "357837718694": [], "678287762122905": [], "834484": [], "205075": [], "119636": [], "430997": [], "0448840452223": [], "67371173213258": [], "0x1841b5cddf0": [], "0x184218279a0": [], "0x184223b7af0": [], "1779642093472": [], "7779008274516843": [], "2705500968276": [], "239799877742534": [], "ipykernel_36988": [], "ipykernel_40004": [], "ipykernel_20148": [], "000581": [], "000019": [], "000093": [], "_env_getdata_aurora": 21, "get_aurora_cel": 21, "_env_getdata_panel": 33, "get_employment_cel": 33, "6030e": 59, "4421e": 59, "4993e": 59, "3665e": 59, "3960e": 59, "4896e": 59, "7105e": 59, "7022e": 59, "1808e": 59, "7639e": 59, "6023e": 59, "4452e": 59, "5004e": 59, "3869e": 59, "3954e": 59, "4917e": 59, "7018e": 59, "1694e": 59, "7577e": 59, "6011e": 59, "4439e": 59, "5006e": 59, "3797e": 59, "3962e": 59, "4904e": 59, "7309e": 59, "7019e": 59, "1724e": 59, "7681e": 59, "4997e": 59, "3741e": 59, "3956e": 59, "4910e": 59, "7230e": 59, "6997e": 59, "1711e": 59, "7590e": 59, "5996e": 59, "4419e": 59, "5000e": 59, "3787e": 59, "3965e": 59, "4909e": 59, "7180e": 59, "7024e": 59, "1827e": 59, "7586e": 59, "6015e": 59, "4431e": 59, "3793e": 59, "4907e": 59, "7191e": 59, "7016e": 59, "1705e": 59, "7622e": 59, "6004e": 59, "4441e": 59, "4998e": 59, "3839e": 59, "7254e": 59, "7002e": 59, "4443e": 59, "4999e": 59, "3810e": 59, "4902e": 59, "7239e": 59, "1761e": 59, "7565e": 59, "4438e": 59, "5001e": 59, "3824e": 59, "3959e": 59, "4903e": 59, "7140e": 59, "7004e": 59, "1754e": 59, "7614e": 59, "6021e": 59, "4444e": 59, "4994e": 59, "3840e": 59, "3955e": 59, "7017e": 59, "1613e": 59, "7616e": 59, "5992e": 59, "4450e": 59, "3838e": 59, "4908e": 59, "7125e": 59, "7013e": 59, "1732e": 59, "7662e": 59, "7475": 59, "74748816774957": 59, "3110e": 59, "1020e": 59, "ipykernel_28072": [], "ipykernel_15668": 120, "2553752622": 120, "567991": 120, "0261": 121, "0088": 121, "0042": 121, "0036": 121, "0024": 121, "0023": 121, "0007": 121, "0188": 121, "0069": 121, "0184": 121, "026068280875851824": 121, "00420277287581835": 121, "0024229424340379844": 121, "0006599800396108243": 121, "018782585526384673": 121, "008772183809351398": 121, "0035581671878296196": 121, "002258533318055646": 121, "0011830437572723908": 121, "006888698088228283": 121, "sanda_index": 124, "94560748": [], "03631782": [], "24418673": [], "01039801": [], "00236894": [], "02500368": [], "16616222": [], "02498772": [], "00680408": [], "04663373": [], "00426503": [], "00592246": [], "00346419": [], "00587797": [], "89401845": [], "05992334": [], "11234352": [], "01286305": [], "0038123": [], "00617015": [], "93511454": [], "37649399": [], "46904782": [], "00451459": [], "05979807": [], "06801119": [], "8041779": [], "29037822": [], "01046084": [], "02623068": [], "38071179": [], "95121306": [], "advis": 124, "excess": 124, "12708238118972615": [], "19364172": [], "43022668": [], "42227606": [], "42219369": [], "03969731": [], "83183631": [], "0446209": [], "58375899": [], "89697977": [], "35182466": [], "41703565": [], "91625097": [], "13608927": [], "61690587": [], "69365334": [], "27918828": [], "2024016": [], "04541335": [], "13391923": [], "45044888": [], "43695841": [], "41781739": [], "76158097": [], "86397324": [], "36207864": [], "53997224": [], "57297452": [], "64149907": [], "91390201": [], "66192588": [], "11098695": [], "4242157": [], "41103954": [], "8087694": [], "4534558": [], "24395105": [], "46910804": [], "02315674": [], "95875459": [], "87827698": [], "59671734": [], "32944522": [], "37227712": [], "19333887": [], "60004377": [], "5173245": [], "5228714": [], "40999269": [], "53478012": [], "33426202": [], "6749268": [], "79146124": [], "73329554": [], "43873827": [], "09386684": [], "96035613": [], "36221912": [], "2586123201823543": [], "259": 124, "2103": 126, "2274": 126, "0163": 126, "2438": 126, "2132360890518064": [], "0029724096241138995": [], "2102636794276925": [], "22743187935855116": 126, "01633182578287201": 126, "24376370514142318": 126, "9999999999999976": 126, "7647336090193217": 126, "0003": 126, "5633": 126, "dep": 126, "adj": 126, "prob": 126, "0607": 126, "likelihood": 126, "aic": 126, "bic": 126, "nonrobust": 126, "318": 126, "639": 126, "342e": 126, "42e": 126, "442e": 126, "81e": 126, "716": 126, "092": 126, "omnibu": 126, "durbin": 126, "watson": 126, "728": 126, "jarqu": 126, "bera": 126, "jb": 126, "320": 126, "19e": 126, "kurtosi": 126, "cond": 126, "13e": 126, "multicollinear": 126, "9999999999999988": 126, "23376313": [], "40096914": [], "26585595": [], "3439": [], "0x23a98eaab50": [], "16003441172552": [], "761160885584912": [], "96955095027931": [], "91358357500407": [], "0x210059592b0": [], "8243862854647": [], "724716028301505": [], "2495365487498": [], "998819423240908": [], "0x20967048be0": [], "0x2096d29da00": [], "0x2096d29dfa0": [], "0963414436314": [], "475458421273509": [], "888777": [], "465068": [], "107840": [], "473989": [], "5103574999391": [], "921870488483928": [], "0x2aa583ec6d0": [], "0x2aa5e648790": [], "0x2aa5f1d72b0": [], "4453811258452": [], "5323011327406104": [], "3564097649079": [], "157035199684572": [], "ipykernel_33080": [], "ipykernel_7996": [], "7935056": 124, "05573883": 124, "17789437": 124, "01291861": 124, "00327331": 124, "03616324": 124, "15807825": 124, "02133172": 124, "00817926": 124, "03642929": 124, "00494878": 124, "00934406": 124, "00510541": 124, "00866307": 124, "70943365": 124, "05460816": 124, "17366209": 124, "01714046": 124, "00543908": 124, "00765503": 124, "84943974": 124, "35520862": 124, "4361084": 124, "00567393": 124, "10858887": 124, "54647282": 124, "26561005": 124, "0139195": 124, "02708104": 124, "35007447": 124, "87203275": 124, "11361078792742538": 124, "20963072": 124, "36363165": 124, "45134661": 124, "13025089": 124, "10068802": 124, "31679702": 124, "36382407": 124, "07217217": 124, "03274754": 124, "28356984": 124, "85172173": 124, "90975369": 124, "31952385": 124, "49851422": 124, "1926697": 124, "08880954": 124, "13806398": 124, "91018533": 124, "38592831": 124, "30080782": 124, "81897977": 124, "22512521": 124, "56978246": 124, "97367999": 124, "06606889": 124, "46204494": 124, "56211986": 124, "36768737": 124, "97789444": 124, "76346229": 124, "06702501": 124, "3791031": 124, "73897488": 124, "87357018": 124, "85450739": 124, "38658623": 124, "55869654": 124, "18709482": 124, "49089899": 124, "05070015": 124, "02144515": 124, "07582235": 124, "02950435": 124, "60493756": 124, "34331682": 124, "13339107": 124, "74942471": 124, "34136664": 124, "20697202": 124, "89639628": 124, "67296089": 124, "52157244": 124, "55823332": 124, "01110759": 124, "05096632": 124, "13785416": 124, "00794219": 124, "23241547432382942": 124, "ipykernel_30044": [], "000442": [], "000128": [], "000043": [], "000021": [], "55780383": [], "55776145": [], "26616533": [], "5456": [], "0x1db4152d8b0": [], "0023876425832": [], "437558204858794": [], "71535987423458": [], "244767414348546": [], "0x18e9b678b80": [], "40133295405724": [], "35488891643625": [], "15445575830401": [], "252350953101471": [], "0x2012923de20": [], "0x2012f49db20": [], "0x2012f49db80": [], "2133469299063": [], "823785744453524": [], "831787": [], "947901": [], "169995": [], "425261": [], "5287065508692": [], "298436076195818": [], "0x22080dee3d0": [], "0x22080e1a940": [], "0x220819a82b0": [], "860420629956": [], "900572995169583": [], "3385307224661": [], "1985718821033515": [], "ipykernel_16436": [], "ipykernel_35364": [], "ipykernel_21592": [], "000031": [], "000048": [], "000041": [], "000025": [], "38454212": 20, "51956827": 20, "32756592": 20, "3359": 20, "0x2a772443100": 45, "27521968502833": 45, "354497907288068": 45, "17472803825572": 45, "867839711739167": 45, "0x226c495c5b0": 58, "51997130894716": 58, "7744669761550345": 58, "35720923607289": 58, "820748607397341": 58, "0x1d9f3218fd0": 75, "0x1d9f325dc40": 75, "0x1d9f325dd60": 75, "200075709762": 75, "376658057747621": 75, "690237": 75, "443207": 75, "003583": 75, "454401": 75, "4575794414952": 75, "694060447190269": 75, "0x209e71ef5e0": 77, "0x209ed438790": 77, "0x209edfc62b0": 77, "929127783917": 77, "5644445110960645": 77, "5892133768467": 77, "110063355244821": 77, "eg": [89, 90, 91], "ipykernel_16404": 120, "ipykernel_16800": 123, "ipykernel_7516": 127, "000394": 128, "000028": 128, "pdf": 128, "dpi": 128}, "objects": {}, "objtypes": {}, "objnames": {}, "titleterms": {"learner": [0, 9, 10, 11, 13, 14, 16, 20, 22, 24, 25, 26, 28, 29, 42, 43, 49, 50, 69, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104], "name": [0, 132], "singl": [0, 19, 27, 60, 61, 107, 120, 126], "multipl": [0, 21, 37, 76, 127], "stage": [0, 19, 27, 37, 60, 76, 120, 122, 126], "infinit": [0, 62, 67, 70, 72, 121], "horizon": [0, 62, 67, 70, 72, 121], "main": [0, 11, 14, 19, 45, 47, 49, 58, 59, 62, 63, 65, 66, 67, 68, 69, 70, 72, 75, 77, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115], "idea": [0, 11, 14, 19, 45, 47, 49, 58, 59, 62, 63, 65, 66, 67, 68, 69, 70, 72, 75, 77, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115], "algorithm": [0, 11, 13, 14, 40, 45, 58, 59, 75, 77, 78, 82, 84, 85, 94, 95, 99, 100, 101, 102, 105, 107, 108, 109, 114, 115], "detail": [0, 9, 11, 13, 14, 45, 49, 58, 75, 77, 82, 84, 85, 95, 100, 102, 105, 108, 109, 114, 115], "kei": [0, 45, 58, 75, 77, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115], "step": [0, 45, 58, 75, 77, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115, 130], "demo": [0, 11, 13, 14, 21, 33, 40, 45, 47, 49, 58, 59, 68, 69, 72, 75, 77, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115, 123, 124], "code": [0, 5, 11, 13, 14, 45, 49, 58, 69, 75, 77, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115], "1": [0, 2, 9, 11, 12, 13, 14, 15, 17, 21, 22, 26, 27, 45, 49, 58, 70, 75, 77, 107, 130, 132], "polici": [0, 2, 7, 45, 49, 55, 58, 59, 62, 63, 64, 67, 69, 70, 71, 72, 73, 74, 75, 77, 89, 90, 91, 92, 117, 118, 122, 126, 129, 132], "learn": [0, 1, 2, 3, 27, 37, 45, 47, 49, 51, 54, 58, 61, 62, 69, 70, 75, 77, 94, 117, 118, 123, 124, 128, 132], "2": [0, 2, 9, 11, 12, 13, 14, 15, 17, 21, 22, 27, 28, 32, 45, 49, 58, 70, 75, 77, 120, 130, 132], "evalu": [0, 7, 45, 49, 58, 59, 62, 63, 64, 65, 67, 70, 72, 73, 74, 75, 77, 89, 90, 91, 92, 117, 122, 126], "refer": [0, 2, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 33, 35, 36, 37, 39, 40, 41, 42, 43, 45, 47, 49, 58, 59, 62, 63, 65, 66, 67, 68, 69, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 114, 115, 116, 117, 118, 121, 122, 126, 132], "causal": [1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 27, 74, 123, 124, 128, 132], "effect": [1, 4, 6, 10, 12, 21, 27, 69, 123, 124, 128, 132], "cel": [1, 27, 121, 122, 126, 132], "clinic": [1, 2], "trial": 1, "advertis": 1, "market": 1, "more": 1, "beyond": 1, "cpl": [2, 122, 126, 132], "scenario": 2, "fix": [2, 132], "independ": [2, 132], "state": [2, 132], "person": [2, 12, 128], "incent": 2, "ad": [2, 5], "target": [2, 17, 69], "bid": 2, "markovian": [2, 117, 118, 132], "transit": [2, 132], "mobil": 2, "health": 2, "3": [2, 9, 11, 12, 13, 14, 15, 21, 22, 29, 38, 120, 122, 132], "non": [2, 11, 118, 132], "healthcar": 2, "trail": 2, "multi": [2, 83, 86, 111], "touch": 2, "attribut": 2, "4": [2, 24, 25, 132], "adapt": [2, 53, 132], "recommend": [2, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 106, 107, 116], "system": 2, "onlin": [2, 89, 90, 91, 92, 94, 99, 117, 128, 129], "dynam": [2, 69, 101], "price": 2, "5": [2, 16, 25, 127, 132], "6": [2, 20, 25, 132], "structur": [3, 9, 11, 13, 14, 79, 83, 106, 132], "csl": [3, 132], "spread": 3, "covid": 3, "19": 3, "gene": 3, "express": 3, "trait": 3, "yeast": 3, "infer": [4, 5, 6], "101": [4, 5], "potenti": [4, 6, 74, 130], "outcom": [4, 6, 47, 51, 74, 123, 124], "assumpt": [4, 6, 15, 33], "averag": [4, 6], "regress": 4, "model": [4, 9, 11, 13, 14, 117, 118, 128, 129], "propens": 4, "score": [4, 13], "stratif": 4, "invers": [4, 91], "weight": [4, 47, 91], "doubli": [4, 15, 62, 90], "robust": [4, 15, 21, 62, 90], "estim": [4, 15, 19, 21, 33, 62, 64, 69, 128], "what": [5, 132], "myst": 5, "ar": 5, "role": 5, "direct": [5, 15, 21, 89], "us": 5, "citat": 5, "execut": 5, "your": 5, "markdown": 5, "file": 5, "preliminari": [6, 8, 12, 73, 74], "do": [6, 57], "oper": 6, "treatment": [6, 10, 12, 21, 59], "heterogen": [6, 12], "optim": [7, 59, 70, 71, 73, 74, 99, 101, 117, 122, 126, 129], "discoveri": [9, 10, 11, 13, 14, 123, 124], "gener": [9, 11, 12, 13, 14, 18, 23, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 120], "graph": [9, 11, 12, 13, 14], "terminolog": [9, 11, 12, 13, 14], "overview": [9, 13, 49, 78, 80, 81, 82, 84, 85, 86, 88, 90, 93, 95, 96, 97, 98, 100, 102, 103, 104, 132], "popular": 9, "graphic": [9, 11, 13, 14, 79, 83], "linear": [9, 11, 13, 14, 128], "equat": [9, 11, 13, 14], "addit": [9, 11, 13], "nois": [9, 11, 13], "lsem": [9, 13], "method": [9, 15, 107, 133], "To": [9, 57], "Be": 9, "For": 9, "paradigm": [9, 27, 32, 38, 132], "mediat": [10, 12, 21, 69, 120, 121, 122, 126], "analysi": [10, 12, 21, 69, 121, 122, 126, 128], "from": 10, "tabl": 10, "anoc": 10, "cvae": 10, "cai": 10, "et": [10, 13], "al": [10, 13], "2020": 10, "function": [11, 69, 73], "base": [11, 13, 14, 50, 68, 117], "goal": [11, 13, 14], "applic": [11, 13, 14], "gaussian": [11, 14, 107], "gaussain": 11, "synthet": [11, 13, 14, 40, 41, 42, 43], "dataset": [11, 13, 14, 59, 120, 127], "ica": 11, "lingam": 11, "summari": [11, 13, 14], "result": [11, 13, 14, 128], "under": [11, 13, 14, 74, 127], "differ": [11, 13, 14, 19, 33], "exampl": 12, "decis": [12, 32, 70, 73, 74], "make": 12, "real": [12, 27, 59, 60, 76, 79, 83, 87, 106, 107, 116], "case": 12, "sepsi": 12, "intens": 12, "care": 12, "unit": 12, "icu": 12, "toi": 12, "remark": 12, "notear": 13, "zheng": 13, "2018": 13, "test": [14, 61], "pc": 14, "ATE": [15, 30], "identif": [15, 21], "import": [15, 67, 69, 72, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 130], "sampl": [15, 67, 72, 86, 88, 107], "dr": [16, 25], "movielen": [16, 17, 18, 20, 24, 26, 28, 29, 128], "data": [16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 38, 53, 56, 59, 60, 69, 76, 79, 83, 87, 106, 107, 116, 120, 127, 132], "8": [17, 23], "dragon": [17, 23], "net": [17, 23], "part": 17, "dragonnet": 17, "regular": 17, "7": [18, 23], "random": [18, 23], "forest": [18, 23], "hte": [19, 31], "approach": [19, 23], "The": 19, "advantag": 19, "lp": [20, 25], "r": [20, 24, 25, 39], "definit": [21, 33], "ipw": 21, "mr": 21, "aurora": 21, "covid19": 21, "meta": [22, 87, 88, 113], "s": [22, 26], "t": [22, 28], "x": [22, 29, 43], "other": 23, "movi": [27, 127], "len": 27, "pre": 27, "process": [27, 32, 59, 73, 74], "final": 27, "select": 27, "mimic3": [27, 123, 124, 125], "markov": [32, 73, 74], "background": [33, 40], "time": [33, 56], "vari": 33, "att": 33, "extens": 34, "h1sl": 35, "h2sl": 35, "matrix": 36, "complet": 36, "mediatedq": 37, "panel": [38, 132], "did": [39, 41], "control": [40, 69], "miscellan": 44, "A": [45, 61, 75, 132], "reduct": 46, "classif": 46, "problem": [46, 60, 76, 79, 83, 87, 94, 99, 101, 106, 107, 116], "entropi": [], "when": 130, "should": [], "i": 132, "owl": 47, "spars": 47, "a1": 47, "deriv": 47, "continu": [48, 49], "action": [48, 49, 52], "space": [48, 52], "deep": 49, "jump": 49, "difficulti": 49, "kernel": 50, "discret": 52, "collect": 53, "concord": 54, "assist": 54, "search": 55, "event": 56, "plan": 57, "q": [58, 65, 66, 70, 77], "quantil": 59, "regim": 59, "motiv": 59, "simul": [59, 107, 129], "calcul": 59, "off": [59, 63, 73, 74], "set": [60, 76, 79, 83, 87, 94, 99, 101, 106, 107, 116], "doubl": 62, "reinforc": [62, 69], "stationari": [62, 67], "distribut": [62, 67, 68], "todo": [68, 72], "note": [62, 63, 67, 68, 72], "deepli": 63, "debias": 63, "valu": [64, 73, 117], "fit": [65, 66, 128], "iter": 66, "break": 67, "curs": 67, "confid": [68, 107], "interv": 68, "op": 68, "asymptot": 68, "ci": 68, "drl": 68, "load": 69, "observ": [69, 127], "specifi": [69, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 129], "hyperparamet": [69, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104], "defin": 69, "obtain": 69, "each": 69, "compon": 69, "standard": 69, "error": [69, 130], "framework": [74, 89, 90, 91], "identifi": 74, "dtr": [76, 120], "bandit": [78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 94, 99, 101, 106, 107, 127, 132], "contextu": 79, "lint": [80, 109], "environ": [80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 117, 118, 129], "interact": [80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104], "bernoulli": [80, 81, 82, 84, 85, 86, 88, 107, 127], "linucb": [81, 110], "epsilon": [82, 107], "greedi": [82, 107, 128], "arm": 83, "mab": [83, 129], "ts": [84, 113, 114, 128], "ucb": 85, "task": [86, 111], "thompson": [86, 88, 107], "mtt": [86, 112], "eg": [], "probabl": [90, 91], "explor": [90, 91], "cascadelint": 93, "rank": 94, "cascad": 94, "support": [94, 99, 101, 107], "mtss_cascad": 95, "ts_cascad": 96, "comblint": 97, "combt": 98, "combinatori": 99, "semi": 99, "mtss_comb": 100, "assort": 101, "multinomi": 101, "logit": 101, "mtss_mnl": 102, "ts_contextual_mnl": 103, "ts_mnl": 104, "ucb_mnl": 105, "slate": [106, 116], "item": 107, "claasic": 107, "upper": 107, "bound": 107, "epsilon_greedi": 108, "ucb1": 115, "oolin": 118, "gradient": 117, "approxim": 117, "dp": 117, "actor": 117, "critic": 117, "mimic": [119, 121, 122, 126], "iii": [119, 121, 122, 126], "mrl": 120, "rl": 120, "creat": 120, "regard": [123, 124], "died_within_48h": [123, 124], "variabl": [123, 124, 127], "sofa": [123, 124], "ver2": 124, "read": 127, "keep": 127, "onli": 127, "top": 127, "occup": 127, "genr": 127, "convert": 127, "gender": 127, "dummi": 127, "subset": 127, "user": 127, "least": 127, "500": 127, "format": 127, "nonlinear": 128, "sigma": 128, "boldsymbol": 128, "gamma": 128, "run": [128, 130], "inform": 128, "uninform": 128, "true": 129, "offlin": 129, "introduct": 131, "author": 131, "expect": 132, "sl": 132, "ml": 132, "case1": 132, "d": 132, "pl": 132, "case2": 132, "case3": 132, "case4": 132, "case5": 132, "case6": 132, "appendix": 132, "singeldtr": 132, "mdp": 132, "b": 132, "multidtr": 132, "c": 132, "content": [], "everi": [], "notebook": 133, "how": [130, 133], "contribut": 133, "compil": 130, "new": [130, 133], "version": 130, "option": 130, "publish": 130, "messag": 130, "ghp": 130, "acknowledg": [], "naiv": 128, "tutori": 131, "talk": 131, "prepar": 133, "jupyt": 133, "contributor": [131, 133], "all": 131}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinxcontrib.bibtex": 9, "sphinx": 56}})