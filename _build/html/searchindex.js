<<<<<<< Updated upstream
Search.setIndex({"docnames": ["0_Learner Template", "0_Motivating_Examples/CEL", "0_Motivating_Examples/CPL", "0_Motivating_Examples/CSL", "1_Preliminary/(old) Causal Inference 101", "1_Preliminary/Causal Inference 101_old", "1_Preliminary/Causal Inference Preliminary", "1_Preliminary/Policy Evaluation and Optimization", "1_Preliminary/Preliminary", "2_Causal_Structure_Learning/Causal Discovery", "2_Causal_Structure_Learning/Causal Mediation Analysis", "2_Causal_Structure_Learning/Functional-based Learner", "2_Causal_Structure_Learning/Preliminaries of Causal Graphs", "2_Causal_Structure_Learning/Score-based Learner", "2_Causal_Structure_Learning/Testing-based Learner", "3_Causal_Effect_Learning/Scenario 1/ATE", "3_Causal_Effect_Learning/Scenario 1/DR-Learner", "3_Causal_Effect_Learning/Scenario 1/Dragonnet", "3_Causal_Effect_Learning/Scenario 1/GRF", "3_Causal_Effect_Learning/Scenario 1/HTE", "3_Causal_Effect_Learning/Scenario 1/Lp-R-Learner", "3_Causal_Effect_Learning/Scenario 1/Mediation Analysis", "3_Causal_Effect_Learning/Scenario 1/Meta Learners", "3_Causal_Effect_Learning/Scenario 1/Other Approaches", "3_Causal_Effect_Learning/Scenario 1/R-Learner", "3_Causal_Effect_Learning/Scenario 1/R-Learner, DR-Learner, Lp-R-Learner", "3_Causal_Effect_Learning/Scenario 1/S-learner", "3_Causal_Effect_Learning/Scenario 1/Single Stage", "3_Causal_Effect_Learning/Scenario 1/T-learner", "3_Causal_Effect_Learning/Scenario 1/X-learner", "3_Causal_Effect_Learning/Scenario 2/ATE", "3_Causal_Effect_Learning/Scenario 2/HTE", "3_Causal_Effect_Learning/Scenario 2/underMDP", "3_Causal_Effect_Learning/Scenario 3/DiD", "3_Causal_Effect_Learning/Scenario 3/Extensions", "3_Causal_Effect_Learning/Scenario 3/H1SL_H2SL", "3_Causal_Effect_Learning/Scenario 3/Matrix Completion", "3_Causal_Effect_Learning/Scenario 3/MediatedQ-learning_Multiple", "3_Causal_Effect_Learning/Scenario 3/Panel Data", "3_Causal_Effect_Learning/Scenario 3/R-DiD", "3_Causal_Effect_Learning/Scenario 3/Synthetic Control", "3_Causal_Effect_Learning/Scenario 3/Synthetic DiD", "3_Causal_Effect_Learning/Scenario 3/Synthetic Learner", "3_Causal_Effect_Learning/Scenario 3/Synthetic X-Learner", "3_Causal_Effect_Learning/Scenario 4/Miscellaneous", "4_Causal_Policy_Learning/Scenario1/A-learning_Single", "4_Causal_Policy_Learning/Scenario1/Classification", "4_Causal_Policy_Learning/Scenario1/Classification/E-learning", "4_Causal_Policy_Learning/Scenario1/Classification/O-Learning", "4_Causal_Policy_Learning/Scenario1/Continuous", "4_Causal_Policy_Learning/Scenario1/Continuous/Deep Jump Learner", "4_Causal_Policy_Learning/Scenario1/Continuous/Kernel-Based Learner", "4_Causal_Policy_Learning/Scenario1/Continuous/Outcome Learning", "4_Causal_Policy_Learning/Scenario1/Discrete", "4_Causal_Policy_Learning/Scenario1/Micellaneous/Adaptively Collected Data", "4_Causal_Policy_Learning/Scenario1/Micellaneous/Concordance", "4_Causal_Policy_Learning/Scenario1/Micellaneous/Policy Search", "4_Causal_Policy_Learning/Scenario1/Micellaneous/Survival", "4_Causal_Policy_Learning/Scenario1/PlanToDo", "4_Causal_Policy_Learning/Scenario1/Q-learning_Single", "4_Causal_Policy_Learning/Scenario1/Quantile/QuantileOTR_test", "4_Causal_Policy_Learning/Scenario1/Single Stage", "4_Causal_Policy_Learning/Scenario1/Test/A_Q test", "4_Causal_Policy_Learning/Scenario2/DR_Infinite", "4_Causal_Policy_Learning/Scenario2/Deeply_Debiased", "4_Causal_Policy_Learning/Scenario2/Evaluation", "4_Causal_Policy_Learning/Scenario2/Evaluation_MA", "4_Causal_Policy_Learning/Scenario2/FQE", "4_Causal_Policy_Learning/Scenario2/FQI", "4_Causal_Policy_Learning/Scenario2/IPW_Infinite", "4_Causal_Policy_Learning/Scenario2/Inference", "4_Causal_Policy_Learning/Scenario2/MediationRL", "4_Causal_Policy_Learning/Scenario2/Model_based_Infinite", "4_Causal_Policy_Learning/Scenario2/Optimization", "4_Causal_Policy_Learning/Scenario2/Spatial_temporal_DR", "4_Causal_Policy_Learning/Scenario2/archive/archive_preliminary_MDP", "4_Causal_Policy_Learning/Scenario2/preliminary_MDP-potential-outcome", "4_Causal_Policy_Learning/Scenario3/A-learning_Multiple", "4_Causal_Policy_Learning/Scenario3/Multi Stage", "4_Causal_Policy_Learning/Scenario3/Q-learning_Multiple", "4_Causal_Policy_Learning/Scenario4/Bandits", "4_Causal_Policy_Learning/Scenario4/Contextual_Bandits/Contextual_Bandits", "4_Causal_Policy_Learning/Scenario4/Contextual_Bandits/LinTS", "4_Causal_Policy_Learning/Scenario4/Contextual_Bandits/LinUCB", "4_Causal_Policy_Learning/Scenario4/MAB/Epsilon_Greedy", "4_Causal_Policy_Learning/Scenario4/MAB/MAB", "4_Causal_Policy_Learning/Scenario4/MAB/TS", "4_Causal_Policy_Learning/Scenario4/MAB/UCB", "4_Causal_Policy_Learning/Scenario4/Meta_Bandits/MTTS", "4_Causal_Policy_Learning/Scenario4/Meta_Bandits/Meta_Bandits", "4_Causal_Policy_Learning/Scenario4/Meta_Bandits/Meta_TS", "4_Causal_Policy_Learning/Scenario4/OnlineEval/Direct Online Policy Evaluator", "4_Causal_Policy_Learning/Scenario4/OnlineEval/Doubly Robust Online Policy Evaluator", "4_Causal_Policy_Learning/Scenario4/OnlineEval/Inverse Probability Weighted Online Policy Evaluator", "4_Causal_Policy_Learning/Scenario4/OnlineEval/Online Policy Evaluation", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/CascadeLinTS", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/Learning to rank", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/MTSS_Cascade", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/TS_Cascade", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/CombLinTS", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/CombTS", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/Combinatorial Optimization", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/MTSS_Comb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/Assortment Optimization", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/MTSS_MNL", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/TS_Contextual_MNL", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/TS_MNL_Beta", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/UCB-MNL", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Structured_Bandit", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single-Item Recommendation", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/Epsilon Greedy", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/LinTS", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/LinUCB", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/Multi-Task", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/MultiTask/MTTS", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/MultiTask/Meta-TS", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/TS", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/UCB1", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Slate Recommendation", "4_Causal_Policy_Learning/Scenario5/OnlineRL_Markov", "4_Causal_Policy_Learning/Scenario6/OnlineRL_non_Markov", "5_Case_Study/MIMIC3/Case_Study_1", "5_Case_Study/MIMIC3/Create_DTR_RL_MIMIC_Data_V2", "5_Case_Study/MIMIC3/Infinite_Horizon", "5_Case_Study/MIMIC3/Longitudinal", "5_Case_Study/MIMIC3/MIMIC3-Demo", "5_Case_Study/MIMIC3/MIMIC3-Demo-Ver2", "5_Case_Study/MIMIC3/MIMIC3_intro", "5_Case_Study/MIMIC3/Single_Stage", "5_Case_Study/MovieLens/Data_Preprocessing", "5_Case_Study/MovieLens/MovieLens", "5_Case_Study/MovieLens/MovieLens_simulation", "Overview", "README", "Untitled", "_old files(to delete)/Map"], "filenames": ["0_Learner Template.ipynb", "0_Motivating_Examples/CEL.ipynb", "0_Motivating_Examples/CPL.ipynb", "0_Motivating_Examples/CSL.ipynb", "1_Preliminary/(old) Causal Inference 101.ipynb", "1_Preliminary/Causal Inference 101_old.md", "1_Preliminary/Causal Inference Preliminary.ipynb", "1_Preliminary/Policy Evaluation and Optimization.md", "1_Preliminary/Preliminary.md", "2_Causal_Structure_Learning/Causal Discovery.ipynb", "2_Causal_Structure_Learning/Causal Mediation Analysis.ipynb", "2_Causal_Structure_Learning/Functional-based Learner.ipynb", "2_Causal_Structure_Learning/Preliminaries of Causal Graphs.ipynb", "2_Causal_Structure_Learning/Score-based Learner.ipynb", "2_Causal_Structure_Learning/Testing-based Learner.ipynb", "3_Causal_Effect_Learning/Scenario 1/ATE.ipynb", "3_Causal_Effect_Learning/Scenario 1/DR-Learner.ipynb", "3_Causal_Effect_Learning/Scenario 1/Dragonnet.ipynb", "3_Causal_Effect_Learning/Scenario 1/GRF.ipynb", "3_Causal_Effect_Learning/Scenario 1/HTE.ipynb", "3_Causal_Effect_Learning/Scenario 1/Lp-R-Learner.ipynb", "3_Causal_Effect_Learning/Scenario 1/Mediation Analysis.ipynb", "3_Causal_Effect_Learning/Scenario 1/Meta Learners.ipynb", "3_Causal_Effect_Learning/Scenario 1/Other Approaches.ipynb", "3_Causal_Effect_Learning/Scenario 1/R-Learner.ipynb", "3_Causal_Effect_Learning/Scenario 1/R-Learner, DR-Learner, Lp-R-Learner.ipynb", "3_Causal_Effect_Learning/Scenario 1/S-learner.ipynb", "3_Causal_Effect_Learning/Scenario 1/Single Stage.ipynb", "3_Causal_Effect_Learning/Scenario 1/T-learner.ipynb", "3_Causal_Effect_Learning/Scenario 1/X-learner.ipynb", "3_Causal_Effect_Learning/Scenario 2/ATE.md", "3_Causal_Effect_Learning/Scenario 2/HTE.md", "3_Causal_Effect_Learning/Scenario 2/underMDP.md", "3_Causal_Effect_Learning/Scenario 3/DiD.ipynb", "3_Causal_Effect_Learning/Scenario 3/Extensions.md", "3_Causal_Effect_Learning/Scenario 3/H1SL_H2SL.ipynb", "3_Causal_Effect_Learning/Scenario 3/Matrix Completion.ipynb", "3_Causal_Effect_Learning/Scenario 3/MediatedQ-learning_Multiple.ipynb", "3_Causal_Effect_Learning/Scenario 3/Panel Data.md", "3_Causal_Effect_Learning/Scenario 3/R-DiD.ipynb", "3_Causal_Effect_Learning/Scenario 3/Synthetic Control.ipynb", "3_Causal_Effect_Learning/Scenario 3/Synthetic DiD.ipynb", "3_Causal_Effect_Learning/Scenario 3/Synthetic Learner.ipynb", "3_Causal_Effect_Learning/Scenario 3/Synthetic X-Learner.ipynb", "3_Causal_Effect_Learning/Scenario 4/Miscellaneous.md", "4_Causal_Policy_Learning/Scenario1/A-learning_Single.ipynb", "4_Causal_Policy_Learning/Scenario1/Classification.md", "4_Causal_Policy_Learning/Scenario1/Classification/E-learning.ipynb", "4_Causal_Policy_Learning/Scenario1/Classification/O-Learning.ipynb", "4_Causal_Policy_Learning/Scenario1/Continuous.md", "4_Causal_Policy_Learning/Scenario1/Continuous/Deep Jump Learner.ipynb", "4_Causal_Policy_Learning/Scenario1/Continuous/Kernel-Based Learner.md", "4_Causal_Policy_Learning/Scenario1/Continuous/Outcome Learning.md", "4_Causal_Policy_Learning/Scenario1/Discrete.md", "4_Causal_Policy_Learning/Scenario1/Micellaneous/Adaptively Collected Data.ipynb", "4_Causal_Policy_Learning/Scenario1/Micellaneous/Concordance.ipynb", "4_Causal_Policy_Learning/Scenario1/Micellaneous/Policy Search.ipynb", "4_Causal_Policy_Learning/Scenario1/Micellaneous/Survival.ipynb", "4_Causal_Policy_Learning/Scenario1/PlanToDo.md", "4_Causal_Policy_Learning/Scenario1/Q-learning_Single.ipynb", "4_Causal_Policy_Learning/Scenario1/Quantile/QuantileOTR_test.ipynb", "4_Causal_Policy_Learning/Scenario1/Single Stage.md", "4_Causal_Policy_Learning/Scenario1/Test/A_Q test.ipynb", "4_Causal_Policy_Learning/Scenario2/DR_Infinite.ipynb", "4_Causal_Policy_Learning/Scenario2/Deeply_Debiased.ipynb", "4_Causal_Policy_Learning/Scenario2/Evaluation.md", "4_Causal_Policy_Learning/Scenario2/Evaluation_MA.md", "4_Causal_Policy_Learning/Scenario2/FQE.ipynb", "4_Causal_Policy_Learning/Scenario2/FQI.ipynb", "4_Causal_Policy_Learning/Scenario2/IPW_Infinite.ipynb", "4_Causal_Policy_Learning/Scenario2/Inference.ipynb", "4_Causal_Policy_Learning/Scenario2/MediationRL.ipynb", "4_Causal_Policy_Learning/Scenario2/Model_based_Infinite.ipynb", "4_Causal_Policy_Learning/Scenario2/Optimization.md", "4_Causal_Policy_Learning/Scenario2/Spatial_temporal_DR.ipynb", "4_Causal_Policy_Learning/Scenario2/archive/archive_preliminary_MDP.ipynb", "4_Causal_Policy_Learning/Scenario2/preliminary_MDP-potential-outcome.ipynb", "4_Causal_Policy_Learning/Scenario3/A-learning_Multiple.ipynb", "4_Causal_Policy_Learning/Scenario3/Multi Stage.md", "4_Causal_Policy_Learning/Scenario3/Q-learning_Multiple.ipynb", "4_Causal_Policy_Learning/Scenario4/Bandits.md", "4_Causal_Policy_Learning/Scenario4/Contextual_Bandits/Contextual_Bandits.ipynb", "4_Causal_Policy_Learning/Scenario4/Contextual_Bandits/LinTS.ipynb", "4_Causal_Policy_Learning/Scenario4/Contextual_Bandits/LinUCB.ipynb", "4_Causal_Policy_Learning/Scenario4/MAB/Epsilon_Greedy.ipynb", "4_Causal_Policy_Learning/Scenario4/MAB/MAB.ipynb", "4_Causal_Policy_Learning/Scenario4/MAB/TS.ipynb", "4_Causal_Policy_Learning/Scenario4/MAB/UCB.ipynb", "4_Causal_Policy_Learning/Scenario4/Meta_Bandits/MTTS.ipynb", "4_Causal_Policy_Learning/Scenario4/Meta_Bandits/Meta_Bandits.ipynb", "4_Causal_Policy_Learning/Scenario4/Meta_Bandits/Meta_TS.ipynb", "4_Causal_Policy_Learning/Scenario4/OnlineEval/Direct Online Policy Evaluator.ipynb", "4_Causal_Policy_Learning/Scenario4/OnlineEval/Doubly Robust Online Policy Evaluator.ipynb", "4_Causal_Policy_Learning/Scenario4/OnlineEval/Inverse Probability Weighted Online Policy Evaluator.ipynb", "4_Causal_Policy_Learning/Scenario4/OnlineEval/Online Policy Evaluation.md", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/CascadeLinTS.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/Learning to rank.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/MTSS_Cascade.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/TS_Cascade.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/CombLinTS.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/CombTS.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/Combinatorial Optimization.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/MTSS_Comb.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/Assortment Optimization.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/MTSS_MNL.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/TS_Contextual_MNL.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/TS_MNL_Beta.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/UCB-MNL.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Structured_Bandit.ipynb", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single-Item Recommendation.ipynb", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/Epsilon Greedy.ipynb", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/LinTS.ipynb", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/LinUCB.md", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/Multi-Task.md", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/MultiTask/MTTS.md", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/MultiTask/Meta-TS.md", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/TS.ipynb", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/UCB1.ipynb", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Slate Recommendation.ipynb", "4_Causal_Policy_Learning/Scenario5/OnlineRL_Markov.ipynb", "4_Causal_Policy_Learning/Scenario6/OnlineRL_non_Markov.ipynb", "5_Case_Study/MIMIC3/Case_Study_1.md", "5_Case_Study/MIMIC3/Create_DTR_RL_MIMIC_Data_V2.ipynb", "5_Case_Study/MIMIC3/Infinite_Horizon.ipynb", "5_Case_Study/MIMIC3/Longitudinal.ipynb", "5_Case_Study/MIMIC3/MIMIC3-Demo.ipynb", "5_Case_Study/MIMIC3/MIMIC3-Demo-Ver2.ipynb", "5_Case_Study/MIMIC3/MIMIC3_intro.ipynb", "5_Case_Study/MIMIC3/Single_Stage.ipynb", "5_Case_Study/MovieLens/Data_Preprocessing.ipynb", "5_Case_Study/MovieLens/MovieLens.ipynb", "5_Case_Study/MovieLens/MovieLens_simulation.ipynb", "Overview.md", "README.md", "Untitled.ipynb", "_old files(to delete)/Map.md"], "titles": ["Learner Name (Single/Multiple Stages/Infinite Horizon)", "Causal Effect Learning (CEL)", "Causal Policy Learning (CPL)", "Causal Structure Learning (CSL)", "Causal Inference 101", "Causal Inference 101", "Causal Inference Preliminary", "Policy Evaluation and Optimization", "Preliminary", "Causal Discovery", "Causal Mediation Analysis", "Functional-based Learner", "Preliminaries of Causal Graphs", "Score-based Learner", "Testing-based Learner", "ATE Estimation", "<strong>5. DR-learner</strong>", "<strong>8. Dragon Net</strong>", "<strong>7. Generalized Random Forest</strong>", "HTE Estimation", "<strong>6. Lp-R-learner</strong>", "Mediation Analysis", "<strong>Meta Learners</strong>", "<strong>Other Approaches</strong>", "<strong>4. R learner</strong>", "<strong>R-Learner, DR-Learner, and Lp-R-Learner</strong>", "<strong>1. S-learner</strong>", "<strong>Single Stage \u2013 Paradigm 1</strong>", "<strong>2. T-learner</strong>", "<strong>3. X-learner</strong>", "ATE", "HTE", "Markov Decision Processes \u2013 Paradigm 2", "<strong>Difference in Difference</strong>", "Extensions", "<strong>H1SL and H2SL</strong>", "<strong>Matrix Completion</strong>", "MediatedQ-Learning (Multiple Stages)", "Panel Data  \u2013 Paradigm 3", "<strong>R-DiD</strong>", "<strong>Synthetic Control</strong>", "<strong>Synthetic DiD</strong>", "<strong>Synthetic Learner</strong>", "<strong>Synthetic X-Learner</strong>", "Miscellaneous", "A-Learning (Single Stage)", "Reduction to Classification Problems", "Entropy learning", "Outcome Weighted Learning", "Continuous Action Space", "Deep Jump Learner for Continuous Actions", "Kernel-Based Learner", "Outcome Learning", "Discrete Action Space", "Adaptively Collected Data", "Concordance-assisted learning", "Policy Search", "Time-to-Event Data", "Plan To Do", "Q-Learning (Single Stage)", "Quantile Optimal Treatment Regime", "Single Stage", "Test A-Learning Single", "Doubly Robust Estimator for Policy Evaluation (Infinite Horizon)", "Deeply-Debiased Off-Policy Evaluation", "Policy Evaluation\u2013Value Estimation", "Policy Evaluation", "Fitted-Q Evaluation", "Fitted-Q Iteration", "Importance Sampling for Policy Evaluation (Infinite Horizon)", "Confidence Interval in OPE", "Dynamic Mediation Analysis in Reinforcement Learning", "Q-Learning (Infinite Horizon)", "Policy Optimization", "Infinite Horizon Importance Sampling for Policy Evaluation", "Preliminary: Off-policy Evaluation and Optimization in Markov Decision Processes", "Preliminary: Off-policy Evaluation and Optimization in Markov Decision Processes", "A-Learning (Multiple Stages)", "Multiple Stages (DTR)", "Q-Learning (Multiple Stages)", "Overview: Bandits ALgorithm", "Contextual Bandits", "LinTS", "LinUCB", "<span class=\"math notranslate nohighlight\">\\(\\epsilon\\)</span>-Greedy", "Multi-Armed Bandits (MAB)", "TS", "UCB", "Multi-Task Thompson Sampling (MTTS)", "Meta Bandits", "Meta Thompson Sampling", "Direct Online Policy Evaluator", "Doubly Robust Online Policy Evaluator", "Inverse Probability Weighted Online Policy Evaluator", "Online Policy Evaluation", "CascadeLinTS", "Online Learning to Rank (Cascading Bandit)", "MTSS_Cascade", "TS_Cascade", "CombLinTS", "CombTS", "Online Combinatorial Optimization (Combinatorial Semi-Bandit)", "MTSS_Comb", "Dynamic Assortment Optimization (Multinomial Logit Bandit)", "MTSS_MNL", "TS_Contextual_MNL", "TS_MNL", "UCB_MNL", "Structured Bandit (Slate Recommendation)", "Single-Item Recommendation", "Epsilon_Greedy", "LinTS", "LinUCB", "Multi-Task", "MTTS", "Meta-TS", "TS", "UCB1", "Slate Recommendation", "Ooline Policy Learning and Evaluation in Markovian Environments", "Ooline Policy Learning in Non-Markovian Environments", "MIMIC III", "Generating 3-stage-DTR dataset", "MIMIC III (Infinite Horizon)", "MIMIC III (3-Stages)", "Mimic3 Demo", "Mimic3 Demo-Ver2", "Mimic3", "MIMIC III (Single-Stage)", "Read in Data", "MovieLens", "Specifying the Simulation Environments", "Overview", "Content of every notebook", "&lt;no title&gt;", "&lt;no title&gt;"], "terms": {"an": [0, 1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 22, 23, 25, 27, 28, 29, 32, 33, 45, 48, 50, 59, 60, 61, 64, 67, 68, 69, 70, 71, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 116, 117, 118, 119, 120, 123, 124, 128, 130, 131, 132, 133], "overview": [0, 10, 11, 12, 14], "includ": [0, 2, 5, 9, 27, 32, 38, 40, 59, 61, 71, 76, 77, 78, 79, 80, 81, 85, 86, 89, 91, 92, 93, 95, 97, 99, 100, 101, 102, 104, 105, 106, 108, 109, 110, 111, 116, 117, 118, 119, 123, 124, 125, 126, 127, 130, 132], "brief": [0, 120, 132], "introduct": [0, 5, 29, 32, 75, 76, 81, 84, 85, 95, 97, 98, 99, 100, 102, 104, 105, 106, 107, 109, 110, 119, 120], "evolut": 0, "i": [0, 1, 2, 4, 6, 9, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 32, 33, 38, 40, 45, 50, 59, 60, 61, 63, 64, 67, 68, 69, 70, 71, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111, 116, 117, 118, 119, 120, 122, 123, 124, 128, 129, 130, 134], "e": [0, 1, 2, 4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 38, 40, 45, 48, 50, 59, 60, 61, 63, 64, 67, 68, 69, 71, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 86, 88, 89, 90, 91, 92, 93, 95, 97, 98, 99, 100, 102, 103, 104, 105, 106, 109, 111, 116, 117, 119, 120, 128, 132], "when": [0, 2, 4, 5, 6, 10, 12, 13, 14, 15, 17, 19, 21, 22, 27, 28, 32, 38, 40, 50, 60, 63, 64, 67, 69, 74, 75, 76, 82, 86, 88, 90, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 111, 116, 118, 120, 125, 126, 128, 130, 132], "first": [0, 5, 9, 10, 14, 15, 17, 18, 19, 20, 21, 22, 23, 25, 26, 32, 33, 38, 40, 48, 59, 60, 63, 64, 67, 71, 74, 81, 87, 88, 92, 93, 95, 97, 98, 106, 117, 119, 123, 124, 128, 130, 132, 133], "develop": [0, 1, 2, 9, 14, 18, 23, 32, 48, 50, 89, 100, 105, 106], "ani": [0, 4, 5, 6, 9, 11, 13, 15, 18, 19, 21, 22, 23, 26, 28, 29, 32, 33, 40, 50, 60, 63, 64, 69, 74, 75, 76, 78, 80, 81, 87, 89, 95, 96, 97, 98, 108, 118, 119, 120, 124, 128, 129, 132], "altern": [0, 15, 45, 77, 103, 119], "extens": [0, 5, 19, 20, 25, 32, 45, 59, 63, 64, 74, 77, 79, 81, 85, 109, 119, 120, 132], "applic": [0, 1, 2, 3, 9, 10, 12, 32, 37, 38, 48, 50, 63, 67, 69, 71, 75, 76, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 118, 124], "situat": [0, 11, 13, 14, 40, 50, 63, 67, 69, 81, 82, 83, 84, 86, 87, 88, 90, 91, 92, 93, 95, 97, 98, 99, 100, 102, 104, 105, 106, 107], "describ": [0, 6, 27, 108, 125, 126, 127, 133], "data": [0, 2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 19, 22, 23, 25, 32, 33, 36, 40, 45, 48, 50, 59, 63, 64, 69, 74, 75, 76, 77, 79, 82, 83, 84, 86, 87, 88, 90, 91, 92, 93, 107, 119, 123, 124, 125, 126, 127, 128, 130, 131, 134], "structur": [0, 2, 5, 10, 12, 15, 17, 19, 21, 32, 38, 45, 48, 59, 64, 71, 77, 78, 79, 80, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 119, 123, 124, 128], "can": [0, 1, 2, 4, 5, 6, 9, 10, 11, 13, 15, 17, 18, 19, 20, 21, 22, 23, 25, 26, 29, 32, 33, 38, 40, 45, 48, 50, 59, 60, 61, 63, 64, 67, 68, 69, 70, 71, 72, 74, 76, 77, 79, 80, 82, 84, 86, 88, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 110, 111, 116, 117, 118, 119, 123, 125, 126, 128, 129, 130, 132, 133], "analyz": [0, 71, 123, 124, 128], "make": [0, 4, 5, 6, 9, 15, 17, 32, 50, 59, 60, 79, 80, 81, 84, 91, 92, 93, 119, 120, 132, 133, 134], "connect": [0, 12, 76, 119], "between": [0, 1, 2, 4, 6, 9, 14, 15, 19, 22, 29, 32, 33, 40, 45, 50, 59, 62, 69, 74, 76, 77, 83, 86, 88, 92, 93, 97, 98, 104, 105, 106, 109, 132], "real": [0, 2, 3, 9, 17, 18, 19, 20, 23, 25, 32, 33, 38, 45, 50, 59, 77, 79, 80, 91, 92, 93, 95, 100, 107, 130], "mention": [0, 74, 132], "motiv": [0, 2, 4, 15, 59, 63, 64, 67, 68, 74, 75, 79, 81, 85, 89, 95, 96, 101, 103, 119, 125, 126], "exampl": [0, 1, 2, 4, 5, 6, 9, 14, 17, 18, 19, 21, 22, 23, 32, 33, 38, 40, 45, 59, 60, 63, 64, 74, 77, 79, 80, 81, 82, 84, 85, 86, 87, 89, 96, 97, 101, 102, 103, 104, 111, 116, 119, 124, 128, 132], "we": [0, 1, 2, 3, 4, 6, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 38, 40, 45, 48, 50, 59, 60, 61, 62, 63, 64, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 116, 117, 118, 119, 120, 123, 124, 125, 126, 127, 128, 130, 132, 133], "us": [0, 1, 2, 4, 6, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 33, 40, 45, 50, 59, 60, 61, 62, 64, 68, 69, 71, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 102, 104, 105, 106, 107, 108, 109, 110, 111, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 128, 130, 132, 133, 134], "advantag": [0, 11, 13, 14, 45, 50, 60, 63, 64, 67, 69, 70, 77, 82, 83, 84, 86, 87, 88, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 109, 130, 132, 133], "descript": [0, 96, 101, 103, 118], "clear": [0, 130], "definit": [0, 10, 27, 45, 64, 67, 75, 76, 77, 96, 125, 126, 127], "concept": [0, 19, 76, 96], "abstract": 0, "pseudo": [0, 16, 25, 60, 77, 79, 133], "In": [0, 1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 32, 33, 38, 40, 45, 48, 50, 59, 60, 63, 64, 69, 70, 74, 75, 76, 77, 79, 80, 81, 82, 83, 85, 86, 89, 90, 91, 92, 93, 95, 96, 98, 99, 100, 101, 102, 103, 104, 106, 107, 108, 109, 111, 116, 118, 119, 120, 123, 124, 125, 126, 128, 130, 132], "follow": [0, 2, 3, 4, 5, 9, 10, 11, 13, 14, 15, 19, 22, 24, 25, 27, 29, 33, 38, 40, 45, 48, 50, 59, 60, 61, 63, 64, 67, 68, 69, 70, 71, 74, 75, 76, 77, 79, 80, 81, 85, 91, 92, 93, 97, 98, 102, 104, 107, 108, 109, 118, 119, 124, 125, 126, 127, 128, 130, 132], "exhibit": [0, 45, 50, 59, 77, 79, 91, 92, 93, 107], "how": [0, 1, 2, 3, 9, 10, 12, 17, 22, 27, 40, 45, 48, 50, 59, 60, 61, 62, 63, 71, 74, 77, 79, 80, 81, 89, 91, 92, 93, 107, 108, 118, 119], "appli": [0, 10, 11, 16, 17, 19, 20, 25, 45, 50, 59, 60, 63, 64, 69, 74, 77, 79, 85, 88, 90, 91, 92, 93, 107, 109, 119, 120, 122, 124, 128, 131, 132], "do": [0, 5, 10, 12, 15, 21, 24, 25, 32, 45, 48, 50, 59, 60, 77, 79, 83, 87, 98, 100, 106, 117, 119, 124, 128, 132], "respect": [0, 4, 6, 9, 13, 45, 50, 59, 60, 63, 67, 69, 74, 75, 76, 77, 79, 91, 92, 93, 119], "import": [0, 1, 2, 3, 10, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 40, 45, 48, 50, 59, 60, 61, 62, 63, 64, 67, 68, 70, 72, 76, 77, 79, 107, 110, 111, 116, 117, 120, 122, 123, 124, 125, 126, 128, 129, 130, 131, 134], "from": [0, 1, 2, 3, 4, 6, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 40, 45, 48, 50, 59, 60, 61, 62, 63, 64, 69, 71, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 110, 111, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 134], "causaldm": [0, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 40, 45, 48, 50, 59, 60, 61, 62, 63, 64, 67, 68, 69, 70, 71, 72, 74, 77, 79, 82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 107, 110, 111, 116, 117, 123, 124, 128, 130, 131, 133, 134], "alearn": [0, 45, 62, 77], "test": [0, 1, 9, 10, 11, 12, 13, 16, 20, 24, 25, 27, 40, 45, 48, 59, 77, 79, 125, 126, 127, 128, 130, 132, 134], "shared_simul": [0, 48, 62, 77, 79], "numpi": [0, 10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 33, 40, 45, 48, 62, 71, 77, 79, 82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 107, 110, 111, 116, 117, 122, 123, 124, 125, 126, 128, 129, 130], "np": [0, 10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 40, 45, 48, 50, 60, 62, 71, 77, 79, 82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 107, 110, 111, 116, 117, 122, 123, 124, 125, 126, 128, 129, 130, 131], "importerror": [0, 16, 20, 24, 62, 107], "traceback": [0, 11, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 45, 50, 59, 60, 62, 63, 64, 67, 68, 69, 70, 71, 72, 74, 77, 79, 82, 83, 107, 110, 111, 116, 117, 122, 123, 126, 128, 129, 130, 131, 134], "most": [0, 2, 5, 9, 11, 12, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 32, 45, 48, 50, 59, 60, 62, 63, 64, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 79, 81, 82, 83, 84, 85, 88, 89, 90, 95, 99, 100, 101, 102, 103, 107, 108, 109, 110, 111, 116, 117, 118, 119, 122, 123, 125, 126, 128, 129, 130, 131, 132, 134], "recent": [0, 2, 3, 9, 11, 12, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 32, 45, 50, 59, 60, 62, 63, 64, 67, 68, 69, 70, 71, 72, 74, 77, 79, 80, 81, 82, 83, 89, 98, 100, 105, 106, 107, 109, 110, 111, 116, 117, 120, 122, 123, 126, 128, 129, 130, 131, 133, 134], "call": [0, 4, 5, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 45, 48, 50, 59, 60, 62, 63, 64, 67, 68, 69, 70, 71, 72, 74, 77, 79, 82, 83, 107, 110, 111, 116, 117, 122, 123, 126, 128, 129, 130, 131, 133, 134], "last": [0, 9, 10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 45, 50, 59, 60, 61, 62, 63, 64, 67, 68, 69, 70, 71, 72, 74, 75, 77, 79, 82, 83, 92, 93, 107, 110, 111, 116, 117, 122, 123, 126, 128, 129, 130, 131, 132, 134], "var": [0, 9, 11, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 45, 50, 59, 60, 62, 63, 64, 67, 68, 69, 70, 71, 72, 74, 77, 79, 82, 83, 107, 110, 111, 116, 117, 122, 123, 125, 126, 128, 129, 130, 131, 134], "folder": [0, 11, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 45, 50, 59, 60, 62, 63, 64, 67, 68, 69, 70, 71, 72, 74, 77, 79, 82, 83, 107, 110, 111, 116, 117, 122, 123, 125, 126, 128, 129, 130, 131, 133, 134], "9j": [0, 11, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 45, 50, 59, 60, 62, 63, 64, 67, 68, 69, 70, 71, 72, 74, 77, 79, 82, 83, 107, 110, 111, 116, 117, 122, 123, 125, 126, 128, 129, 130, 131, 134], "vb5nb4rd5bx0gr1q5ytx9q600000gn": [0, 11, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 45, 50, 59, 60, 62, 63, 64, 67, 68, 69, 70, 71, 72, 74, 77, 79, 82, 83, 107, 110, 111, 116, 117, 122, 123, 125, 126, 128, 129, 130, 131, 134], "t": [0, 2, 4, 5, 6, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 26, 27, 29, 32, 33, 38, 40, 45, 50, 59, 60, 62, 63, 64, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 116, 117, 118, 119, 122, 123, 124, 125, 126, 128, 129, 130, 131, 132, 134], "ipykernel_68957": 0, "261550316": 0, "py": [0, 9, 10, 11, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 45, 50, 59, 60, 62, 63, 64, 67, 68, 69, 70, 71, 72, 74, 77, 79, 82, 83, 107, 110, 111, 116, 117, 122, 123, 125, 126, 128, 129, 130, 131, 134], "modul": [0, 11, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 45, 50, 59, 60, 62, 63, 64, 67, 68, 69, 70, 71, 72, 74, 77, 79, 82, 83, 107, 110, 111, 116, 117, 122, 123, 126, 128, 129, 130, 131, 134], "3": [0, 1, 5, 10, 16, 17, 18, 20, 23, 24, 25, 26, 27, 28, 33, 40, 45, 48, 50, 59, 60, 62, 71, 77, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 95, 96, 97, 98, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 116, 117, 118, 119, 120, 123, 125, 126, 127, 128, 129, 130, 131], "4": [0, 3, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 29, 33, 40, 45, 48, 50, 59, 60, 62, 64, 71, 74, 77, 79, 80, 81, 83, 84, 85, 86, 88, 89, 90, 91, 92, 93, 96, 97, 101, 102, 103, 104, 107, 108, 109, 110, 111, 116, 117, 118, 119, 122, 123, 124, 125, 126, 128, 129, 130, 131], "cannot": [0, 2, 4, 6, 11, 14, 15, 16, 20, 24, 62, 64, 76, 107, 120], "user": [0, 2, 4, 6, 10, 15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 33, 40, 45, 48, 59, 60, 62, 77, 79, 81, 82, 83, 84, 85, 88, 89, 90, 96, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 118, 128, 130, 134], "alinaxu": [0, 10, 15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 33, 40, 60, 62, 107, 128, 134], "opt": [0, 10, 11, 16, 18, 20, 22, 23, 24, 45, 50, 59, 60, 62, 77, 79, 82, 83, 107, 122, 123, 124, 126, 128, 129, 130, 131, 134], "anaconda3": [0, 10, 11, 16, 18, 20, 22, 23, 24, 45, 50, 59, 60, 62, 77, 79, 82, 83, 107, 122, 123, 126, 128, 129, 130, 134], "lib": [0, 10, 11, 16, 18, 20, 22, 23, 24, 45, 50, 59, 60, 62, 71, 77, 79, 82, 83, 107, 122, 123, 126, 128, 129, 130, 134], "python3": [0, 10, 11, 16, 18, 20, 22, 23, 24, 45, 50, 59, 60, 62, 71, 77, 79, 82, 83, 107, 122, 123, 126, 128, 129, 130, 134], "9": [0, 5, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 33, 40, 45, 50, 59, 60, 62, 71, 74, 77, 79, 82, 83, 107, 109, 111, 116, 119, 122, 123, 124, 125, 126, 128, 129, 130, 131, 134], "site": [0, 2, 10, 11, 16, 18, 20, 22, 23, 24, 45, 50, 59, 60, 62, 71, 77, 79, 82, 83, 107, 122, 123, 126, 128, 129, 130, 134], "packag": [0, 9, 10, 11, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 45, 48, 50, 59, 60, 61, 62, 71, 77, 79, 82, 83, 97, 104, 107, 122, 123, 125, 126, 128, 129, 130, 133, 134], "__init__": [0, 16, 20, 24, 62, 82, 83, 107, 128, 129, 130, 131], "find": [0, 2, 4, 6, 9, 14, 15, 27, 33, 45, 50, 59, 60, 71, 77, 79, 80, 81, 85, 86, 89, 91, 92, 93, 96, 99, 100, 101, 102, 103, 108, 109, 111, 116, 119, 123, 124, 128, 130, 133], "optim": [0, 2, 5, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 25, 45, 48, 50, 59, 62, 63, 64, 67, 68, 69, 74, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 102, 104, 105, 106, 107, 108, 109, 110, 111, 116, 117, 118, 120, 123, 130, 132, 133], "regim": [0, 2, 15, 19, 45, 50, 59, 62, 77, 79, 110, 111, 116, 117, 124, 128, 131, 132], "appropri": [0, 11, 60, 63, 67, 69, 71, 74, 88, 97, 100, 104, 133], "interpret": [0, 3, 10, 13, 45, 50, 59, 71, 82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 110, 111, 116, 117, 129], "A": [0, 1, 2, 3, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 32, 33, 40, 48, 50, 59, 60, 61, 63, 64, 71, 74, 75, 76, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 116, 117, 118, 119, 122, 123, 124, 125, 126, 128, 129, 130, 131], "sentenc": [0, 110, 111, 116, 117], "analysi": [0, 3, 9, 11, 13, 14, 27, 33, 37, 38, 50, 84, 87, 97, 103, 109, 110, 111, 116, 117, 118, 125, 126, 127, 132], "result": [0, 2, 4, 5, 10, 15, 17, 18, 19, 20, 21, 22, 23, 25, 27, 28, 29, 45, 50, 59, 62, 63, 64, 67, 69, 71, 74, 77, 79, 95, 97, 98, 101, 110, 111, 116, 117, 123, 125, 126, 127, 131, 132], "estim": [0, 1, 2, 5, 6, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 32, 38, 40, 45, 48, 50, 59, 60, 62, 64, 67, 68, 69, 70, 74, 75, 76, 77, 79, 83, 84, 87, 91, 92, 93, 97, 98, 100, 107, 109, 110, 111, 116, 117, 119, 120, 123, 124, 125, 126, 128, 131, 132], "fix": [0, 45, 59, 60, 67, 68, 71, 77, 79, 81, 84, 91, 92, 93, 110, 119, 120, 123, 124, 128], "valu": [0, 2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 20, 21, 22, 23, 25, 27, 32, 40, 45, 48, 50, 59, 60, 61, 62, 63, 64, 67, 68, 69, 74, 76, 77, 79, 81, 84, 85, 89, 91, 92, 93, 96, 109, 110, 122, 123, 124, 125, 126, 127, 128, 130, 131], "subfield": 1, "infer": [1, 2, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 25, 26, 27, 32, 37, 38, 40, 59, 60, 64, 76, 91, 92, 93, 103, 106, 119, 120, 124, 132], "aim": [1, 2, 6, 11, 13, 14, 15, 17, 18, 19, 21, 22, 23, 28, 32, 33, 40, 45, 59, 61, 67, 68, 76, 77, 79, 81, 85, 89, 96, 101, 103, 108, 118, 119, 130, 132], "identifi": [1, 3, 9, 10, 11, 13, 14, 15, 17, 18, 21, 22, 23, 26, 33, 38, 71, 128], "conduct": [1, 27, 38, 60, 123, 124, 128, 130], "statist": [1, 2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 16, 18, 19, 20, 21, 23, 25, 33, 35, 36, 39, 40, 41, 42, 43, 45, 48, 50, 60, 63, 64, 69, 70, 71, 74, 77, 81, 82, 83, 89, 91, 92, 93, 95, 96, 98, 100, 109, 111, 119, 120, 123, 128, 132], "specif": [1, 2, 3, 4, 5, 6, 10, 15, 17, 18, 19, 21, 22, 23, 26, 27, 32, 33, 38, 40, 45, 59, 60, 63, 64, 68, 69, 70, 71, 74, 75, 76, 79, 80, 82, 84, 86, 88, 89, 90, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 108, 109, 110, 111, 116, 118, 123, 128, 130, 132], "intervent": [1, 2, 4, 6, 10, 12, 15, 27, 33], "system": [1, 5, 9, 10, 11, 12, 13, 14, 17, 19, 50, 69, 74, 75, 80, 81, 85, 88, 89, 90, 96, 97, 100, 102, 103, 104, 105, 108, 109, 120], "It": [1, 2, 4, 5, 19, 25, 32, 40, 67, 68, 69, 74, 76, 82, 83, 84, 86, 87, 88, 95, 97, 98, 99, 100, 101, 102, 104, 105, 109, 111, 116, 119, 120], "tri": 1, "answer": [1, 2, 17, 33], "question": [1, 2, 17, 33, 63, 74], "what": [1, 2, 32, 33, 77, 79, 80, 103], "have": [1, 2, 3, 4, 6, 10, 12, 15, 27, 32, 33, 40, 48, 60, 61, 63, 69, 74, 75, 76, 78, 80, 81, 88, 89, 90, 95, 105, 108, 109, 118, 119, 125, 126, 127, 130, 132, 133], "done": [1, 119], "someth": [1, 62], "differ": [1, 2, 3, 4, 5, 6, 12, 15, 22, 28, 32, 38, 40, 45, 59, 60, 61, 62, 69, 74, 75, 76, 77, 79, 81, 82, 85, 86, 88, 89, 90, 92, 93, 97, 98, 100, 101, 102, 104, 105, 108, 109, 111, 116, 119, 120, 129, 130, 132], "s": [1, 2, 3, 5, 6, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 27, 28, 29, 32, 33, 38, 40, 45, 59, 60, 61, 63, 64, 67, 68, 69, 71, 74, 75, 76, 77, 78, 79, 81, 82, 83, 84, 88, 89, 90, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 119, 123, 124, 128, 129, 130, 131, 132], "consequ": [1, 4, 15, 50, 63, 74], "excecut": 1, "polici": [1, 5, 15, 19, 21, 22, 23, 25, 32, 33, 48, 62, 67, 68, 70, 81, 84, 123, 130, 133], "quantifi": [1, 2, 3, 10, 40, 71, 87, 92, 93, 96, 125, 126], "etc": [1, 2, 17, 19, 32, 38, 45, 59, 81, 101, 108, 118], "suppos": [1, 9, 10, 11, 12, 13, 14, 19, 33, 38, 40, 45, 61, 77, 78, 81, 82, 83, 84, 85, 86, 87, 96, 101, 103, 110, 111, 116, 117, 119], "you": [1, 5, 10, 45, 48, 59, 60, 79, 98, 124, 128, 129, 130, 133, 134], "ar": [1, 2, 3, 4, 6, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 28, 29, 32, 33, 38, 40, 45, 48, 59, 60, 61, 63, 64, 67, 69, 71, 74, 75, 76, 77, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 108, 109, 110, 111, 116, 117, 118, 119, 123, 124, 125, 126, 128, 129, 130, 132, 133], "medic": [1, 15], "research": [1, 2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 21, 32, 33, 63, 68, 74, 100, 103, 106, 107], "who": [1, 2, 4, 6, 15, 27, 33, 61, 82, 83, 88, 89, 125, 126, 127], "just": [1, 18, 20, 22, 23, 25, 28, 32, 40, 119], "fictiti": 1, "hopefulli": 1, "allevi": 1, "patient": [1, 2, 27, 32, 50, 60, 89, 124, 125, 126, 127, 128], "symptom": 1, "hypertens": 1, "sinc": [1, 4, 10, 15, 21, 32, 61, 64, 69, 80, 81, 85, 91, 92, 93, 103, 109, 116, 119, 120, 132], "thi": [1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 15, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 32, 33, 38, 40, 48, 50, 60, 61, 63, 64, 67, 68, 69, 70, 72, 74, 75, 76, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 111, 116, 117, 118, 119, 120, 123, 124, 125, 126, 128, 129, 130, 132, 133], "newli": [1, 50, 71], "drug": [1, 3], "must": [1, 2, 5], "go": [1, 33, 133], "through": [1, 2, 5, 9, 10, 11, 12, 14, 15, 17, 21, 33, 76, 81, 85, 88, 89, 96, 103, 106, 108, 109, 118, 119, 125, 126, 130], "preclin": 1, "bitro": 1, "vivo": 1, "three": [1, 6, 9, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 24, 25, 26, 28, 29, 32, 33, 60, 71, 80, 81, 82, 83, 84, 86, 87, 90, 91, 92, 93, 95, 97, 98, 99, 102, 104, 105, 106, 108, 109, 118, 119, 120, 124, 132], "phase": 1, "final": [1, 2, 17, 19, 20, 21, 22, 25, 28, 29, 59, 60, 63, 64, 67, 68, 74, 75, 77, 79, 81, 82, 83, 86, 97, 104, 105, 106, 111, 116, 119, 123, 124, 128, 130, 132], "approv": 1, "confirm": [1, 4, 6, 15], "potenti": [1, 2, 15, 19, 21, 22, 28, 29, 32, 33, 45, 59, 60, 64, 67, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 96, 98, 99, 100, 101, 102, 103, 108, 119, 125, 126, 132], "side": [1, 67, 68, 119], "dure": [1, 2, 3, 61], "procedur": [1, 6, 11, 15, 16, 17, 19, 25, 60, 64, 70], "usual": [1, 2, 15, 60, 69, 74], "evalu": [1, 5, 11, 13, 14, 15, 18, 21, 22, 23, 27, 32, 33, 40, 68, 70, 71, 81, 109, 123, 132], "mesur": 1, "well": [1, 9, 11, 13, 19, 22, 27, 32, 38, 48, 60, 67, 69, 74, 75, 76, 84, 85, 95, 99, 101, 102, 109, 110, 119, 120, 132], "perform": [1, 9, 13, 17, 18, 19, 20, 22, 23, 25, 28, 48, 60, 63, 67, 68, 69, 74, 81, 82, 83, 84, 86, 87, 88, 90, 91, 92, 93, 95, 97, 98, 99, 100, 102, 104, 105, 106, 109, 110, 119, 130], "compar": [1, 3, 15, 16, 18, 20, 22, 23, 25, 40, 63, 71, 74, 84, 90, 119, 123, 124, 128, 130, 132], "placebo": 1, "other": [1, 2, 3, 4, 5, 6, 9, 13, 15, 17, 19, 21, 22, 25, 27, 28, 40, 45, 50, 59, 64, 74, 75, 76, 77, 79, 80, 81, 82, 85, 89, 95, 98, 99, 100, 101, 102, 105, 106, 108, 109, 118, 119, 129, 130, 131, 132], "exist": [1, 2, 4, 5, 6, 9, 10, 11, 12, 13, 17, 19, 21, 32, 45, 50, 59, 63, 71, 76, 96, 103, 108, 118, 119, 132], "treatment": [1, 2, 4, 9, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 38, 40, 45, 48, 50, 59, 61, 64, 71, 76, 77, 79, 80, 89, 109, 119, 123, 124, 125, 126, 128, 132], "method": [1, 2, 5, 10, 12, 13, 17, 19, 21, 22, 28, 29, 32, 33, 36, 38, 40, 45, 50, 59, 60, 63, 64, 67, 68, 69, 70, 71, 74, 77, 79, 90, 91, 92, 93, 119, 120, 123, 128, 132, 133], "experiment": [1, 4, 6, 15, 33, 132], "design": [1, 17, 18, 19, 23, 63, 64, 74, 97, 102, 104, 119], "wide": [1, 2, 9, 15, 19, 32, 33, 63, 69, 74, 80, 81, 84, 85, 89, 95, 97, 101, 102, 104, 108, 109, 110, 130, 132], "known": [1, 2, 3, 9, 12, 15, 21, 22, 26, 32, 45, 69, 74, 75, 76, 77, 80, 85, 86, 88, 89, 90, 91, 92, 93, 96, 97, 101, 102, 103, 104, 109, 111, 116, 119, 120, 132], "b": [1, 2, 9, 10, 11, 13, 14, 15, 16, 18, 19, 20, 22, 23, 25, 26, 28, 29, 45, 48, 50, 59, 60, 63, 69, 74, 75, 76, 77, 79, 80, 81, 82, 86, 88, 89, 90, 95, 96, 99, 101, 102, 108, 109, 111, 116, 117, 118, 129], "randomli": [1, 2, 4, 6, 16, 17, 18, 20, 24, 26, 28, 29, 84, 110], "assign": [1, 2, 4, 6, 12, 15, 19, 22, 23, 32, 33, 38, 48, 59, 71, 76, 79], "one": [1, 2, 4, 5, 6, 15, 19, 21, 22, 26, 32, 33, 40, 45, 48, 60, 63, 64, 67, 69, 74, 76, 77, 81, 85, 86, 89, 95, 96, 97, 98, 103, 104, 105, 106, 108, 109, 111, 116, 119, 124, 128, 130], "two": [1, 2, 3, 4, 5, 6, 10, 14, 15, 16, 17, 21, 22, 25, 26, 28, 29, 32, 33, 40, 60, 61, 63, 64, 69, 74, 76, 80, 81, 85, 86, 89, 91, 92, 93, 97, 102, 104, 109, 116, 119, 124, 125, 126, 128, 132, 133], "group": [1, 2, 4, 6, 15, 19, 22, 28, 29, 33, 38, 40, 45, 60, 77, 85, 101, 109, 125, 126, 128, 132], "receiv": [1, 2, 4, 6, 15, 32, 33, 40, 59, 61, 75, 76, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 110, 111, 116, 117, 118, 124, 128, 130, 132], "measur": [1, 3, 4, 6, 9, 10, 11, 12, 13, 14, 15, 19, 33, 38, 64, 69, 71, 76, 119, 132], "sbp": 1, "systol": 1, "blood": 1, "pressur": [1, 27, 125, 126, 127], "each": [1, 2, 3, 4, 6, 9, 10, 11, 13, 14, 18, 19, 20, 21, 22, 23, 25, 28, 32, 33, 40, 45, 50, 59, 61, 69, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 111, 116, 117, 118, 123, 124, 125, 126, 128, 130, 132], "both": [1, 4, 5, 6, 11, 13, 14, 15, 17, 22, 28, 50, 60, 63, 64, 69, 71, 74, 76, 82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 110, 116, 119, 124, 128, 130, 132], "befor": [1, 10, 11, 15, 16, 22, 23, 25, 33, 38, 90], "after": [1, 2, 3, 11, 13, 14, 15, 17, 24, 25, 27, 33, 38, 40, 61, 63, 64, 67, 68, 69, 70, 72, 74, 75, 79, 82, 84, 86, 87, 97, 98, 110, 111, 116, 117, 119, 125, 126, 127], "By": [1, 17, 19, 45, 59, 61, 64, 75, 76, 79, 84, 88, 108, 110], "analys": 1, "abl": [1, 4, 6, 15, 17, 19, 33, 86, 88, 125, 126], "determin": [1, 9, 12, 14, 84, 88, 97, 102, 103, 104, 105, 106, 108, 118], "treat": [1, 17, 27, 33, 38, 40, 108, 125, 126, 132], "shop": [1, 19], "websit": [1, 2, 19, 27, 78, 81, 85, 89, 108, 109, 130, 133], "seller": 1, "often": [1, 4, 6, 17, 22, 28, 32, 40, 60, 132], "veri": [1, 3, 5, 19, 22, 26, 28, 33, 38, 60, 132], "cautiou": 1, "about": [1, 2, 4, 5, 6, 15, 17, 18, 20, 22, 23, 25, 29, 32, 40, 60, 61, 81, 86, 89, 90, 128], "custom": [1, 2, 19, 60, 61, 88, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 129], "purchas": [1, 2, 61, 103, 104, 105, 106, 107], "experi": [1, 4, 6, 15, 19, 48, 76, 81, 85, 89, 91, 92, 93, 108, 109, 130], "whenev": [1, 2, 81, 85, 96, 103], "consum": [1, 33], "satisfi": [1, 9, 15, 17, 18, 23, 24, 25, 63, 64, 69, 74, 81, 85, 89, 99, 100, 101, 102, 108, 109, 118, 119, 130, 134], "item": [1, 2, 80, 81, 82, 84, 85, 86, 87, 88, 89, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 110, 111, 117, 118, 129, 132], "thei": [1, 2, 4, 5, 6, 32, 33, 69, 74, 76, 81, 85, 89, 108, 109, 130], "bought": 1, "order": [1, 2, 9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 23, 25, 32, 60, 64, 88, 89, 90, 95, 96, 97, 98, 99, 100, 102, 104, 105, 106, 108, 118, 125, 126], "wrong": [1, 62], "size": [1, 22, 23, 25, 45, 50, 59, 62, 71, 99, 100, 101, 102, 123, 130, 131, 132], "cloth": [1, 19], "broken": 1, "miss": [1, 5, 76], "sever": [1, 2, 16, 17, 19, 21, 24, 25, 27, 32, 38, 82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 108, 125, 126, 127, 130, 132], "option": [1, 18, 20, 23, 25, 45, 50, 59, 62, 77, 79, 81, 82, 83, 84, 86, 87, 110, 111, 116, 117], "provid": [1, 2, 12, 14, 15, 19, 27, 28, 29, 32, 40, 45, 59, 62, 64, 71, 74, 76, 77, 79, 84, 88, 91, 92, 93, 105, 110, 119, 120, 123, 124, 128, 132, 133], "address": [1, 2, 17, 19, 32, 50, 84, 88, 119, 132], "problem": [1, 2, 3, 10, 17, 18, 19, 23, 24, 25, 32, 33, 38, 48, 59, 60, 63, 64, 67, 68, 69, 74, 79, 80, 84, 86, 87, 95, 97, 98, 99, 100, 102, 104, 105, 106, 107, 110, 117, 119, 120, 125, 126, 132, 133], "For": [1, 2, 3, 4, 5, 6, 17, 19, 20, 22, 25, 27, 29, 32, 33, 38, 45, 59, 60, 61, 63, 69, 74, 76, 77, 78, 79, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 116, 117, 119, 125, 126, 127, 130, 132], "mai": [1, 2, 3, 4, 6, 10, 15, 18, 19, 21, 23, 32, 48, 60, 76, 81, 82, 89, 111, 125, 126, 133, 134], "offer": [1, 2, 64, 84, 103, 104, 105, 106, 107, 108, 118], "1": [1, 4, 5, 6, 10, 16, 18, 19, 20, 23, 24, 25, 28, 29, 32, 33, 38, 40, 48, 60, 61, 62, 63, 64, 67, 68, 69, 70, 71, 74, 75, 76, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 110, 111, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 128, 129, 130, 131, 134], "fulli": [1, 81, 85, 88, 89, 109, 119, 130], "refund": 1, "without": [1, 22, 40, 75, 76, 93, 132], "return": [1, 2, 21, 22, 23, 45, 50, 59, 62, 71, 77, 79, 82, 83, 119, 122, 123, 125, 128, 129, 130, 131], "2": [1, 10, 16, 18, 19, 20, 23, 24, 25, 26, 29, 33, 35, 37, 39, 40, 41, 42, 43, 48, 60, 61, 62, 63, 64, 67, 68, 69, 70, 71, 74, 75, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 116, 117, 118, 119, 120, 123, 124, 125, 126, 128, 129, 130, 131, 134], "discount": [1, 64, 74, 75, 76, 119], "next": [1, 10, 15, 19, 22, 29, 38, 60, 69, 74, 75, 76, 92, 93, 125, 126, 133], "compens": 1, "level": [1, 3, 4, 5, 6, 19, 60, 119, 125, 126, 132], "vari": [1, 37, 81, 124], "accord": [1, 2, 4, 6, 12, 17, 27, 32, 33, 64, 67, 69, 71, 76, 86, 88, 106, 109, 111, 116, 125, 126, 132], "primari": [1, 3, 17, 61, 80, 132], "goal": [1, 2, 3, 17, 27, 40, 48, 60, 64, 75, 76, 81, 85, 89, 91, 92, 93, 101, 103, 108, 109, 130, 132, 133], "outcom": [1, 2, 3, 10, 12, 15, 16, 17, 19, 20, 21, 22, 24, 25, 28, 29, 32, 33, 37, 38, 40, 45, 50, 59, 60, 61, 71, 77, 79, 80, 88, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 119, 124, 128, 132], "so": [1, 2, 4, 5, 9, 11, 13, 15, 17, 24, 25, 27, 60, 75, 76, 79, 84, 87, 109, 110, 117, 125, 126], "examin": [1, 96, 124, 128, 132], "which": [1, 2, 3, 4, 5, 6, 10, 12, 15, 17, 18, 19, 21, 22, 23, 24, 25, 27, 28, 29, 32, 33, 38, 40, 45, 48, 50, 59, 60, 63, 68, 69, 71, 74, 75, 76, 77, 79, 80, 81, 82, 85, 86, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 111, 116, 118, 119, 120, 123, 125, 126, 127, 128, 132], "take": [1, 11, 13, 14, 22, 29, 32, 33, 48, 60, 64, 71, 75, 79, 81, 84, 85, 86, 88, 89, 90, 95, 97, 99, 100, 101, 102, 104, 105, 106, 107, 109, 110, 122, 123, 126, 130, 132], "histori": [1, 2, 27, 45, 59, 60, 61, 76, 84, 91, 92, 93, 109, 110, 119, 120, 132], "maxim": [1, 2, 27, 48, 50, 59, 60, 79, 80, 81, 85, 89, 96, 108, 109, 119, 124, 128], "profit": [1, 2, 103, 108, 118], "asid": [1, 19, 33, 60], "abov": [1, 4, 6, 9, 10, 11, 15, 16, 17, 18, 19, 21, 22, 23, 25, 29, 32, 33, 40, 50, 103, 119, 124, 125, 126, 128, 133], "idea": [1, 17, 20, 22, 24, 25, 26, 33, 40, 119, 133], "fundament": 1, "ha": [1, 2, 3, 5, 9, 10, 13, 18, 19, 21, 23, 33, 38, 45, 48, 50, 59, 60, 63, 64, 69, 70, 71, 74, 77, 78, 79, 82, 85, 86, 87, 88, 89, 97, 100, 101, 103, 104, 108, 109, 111, 116, 117, 119, 123, 128, 132], "broad": [1, 38], "our": [1, 2, 4, 6, 15, 17, 18, 23, 32, 33, 38, 40, 50, 60, 64, 69, 70, 71, 74, 76, 79, 89, 91, 92, 93, 119], "daili": 1, "live": 1, "leverag": [1, 14, 18, 20, 23, 25, 50, 90, 119], "studi": [1, 2, 3, 4, 5, 6, 9, 13, 15, 19, 21, 27, 32, 40, 60, 61, 63, 67, 74, 81, 85, 89, 108, 109, 120, 124, 128, 130, 132], "new": [1, 2, 4, 6, 17, 32, 33, 45, 60, 61, 77, 79, 81, 88, 89, 90, 101, 108, 109, 118, 119, 129, 130, 132], "catalyst": 1, "rate": [1, 2, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 24, 25, 26, 27, 28, 29, 50, 63, 64, 74, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 96, 108, 109, 110, 119, 124, 125, 126, 128, 129, 130], "chemic": 1, "reaction": 1, "smoke": [1, 40], "risk": 1, "lung": 1, "cancer": 1, "ad": [1, 4, 6, 19, 45, 77, 91, 92, 93, 101, 108, 118], "exposur": [1, 2, 3, 10, 19, 37, 40, 71, 124], "convers": [1, 2, 19], "bui": [1, 104, 105, 106], "product": [1, 2, 33, 103, 108, 118, 123, 130], "extracurricular": 1, "remedi": 1, "class": [1, 4, 9, 24, 25, 50, 60, 63, 64, 67, 74, 80, 81, 87, 89, 97, 102, 104, 108, 109, 117, 118, 120, 131, 132], "improv": [1, 2, 5, 16, 17, 18, 19, 20, 24, 26, 28, 29, 60, 95, 119, 120], "student": [1, 15, 16, 17, 18, 20, 24, 27, 28, 29, 81, 82, 83, 88, 89, 109, 129, 130, 131], "grade": 1, "cdot": [1, 4, 6, 9, 10, 11, 12, 13, 14, 15, 18, 20, 21, 23, 24, 25, 33, 45, 50, 61, 63, 64, 67, 68, 69, 71, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 95, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 110, 111, 116, 117, 119, 132], "social": [1, 132], "phenomena": 1, "natur": [1, 2, 5, 10, 12, 21, 24, 25, 48, 60, 71, 119, 123, 124, 125, 126, 128, 130], "quantif": 1, "allow": [1, 2, 4, 5, 6, 48, 50, 59, 60, 64, 76, 79, 132], "understand": [1, 10, 19, 59, 79, 84, 119], "relationship": [1, 3, 4, 6, 9, 10, 11, 12, 13, 14, 40, 48, 59, 69, 82, 97, 104, 106, 111, 119, 132], "methodolog": [1, 9, 12, 38, 45, 71, 77, 132], "onli": [1, 2, 4, 5, 6, 12, 15, 17, 26, 33, 38, 40, 60, 61, 63, 64, 69, 70, 74, 75, 76, 80, 90, 95, 96, 97, 98, 103, 104, 105, 106, 119, 132, 133], "scientif": [1, 4, 6], "also": [1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 19, 21, 22, 24, 25, 26, 33, 45, 59, 60, 62, 63, 67, 68, 69, 71, 74, 76, 77, 79, 86, 88, 89, 97, 98, 99, 100, 101, 102, 103, 104, 106, 109, 111, 116, 120, 125, 126, 130, 132], "practic": [1, 2, 50, 59, 64, 79, 81, 82, 84, 85, 86, 88, 91, 92, 93, 95, 97, 98, 99, 100, 102, 104, 105, 106, 109, 110, 111, 116, 119], "where": [1, 2, 4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 38, 40, 45, 48, 50, 59, 60, 61, 63, 64, 67, 69, 70, 71, 74, 75, 76, 77, 79, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91, 92, 93, 96, 97, 99, 101, 102, 103, 104, 108, 109, 110, 118, 119, 123, 124, 125, 126, 128, 129, 130, 132, 133], "seek": 1, "growth": 2, "engag": 2, "critic": [2, 5, 27, 40, 63, 74, 76, 125, 126, 127], "fast": [2, 9, 10, 11, 12, 13, 14, 33, 63, 132], "chang": [2, 22, 27, 32, 33, 38, 50, 69, 77, 99, 124, 125, 126, 128, 132, 133], "market": [2, 33, 129], "campaign": [2, 61], "internet": 2, "compani": [2, 19, 33], "encourag": [2, 48], "The": [2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 35, 38, 39, 40, 41, 42, 43, 45, 48, 50, 59, 60, 61, 63, 64, 67, 68, 69, 71, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 111, 116, 117, 118, 119, 120, 123, 124, 125, 126, 127, 128, 130, 132, 133], "posit": [2, 4, 6, 11, 13, 14, 15, 21, 22, 26, 32, 33, 45, 59, 71, 77, 79, 89, 108, 118, 130], "effect": [2, 3, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 28, 29, 32, 33, 38, 40, 48, 61, 64, 79, 103, 108, 118, 123, 124, 128], "desir": [2, 3, 60], "busi": 2, "lead": [2, 19, 64], "surplu": 2, "oper": [2, 10, 12, 15, 64, 103, 106, 107], "cost": [2, 25, 48, 106], "increas": [2, 50, 64, 80, 84, 91, 92, 93, 97, 109, 124, 125, 126, 128], "impel": 2, "carri": 2, "out": [2, 10, 16, 17, 18, 19, 20, 24, 26, 28, 29, 59, 76, 82, 83, 128, 130], "more": [2, 3, 4, 5, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 25, 26, 28, 29, 32, 45, 50, 60, 61, 63, 64, 67, 68, 69, 70, 72, 74, 76, 77, 81, 83, 84, 90, 99, 100, 102, 105, 106, 109, 110, 111, 116, 117, 119, 128, 133], "refin": 2, "strategi": 2, "acquisit": 2, "retent": 2, "associ": [2, 4, 5, 6, 9, 11, 13, 21, 36, 40, 48, 50, 60, 76, 80, 91, 92, 93, 120, 125, 126, 128, 132], "massiv": [2, 19], "scale": [2, 9, 20, 25, 40, 50, 67, 80, 95, 96, 97, 99, 101, 102, 104, 105, 109, 132], "promot": 2, "balanc": [2, 75, 86, 109], "increment": [2, 33, 119], "sustain": 2, "invest": [2, 45, 59, 77, 79], "roi": [2, 86, 108, 109, 116, 117, 118], "requir": [2, 9, 11, 14, 17, 18, 23, 32, 45, 48, 50, 63, 64, 74, 76, 77, 79, 89, 119, 132, 134], "predict": [2, 5, 15, 18, 21, 22, 23, 26, 28, 29, 40, 50, 59, 79, 119, 125, 126, 130], "caus": [2, 4, 6, 9, 11, 12, 13, 14, 19, 21, 32, 33, 48, 60, 125, 126], "action": [2, 4, 6, 15, 16, 17, 18, 19, 20, 21, 24, 27, 28, 29, 32, 33, 45, 48, 59, 61, 62, 63, 64, 67, 68, 69, 71, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 116, 117, 118, 119, 120, 122, 123, 124, 125, 126, 128, 129, 130, 131, 132], "uplift": [2, 60, 61], "model": [2, 6, 10, 12, 15, 17, 21, 22, 24, 25, 26, 28, 29, 36, 45, 50, 59, 60, 62, 63, 64, 67, 74, 75, 76, 77, 79, 80, 82, 83, 88, 89, 91, 92, 93, 95, 96, 97, 99, 102, 103, 104, 105, 106, 108, 109, 111, 118, 124, 128, 132], "heterogen": [2, 9, 15, 16, 18, 19, 20, 22, 23, 24, 25, 26, 28, 29, 33, 38, 88, 96, 97, 101, 102, 103, 104, 132], "attent": [2, 3, 9, 11, 12, 13, 14, 32, 50, 80, 91, 92, 93, 109, 125, 126, 132], "literatur": [2, 9, 15, 19, 21, 32, 50, 60, 63, 70, 71, 74, 76, 89, 106, 119, 120, 123, 132, 133], "book": [2, 5, 59, 79, 119, 132, 133], "sampl": [2, 4, 6, 16, 17, 18, 20, 22, 23, 25, 32, 45, 48, 50, 59, 60, 63, 64, 70, 75, 81, 82, 84, 85, 86, 89, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 110, 111, 116, 117, 118, 119, 130, 132], "code": [2, 9, 10, 17, 18, 23, 33, 48, 62, 118, 124, 128, 133], "relat": [2, 9, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 40, 45, 69, 75, 76, 77, 80, 81, 89, 109, 119, 125, 126, 127, 130, 132], "under": [2, 3, 4, 5, 6, 9, 10, 15, 16, 17, 19, 20, 21, 22, 25, 26, 28, 29, 32, 33, 45, 48, 50, 59, 63, 64, 67, 69, 71, 74, 81, 88, 90, 97, 102, 103, 104, 105, 106, 109, 124, 125, 126, 128, 130, 132, 133], "set": [2, 3, 5, 9, 10, 11, 12, 13, 14, 18, 21, 23, 27, 32, 50, 60, 62, 64, 69, 71, 74, 75, 76, 79, 82, 83, 84, 86, 87, 88, 90, 91, 92, 93, 95, 97, 98, 99, 100, 102, 104, 105, 106, 110, 119, 120, 122, 123, 124, 125, 126, 128, 130, 131, 132, 133], "point": [2, 15, 16, 17, 18, 20, 23, 24, 26, 28, 29, 32, 33, 48, 50, 59, 61, 67, 68, 69, 70, 75, 76, 77, 79, 85, 89, 119, 120, 130], "interest": [2, 3, 4, 6, 10, 12, 17, 18, 19, 21, 23, 32, 33, 38, 45, 50, 59, 60, 61, 71, 74, 77, 79, 95, 96, 97, 98, 119, 123, 124, 125, 126, 128, 130, 132], "dataset": [2, 3, 15, 19, 26, 27, 33, 40, 45, 50, 59, 61, 75, 76, 78, 79, 81, 85, 89, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 118, 119, 125, 126, 127, 128, 130], "space": [2, 9, 21, 27, 45, 50, 59, 61, 63, 69, 74, 75, 76, 77, 79, 82, 83, 84, 86, 87, 89, 90, 91, 92, 93, 99, 100, 102, 108, 110, 111, 116, 117, 118], "should": [2, 10, 12, 17, 77, 79, 82, 95, 97, 98, 99, 100, 102, 104, 105, 133], "variou": [2, 3, 11, 13, 38, 59, 63, 74, 79, 90, 99, 108, 132], "email": [2, 45, 59], "sent": 2, "total": [2, 10, 12, 19, 21, 33, 38, 40, 50, 60, 61, 71, 77, 81, 84, 85, 87, 88, 95, 97, 98, 99, 100, 102, 104, 105, 106, 108, 109, 110, 117, 118, 123, 128, 130, 132], "amount": [2, 17, 32, 96, 125, 126], "spent": [2, 50, 61], "fetch_hillstrom": [2, 60, 61], "discret": [2, 4, 5, 6, 27, 50, 60, 75, 76, 82, 83, 84, 86, 87, 124, 125, 126, 128, 132], "q": [2, 5, 9, 17, 32, 45, 50, 60, 62, 63, 64, 74, 75, 76, 77, 80, 84, 86, 88, 90, 97, 102, 104, 106, 109, 110, 119, 123, 124, 128, 132], "much": [2, 3, 19], "spend": [2, 45, 59, 60, 61], "averag": [2, 9, 12, 15, 16, 17, 19, 20, 22, 25, 29, 33, 38, 40, 45, 59, 64, 69, 70, 71, 77, 79, 84, 87, 110, 117, 119, 123, 125, 126, 130, 131, 132], "add": [2, 5, 45, 59, 88, 96, 101, 103, 131, 133], "quantil": [2, 70, 132], "continu": [2, 4, 6, 9, 10, 11, 12, 13, 14, 45, 59, 60, 69, 74, 75, 77, 79, 84, 86, 87, 88, 90, 99, 100, 101, 102, 125, 126, 128, 130, 132, 133], "owl": [2, 132], "john": [2, 5, 75, 76, 119], "wanamak": 2, "onc": [2, 5, 88, 90, 96], "phrase": 2, "half": 2, "monei": [2, 61], "advertis": [2, 19, 33, 99, 100, 101, 102], "wast": 2, "troubl": 2, "don": [2, 60, 104, 105, 106], "know": [2, 19, 60], "indic": [2, 4, 6, 11, 13, 14, 15, 27, 33, 50, 84, 92, 93, 96, 103, 104, 105, 106, 108, 125, 126], "high": [2, 3, 4, 9, 10, 11, 12, 13, 14, 15, 32, 40, 45, 77, 119, 125, 126, 131], "intent": 2, "convert": [2, 4, 6, 11, 13, 14, 130], "todai": 2, "digit": 2, "techniqu": [2, 40, 63, 74, 132], "enabl": [2, 9, 10, 12, 97, 102, 104], "lift": 2, "via": [2, 3, 4, 9, 10, 11, 12, 13, 14, 15, 40, 60, 63, 64, 67, 74, 75, 88, 91, 92, 93, 97, 102, 103, 104, 119, 120], "random": [2, 4, 6, 9, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 24, 26, 35, 39, 41, 42, 43, 60, 62, 70, 71, 75, 76, 81, 82, 83, 84, 85, 86, 88, 89, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 109, 110, 111, 123, 125, 126, 128, 130, 131], "control": [2, 3, 4, 5, 6, 9, 12, 15, 16, 19, 20, 21, 22, 24, 25, 27, 28, 29, 32, 33, 38, 45, 77, 119, 123, 124, 125, 126, 128, 132], "select": [2, 10, 26, 40, 48, 50, 61, 75, 80, 81, 82, 83, 84, 85, 86, 87, 89, 95, 97, 98, 99, 100, 102, 103, 104, 106, 107, 109, 110, 111, 116, 117, 119, 120, 125, 126, 127, 130], "form": [2, 11, 15, 63, 68, 74, 75, 82, 86, 88, 90, 97, 104, 119], "interven": [2, 4, 6, 9, 12, 33], "base": [2, 4, 5, 9, 10, 12, 15, 17, 18, 19, 21, 22, 23, 32, 33, 45, 48, 50, 59, 63, 64, 67, 68, 69, 71, 74, 76, 77, 79, 80, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 95, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 109, 110, 111, 116, 117, 120, 122, 124, 125, 126, 128, 130, 132], "collect": [2, 3, 4, 6, 17, 18, 19, 23, 27, 40, 60, 75, 76, 81, 85, 89, 103, 108, 109, 119, 125, 126, 127, 130, 132], "converion": 2, "even": [2, 15, 32, 40, 120, 132], "win": 2, "impress": [2, 19], "those": [2, 5, 48, 76, 82, 83, 84, 86, 87, 88, 90], "With": [2, 45, 48, 69, 97, 104, 108, 124, 128], "wearabl": 2, "devic": 2, "easili": [2, 22, 28, 82, 86, 91, 97, 98, 100, 104, 105, 111, 116], "keep": [2, 6, 10, 12, 103, 106], "track": [2, 9], "own": [2, 89, 132], "meanwhil": [2, 75], "util": [2, 10, 11, 13, 14, 17, 33, 59, 60, 63, 64, 69, 70, 74, 79, 81, 82, 83, 88, 89, 95, 97, 103, 104, 105, 106, 108, 119, 120, 125, 126, 127, 128, 129, 130], "manag": [2, 133], "increasingli": 2, "hot": 2, "topic": [2, 32, 119], "among": [2, 4, 9, 10, 11, 12, 13, 14, 40, 60, 67, 74, 80, 81, 85, 88, 89, 97, 102, 104, 109, 128, 130, 132], "them": [2, 6, 10, 15, 21, 22, 28, 32, 60, 74, 85, 96, 103, 105, 109, 128], "decid": [2, 18, 23, 95, 97, 98, 99, 100, 101, 102], "biggest": 2, "challeng": [2, 3, 10, 40, 64, 70, 119, 120], "given": [2, 4, 6, 11, 13, 14, 15, 16, 17, 21, 22, 24, 25, 26, 27, 29, 32, 33, 45, 50, 59, 60, 63, 64, 67, 70, 74, 75, 76, 77, 79, 80, 82, 83, 91, 92, 93, 97, 102, 104, 119, 132], "activ": 2, "suggest": [2, 4, 45, 67, 80, 87, 108, 109, 117], "help": [2, 27, 79, 81, 85, 89, 108, 109, 130], "regul": [2, 3, 10, 12, 21], "psycholog": [2, 21], "howev": [2, 4, 6, 9, 12, 15, 18, 19, 21, 22, 23, 25, 28, 32, 40, 45, 63, 64, 69, 70, 74, 77, 79, 86, 109, 111, 116, 119, 120], "send": [2, 45, 59, 99, 100, 102], "written": [2, 5, 9, 14, 15, 19, 20, 21, 25, 32], "intuit": [2, 48, 81, 84, 109, 110], "asleep": 2, "intens": [2, 19], "workout": 2, "rare": [2, 70], "exercis": 2, "would": [2, 4, 19, 21, 22, 26, 32, 33, 38, 45, 48, 59, 60, 61, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 89, 90, 91, 92, 93, 96, 101, 103, 108, 109, 111, 116, 118, 119, 120, 124, 128, 132], "decreas": [2, 3, 64, 84, 109, 110, 125, 126], "To": [2, 13, 15, 17, 18, 22, 23, 33, 40, 50, 60, 63, 64, 69, 71, 74, 75, 82, 83, 84, 86, 87, 88, 90, 95, 96, 97, 98, 99, 100, 102, 104, 105, 106, 119, 130, 133], "number": [2, 4, 9, 11, 13, 14, 22, 23, 25, 27, 33, 40, 45, 48, 50, 60, 69, 71, 77, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 117, 118, 125, 126, 130, 132], "formal": [2, 3, 4, 15, 17, 24, 25, 74, 76, 96, 101], "reinforc": [2, 5, 9, 10, 11, 12, 13, 14, 59, 67, 68, 69, 74, 75, 76, 79, 84, 109, 110, 119, 120, 123], "mdp": [2, 32, 63, 69, 71, 74, 75, 76, 119, 120], "seri": [2, 5, 9, 18, 23, 45, 69, 74, 77], "stage": [2, 16, 17, 25, 32, 33, 123, 130, 132], "condit": [2, 4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 25, 32, 33, 45, 50, 60, 63, 64, 76, 77, 88, 91, 92, 93, 97, 102, 104, 108, 119, 120], "affect": [2, 3, 4, 6, 12, 15, 21, 33, 48, 132], "previou": [2, 17, 19, 76, 81, 87, 89, 91, 92, 93, 97, 102, 104, 108, 109, 118, 130, 132], "delai": [2, 71, 79, 123], "current": [2, 3, 60, 71, 75, 76, 80, 91, 92, 93, 119, 132], "decis": [2, 5, 9, 15, 33, 45, 50, 59, 60, 61, 71, 77, 79, 80, 89, 91, 92, 93, 103, 119, 120, 132, 133, 134], "subsequ": [2, 4, 6, 108], "regard": [2, 19, 64, 67, 69, 74, 81, 132], "cumul": [2, 69, 75, 76, 80, 81, 85, 89, 97, 102, 104, 108, 109, 119, 130], "sequenc": [2, 78, 80, 89, 108, 118, 120, 128], "longitudin": [2, 32, 37, 38, 124], "subject": [2, 4, 6, 15, 19, 22, 33, 45, 59, 77, 79], "experienc": 2, "entir": [2, 5, 17, 32, 97, 102, 104, 125, 126, 132], "formul": [2, 9, 13, 76, 102, 132], "illustr": [2, 17, 18, 21, 23, 27, 40, 60, 64, 71, 80, 85, 91, 92, 93, 109, 119, 125, 126, 127, 132], "context": [2, 21, 33, 38, 50, 80, 81, 91, 92, 93, 132], "hiv": 2, "infect": [2, 3], "time": [2, 5, 9, 10, 11, 13, 14, 19, 21, 25, 32, 37, 38, 40, 45, 50, 60, 64, 69, 71, 74, 75, 76, 77, 81, 84, 85, 87, 88, 89, 91, 92, 93, 108, 109, 110, 117, 119, 120, 123, 124, 125, 126, 128, 130, 132], "datamdp": [2, 77, 78, 79], "cd4": 2, "count": [2, 84, 87, 110, 117, 129], "wa": [2, 4, 9, 13, 15, 21, 24, 25, 27, 32, 33, 40, 48, 59, 60, 77, 79, 120, 130], "all": [2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 24, 25, 26, 27, 28, 29, 32, 33, 38, 40, 45, 48, 59, 60, 64, 71, 74, 76, 77, 78, 79, 81, 88, 89, 91, 92, 93, 96, 99, 100, 101, 102, 105, 107, 108, 109, 118, 119, 120, 123, 124, 125, 126, 128, 130, 132], "interact": [2, 20, 25, 89, 108, 118], "same": [2, 4, 5, 6, 15, 18, 19, 21, 22, 23, 28, 29, 33, 45, 48, 59, 64, 76, 77, 79, 90, 99, 100, 103, 104, 105, 106, 108, 119], "possibl": [2, 4, 6, 9, 13, 22, 29, 40, 64, 99, 100, 102, 130, 132], "style": [2, 14, 107], "mani": [2, 3, 5, 9, 10, 12, 48, 67, 74, 75, 76, 91, 92, 93, 97, 102, 104, 108, 118, 119], "channel": [2, 60], "distribut": [2, 4, 6, 9, 14, 21, 22, 23, 25, 48, 60, 61, 64, 74, 75, 76, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 111, 116, 119, 120, 130, 132], "credit": 2, "correspond": [2, 4, 6, 10, 12, 32, 40, 45, 48, 50, 59, 60, 63, 64, 69, 70, 71, 74, 76, 77, 79, 81, 84, 85, 86, 87, 88, 89, 90, 96, 97, 100, 103, 104, 105, 106, 108, 109, 110, 111, 116, 117, 118, 119, 120, 132], "contribut": [2, 3, 10], "becom": [2, 15, 24, 25, 32, 40, 64, 69, 120], "rule": [2, 48, 50, 100], "simpl": [2, 18, 23, 33, 67, 68, 69, 80, 84, 89, 102, 109, 110, 131, 132, 134], "been": [2, 4, 6, 9, 13, 15, 18, 23, 27, 32, 33, 50, 60, 63, 69, 70, 74, 80, 85, 86, 88, 89, 100, 105, 109, 111, 116, 125, 126, 127, 132], "long": [2, 32, 63, 69, 71, 74, 103, 132], "ever": 2, "enhanc": 2, "capabl": 2, "driven": 2, "attempt": 2, "popular": [2, 50, 68, 96, 97, 103, 106, 108, 109, 118, 119, 129, 130], "framework": [2, 4, 6, 15, 71, 81, 82, 88, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 118, 123], "classic": [2, 4, 6, 9, 14, 21, 22, 24, 25, 32, 50, 59, 67, 79, 81, 85, 86, 109, 116, 120, 132, 133], "bandit": [2, 5, 91, 92, 93, 95, 97, 98, 99, 100, 102, 104, 105, 106, 107, 110, 111, 117, 118, 120, 130], "prefer": [2, 19, 22, 28], "click": [2, 19, 96, 104, 105, 106, 108], "overal": [2, 19, 21, 22, 23, 25, 33, 45, 59, 60, 77, 79, 81, 85, 96, 97, 101, 102, 103, 104, 109, 125, 126, 132], "repres": [2, 4, 6, 9, 11, 12, 13, 14, 15, 27, 38, 50, 119, 125, 126, 127, 132], "movi": [2, 26, 81, 84, 85, 89, 104, 105, 106, 108, 109, 118, 130], "youtub": 2, "netflix": 2, "agent": [2, 60, 75, 76, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 111, 116, 118, 119, 130], "list": [2, 11, 13, 14, 32, 40, 62, 77, 90, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 108, 118, 122, 123, 125, 126, 129, 130, 132], "video": [2, 60], "visit": [2, 32, 50, 64, 69, 81, 85, 89, 96, 103, 108, 109, 119, 130], "either": [2, 4, 6, 15, 27, 45, 59, 61, 63, 67, 68, 74, 77, 79, 81, 84, 86, 87, 88, 90, 92, 95, 97, 98, 99, 100, 102, 103, 104, 105, 106, 108, 109, 110, 117, 119, 120, 132], "leav": [2, 3, 32, 85, 89, 96, 108, 132], "typic": [2, 40, 63, 69, 70, 74, 80, 81, 85, 101, 102, 119, 132], "larg": [2, 17, 19, 27, 40, 48, 62, 63, 64, 67, 69, 71, 74, 76, 80, 84, 86, 87, 88, 89, 90, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 109, 117, 125, 126, 127], "avail": [2, 4, 6, 9, 10, 13, 14, 17, 33, 61, 76, 81, 85, 89, 95, 96, 102, 103, 108, 109, 118, 125, 126, 127, 130], "therefor": [2, 17, 32, 40, 45, 59, 64, 67, 68, 69, 81, 85, 86, 89, 90, 96, 99, 100, 102, 109, 111, 116, 119, 124, 128, 130, 132], "explor": [2, 22, 32, 60, 63, 64, 67, 68, 69, 70, 72, 74, 79, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 95, 98, 109, 110, 111, 116, 117, 119, 130], "exploit": [2, 19, 84, 85, 86, 87, 91, 92, 93, 98, 109, 110, 111, 116, 117], "inform": [2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 17, 19, 22, 27, 29, 33, 40, 45, 50, 61, 69, 74, 77, 78, 80, 81, 82, 83, 86, 88, 89, 90, 92, 93, 95, 96, 97, 99, 100, 102, 103, 104, 105, 108, 109, 111, 116, 118, 120, 123, 124, 128, 131, 132, 133], "far": [2, 84, 87, 109, 110], "approach": [2, 3, 4, 6, 15, 16, 17, 18, 21, 22, 25, 32, 33, 45, 48, 59, 63, 64, 67, 68, 69, 70, 74, 77, 79, 80, 81, 103, 105, 106, 107, 109, 119, 120, 132], "As": [2, 15, 20, 22, 25, 26, 29, 32, 40, 63, 64, 67, 71, 74, 75, 76, 80, 82, 83, 87, 88, 90, 95, 97, 98, 109, 111, 117, 119, 123, 124, 125, 126, 128, 132], "chapter": [2, 61, 76, 81, 85, 89, 95, 97, 98, 99, 100, 102, 104, 105, 106, 108, 109, 118, 119, 120, 132], "genr": [2, 26, 81, 85, 89, 108, 109, 130], "five": [2, 104, 105, 106, 108, 130], "whose": [2, 3, 76, 132], "unknown": [2, 9, 12, 13, 69, 74, 80, 81, 85, 86, 88, 90, 91, 92, 93, 97, 102, 104, 109, 111, 116, 128, 132], "over": [2, 3, 15, 22, 33, 38, 50, 63, 64, 69, 71, 74, 90, 91, 92, 93, 106, 109, 119, 125, 129, 132], "satisfact": [2, 27, 81, 85, 89, 108, 109, 130], "movielen": [2, 15, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 103, 104, 105, 106, 108, 109, 118, 129], "arm": [2, 80, 81, 82, 83, 84, 86, 87, 88, 89, 90, 100, 101, 108, 109, 110, 117, 118, 129, 130, 132], "contextu": [2, 40, 80, 82, 83, 85, 91, 92, 93, 103, 104, 105, 109, 111, 130, 132], "meta": [2, 19, 29, 80, 88, 96, 97, 101, 102, 103, 104, 108, 132], "multipl": [2, 9, 10, 11, 12, 13, 14, 32, 45, 48, 60, 62, 80, 90, 120, 128, 132], "million": [2, 3, 9, 10, 11, 12, 13, 14], "try": [2, 16, 21, 25, 27, 109, 122, 125, 128, 133], "assort": [2, 104, 106, 107, 108, 118, 132], "rank": [2, 95, 97, 98, 108, 118, 132], "top": [2, 9, 10, 11, 12, 13, 14, 40, 76, 81, 85, 89, 95, 96, 97, 98, 106, 108, 109, 119, 125, 126], "restaur": [2, 33, 95, 96, 97, 98], "true": [2, 3, 10, 11, 13, 14, 17, 18, 21, 22, 23, 25, 45, 48, 59, 60, 61, 62, 64, 67, 71, 77, 79, 82, 83, 84, 86, 88, 90, 92, 104, 106, 107, 108, 109, 110, 111, 116, 117, 122, 123, 124, 125, 128, 130], "expect": [2, 15, 16, 17, 18, 20, 22, 23, 24, 25, 26, 28, 29, 32, 38, 45, 48, 50, 59, 63, 69, 71, 74, 75, 76, 77, 79, 81, 82, 83, 86, 88, 89, 90, 92, 93, 98, 100, 109, 124, 125, 126, 128, 130], "yelp": [2, 95, 96, 97, 98], "discuss": [2, 9, 32, 69, 74, 75, 76, 90, 119, 132, 133], "offlin": [2, 27, 32, 50, 60, 92, 119, 120, 132], "prevent": 2, "unnecessari": [2, 125, 126], "essenti": [2, 3, 74, 88, 120], "variant": [2, 3, 69, 84, 109, 110, 119], "frequent": [2, 40], "commerci": 2, "googl": 2, "displai": [2, 5, 17, 21, 33, 95, 96, 97, 98], "twitter": 2, "view": [2, 3, 21, 74, 92, 93, 122, 125], "bipartit": 2, "match": [2, 33, 63, 69, 92, 93, 101, 104, 105, 106, 108, 118], "need": [2, 20, 25, 33, 45, 50, 60, 69, 77, 81, 85, 86, 87, 89, 90, 96, 101, 103, 108, 109, 111, 116, 118, 119, 120, 123, 133, 134], "show": [2, 4, 10, 15, 19, 40, 60, 63, 74, 76, 84, 92, 95, 97, 98, 101, 103, 109, 110, 130], "like": [2, 5, 19, 21, 22, 26, 27, 28, 38, 45, 48, 59, 60, 64, 79, 81, 85, 89, 108, 109, 124, 128, 130], "attract": [2, 3, 4, 9, 11, 12, 13, 14, 15, 22, 60, 91, 92, 93, 96, 97, 98, 99, 100, 101, 102, 108], "while": [2, 6, 10, 12, 22, 28, 32, 33, 38, 45, 48, 60, 71, 77, 80, 81, 90, 97, 102, 104, 105, 123, 130, 132], "adher": 2, "budget": 2, "constraint": [2, 5, 9, 10, 13, 40, 67, 99, 100, 101, 102, 108, 118], "feedback": [2, 80, 81, 82, 85, 89, 91, 92, 93, 97, 101, 102, 104, 108, 109, 111, 116, 118], "achiev": [2, 17, 19, 20, 25, 33, 48, 63, 64, 74, 86, 90], "whom": 2, "its": [2, 5, 9, 11, 13, 17, 19, 20, 22, 25, 48, 50, 60, 63, 64, 68, 69, 74, 75, 76, 81, 86, 88, 89, 92, 95, 109, 111, 116, 119, 132, 133], "chanc": 2, "accept": [2, 5, 122, 126], "adult": [2, 99, 100, 101, 102], "combinatori": [2, 97, 99, 100, 102, 104, 107, 108, 118, 132], "world": [2, 80, 81, 85, 89, 95, 100, 109], "across": [2, 38, 88, 89, 99], "retail": 2, "adjust": [2, 10, 21, 90], "period": [2, 11, 32, 33, 40, 71, 125, 126, 132], "rideshar": 2, "servic": [2, 96, 129], "weather": 2, "occur": [2, 76, 119], "outsid": [2, 3, 10, 21, 32], "airlin": 2, "rais": [2, 21, 33, 71, 122, 123, 126, 128], "ticket": 2, "farewel": 2, "date": [2, 88, 90], "rise": [2, 15], "low": [2, 5, 63, 69, 74, 106, 108, 120, 125, 126, 131], "evalut": 2, "section": [2, 4, 6, 15, 17, 19, 20, 21, 22, 25, 32, 33, 38, 69, 70, 74, 76, 119, 123, 125, 126, 128, 130, 132, 133], "harper": 2, "f": [2, 10, 63, 74, 90, 96, 97, 102, 104, 108, 118, 122, 123, 126, 129, 133], "m": [2, 5, 10, 12, 15, 16, 17, 19, 20, 21, 24, 25, 33, 37, 38, 45, 50, 59, 60, 63, 64, 67, 75, 77, 79, 81, 82, 88, 89, 90, 91, 92, 93, 95, 96, 100, 103, 104, 105, 109, 111, 123, 124, 128, 129, 132], "konstan": 2, "j": [2, 9, 11, 13, 14, 15, 16, 17, 19, 20, 21, 22, 25, 26, 28, 29, 40, 45, 60, 64, 71, 74, 76, 77, 80, 81, 88, 89, 90, 91, 92, 93, 97, 103, 104, 105, 106, 107, 109, 116, 117, 119, 123, 128], "acm": [2, 50], "transact": 2, "intellig": [2, 5, 19, 50, 80, 81, 82, 83, 89, 95, 96, 98, 109, 111, 119, 120], "tii": 2, "19": [2, 5, 10, 21, 40, 45, 50, 60, 62, 63, 122, 125], "2015": [2, 5, 48, 59, 69, 74, 79, 80, 96, 99, 101, 109, 119], "asghar": 2, "n": [2, 4, 6, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 38, 40, 45, 48, 50, 59, 60, 61, 62, 63, 64, 67, 68, 69, 74, 75, 76, 77, 78, 79, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 95, 96, 97, 99, 101, 102, 103, 104, 105, 107, 108, 109, 110, 111, 117, 118, 119, 124, 125, 126, 128, 129, 130, 132, 133], "review": [2, 9, 12, 17, 19, 45, 50, 69, 70, 74, 77, 85, 97, 102, 104, 108, 109, 133], "arxiv": [2, 5, 9, 10, 11, 12, 13, 14, 16, 19, 20, 25, 50, 60, 63, 67, 71, 81, 85, 86, 91, 92, 93, 95, 96, 97, 101, 102, 103, 104, 105, 108, 109, 118, 119, 120, 123], "preprint": [2, 5, 9, 10, 11, 12, 13, 14, 16, 19, 20, 25, 50, 60, 63, 67, 71, 81, 85, 86, 91, 92, 93, 95, 96, 97, 101, 102, 103, 104, 105, 108, 109, 118, 119, 120, 123], "1605": 2, "05362": 2, "2016": [2, 5, 63, 69, 74, 95, 96, 97, 101, 104, 119], "asuncion": 2, "newman": 2, "d": [2, 5, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 24, 25, 32, 33, 45, 50, 59, 60, 64, 69, 71, 74, 75, 76, 77, 79, 80, 81, 85, 86, 89, 90, 96, 103, 108, 109, 116, 117, 118, 119, 123, 131], "uci": 2, "machin": [2, 5, 9, 10, 11, 12, 13, 14, 15, 17, 19, 22, 26, 28, 29, 63, 64, 68, 69, 70, 74, 80, 81, 82, 84, 87, 89, 90, 96, 99, 100, 101, 106, 108, 109, 110, 111, 116, 117, 118, 119], "repositori": [2, 9, 10, 11, 13, 133], "2007": [2, 9, 10, 11, 12, 13, 14, 81], "tsiati": [2, 15, 45, 77, 132], "davidian": [2, 15, 45, 77, 132], "hollowai": [2, 132], "laber": [2, 15, 45, 77, 132], "2019": [2, 3, 5, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 22, 23, 25, 26, 28, 29, 35, 39, 41, 42, 43, 63, 67, 81, 85, 96, 98, 103, 104, 105, 106, 107, 109, 132], "precis": [2, 19, 82, 86, 88, 90, 97, 104, 132], "medicin": [2, 19, 48, 91, 92, 93, 132], "chapman": [2, 132], "hall": [2, 132], "crc": [2, 132], "era": [3, 10], "revolut": [3, 10], "area": [3, 10, 32, 38, 48, 85, 91, 92, 93, 109, 119], "gener": [3, 4, 6, 10, 19, 21, 22, 27, 32, 35, 39, 40, 41, 42, 43, 48, 50, 59, 60, 63, 67, 69, 70, 74, 75, 76, 79, 80, 81, 85, 89, 91, 92, 93, 101, 108, 109, 111, 117, 118, 126, 129, 130, 132, 133], "graph": [3, 10, 71, 132], "direct": [3, 9, 10, 11, 12, 13, 14, 60, 64, 67, 68, 71, 74, 80, 103, 106, 119, 123, 124, 128], "indirect": [3, 10, 12, 21, 71, 124, 128], "mediat": [3, 9, 11, 13, 14, 32, 37, 76], "intermedi": 3, "variabl": [3, 4, 6, 9, 10, 11, 12, 13, 14, 16, 19, 20, 21, 22, 23, 25, 27, 32, 48, 59, 70, 71, 76, 78, 79, 81, 85, 89, 96, 109, 119, 120, 130, 132], "instanc": [3, 32, 48, 62, 90, 97, 104], "outbreak": 3, "coronaviru": [3, 10], "diseas": 3, "chines": [3, 10, 21], "govern": 3, "taken": [3, 38, 61, 64, 78, 89, 92, 93, 132], "extrem": [3, 22, 28], "stop": [3, 91, 92, 93, 96, 108], "viru": 3, "lock": 3, "wuhan": 3, "down": 3, "jan": [3, 9, 10, 11, 12, 13, 14], "23rd": 3, "2020": [3, 5, 9, 11, 12, 13, 14, 16, 18, 19, 20, 21, 24, 25, 40, 50, 81, 82, 86, 95, 100, 102, 105, 106, 109, 111, 119, 120], "12": [3, 5, 9, 10, 11, 12, 13, 14, 16, 17, 20, 21, 23, 24, 27, 28, 29, 45, 59, 60, 62, 79, 81, 82, 83, 109, 120, 122, 123, 124, 125, 128, 129, 130], "citi": [3, 10, 21], "hubei": [3, 10, 21], "lockdown": [3, 10, 21], "directli": [3, 5, 12, 17, 27, 45, 59, 60, 63, 64, 67, 68, 69, 70, 71, 72, 74, 75, 76, 77, 98, 102, 106, 110, 111, 116, 117, 119, 120, 123, 128], "block": [3, 5, 124, 128], "peopl": [3, 15, 26, 27, 28, 29], "stimul": [3, 60], "quarantin": 3, "further": [3, 10, 12, 20, 25, 33, 60, 64, 71, 97, 99, 100, 102, 104, 108, 118, 123, 124, 128, 130, 132], "migrat": 3, "countrywid": 3, "china": [3, 10, 21], "thu": [3, 9, 12, 15, 17, 18, 20, 23, 25, 38, 50, 60, 76, 89, 91, 92, 93], "indirectli": 3, "reduc": [3, 10, 12, 21, 40, 60, 64], "great": [3, 19, 96], "crisi": 3, "mechan": [3, 10, 76], "individu": [3, 4, 6, 10, 15, 22, 27, 29, 33, 38, 45, 48, 50, 59, 61, 64, 77, 78, 79, 103, 118, 124, 128, 129], "decad": [3, 33], "discoveri": [3, 12, 50], "disentangl": [3, 9, 11, 12, 13, 14], "complex": [3, 5, 9, 11, 12, 13, 14, 22, 28, 32, 50, 64, 99, 100, 102, 106, 120, 132], "field": [3, 45, 77, 80], "5": [3, 9, 10, 11, 12, 13, 14, 15, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 33, 37, 40, 45, 48, 50, 59, 60, 62, 63, 64, 67, 68, 69, 70, 71, 72, 74, 77, 79, 81, 85, 86, 89, 90, 96, 101, 103, 104, 105, 106, 107, 109, 110, 111, 116, 117, 122, 123, 124, 125, 126, 128, 130, 131], "singl": [3, 22, 26, 28, 32, 40, 50, 63, 71, 74, 77, 79, 110, 111, 116, 117, 125, 126, 127, 132], "nucleotid": 3, "polymorph": 3, "snp": 3, "person": [3, 9, 32, 45, 50, 59, 77, 79, 81, 109, 133], "genom": 3, "fewer": [3, 132], "non": [3, 9, 10, 12, 13, 14, 17, 19, 21, 27, 45, 48, 59, 60, 77, 79, 92, 93, 128], "spuriou": 3, "protein": 3, "systemat": [3, 133], "phenotyp": 3, "focu": [3, 4, 6, 12, 16, 17, 18, 19, 20, 24, 26, 28, 29, 45, 67, 77, 80, 81, 85, 89, 91, 92, 93, 102, 103, 104, 109, 119, 130, 132], "brem": 3, "kruglyak": 3, "2005": [3, 5, 59, 68, 79, 120], "discov": [3, 108], "featur": [3, 4, 6, 12, 15, 27, 48, 50, 61, 71, 81, 82, 83, 88, 89, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 111, 118, 119, 123, 125, 126, 127, 130, 132], "explain": 3, "104": [3, 21, 40, 45, 77, 85], "segreg": 3, "simul": [3, 6, 10, 12, 17, 27, 81, 85, 89, 108, 130], "genet": 3, "divers": [3, 59, 79, 132], "strain": 3, "by4716": 3, "rm11": 3, "1a": [3, 20, 25], "contain": [3, 4, 6, 9, 11, 12, 13, 14, 15, 17, 19, 27, 33, 40, 50, 61, 78, 90, 91, 92, 93, 96, 108, 118, 130, 132, 133], "thousand": [3, 129], "genotyp": 3, "rich": 3, "influenc": [3, 10, 12, 21, 40, 64, 132], "target": [3, 10, 22, 23, 25, 32, 50, 59, 60, 63, 67, 69, 74, 75, 76, 79, 92, 101, 123, 124, 128, 132], "herit": 3, "due": [3, 14, 32, 40, 63, 64, 67, 68, 69, 70, 71, 106, 119, 120, 123, 125, 126, 127, 130, 132], "dimension": [3, 4, 9, 10, 11, 12, 13, 14, 15, 18, 23, 40, 45, 64, 77, 89, 108, 118, 120, 132], "name": [3, 5, 9, 11, 13, 14, 16, 17, 18, 20, 21, 24, 25, 26, 27, 32, 33, 45, 50, 60, 62, 63, 67, 74, 80, 85, 87, 89, 101, 107, 109, 117, 119, 122, 129, 134], "quantit": 3, "loci": 3, "qtl": 3, "involv": [3, 80, 119], "parsimoni": 3, "reveal": 3, "necessari": [3, 4, 6, 82, 97, 98, 99, 100, 104, 105], "depend": [3, 5, 50, 60, 64, 69, 74, 76, 80, 81, 91, 92, 93, 101, 102, 103, 106, 108, 118, 119, 120, 132], "present": [3, 64, 75, 95, 97, 98, 99, 100, 102, 104, 105, 106, 132], "toward": [3, 64, 96, 97, 101, 102, 103, 104, 108], "yer124c": 3, "daughter": 3, "cell": [3, 5, 50, 63, 64, 67, 68, 69, 70, 72, 74, 110, 111, 116, 117], "particip": 3, "pathwai": 3, "wall": 3, "metabol": 3, "delet": [3, 11, 13, 14], "separ": [3, 15, 19, 21, 22, 28, 29, 63, 74, 101, 129], "divis": 3, "sensit": [3, 21, 45, 48, 77, 128], "against": [3, 64], "consid": [4, 6, 9, 11, 12, 13, 14, 19, 26, 32, 33, 45, 59, 60, 61, 63, 64, 67, 68, 69, 71, 74, 75, 76, 77, 79, 81, 82, 85, 86, 88, 89, 90, 95, 96, 97, 99, 100, 102, 103, 104, 105, 108, 111, 116, 118, 123, 124, 128, 131, 132], "popul": [4, 6, 15, 33], "doe": [4, 6, 9, 11, 12, 13, 14, 81, 95, 97, 98, 120, 122, 124, 126, 128, 129, 132], "y": [4, 6, 10, 12, 16, 17, 19, 20, 21, 25, 40, 45, 48, 50, 59, 60, 62, 77, 79, 80, 81, 91, 92, 93, 96, 97, 100, 101, 102, 103, 104, 106, 108, 109, 118, 128, 130, 131, 132], "establish": [4, 6, 14, 40, 59, 64, 79], "respons": [4, 5, 6, 15, 22, 26, 28, 103, 104, 105, 106, 120], "advoc": [4, 6], "neyman": [4, 6], "rubin": [4, 6], "robin": [4, 6, 15, 17, 45, 77, 128], "denot": [4, 6, 9, 11, 13, 19, 20, 21, 22, 25, 27, 28, 32, 33, 38, 40, 50, 60, 63, 64, 67, 68, 69, 71, 74, 75, 76, 80, 81, 85, 88, 89, 91, 92, 93, 96, 101, 103, 108, 109, 118, 119, 125, 126, 132], "vector": [4, 6, 9, 11, 12, 13, 14, 20, 25, 76, 81, 82, 86, 89, 96, 97, 102, 103, 104, 108, 111, 116, 118, 119, 120, 132], "simplic": [4, 6, 22, 69, 99, 100, 102, 132], "simplest": [4, 5, 6, 60], "case": [4, 6, 9, 11, 13, 14, 15, 19, 22, 24, 25, 28, 32, 40, 45, 48, 59, 60, 77, 79, 87, 116, 118, 131, 132, 133], "binari": [4, 6, 10, 21, 27, 45, 48, 59, 61, 77, 79, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 95, 96, 97, 98, 101, 103, 104, 105, 106, 109, 124, 125, 126, 128, 130, 132], "0": [4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 38, 40, 45, 48, 50, 59, 60, 61, 62, 63, 64, 67, 68, 69, 71, 74, 75, 76, 77, 79, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 116, 117, 119, 122, 123, 124, 125, 126, 128, 129, 130, 131, 132, 134], "sai": [4, 6, 9, 11, 13, 14], "versu": [4, 6, 17, 21, 27, 32, 122, 125, 132], "acquir": [4, 6], "app": [4, 6, 71], "download": [4, 6, 17, 18, 23], "baselin": [4, 6, 11, 13, 14, 15, 22, 27, 69, 74, 81, 88, 89, 109, 123, 130], "observ": [4, 5, 6, 9, 11, 13, 15, 17, 19, 20, 21, 22, 23, 25, 26, 32, 33, 38, 40, 48, 50, 59, 61, 63, 64, 67, 69, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 104, 107, 108, 109, 110, 117, 118, 119, 120, 123, 124, 128, 130, 132], "summar": [4, 6, 9, 10, 17, 19, 22, 26, 28, 29, 60, 71, 85, 120, 123, 124, 128, 130, 132], "z_i": [4, 6, 9, 11, 12, 13, 14, 20, 25], "x_i": [4, 15, 48, 50, 60], "t_i": [4, 33, 75, 76], "y_i": [4, 33, 48, 50, 60], "th": [4, 6, 15, 18, 23, 40, 64, 69, 70, 71, 75, 76, 89, 96, 123], "covari": [4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 25, 33, 88, 90, 99, 100, 102, 125, 126], "prior": [4, 6, 11, 80, 81, 82, 86, 88, 89, 90, 97, 98, 99, 100, 102, 104, 105, 106, 109, 111, 116, 123, 130], "assum": [4, 6, 9, 11, 13, 24, 25, 45, 48, 59, 69, 75, 76, 77, 79, 80, 81, 82, 83, 85, 86, 88, 89, 90, 95, 97, 98, 99, 100, 102, 103, 104, 105, 106, 108, 109, 111, 116, 118, 120, 130, 132], "chosen": [4, 6, 16, 17, 18, 19, 20, 24, 26, 28, 29, 67, 76, 81, 92, 93, 96, 97, 101, 103, 104, 105, 106], "henc": [4, 6, 10, 15, 27, 48, 63, 69, 74, 81, 85, 89, 97, 104, 109, 119, 120, 130], "sometim": [4, 6, 119], "refer": [4, 5, 6, 133], "counterfactu": [4, 6, 33, 40, 76, 119, 132], "becaus": [4, 6, 129], "realiti": [4, 6], "hypothet": [4, 6], "contrari": [4, 6, 130], "fact": [4, 6, 63, 64, 67, 68, 74, 75, 81, 119], "actual": [4, 6, 15, 120], "than": [4, 6, 10, 15, 19, 22, 25, 26, 28, 29, 50, 63, 64, 69, 70, 74, 76, 81, 83, 85, 89, 109, 130], "notion": [4, 6], "defin": [4, 5, 6, 10, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 32, 33, 38, 45, 50, 59, 60, 63, 64, 69, 70, 74, 75, 76, 77, 79, 84, 91, 92, 93, 96, 101, 108, 109, 110, 118, 124, 128, 132, 134], "now": [4, 6, 22, 40, 60, 108, 119, 131], "deduc": [4, 6], "x": [4, 6, 15, 17, 18, 19, 21, 23, 24, 25, 40, 45, 48, 50, 59, 60, 62, 77, 79, 80, 82, 83, 88, 90, 91, 92, 93, 98, 99, 109, 111, 118, 122, 123, 128, 130, 131], "sutva": [4, 6, 15, 32, 33, 76], "stabl": [4, 6, 10, 15, 21, 122, 125], "unit": [4, 6, 15, 33, 38, 40, 132], "begin": [4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 32, 33, 40, 45, 48, 50, 59, 60, 63, 64, 67, 68, 69, 70, 71, 74, 75, 76, 77, 79, 82, 83, 84, 86, 87, 88, 90, 91, 92, 93, 95, 96, 97, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 117, 118, 119, 124, 128, 132], "align": [4, 6, 15, 17, 21, 24, 25, 32, 33, 40, 45, 48, 59, 63, 64, 69, 71, 74, 75, 77, 79, 82, 83, 84, 86, 87, 106, 110, 111, 117, 119, 124, 128], "end": [4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 32, 33, 40, 45, 48, 50, 59, 60, 63, 64, 67, 68, 69, 70, 71, 74, 75, 76, 77, 79, 82, 83, 84, 86, 87, 88, 90, 91, 92, 93, 95, 96, 97, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 116, 117, 118, 119, 124, 128, 132], "That": [4, 6, 15, 19, 24, 25, 26, 33, 60], "regardless": [4, 6, 15], "interfer": [4, 6, 15, 32], "No": [4, 6, 9, 11, 13, 14, 15, 17, 18, 21, 25, 27, 33, 45, 50, 59, 60, 63, 64, 67, 68, 69, 70, 71, 72, 74, 88, 89, 90, 103, 110, 111, 116, 117, 123, 128, 129, 130, 131, 132], "unmeasur": [4, 6, 9, 11, 13, 14, 15, 21, 22, 26, 32, 76, 120], "confound": [4, 5, 6, 9, 11, 12, 13, 14, 15, 21, 22, 26, 32, 76, 120, 123, 124, 128, 132], "strong": [4, 6, 14, 15, 18, 23, 32, 69, 74], "ignor": [4, 6, 15, 16, 17, 20, 24, 69, 74, 91, 92, 93, 129, 133], "perp": [4, 6, 15, 21, 76], "refut": [4, 6, 15], "believ": [4, 6, 15, 132], "relev": [4, 6, 15, 69], "reason": [4, 6, 9, 12, 14, 15, 19], "p": [4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 17, 19, 20, 21, 22, 25, 26, 28, 29, 32, 45, 48, 50, 62, 71, 74, 75, 76, 77, 81, 82, 83, 84, 87, 88, 90, 95, 97, 99, 100, 101, 102, 104, 105, 107, 109, 110, 111, 116, 117, 119, 123, 128, 129, 130, 131, 132, 133], "ensur": [4, 6, 9, 15, 76], "similar": [4, 5, 6, 15, 21, 33, 48, 63, 64, 68, 69, 74, 76, 77, 80, 82, 83, 84, 86, 87, 88, 89, 90, 95, 96, 111, 119, 132], "vice": [4, 6, 15], "versa": [4, 6, 15], "text": [4, 5, 6, 12, 15, 16, 17, 19, 21, 22, 25, 26, 28, 29, 32, 33, 40, 48, 59, 61, 63, 67, 68, 75, 79, 87, 88, 90, 97, 102, 104, 105, 119], "ATE": [4, 6, 12, 17, 19, 21, 26, 32, 38, 71, 123], "There": [4, 5, 6, 19, 38, 40, 60, 61, 87, 97, 119], "deriv": [4, 6, 18, 21, 22, 23, 29, 32, 45, 50, 64, 70, 71, 79, 102, 123], "confoun": 4, "come": [4, 33, 99, 100, 132], "consider": 4, "e_x": 4, "quad": [4, 15, 18, 22, 23, 29, 45, 77, 88, 90, 91, 92, 93, 97, 102, 104], "similarli": [4, 10, 15, 33, 45, 63, 64, 74, 75, 76, 77, 88, 90, 101, 102, 108, 123, 125, 126], "mu": [4, 15, 16, 21, 22, 25, 26, 82, 86, 88, 89, 90, 91, 92, 93, 95, 97, 102, 104, 124], "gamma": [4, 15, 17, 20, 25, 32, 45, 63, 64, 67, 68, 69, 74, 75, 76, 77, 82, 83, 88, 90, 95, 97, 99, 102, 104, 105, 111, 119], "paramet": [4, 9, 11, 15, 17, 18, 20, 23, 25, 50, 60, 82, 84, 87, 88, 90, 97, 102, 103, 104, 106, 109, 110, 111, 123, 128], "mle": 4, "least": [4, 15, 20, 22, 25, 81, 85, 89, 103, 108, 109, 130], "squar": [4, 15, 20, 25], "Then": [4, 9, 10, 11, 12, 13, 14, 15, 18, 23, 70, 71, 77, 79, 81, 85, 87, 89, 91, 92, 93, 97, 102, 104, 108, 109, 117, 118, 119, 130, 133], "hat": [4, 15, 16, 17, 18, 20, 22, 23, 24, 25, 26, 28, 29, 33, 40, 45, 59, 60, 63, 67, 69, 74, 75, 76, 77, 79, 83, 84, 88, 95, 99, 107, 119, 130], "sum_": [4, 15, 17, 18, 21, 23, 32, 33, 40, 45, 50, 59, 60, 63, 64, 67, 68, 69, 70, 71, 74, 75, 76, 77, 81, 85, 87, 89, 91, 92, 93, 95, 96, 97, 101, 102, 103, 104, 105, 106, 107, 109, 117, 119], "anoth": [4, 5, 9, 17, 19, 40, 60, 69, 70, 74, 119, 124, 128], "pi": [4, 15, 16, 20, 25, 32, 48, 59, 60, 63, 64, 67, 68, 69, 70, 71, 74, 75, 76, 79, 91, 92, 93, 119], "get": [4, 15, 16, 17, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 33, 38, 45, 59, 61, 62, 77, 79, 82, 83, 84, 85, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 118, 124, 128, 130, 131], "function": [4, 5, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 32, 45, 48, 50, 59, 60, 63, 64, 67, 68, 69, 74, 76, 77, 81, 82, 83, 84, 86, 87, 88, 90, 91, 92, 93, 95, 97, 98, 99, 100, 102, 103, 104, 105, 106, 108, 109, 110, 118, 119, 130, 132], "One": [4, 15, 63, 74, 119, 128, 129, 133], "difficult": [4, 15, 84], "build": [4, 5, 71, 74, 81, 123, 132, 133], "simpli": [4, 60, 89, 99], "stratifi": 4, "choos": [4, 16, 17, 18, 20, 24, 26, 27, 28, 29, 63, 64, 74, 80, 81, 85, 87, 89, 91, 92, 93, 97, 101, 102, 103, 104, 108, 109, 117, 118, 130], "cutoff": 4, "c_0": 4, "c_1": 4, "c_k": 4, "belong": [4, 27, 40, 67, 132], "k": [4, 5, 9, 10, 11, 12, 13, 14, 20, 25, 40, 50, 60, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 116, 117, 118, 119, 129, 130, 131], "c_": [4, 45, 77, 84, 87, 110, 117], "le": [4, 5, 50, 63, 64, 67, 68, 75, 76, 96], "bar": [4, 18, 23, 32, 69, 76, 78, 79, 119], "_": [4, 9, 11, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 28, 29, 32, 40, 45, 48, 50, 59, 60, 61, 63, 64, 67, 68, 69, 70, 74, 75, 76, 77, 78, 79, 82, 86, 88, 89, 90, 91, 92, 93, 95, 97, 98, 99, 100, 102, 104, 105, 106, 107, 108, 109, 111, 116, 117, 118, 119, 122, 125, 126, 132], "1k": 4, "0k": 4, "n_k": 4, "theoret": [4, 19, 64, 76, 90, 103, 118, 133], "justif": 4, "semiparametr": [4, 16, 19, 20, 21, 24, 25, 63, 64, 74, 128], "theori": [4, 17, 19, 20, 21, 25, 45, 48, 64, 77, 81, 103, 104, 106, 108, 128], "augment": [4, 15, 48, 64], "ipw": [4, 15, 60, 71, 128], "probabl": [4, 15, 21, 48, 50, 60, 63, 64, 69, 74, 75, 84, 85, 90, 103, 108, 109, 110, 128], "everi": [4, 15, 63, 69, 74, 81, 85, 88, 89, 90, 95, 97, 102, 104, 105, 109, 119, 130], "themselv": [4, 15], "did": [4, 15, 33, 38, 40, 77, 79, 132], "frac": [4, 15, 16, 17, 18, 20, 21, 23, 25, 33, 45, 48, 50, 59, 60, 63, 64, 69, 71, 74, 77, 84, 87, 103, 104, 105, 106, 107, 109, 110, 117], "ty": 4, "unbias": [4, 15, 69], "left": [4, 15, 18, 20, 23, 24, 25, 50, 60, 63, 74, 77, 91, 92, 93, 130, 131, 132], "right": [4, 9, 12, 15, 18, 20, 23, 24, 25, 50, 60, 63, 67, 68, 74, 77, 91, 92, 93, 119, 132], "t_iy_i": 4, "combin": [4, 15, 20, 21, 22, 25, 28, 29, 60, 63, 64, 74, 87, 89, 119, 130], "obtain": [4, 9, 11, 13, 15, 17, 18, 20, 21, 22, 23, 24, 25, 28, 29, 32, 60, 64, 69, 79, 100, 101, 119, 130, 132], "whether": [5, 33, 92, 93, 104, 105, 106, 125, 126], "write": [5, 15, 18, 23], "content": [5, 20, 25, 32, 132], "jupyt": [5, 133], "notebook": [5, 123, 124, 128], "ipynb": [5, 9, 14], "regular": [5, 50, 74, 88], "md": 5, "ll": [5, 27, 130], "flavor": 5, "stand": [5, 45, 77, 103], "markedli": 5, "slight": 5, "variat": [5, 9, 33], "commonmark": 5, "small": [5, 48, 125, 126], "syntax": 5, "sphinx": 5, "ecosystem": 5, "power": [5, 20, 25, 133], "tool": [5, 15], "kind": [5, 32, 70], "markup": 5, "languag": [5, 80], "serv": [5, 15, 17, 27, 76], "purpos": [5, 15, 27, 33, 38, 125, 126, 127], "line": [5, 19, 33, 50, 63, 74, 128, 133], "wherea": [5, 71, 76, 123], "span": 5, "input": [5, 21, 27, 33, 50, 71, 82, 83, 122, 123, 124, 125, 126, 127, 128, 130, 132], "being": [5, 84, 87, 89, 90, 96, 97, 102, 103, 104, 106, 108, 110, 117, 125, 126, 127, 130], "At": [5, 75, 77, 79, 81, 82, 84, 86, 87, 96, 97, 99, 102, 104, 109, 110, 111, 116, 117, 124], "insert": [5, 130], "mydirectivenam": 5, "my": [5, 19], "work": [5, 9, 13, 17, 21, 32, 45, 60, 64, 71, 77, 79], "alreadi": [5, 18, 23, 59, 79, 134], "doesn": [5, 32, 132], "pre": [5, 11, 21, 33, 40, 76, 84, 108, 109, 110], "note": [5, 10, 11, 13, 14, 17, 19, 22, 29, 32, 38, 40, 45, 48, 59, 60, 61, 75, 76, 77, 79, 82, 84, 86, 87, 88, 89, 90, 95, 97, 98, 99, 100, 102, 103, 104, 105, 108, 111, 116, 118, 120, 134], "box": 5, "here": [5, 9, 10, 11, 12, 13, 14, 17, 18, 19, 23, 45, 48, 50, 64, 75, 77, 79, 82, 83, 84, 86, 87, 88, 89, 90, 92, 93, 95, 97, 98, 99, 100, 102, 104, 105, 106, 108, 109, 110, 116, 118, 123, 124, 128, 130], "built": [5, 48, 74], "see": [5, 9, 10, 11, 13, 14, 20, 21, 22, 25, 26, 40, 64, 74, 81, 85, 90, 108, 109, 122, 125, 126, 132], "document": [5, 15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 33, 40, 60, 122, 125, 133, 134], "less": [5, 19, 45, 50, 77, 119], "pattern": [5, 124, 128], "some": [5, 15, 16, 19, 21, 22, 25, 28, 32, 33, 38, 45, 50, 60, 63, 64, 74, 76, 77, 90, 91, 92, 93, 97, 108, 118, 125, 126, 132], "rolenam": 5, "again": [5, 79, 124, 128], "valid": [5, 64, 70, 76, 119], "doc": [5, 10, 21, 122, 125], "page": [5, 16, 19, 20, 24, 25, 69, 80, 101, 108, 109, 118, 120, 133], "rel": [5, 22, 28, 69, 74, 89, 132], "path": [5, 10, 21, 71, 134], "intro": 5, "cite": [5, 74], "store": [5, 92], "bibtex": 5, "holdgraf_evidence_2014": 5, "render": 5, "moreov": [5, 15, 19, 32, 63, 64, 74], "bibliographi": 5, "properli": [5, 9], "bib": 5, "look": [5, 19, 23, 33, 64, 134], "egw05": [5, 68], "damien": [5, 68], "ernst": [5, 68], "pierr": [5, 68], "geurt": [5, 68], "loui": [5, 68], "wehenkel": [5, 68], "tree": [5, 18, 19, 23, 38, 60, 68, 128], "batch": [5, 67, 68, 97, 102, 104, 119], "mode": [5, 68, 97, 102, 104, 129], "learn": [5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 25, 26, 28, 29, 32, 38, 40, 60, 64, 67, 68, 69, 70, 74, 75, 76, 80, 81, 82, 84, 85, 87, 88, 89, 90, 91, 92, 93, 95, 97, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 116, 117, 118, 123, 124, 128, 133], "journal": [5, 9, 10, 11, 12, 13, 14, 16, 19, 20, 21, 24, 25, 33, 36, 37, 40, 45, 48, 60, 68, 76, 77, 81, 91, 92, 93, 103, 120, 124], "hzal18": [5, 119], "tuoma": [5, 119], "haarnoja": [5, 119], "aurick": [5, 119], "zhou": [5, 50, 60, 63, 69, 80, 106, 109, 119], "pieter": [5, 119], "abbeel": [5, 119], "sergei": [5, 119], "levin": [5, 119], "soft": [5, 119], "actor": 5, "off": [5, 50, 63, 67, 69, 70, 71, 74, 85, 91, 92, 93, 98, 109, 119, 120, 133], "maximum": [5, 60, 77, 79, 83, 84, 87, 88, 101, 108, 110, 117, 118, 119], "entropi": [5, 15, 119], "deep": [5, 17, 19, 45, 60, 71, 77, 119, 120, 123, 132], "stochast": [5, 63, 74, 75, 76, 80, 81, 85, 89, 91, 92, 93, 108, 109, 118, 119], "intern": [5, 9, 10, 11, 12, 13, 14, 16, 19, 20, 25, 50, 63, 64, 69, 70, 74, 80, 81, 82, 83, 89, 90, 95, 96, 98, 99, 100, 101, 106, 108, 109, 111, 118, 119, 120, 133], "confer": [5, 9, 10, 11, 12, 13, 14, 17, 19, 50, 63, 64, 69, 70, 74, 80, 81, 82, 83, 89, 90, 95, 96, 98, 99, 100, 101, 103, 104, 106, 108, 109, 111, 118, 119, 120], "1861": [5, 119], "1870": [5, 119], "pmlr": [5, 19, 50, 63, 64, 69, 70, 74, 80, 81, 82, 89, 90, 95, 96, 98, 99, 100, 101, 103, 104, 106, 108, 109, 111, 118, 119], "2018": [5, 9, 10, 11, 12, 14, 15, 17, 45, 48, 50, 60, 69, 74, 75, 76, 77, 80, 84, 101, 103, 105, 109, 110, 116, 117, 119], "hk20": [5, 120], "yichun": [5, 10, 21, 120], "hu": [5, 120], "nathan": [5, 63, 120], "kallu": [5, 50, 63, 120], "dtr": [5, 59, 79, 120, 132], "adapt": [5, 17, 18, 19, 20, 23, 25, 48, 50, 59, 76, 79, 80, 84, 97, 98, 100, 102, 104, 105, 107, 109, 110, 119, 120], "regret": [5, 45, 75, 76, 77, 80, 85, 88, 89, 90, 97, 99, 102, 104, 109, 120], "02791": [5, 120], "jl16": [5, 63, 69], "nan": [5, 10, 21, 63, 67, 69, 128], "jiang": [5, 63, 67, 69, 74, 80, 109], "lihong": [5, 63, 69], "li": [5, 15, 33, 40, 50, 63, 69, 74, 81, 82, 83, 91, 92, 93, 95, 103, 105, 106, 109, 111, 119, 120], "doubli": [5, 6, 16, 19, 20, 25, 45, 50, 60, 64, 69, 74, 77, 91, 93], "robust": [5, 16, 19, 20, 25, 32, 45, 50, 60, 64, 69, 71, 74, 77, 88, 91, 93, 96, 97, 101, 102, 103, 104, 108, 123, 128, 132], "652": [5, 63, 69, 74], "661": [5, 63, 69, 74, 81, 109], "ku19": [5, 63], "masatoshi": [5, 63], "uehara": [5, 63], "effici": [5, 15, 16, 19, 21, 22, 25, 29, 63, 64, 67, 68, 69, 70, 72, 74, 83, 88, 89, 90, 95, 97, 99, 100, 101, 102, 103, 104, 106, 110, 111, 116, 117, 119, 128, 130], "break": [5, 63, 74], "curs": [5, 18, 23, 63, 64, 74], "horizon": [5, 32, 64, 71, 75, 76, 99, 100, 102, 119, 120, 132], "doubl": [5, 15, 17, 20, 25, 32, 74, 92, 119], "1909": [5, 63], "05850": [5, 63], "lvy19": [5, 67], "hoang": [5, 63, 67], "cameron": [5, 63, 67], "voloshin": [5, 63, 67], "yisong": [5, 63, 67], "yue": [5, 9, 10, 11, 12, 13, 14, 60, 63, 67], "1903": [5, 67], "08738": [5, 67], "lltz18": [5, 69], "qiang": [5, 63, 69], "liu": [5, 48, 63, 69, 74], "ziyang": [5, 63, 69], "tang": [5, 63, 69, 74], "dengyong": [5, 63, 69], "infinit": [5, 32, 64, 71, 75, 76, 81, 119, 120, 132], "advanc": [5, 9, 10, 11, 12, 13, 14, 19, 22, 50, 69, 74, 88, 89, 90, 100, 103, 104, 105, 133], "neural": [5, 9, 10, 11, 12, 13, 14, 17, 19, 50, 69, 74, 80, 88, 89, 90, 100, 103, 104, 105, 109], "process": [5, 9, 10, 11, 12, 13, 14, 17, 19, 38, 50, 63, 69, 74, 80, 88, 89, 90, 99, 100, 102, 103, 104, 105, 108, 109, 119, 120, 123, 132], "5356": [5, 69], "5366": [5, 69], "mgkulic21": [5, 120], "lingheng": [5, 120], "meng": [5, 120], "rob": [5, 120], "gorbet": [5, 120], "dana": [5, 120], "kuli": [5, 120], "\u0107": [5, 120], "memori": [5, 120, 130], "pomdp": [5, 32, 120, 132], "2021": [5, 9, 13, 16, 19, 20, 24, 25, 33, 36, 50, 64, 70, 71, 88, 89, 90, 91, 92, 93, 120], "ieee": [5, 120], "rsj": [5, 120], "robot": [5, 120], "iro": [5, 120], "5619": [5, 120], "5626": [5, 22, 120], "mbm": [5, 119], "16": [5, 10, 18, 21, 50, 60, 62, 119, 122, 125, 130, 131], "volodymyr": [5, 119], "mnih": [5, 119], "adria": [5, 119], "puigdomenech": [5, 119], "badia": [5, 119], "mehdi": [5, 119], "mirza": [5, 119], "alex": [5, 119], "grave": [5, 119], "timothi": [5, 119], "lillicrap": [5, 119], "tim": [5, 119], "harlei": [5, 119], "david": [5, 9, 10, 11, 12, 13, 14, 17, 19, 119], "silver": [5, 119], "korai": [5, 119], "kavukcuoglu": [5, 119], "asynchron": [5, 119], "1928": [5, 119], "1937": [5, 119], "mk": [5, 119], "15": [5, 10, 15, 18, 21, 23, 27, 40, 50, 59, 62, 77, 82, 83, 119, 125, 129, 130, 131], "andrei": [5, 119], "rusu": [5, 119], "joel": [5, 119], "veness": [5, 119], "marc": [5, 119], "g": [5, 9, 10, 11, 12, 13, 14, 17, 22, 27, 29, 45, 60, 63, 64, 67, 69, 71, 74, 75, 76, 80, 82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 103, 104, 105, 106, 109, 110, 119, 120, 128, 130, 132], "bellemar": [5, 119], "martin": [5, 76, 119], "riedmil": [5, 119], "andrea": [5, 119], "fidjeland": [5, 119], "georg": [5, 119], "ostrovski": [5, 119], "human": [5, 119], "518": [5, 119], "7540": [5, 119], "529": [5, 119], "533": [5, 91, 92, 93, 119], "pre00": [5, 69], "doina": [5, 69], "precup": [5, 69, 74], "elig": [5, 69, 74, 119], "trace": [5, 69, 74, 119], "comput": [5, 9, 13, 19, 69, 74, 81, 88, 97, 103, 104, 105, 106, 119], "scienc": [5, 9, 10, 11, 12, 13, 14, 15, 19, 22, 26, 28, 29, 45, 69, 74, 77, 97, 104, 132], "depart": [5, 69, 74], "faculti": [5, 69, 74], "public": [5, 23, 69, 74], "80": [5, 18, 45, 60, 62, 69, 74, 77], "2000": [5, 9, 10, 11, 12, 13, 14, 40, 59, 69, 74, 79, 110, 111, 116, 117], "put14": [5, 76], "l": [5, 24, 25, 50, 60, 63, 71, 74, 75, 76, 80, 81, 82, 83, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111, 123], "puterman": [5, 75, 76], "markov": [5, 9, 11, 13, 14, 69, 96, 119, 120, 132], "dynam": [5, 9, 15, 45, 48, 50, 59, 75, 76, 77, 79, 104, 106, 107, 108, 118, 119, 120, 123, 132], "program": [5, 40, 75, 76, 97, 103, 104, 106], "wilei": [5, 75, 76], "son": [5, 75, 76], "2014": [5, 9, 10, 11, 12, 13, 14, 45, 60, 75, 76, 77], "sla": [5, 119], "schulman": [5, 119], "michael": [5, 33, 119], "jordan": [5, 119], "philipp": [5, 119], "moritz": [5, 119], "trust": [5, 119], "region": [5, 119], "1889": [5, 119], "1897": [5, 119], "swd": [5, 119], "17": [5, 10, 21, 50, 60, 62, 97, 119, 122, 125, 129, 130], "filip": [5, 119], "wolski": [5, 119], "prafulla": [5, 119], "dhariw": [5, 119], "alec": [5, 119], "radford": [5, 119], "oleg": [5, 119], "klimov": [5, 119], "proxim": [5, 71, 119], "algorithm": [5, 9, 10, 12, 19, 20, 22, 25, 26, 28, 29, 48, 63, 68, 75, 76, 81, 82, 85, 88, 89, 90, 91, 92, 93, 95, 98, 99, 100, 105, 106, 119, 124, 128, 130, 132, 133], "1707": [5, 86, 108, 109, 118, 119], "06347": [5, 119], "2017": [5, 9, 10, 11, 12, 13, 14, 16, 19, 20, 23, 25, 37, 80, 86, 103, 104, 106, 108, 109, 118, 119, 120, 124], "swcs21": [5, 64], "chengchun": [5, 64, 119, 120], "shi": [5, 17, 19, 45, 50, 60, 64, 70, 71, 76, 77, 119, 120, 123], "runzh": [5, 64], "wan": [5, 64, 70, 88, 89, 96, 97, 101, 102, 103, 104, 108], "victor": [5, 17, 19, 64], "chernozhukov": [5, 15, 17, 64, 70], "rui": [5, 9, 10, 11, 12, 13, 14, 48, 60, 64, 119, 120], "song": [5, 9, 10, 11, 12, 13, 14, 45, 48, 50, 59, 60, 64, 71, 77, 79, 88, 89, 91, 92, 93, 96, 97, 101, 102, 103, 104, 108, 119, 120, 123], "deepli": [5, 70], "debias": [5, 15, 17, 70], "interv": [5, 18, 23, 50, 59, 60, 64, 75, 76, 91, 92, 93, 119, 120], "9580": [5, 64, 70], "9591": [5, 64, 70], "swl": [5, 76], "20": [5, 9, 10, 14, 18, 21, 23, 33, 45, 50, 59, 60, 62, 76, 102, 104, 105, 122, 125, 130, 131], "shi2020reinforc": [5, 76], "szls20": [5, 119], "sheng": [5, 119], "zhang": [5, 15, 80, 106, 109, 119], "wenbin": [5, 9, 10, 11, 12, 13, 14, 119], "lu": [5, 9, 10, 11, 12, 13, 14, 45, 50, 77, 91, 92, 93, 109, 119], "2001": [5, 27, 119, 125, 126, 127], "04515": [5, 119], "szy": [5, 120], "22": [5, 10, 18, 21, 23, 45, 59, 62, 119, 120], "jin": [5, 103, 105, 120], "zhu": [5, 9, 10, 11, 12, 13, 14, 50, 103, 105, 120], "shen": [5, 80, 91, 92, 93, 109, 120], "ye": [5, 9, 120, 132], "shikai": [5, 120], "luo": [5, 60, 120], "hongtu": [5, 120], "confid": [5, 16, 19, 20, 25, 59, 83, 85, 87, 91, 92, 93, 107, 117, 119, 120], "american": [5, 21, 36, 40, 48, 60, 91, 92, 93, 120, 128], "2022": [5, 18, 21, 23, 60, 89, 96, 97, 101, 102, 103, 104, 108, 120], "ss96": [5, 119], "satind": [5, 119], "singh": [5, 119], "richard": [5, 9, 10, 11, 12, 13, 14, 76, 119], "sutton": [5, 75, 76, 84, 109, 110, 119], "replac": [5, 10, 12, 45, 50, 60, 64, 69, 74, 119, 130], "123": [5, 10, 40, 119, 122, 124, 125, 126, 128], "158": [5, 21, 79, 119], "1996": [5, 119], "spa12": [5, 120], "matthij": [5, 120], "tj": [5, 77, 120], "spaan": [5, 120], "partial": [5, 10, 12, 24, 25, 27, 32, 45, 77, 99, 100, 102, 120, 125, 126, 127, 132], "state": [5, 6, 11, 13, 14, 19, 21, 22, 27, 28, 32, 33, 40, 60, 63, 64, 67, 68, 69, 71, 74, 75, 76, 119, 120, 122, 123, 124, 128, 130], "art": [5, 11, 13, 14, 19, 60, 63, 74, 120, 132], "387": [5, 21, 120], "414": [5, 120], "2012": [5, 21, 27, 48, 80, 103, 118, 120, 125, 126, 127, 128], "sut88": [5, 119], "tempor": [5, 9, 10, 69, 74, 119], "44": [5, 60, 62, 119, 125], "1988": [5, 16, 19, 20, 24, 25, 40, 97, 119], "sb18": [5, 76, 119], "andrew": [5, 33, 76, 119], "barto": [5, 75, 76, 84, 109, 110, 119], "mit": [5, 75, 76, 84, 109, 110, 119], "press": [5, 75, 76, 84, 86, 109, 110, 119], "tfl": [5, 63], "yihao": [5, 63], "feng": [5, 63], "bia": [5, 15, 21, 22, 23, 25, 32, 48, 50, 60, 63, 64, 67, 69, 74, 120, 125, 126, 132], "reduct": [5, 63, 120], "represent": [5, 9, 10, 11, 12, 13, 14, 48, 63], "tb16": [5, 63], "philip": [5, 63, 69], "thoma": [5, 63, 69, 74], "emma": [5, 63], "brunskil": [5, 63], "2139": [5, 63], "2148": [5, 63], "tho15": [5, 69], "safe": [5, 69, 74], "doctor": [5, 12, 32, 69, 129], "dissert": [5, 69], "univers": [5, 69, 86, 109], "massachusett": [5, 69], "amherst": [5, 69], "uhj19": [5, 63], "jiawei": [5, 63], "huang": [5, 63], "minimax": [5, 63, 64], "weight": [5, 9, 10, 11, 12, 13, 14, 15, 17, 18, 20, 21, 22, 23, 25, 29, 40, 63, 64, 69, 74, 101, 108, 118, 128, 132], "1910": [5, 63], "12809": [5, 63], "vhgs16": [5, 119], "hado": [5, 119], "van": [5, 16, 19, 20, 25, 37, 86, 102, 108, 109, 116, 117, 118, 119, 124], "hasselt": [5, 119], "arthur": [5, 119], "guez": [5, 119], "proceed": [5, 19, 21, 22, 26, 28, 29, 45, 50, 77, 81, 83, 109, 119, 128], "aaai": [5, 119], "artifici": [5, 19, 50, 80, 81, 82, 83, 89, 95, 96, 98, 109, 111, 119], "volum": [5, 119], "30": [5, 10, 21, 27, 40, 62, 119], "vljy19": [5, 63, 67], "empir": [5, 63, 67, 69, 76, 81, 85, 109], "1911": [5, 63, 67], "06854": [5, 63, 67], "zlpm17": [5, 120], "pengfei": [5, 120], "xin": [5, 120], "pascal": [5, 120], "poupart": [5, 120], "guanghui": [5, 120], "miao": [5, 120], "On": [5, 33, 48, 50, 120, 130], "1704": [5, 120], "07978": [5, 120], "If": [5, 15, 59, 77, 79, 88, 89, 95, 99, 102, 108, 118, 128, 133], "insid": 5, "jupytext": 5, "metadata": [5, 23, 88, 89], "run": [5, 10, 14, 119], "command": [5, 133], "init": 5, "print": [5, 11, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 40, 45, 59, 62, 77, 79, 124, 125, 126, 128, 130, 131, 134], "default": [5, 9, 11, 59, 60, 82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 119, 130, 131, 133], "kernel": [5, 18, 19, 20, 23, 25, 32, 48, 50, 63, 74, 75, 76, 119, 132, 134], "output": [5, 11, 17, 50, 123, 130], "rest": [5, 6, 10, 12, 17, 38, 40, 81, 89, 91, 92, 93, 125, 126, 130], "nb": 5, "r": [6, 10, 12, 15, 16, 17, 18, 19, 21, 22, 23, 26, 28, 29, 32, 33, 38, 45, 50, 59, 60, 61, 63, 69, 70, 71, 74, 75, 76, 77, 78, 79, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 116, 117, 118, 119, 122, 123, 124, 125, 128, 130, 131, 132], "s_i": [6, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 29, 33, 38, 132], "a_i": [6, 15, 17, 18, 19, 20, 21, 23, 24, 25, 48, 50, 60, 61, 91, 92, 93, 132], "r_i": [6, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 29, 45, 61, 77, 78, 91, 92, 93, 132], "equival": [6, 9, 10, 11, 12, 13, 14, 48, 64, 80, 85, 109], "pearl": [6, 9, 10, 11, 12, 13, 14, 21], "spirt": [6, 9, 10, 11, 12, 13, 14], "mathemat": [6, 10, 12, 45, 77, 101, 108, 118], "physic": [6, 10, 12, 21, 132], "hold": [6, 10, 12, 21, 32, 69, 74, 75, 76], "constant": [6, 10, 12, 22, 28, 48], "unchang": [6, 10, 12], "regress": [6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 22, 24, 25, 28, 29, 40, 45, 59, 60, 67, 69, 74, 77, 79, 97, 124, 128], "propens": [6, 12, 15, 16, 17, 20, 21, 22, 24, 25, 29, 33, 45, 50, 60, 69, 74, 77], "score": [6, 9, 12, 15, 16, 17, 20, 21, 22, 24, 25, 27, 29, 33, 45, 50, 60, 69, 74, 77, 125, 126, 127, 128, 130, 132], "roust": 6, "introduc": [6, 15, 17, 18, 19, 20, 21, 22, 23, 25, 26, 29, 33, 38, 45, 63, 64, 69, 70, 71, 74, 75, 76, 77, 79, 80, 81, 87, 88, 90, 91, 92, 93, 96, 103, 106, 109, 117, 119, 120, 132, 133], "cel": [6, 16, 17, 20, 21, 24, 32, 33, 71, 130, 134], "detail": [6, 10, 12, 15, 16, 17, 19, 20, 22, 25, 29, 32, 38, 40, 61, 64, 85, 109, 128, 132, 133], "hte": [6, 15, 16, 17, 18, 20, 22, 23, 24, 25, 26, 28, 29, 32, 38, 125, 126], "captur": [6, 9, 17, 18, 22, 23, 50, 71, 92, 93], "heterogenieti": 6, "quit": [6, 17, 19, 22, 69, 74, 132], "few": [6, 19, 63, 74, 76, 81, 85, 89, 101, 109, 132], "deal": [6, 32, 40, 97, 98, 102, 104, 107, 132], "reli": [9, 12, 13, 63, 74], "locat": [9, 12], "reward": [9, 12, 15, 19, 21, 22, 23, 25, 27, 32, 40, 48, 59, 60, 61, 69, 71, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 116, 117, 118, 119, 122, 123, 124, 128, 129, 130, 131, 132], "conveni": [9, 12], "violat": [9, 12, 32, 64], "emerg": [9, 12], "basic": [9, 15, 16, 22, 25, 26, 40, 45, 99, 100, 102, 132], "wai": [9, 22, 24, 25, 29, 60, 63, 64, 67, 68, 69, 70, 71, 72, 74, 79, 110, 111, 116, 117, 119], "mathcal": [9, 10, 11, 12, 13, 14, 21, 32, 33, 45, 50, 63, 64, 69, 74, 75, 76, 77, 82, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 116, 117, 118, 119, 130, 132], "mathbf": [9, 10, 11, 12, 13, 14], "z": [9, 10, 11, 12, 13, 14, 16, 17, 19, 25, 71, 74, 86, 95, 96, 98, 99, 101, 108, 109, 116, 117, 118, 123], "node": [9, 11, 12, 13, 14, 132], "edg": [9, 10, 11, 12, 13, 14], "said": [9, 11, 12, 13, 14], "parent": [9, 11, 12, 13, 14, 133], "z_j": [9, 11, 12, 13, 14], "let": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 28, 29, 50, 59, 63, 64, 69, 71, 74, 75, 76, 78, 81, 85, 89, 96, 101, 103, 108, 109, 118, 119], "pa_": [9, 11, 12, 13, 14], "cycl": [9, 11, 12, 13, 14], "acycl": [9, 10, 11, 12, 13, 14], "dag": [9, 10, 11, 12, 13, 14, 125, 126], "character": [9, 10, 11, 12, 13, 14, 68, 75, 92, 93, 95, 97, 103, 108, 118], "z_1": [9, 11, 12, 13, 14], "z_2": [9, 11, 12, 13, 14], "z_d": [9, 11, 12, 13, 14], "rightarrow": [9, 11, 12, 13, 14, 20, 21, 25, 32], "mean": [9, 11, 12, 13, 14, 19, 32, 50, 59, 60, 62, 63, 69, 74, 76, 77, 79, 82, 84, 86, 87, 88, 90, 91, 92, 93, 97, 99, 100, 101, 102, 104, 105, 109, 110, 111, 116, 117, 119, 122, 125, 130, 132], "propos": [9, 10, 13, 14, 17, 21, 32, 48, 50, 60, 63, 64, 69, 70, 71, 74, 77, 91, 92, 93, 95, 123, 124, 128, 132], "plusibl": 9, "up": [9, 13, 18, 20, 23, 25, 76, 80, 88, 90, 119, 132], "markovian": 9, "unless": [9, 14], "certain": [9, 17, 60, 76, 120], "assumpt": [9, 11, 13, 14, 16, 17, 19, 21, 22, 25, 26, 32, 40, 48, 64, 69, 71, 74, 76, 80, 81, 92, 96, 97, 102, 104, 119, 120, 132], "specifi": [9, 10, 11, 15, 18, 23, 24, 25, 45, 48, 59, 61, 64, 76, 77, 79, 92, 109, 110, 111, 116, 124, 128, 129], "type": [9, 15, 32, 38, 61, 63, 64, 67, 68, 69, 70, 74, 81, 85, 86, 89, 91, 92, 103, 104, 105, 106, 107, 109, 128, 129, 132, 133], "focus": [9, 19, 32, 60, 69, 85, 96, 108, 109, 118, 119, 132], "local": [9, 14, 18, 19, 20, 22, 23, 25, 131, 133], "independ": [9, 10, 11, 12, 13, 14, 15, 20, 21, 25, 32, 60, 61, 76, 99, 119], "skeleton": [9, 132], "orient": [9, 10, 14], "pc": [9, 10, 11, 12, 13, 132], "et": [9, 11, 12, 14, 15, 16, 21, 25, 36, 48, 60, 63, 64, 69, 70, 74, 76, 84, 87, 91, 92, 93, 95, 99, 109, 110, 117, 119], "al": [9, 11, 12, 14, 15, 16, 21, 25, 36, 48, 60, 63, 64, 69, 70, 74, 76, 84, 87, 91, 92, 93, 95, 99, 109, 110, 117, 119], "kalisch": [9, 10, 11, 12, 13, 14], "b\u00fchlmann": [9, 10, 11, 12, 13, 14], "easi": [9, 14, 19, 22, 24, 25, 26, 59, 67, 69, 79, 84, 103], "shah": [9, 10, 11, 12, 13, 14], "peter": [9, 10, 11, 12, 13, 14, 16, 19, 20, 24, 25], "second": [9, 15, 21, 22, 28, 45, 50, 64, 77, 95, 97, 98, 119, 130, 132], "ica": [9, 13, 14], "lingam": [9, 13, 14, 132], "shimizu": [9, 10, 11, 12, 13, 14], "2006": [9, 10, 11, 12, 13, 14, 16, 19, 20, 25, 98], "cam": [9, 10, 11, 12, 13, 14], "greedi": [9, 10, 11, 12, 13, 14, 85, 91, 92, 93, 110, 119, 131, 132], "search": [9, 10, 11, 12, 13, 14, 96, 119], "ge": [9, 32, 63, 64, 69, 71, 74, 75, 76, 88, 89, 96, 97, 101, 102, 103, 104, 108, 119, 123], "chicker": [9, 10, 11, 12, 13, 14], "2002": [9, 10, 11, 12, 13, 14, 81, 84, 87, 109, 110, 117], "fge": 9, "ramsei": [9, 10, 11, 12, 13, 14], "bayesian": [9, 10, 11, 12, 13, 14, 88, 89, 97, 98, 100, 102, 104], "zheng": [9, 10, 11, 12, 14, 37, 124], "open": [9, 10, 27, 71, 82, 83, 122, 123, 124, 125, 126, 127, 129, 130, 133], "construct": [9, 10, 11, 12, 13, 14, 16, 20, 21, 22, 25, 26, 33, 63, 64, 67, 69, 70, 71, 74, 88, 119], "notear": [9, 11, 14, 125, 126, 132], "vae": [9, 13], "parameter": [9, 13, 88, 90, 97, 102, 104, 119], "network": [9, 10, 11, 12, 13, 14, 17, 19, 50, 60], "yu": [9, 10, 11, 12, 13, 14, 19, 22, 26, 28, 29, 48, 60], "friendli": [9, 13], "gnn": [9, 10, 11, 12, 13, 14], "chen": [9, 10, 11, 12, 13, 14, 91, 92, 93, 100, 101, 108, 118], "cai": [9, 11, 12, 13, 14, 50, 91, 92, 93], "cut": [9, 13], "support": [9, 20, 25, 71, 76, 81, 86, 87, 90, 119, 129, 132], "train": [9, 10, 16, 17, 18, 19, 20, 23, 24, 25, 45, 48, 59, 62, 77, 79, 82, 83, 95, 124, 128, 130, 131, 132], "free": [9, 67, 132], "gaussian": [9, 10, 12, 13, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 99, 100, 102, 111, 116, 131, 132], "o": [9, 10, 11, 12, 13, 14, 15, 17, 132], "max": [9, 50, 59, 60, 63, 74, 79, 129, 130, 132], "adjac": [9, 10, 11, 13, 14, 132], "b_": [9, 11, 13, 14], "leq": [9, 11, 13, 14, 32, 33, 40, 91, 92, 93, 101, 103, 132], "matrix": [9, 10, 11, 13, 14, 21, 40, 71, 82, 86, 88, 97, 99, 100, 102, 104, 105, 108, 123, 125, 126, 128], "otherwis": [9, 11, 13, 14, 59, 61, 79, 84, 90, 96, 110, 133], "nest": [9, 11, 13, 14, 45, 77, 129], "faith": [9, 11, 13, 14], "suffici": [9, 11, 13, 14, 17, 63, 69], "pair": [9, 11, 13, 14, 63, 64, 69, 74, 76, 82, 86, 97, 98, 100, 104, 105, 106, 111, 116], "epsilon": [9, 11, 13, 14, 17, 24, 25, 85, 91, 92, 93, 110, 119, 132], "label": [9, 10, 11, 13, 14, 40, 48, 50, 63, 64, 67, 69, 70, 74, 75, 76, 88, 91, 92, 93, 96, 97, 102, 103, 104, 108, 118, 119, 128], "lsem_x": [9, 11, 13, 14], "jointli": [9, 11, 13, 14, 45, 77], "error": [9, 11, 13, 14, 19, 45, 59, 77, 79, 124, 128, 129], "plu": [9, 11, 13], "n_i": [9, 11, 13], "anm": [9, 11, 13], "f_i": [9, 11, 13], "special": [9, 11, 13, 32, 132], "handl": [9, 11, 13, 14, 19, 22, 50, 60, 69, 74, 109, 122, 125, 129, 132], "version": [9, 11, 13, 18, 23, 63, 64, 69, 71, 74, 81, 84, 85, 103, 109, 110, 120], "f_2": [9, 13], "f_1": [9, 13], "nonlinear": [9, 13, 22, 28], "transform": [9, 13, 45], "fisher": [9, 14], "implement": [9, 11, 13, 14, 15, 18, 19, 22, 23, 26, 40, 48, 50, 59, 60, 67, 69, 79, 82, 83, 84, 86, 87, 88, 90, 91, 92, 93, 95, 97, 98, 99, 100, 102, 104, 105, 106, 130, 132, 133], "http": [9, 10, 11, 13, 14, 17, 21, 23, 27, 33, 40, 61, 122, 125, 133, 134], "github": [9, 10, 11, 13, 14, 17, 40, 71, 131, 133], "com": [9, 10, 11, 13, 14, 17, 27, 33, 40, 61, 133], "bd2kccd": [9, 14], "highli": [9, 14], "java": [9, 14], "blob": [9, 14, 40], "20pc": [9, 14], "20in": [9, 14], "20action": [9, 14], "recov": [9, 11], "hyper": [9, 11, 87, 123], "cdt15": [9, 11], "xunzheng": [9, 13], "incorpor": [9, 10, 19, 84, 86, 109, 110], "auto": [9, 130], "encod": [9, 129], "modifi": [9, 12, 17, 82, 86, 97, 98, 99, 100, 102, 104, 105, 111, 116, 123], "smooth": [9, 50], "evid": 9, "lower": [9, 11, 13, 14, 15, 60, 63, 69, 74, 92, 99, 124, 128], "bound": [9, 19, 20, 21, 25, 63, 64, 74, 75, 76, 83, 85, 87, 90, 91, 92, 93, 99, 107, 117, 128], "loss": [9, 10, 17, 19, 40, 75, 76, 132], "fishmoon1234": 9, "pytorch": [9, 10], "paszk": 9, "anoc": [9, 11, 12, 13, 14], "cvae": 9, "constrain": [9, 10, 11, 12, 13, 14], "novel": [9, 10, 17, 71, 74], "identif": [9, 10, 11, 12, 13, 14, 132, 133], "publicli": [9, 10, 125, 126, 127], "anonym": [9, 10, 27, 125, 126, 127], "granger": 9, "1969": 9, "entner": 9, "hoyer": [9, 10, 11, 12, 13, 14], "2010": [9, 21, 40, 81, 109, 128], "momentari": 9, "mci": 9, "rung": 9, "autoregress": 9, "hyv\u00e4rinen": [9, 10, 11, 12, 13, 14], "timino": 9, "2013": [9, 11, 13, 14, 15, 22, 81, 82, 100, 101, 108, 109, 111, 118], "dynotear": 9, "pamfil": 9, "contemporan": 9, "intra": [9, 88], "slice": [9, 21, 122, 125], "lag": [9, 120, 122, 125], "interslic": 9, "nt": [9, 21, 63, 64, 70, 71, 74, 123, 128], "sun": [9, 60], "nonparametr": [9, 19, 74], "along": [9, 33, 71, 80, 132], "properti": [9, 19, 60, 106, 116], "judea": [9, 10, 11, 12, 13, 14, 21], "survei": [9, 10, 11, 12, 13, 14, 81, 85, 101, 103, 109, 133], "96": [9, 10, 11, 12, 13, 14, 40, 45, 59, 62, 77, 116, 117, 122, 123, 125], "146": [9, 10, 11, 12, 13, 14, 40, 85, 122, 124, 129], "2009": [9, 10, 11, 12, 13, 14], "pater": [9, 10, 11, 12, 13, 14], "clark": [9, 10, 11, 12, 13, 14], "glymour": [9, 10, 11, 12, 13, 14], "schein": [9, 10, 11, 12, 13, 14], "stuart": [9, 10, 11, 12, 13, 14], "kauffman": [9, 10, 11, 12, 13, 14], "valerio": [9, 10, 11, 12, 13, 14], "aimal": [9, 10, 11, 12, 13, 14], "frank": [9, 10, 11, 12, 13, 14], "wimberli": [9, 10, 11, 12, 13, 14], "gene": [9, 10, 11, 12, 13, 14], "express": [9, 10, 11, 12, 13, 14, 18, 22, 23, 33, 63, 74, 80, 86], "microarrai": [9, 10, 11, 12, 13, 14], "marku": [9, 10, 11, 12, 13, 14], "8": [9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 33, 40, 45, 59, 60, 62, 64, 69, 70, 74, 79, 81, 109, 111, 116, 122, 123, 124, 125, 126, 129, 131], "mar": [9, 10, 11, 12, 13, 14], "613": [9, 10, 11, 12, 13, 14], "636": [9, 10, 11, 12, 13, 14], "rajen": [9, 10, 11, 12, 13, 14], "jona": [9, 10, 11, 12, 13, 14], "hard": [9, 10, 11, 12, 13, 14], "generalis": [9, 10, 11, 12, 13, 14], "1804": [9, 10, 11, 12, 13, 14], "07203": [9, 10, 11, 12, 13, 14], "shohei": [9, 10, 11, 12, 13, 14], "patrik": [9, 10, 11, 12, 13, 14], "aapo": [9, 10, 11, 12, 13, 14], "antti": [9, 10, 11, 12, 13, 14], "kerminen": [9, 10, 11, 12, 13, 14], "7": [9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 40, 50, 59, 60, 62, 63, 64, 67, 68, 69, 70, 71, 72, 74, 81, 96, 103, 109, 110, 111, 116, 117, 122, 123, 124, 125, 126, 129, 130, 131], "oct": [9, 10, 11, 12, 13, 14], "2003": [9, 10, 11, 12, 13, 14, 45, 77], "2030": [9, 10, 11, 12, 13, 14], "6": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 26, 27, 28, 29, 40, 45, 48, 50, 59, 60, 62, 63, 64, 67, 68, 69, 70, 71, 72, 74, 81, 103, 108, 109, 110, 111, 116, 117, 122, 123, 124, 125, 126, 128, 129, 130, 131], "ernest": [9, 10, 11, 12, 13, 14], "penal": [9, 10, 11, 12, 13, 14, 19, 48, 59, 79], "annal": [9, 10, 11, 12, 13, 14, 18, 19, 21, 23, 35, 39, 41, 42, 43, 45, 77, 128], "42": [9, 10, 11, 12, 13, 14, 60, 62, 82, 83, 84, 86, 87, 88, 90, 110, 111, 116, 117, 131], "2526": [9, 10, 11, 12, 13, 14], "2556": [9, 10, 11, 12, 13, 14], "maxwel": [9, 10, 11, 12, 13, 14], "nov": [9, 10, 11, 12, 13, 14, 33], "507": [9, 10, 11, 12, 13, 14, 98], "554": [9, 10, 11, 12, 13, 14], "joseph": [9, 10, 11, 12, 13, 14], "madelyn": [9, 10, 11, 12, 13, 14], "ruben": [9, 10, 11, 12, 13, 14], "sanchez": [9, 10, 11, 12, 13, 14], "romero": [9, 10, 11, 12, 13, 14], "magnet": [9, 10, 11, 12, 13, 14], "reson": [9, 10, 11, 12, 13, 14], "imag": [9, 10, 11, 12, 13, 14, 17, 21, 33], "analyt": [9, 10, 11, 12, 13, 14, 61], "121": [9, 10, 11, 12, 13, 14, 27, 40], "129": [9, 10, 11, 12, 13, 14, 40, 122, 124, 125, 126, 128], "xun": [9, 10, 11, 12, 13, 14], "bryon": [9, 10, 11, 12, 13, 14], "aragam": [9, 10, 11, 12, 13, 14], "pradeep": [9, 10, 11, 12, 13, 14], "ravikumar": [9, 10, 11, 12, 13, 14], "eric": [9, 10, 11, 12, 13, 14, 21], "xing": [9, 10, 11, 12, 13, 14], "tear": [9, 10, 11, 12, 13, 14], "pp": [9, 10, 11, 12, 13, 14, 21, 45, 50, 77, 80, 81, 82, 83, 89, 90, 95, 96, 98, 99, 100, 101, 103, 104, 106, 108, 111, 128], "9472": [9, 10, 11, 12, 13, 14], "9483": [9, 10, 11, 12, 13, 14], "10": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 33, 45, 48, 50, 59, 60, 62, 71, 79, 83, 97, 99, 100, 102, 104, 109, 122, 123, 124, 125, 126, 128, 129], "jie": [9, 10, 11, 12, 13, 14], "tian": [9, 10, 11, 12, 13, 14], "gao": [9, 10, 11, 12, 13, 14], "mo": [9, 10, 11, 12, 13, 14], "1904": [9, 10, 11, 12, 13, 14, 81, 85, 109], "10098": [9, 10, 11, 12, 13, 14], "11": [9, 10, 11, 12, 13, 14, 17, 21, 24, 26, 27, 28, 29, 33, 45, 59, 60, 62, 71, 74, 79, 82, 83, 109, 116, 117, 122, 123, 124, 125, 128, 130], "shengyu": [9, 10, 11, 12, 13, 14], "zhitang": [9, 10, 11, 12, 13, 14], "1906": [9, 10, 11, 12, 13, 14], "04477": [9, 10, 11, 12, 13, 14], "hengrui": [9, 10, 11, 12, 13, 14], "demand": [10, 40], "kei": [10, 17, 27, 33, 48, 50, 69, 96, 122, 126, 129, 130, 132, 133], "factor": [10, 69, 75, 76, 96, 97, 98, 99, 100, 102, 103, 108], "guid": [10, 83, 86, 88, 90, 109, 111, 116, 119], "downstream": 10, "task": [10, 64, 67, 69, 74, 76, 80, 85, 89, 90, 109, 129], "m_1": [10, 12, 71], "m_2": [10, 12], "m_p": [10, 12], "dimens": [10, 12, 120], "give": [10, 15, 18, 23, 26, 28, 29, 75, 81, 85, 89, 109, 124, 128, 130], "te": [10, 12, 21, 71, 123, 124, 128], "de": [10, 12, 21, 64, 80, 109], "ie": [10, 12, 21], "equat": [10, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 32, 33, 40, 50, 60, 63, 64, 67, 68, 69, 70, 74, 75, 77, 87, 88, 90, 91, 92, 93, 95, 96, 97, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 117, 118, 119], "split": [10, 12, 15, 18, 23, 33, 63, 64, 74, 95, 96, 97, 101, 102, 104, 108, 118, 119, 125, 126, 129, 130], "remov": [10, 11, 12, 48, 71, 82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 130], "citet": [10, 70, 74], "pearl2009caus": 10, "dm": [10, 15, 21, 63, 67, 74], "dm_i": 10, "big": [10, 15, 16, 17, 18, 20, 21, 23, 25, 32, 33, 45, 48, 50, 63, 64, 67, 68, 69, 74, 75, 77, 88, 92, 95, 104, 119], "m_i": [10, 21], "_i": [10, 22, 29, 40, 45, 60, 61, 82, 91, 92, 93, 97, 102, 104, 108, 111, 118, 130], "omega_i": 10, "setminu": 10, "except": [10, 40, 77, 130], "im": [10, 71, 123], "def_im": 10, "im_i": 10, "firstli": [10, 87, 109, 117], "sourc": [10, 133], "degre": [10, 11, 13, 14, 19, 20, 25, 40, 95], "freedom": 10, "smaller": [10, 22, 25, 125, 126], "decompos": [10, 64, 71, 97, 102, 104, 123], "compon": [10, 11, 59, 63, 74, 75, 123, 124, 128, 132], "row": [10, 15, 16, 17, 18, 20, 21, 22, 24, 27, 28, 29, 33, 40, 60, 80, 122, 125, 129, 130, 131], "compos": 10, "investig": [10, 33, 81], "spread": [10, 21], "major": [10, 21, 59, 71, 81, 86, 97, 102, 104, 109, 111, 116, 119, 123], "panda": [10, 11, 15, 16, 17, 18, 20, 21, 23, 24, 26, 27, 28, 29, 33, 40, 62, 71, 77, 79, 122, 123, 124, 125, 126, 128, 129, 130, 134], "pd": [10, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 33, 40, 45, 59, 60, 62, 71, 77, 79, 122, 123, 124, 125, 126, 128, 129, 130, 131, 134], "os": [10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 33, 40, 50, 60, 63, 64, 67, 68, 69, 70, 71, 72, 74, 110, 111, 116, 117, 125, 126, 131, 134], "pickl": [10, 17, 27, 50, 71, 82, 83, 122, 123, 124, 125, 126, 129, 130, 134], "data_typ": 10, "realdata": 10, "real_data_fil": 10, "covid19": [10, 33], "pkl": 10, "epoch": [10, 103, 104, 105, 106, 107], "100": [10, 15, 40, 45, 50, 60, 62, 77, 88, 102, 104, 105, 109, 122, 123, 125, 126, 128, 131], "node_numb": 10, "32": [10, 16, 19, 20, 21, 25, 40, 62, 81, 103, 104, 105, 125, 126], "sample_s": 10, "38": [10, 18, 21, 23, 33, 40, 45, 60, 62], "batch_siz": [10, 17], "rep_numb": 10, "namespac": 10, "simu_g_fil": 10, "s1_trueg": 10, "graph_degre": 10, "a_typ": [10, 11, 13, 14], "seed": [10, 11, 13, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 48, 50, 60, 62, 71, 82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 107, 109, 110, 111, 116, 117, 123, 125, 126, 128, 130, 131], "2333": [10, 50], "k_max_it": 10, "original_lr": 10, "003": [10, 45], "torch": 10, "lr_schedul": 10, "138": [10, 40, 125, 126, 128], "userwarn": [10, 128], "detect": [10, 50, 82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 130], "step": [10, 16, 17, 20, 22, 24, 25, 26, 28, 29, 40, 48, 60, 62, 63, 64, 69, 74, 78, 91, 92, 93, 119, 130], "later": [10, 15, 27, 32, 45, 63, 64, 67, 68, 69, 70, 72, 74, 77, 110, 111, 116, 117], "opposit": [10, 48], "failur": [10, 27, 125, 126, 127, 128], "skip": 10, "schedul": [10, 88, 90, 104, 107], "org": [10, 21, 23, 122, 125, 134], "html": [10, 21, 61, 122, 125, 133], "warn": [10, 16, 17, 20, 24, 45, 50, 59, 60, 62, 77, 79, 82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 128, 129, 130], "best": [10, 17, 21, 50, 59, 71, 79, 81, 108, 123, 128, 130], "elbo": 10, "2604245517164468": 10, "nll": 10, "001169236510424758": 10, "mse": 10, "307728190154737e": 10, "05": [10, 15, 18, 23, 33, 60, 124], "seaborn": [10, 130, 131], "sn": [10, 130, 131], "matplotlib": [10, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 40, 125, 126, 129, 130], "pyplot": [10, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 40, 125, 126, 129, 130], "plt": [10, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 40, 60, 122, 125, 126, 129, 130, 131], "load": [10, 27, 33, 40, 82, 83, 123, 124, 129, 130], "join": [10, 60, 134], "anoce_result": 10, "rb": [10, 71, 82, 83, 123, 124, 129, 130], "calcul": [10, 17, 19, 33, 40, 63, 67, 74, 77, 79, 82, 83, 84, 87, 88, 90, 104, 106, 109, 110, 111, 117, 123, 124, 128, 130], "calculate_effect": 10, "plot": [10, 11, 13, 14, 40, 125, 126], "covid": [10, 21], "matshow": 10, "cmap": 10, "bwr": 10, "vmin": 10, "vmax": 10, "fig1": 10, "gcf": 10, "colorbar": 10, "df": [10, 11, 13, 14, 21], "datafram": [10, 14, 21, 22, 23, 45, 59, 60, 62, 77, 79, 122, 124, 125, 128, 129, 130, 131], "arrai": [10, 15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 45, 48, 50, 60, 62, 71, 77, 95, 97, 98, 99, 100, 102, 104, 105, 106, 107, 110, 111, 116, 117, 122, 123, 124, 125, 126, 128, 129, 130, 131, 132], "read_csv": [10, 15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 33, 40, 71, 77, 79, 122, 123, 124, 125, 126, 128, 129, 130, 134], "csv": [10, 15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 33, 40, 71, 122, 123, 124, 125, 126, 128, 130, 134], "column": [10, 14, 15, 16, 17, 18, 20, 21, 22, 24, 26, 27, 28, 29, 33, 40, 45, 60, 62, 95, 97, 99, 102, 104, 105, 122, 124, 125, 126, 128, 129, 130, 131], "31": [10, 11, 13, 21, 40, 59, 62, 74], "round": [10, 11, 13, 14, 16, 17, 18, 20, 21, 24, 26, 28, 29, 33, 45, 59, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 110, 111, 116, 117, 118, 130], "reshap": [10, 11, 13, 14, 17, 21, 22, 26, 50, 71, 122, 123, 128, 131], "shenzhen": [10, 21], "198": [10, 27, 77, 128], "027": 10, "guangzhou": [10, 21], "099": 10, "059": 10, "beij": [10, 21], "036": [10, 16], "039": [10, 16, 130], "chengdu": [10, 21], "081": [10, 21, 85], "019": [10, 24], "shanghai": [10, 21], "016": [10, 21], "063": [10, 130], "dongguan": [10, 21], "066": 10, "023": [10, 130], "suzhou": [10, 21], "064": 10, "xian": [10, 21], "051": 10, "042": 10, "hangzhou": [10, 21], "097": 10, "083": [10, 21], "zhengzhou": [10, 21], "069": 10, "062": [10, 21, 130], "chongq": [10, 21], "021": 10, "changsha": [10, 21], "073": 10, "034": 10, "nanj": [10, 21], "094": 10, "044": 10, "13": [10, 11, 13, 14, 18, 21, 23, 27, 33, 62, 77, 82, 83, 109, 124, 125, 130], "kunm": [10, 21], "006": [10, 62], "040": [10, 130], "14": [10, 11, 13, 14, 18, 21, 23, 27, 50, 62, 77, 82, 83, 122, 125, 130], "tianjin": [10, 21], "075": 10, "049": 10, "hefei": [10, 21], "020": [10, 24], "007": 10, "046": 10, "wenzhou": [10, 21], "302": 10, "030": [10, 24], "18": [10, 21, 40, 50, 60, 62, 81, 89, 109, 122, 129, 130], "nanchang": [10, 21], "050": 10, "004": [10, 62, 130], "zhoukou": [10, 21], "008": [10, 130], "013": 10, "fuyang": [10, 21], "21": [10, 18, 21, 23, 33, 45, 59, 60, 62, 97, 126], "shangqiu": [10, 21], "yueyang": [10, 21], "002": [10, 21, 104], "012": 10, "23": [10, 21, 23, 33, 45, 59, 62, 124], "zhumadian": [10, 21], "024": [10, 24], "24": [10, 21, 33, 59, 62, 126, 129], "changd": [10, 21], "001": [10, 21, 130], "25": [10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 23, 24, 27, 28, 29, 33, 59, 60, 62, 79, 82, 83, 88, 125, 126, 129, 130, 131], "nanyang": [10, 21], "029": [10, 24, 130], "26": [10, 21, 48, 62], "022": 10, "27": [10, 21, 62], "xinyang": [10, 21], "031": [10, 24], "28": [10, 21, 33, 60, 62, 100, 129], "anq": [10, 21], "009": 10, "29": [10, 21, 40, 45, 60, 62, 77], "jiujiang": [10, 21], "017": [10, 21, 24], "mt_data": 10, "zero": [10, 11, 13, 14, 15, 21, 22, 26, 27, 45, 50, 60, 63, 74, 77, 82, 88, 95, 97, 98, 99, 100, 102, 107, 110, 111, 116, 117, 129, 130, 131], "fig": [10, 132], "figur": [10, 17, 33, 40, 131, 132], "figsiz": [10, 40], "ax": [10, 131], "add_subplot": 10, "cax": 10, "shrink": 10, "horizont": 10, "cities_nam": 10, "set_xtick": 10, "arang": [10, 20], "len": [10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 24, 26, 28, 29, 33, 40, 45, 48, 50, 59, 60, 71, 77, 79, 81, 85, 89, 90, 108, 109, 122, 123, 124, 125, 126, 128, 129, 130, 131], "set_ytick": 10, "set_xticklabel": 10, "rotat": 10, "90": [10, 60, 62], "set_yticklabel": 10, "linear": [10, 12, 19, 24, 25, 48, 81, 82, 83, 91, 92, 93, 95, 99, 102, 103, 104, 105, 106, 109, 111, 124, 128], "addit": [10, 12, 14, 22, 63, 64, 69, 70, 74, 75, 76, 90, 130], "graphic": [10, 12], "uniqu": [11, 13, 14, 50, 67, 68, 75, 76, 119, 122, 126, 129], "invari": [11, 13, 14, 132], "trasform": [11, 13, 14], "disadvantag": [11, 13, 14, 82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106], "knowledg": [11, 50, 81, 82, 86, 89, 90, 111, 116], "realiz": [11, 13, 14, 69, 86, 130], "underli": [11, 13, 14, 17, 19, 75, 76, 91, 120], "lsem": [11, 14, 125, 126], "g_j": [11, 13], "differenti": [11, 13], "argument": [11, 13, 64], "corollari": [11, 13], "threshold": 11, "synthetic_dataset": [11, 13, 14], "1234": [11, 13, 14], "300": [11, 13, 14, 18, 20, 50, 85], "ground_truth_g": [11, 13, 14], "simulate_random_dag": [11, 13, 14], "graph_typ": [11, 13, 14], "erdo": [11, 13, 14], "renyi": [11, 13, 14], "w_rang": [11, 13, 14], "c": [11, 13, 14, 15, 17, 18, 23, 45, 48, 50, 59, 60, 70, 71, 74, 77, 79, 80, 81, 82, 83, 84, 86, 87, 88, 89, 90, 95, 96, 97, 98, 99, 100, 102, 104, 105, 106, 107, 108, 109, 110, 111, 117, 118, 123, 129, 130, 131], "ones": [11, 13, 14, 15, 21, 22, 26, 45, 48, 60, 62, 71, 77, 86, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 116, 123, 128, 130, 131], "simulate_lsem": [11, 13, 14], "plot_net": [11, 13, 14, 125, 126], "nx": [11, 13, 14, 125, 126], "to_numpy_arrai": [11, 13, 14], "labels_nam": [11, 13, 14, 125, 126], "rang": [11, 13, 14, 21, 50, 59, 62, 71, 77, 79, 101, 123, 128, 129, 130, 131, 132], "modulenotfounderror": [11, 13, 14, 17, 18, 21, 25, 27, 50], "ipykernel_69022": 11, "2370726509": [11, 13, 14], "pip": [11, 14, 18, 23, 60, 133, 134], "instal": [11, 14, 18, 23, 60, 133, 134], "igraph": 11, "factor_analyz": 11, "directlingam": 11, "fit": [11, 15, 17, 18, 20, 21, 22, 23, 25, 26, 28, 29, 32, 40, 45, 59, 60, 62, 77, 79, 124, 125, 126, 128, 131], "adjacency_matrix_": 11, "ica_r": 11, "ab": [11, 13, 14, 131], "fdr": [11, 13, 14], "tpr": [11, 13, 14], "shd": [11, 13, 14], "count_accuraci": [11, 13, 14], "digraph": [11, 13, 14, 125, 126], "statsmodel": [11, 18, 23, 59, 60, 71, 79], "tsa": [11, 71], "tsa_model": [11, 71], "futurewarn": [11, 71], "int64index": [11, 71], "deprec": [11, 71], "futur": [11, 32, 71, 75, 76], "index": [11, 14, 17, 18, 21, 23, 24, 40, 50, 59, 69, 71, 79, 89, 96, 122, 124, 125, 126, 128, 129, 131, 133, 134], "dtype": [11, 21, 24, 45, 59, 62, 71, 79, 122, 124, 125, 126, 128, 129, 131], "instead": [11, 16, 17, 18, 20, 22, 23, 24, 26, 28, 29, 32, 59, 63, 69, 71, 74, 77, 79, 81, 88, 97, 102, 104, 119, 122, 125, 133], "to_datetim": [11, 71], "datetimeindex": [11, 71], "float64index": [11, 71], "67": [11, 13, 14, 40, 59, 62, 79, 80, 82, 83, 103, 106, 107, 109, 130], "prune": [11, 13, 14], "metric": [11, 13, 14, 48], "fals": [11, 13, 14, 18, 21, 23, 45, 59, 71, 82, 83, 88, 90, 104, 105, 106, 107, 110, 122, 123, 124, 125, 128, 130, 131], "ham": [11, 13, 14], "distanc": [11, 13, 14], "smallest": [11, 13, 14, 22, 50], "revers": [11, 13, 14, 125, 126], "account": [11, 13, 14, 21, 71, 79, 86, 88, 96, 97, 101, 102, 103, 104, 123, 132], "neg": [11, 13, 14, 21, 45, 48, 59, 71, 77, 79, 123, 125, 126, 128], "better": [11, 13, 14, 17, 18, 22, 23, 28, 29, 45, 59, 61, 63, 77, 79, 84, 87, 124, 125, 126, 128], "00": [11, 13, 14, 18, 23, 33, 45, 59, 60, 62, 77, 124, 128, 131], "50": [11, 13, 14, 21, 27, 33, 50, 59, 62, 71, 123, 128, 129, 130], "62": [11, 13, 14, 27, 62, 77, 128], "daggnn": [11, 13, 14], "equal": [11, 13, 14, 50, 63, 64, 69, 74, 75, 96, 99, 100, 102, 103], "varianc": [11, 13, 14, 22, 23, 25, 50, 63, 64, 69, 70, 74, 82, 86, 111, 116, 119], "biometrika": [11, 13, 14, 15, 16, 19, 20, 24, 25], "101": [11, 13, 14, 21, 40, 60], "219": [11, 13, 14, 123], "228": [11, 13, 14, 22, 23], "mooij": [11, 13, 14], "janz": [11, 13, 14], "sch\u00f6lkopf": [11, 13, 14], "cma": 12, "dissect": 12, "transmit": 12, "comprehens": [12, 27, 125, 126, 127], "cate": [12, 19], "moder": 13, "sem": 13, "good": [13, 22, 67, 68, 76, 86, 109, 119, 132], "analysis": 13, "contrain": 13, "ipykernel_69035": 13, "notears_linear": [13, 125, 126], "lambda1": [13, 125, 126], "loss_typ": [13, 125, 126], "l2": [13, 125, 126], "notears_r": 13, "author": [14, 17], "nois": [14, 88, 99, 100, 132], "normal": [14, 17, 62, 63, 69, 70, 74, 88, 92, 100, 101], "sparsiti": [14, 48, 81], "teat": 14, "ipykernel_69043": 14, "pydot": 14, "git": [14, 133], "pycaus": 14, "start_vm": 14, "tetrad": 14, "tetradrunn": 14, "new_df": 14, "map": [14, 67, 68, 76, 80, 91, 92, 93, 119, 123, 132, 133], "02": [14, 45, 59, 62, 77, 124, 128, 130, 131], "format": [14, 77, 130], "algoid": 14, "testid": 14, "gettetradgraph": 14, "getnod": 14, "dot_str": 14, "tetradgraphtodot": 14, "graph_from_dot_data": 14, "node_a": 14, "fill": 14, "fillcolor": 14, "red": 14, "add_nod": 14, "nx_pydot": 14, "from_pydot": 14, "pc_re": 14, "trial": [15, 32, 33, 80, 109], "ve": [15, 19, 132], "preliminari": [15, 38], "notat": [15, 33, 76, 95, 97, 98, 99, 100, 102, 104, 105, 106, 107, 133], "rl": [15, 64, 75, 76, 119, 120, 132], "main": [15, 20, 24, 25, 40, 119, 132, 133], "mathbb": [15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 32, 33, 38, 45, 48, 50, 60, 63, 64, 67, 68, 69, 74, 75, 76, 77, 91, 92, 93, 119, 132], "common": [15, 19, 22, 26, 99, 101, 129, 132], "causal": [15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 28, 32, 33, 36, 37, 38, 40, 71, 119, 120, 123, 124, 128, 133, 134], "consist": [15, 16, 17, 19, 20, 21, 22, 24, 25, 26, 27, 32, 48, 60, 63, 67, 69, 70, 71, 74, 75, 76, 92, 101, 108, 118, 125, 126, 127, 130], "These": [15, 19, 22, 63, 64, 74, 76], "nuc": [15, 21, 22, 26, 32], "remark": [15, 84, 88, 90, 110], "commonli": [15, 19, 21, 67, 68, 69, 70, 74, 75, 81, 82, 91, 92, 93, 111], "impos": [15, 67, 76], "automat": [15, 69, 74, 76, 90], "behavior": [15, 22, 23, 25, 60, 69, 75, 76, 92, 96, 103, 118], "strictli": [15, 69, 74], "re": [15, 89], "shown": [15, 17, 33, 86, 88, 96, 109, 111, 116], "below": [15, 16, 17, 21, 22, 24, 25, 26, 28, 71, 77, 79, 81, 85, 89, 109, 120, 123, 124, 125, 126, 128, 130, 132], "_s": 15, "_x": 15, "e_": [15, 96, 97], "rh": [15, 119], "rid": 15, "pure": [15, 119], "categori": [15, 63, 67, 74, 109, 132], "IS": [15, 21, 63, 69, 74], "dr": [15, 19, 20, 21, 50, 63, 69, 74], "widehat": [15, 16, 17, 21, 25, 50, 63, 64, 67, 68, 70, 74, 91, 92, 93, 119], "learner": [15, 17, 18, 19, 21, 23, 27, 45, 48, 59, 60, 62, 77, 79, 107, 110, 111, 116, 117, 123, 124, 125, 126, 128, 130, 131, 132, 134], "elabor": [15, 32], "sklearn": [15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 40, 48, 125, 126, 128, 130], "ensembl": [15, 16, 17, 18, 20, 21, 24, 26, 28, 29, 125, 126], "gradientboostingregressor": [15, 16, 17, 18, 20, 21, 24, 26, 28, 29], "linear_model": [15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 40, 59, 79, 125, 126, 130], "linearregress": [15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 125, 126, 130], "chdir": [15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 33, 40, 60, 63, 64, 67, 68, 69, 70, 71, 72, 74, 110, 111, 116, 117, 131], "cdm": [15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 33, 40, 60, 134], "movielens_cel": [15, 16, 17, 18, 20, 24, 26, 27, 28, 29, 134], "pop": [15, 16, 17, 18, 20, 24, 26, 28, 29], "user_id": [15, 16, 17, 18, 20, 24, 27, 28, 29, 129, 130], "movie_id": [15, 16, 17, 18, 20, 24, 27, 28, 29, 129, 130], "ag": [15, 16, 17, 18, 20, 21, 24, 27, 28, 29, 63, 64, 67, 68, 69, 70, 72, 74, 81, 89, 109, 110, 111, 116, 117, 129, 130, 131], "comedi": [15, 16, 17, 18, 20, 24, 27, 28, 29, 81, 84, 85, 87, 88, 89, 108, 109, 129, 130, 131], "drama": [15, 16, 17, 18, 20, 24, 26, 27, 28, 29, 81, 85, 89, 90, 108, 109, 129, 130, 131], "thriller": [15, 16, 17, 18, 20, 24, 27, 28, 29, 81, 82, 83, 84, 85, 86, 88, 89, 90, 108, 109, 129, 130, 131], "sci": [15, 16, 17, 18, 20, 24, 26, 27, 28, 29, 81, 83, 85, 86, 89, 109, 129, 130], "fi": [15, 16, 17, 18, 20, 24, 26, 27, 28, 29, 81, 83, 85, 86, 89, 109, 129, 130], "gender_m": [15, 16, 17, 18, 20, 24, 27, 28, 29, 129, 130], "occupation_academ": [15, 16, 17, 18, 20, 24, 27, 28, 29, 129, 130], "educ": [15, 16, 17, 18, 20, 21, 24, 27, 28, 29, 81, 89, 109, 129, 130, 131], "occupation_colleg": [15, 16, 17, 18, 20, 24, 27, 28, 29, 129, 130], "grad": [15, 16, 17, 18, 20, 24, 27, 28, 29, 81, 82, 83, 88, 89, 109, 129, 130], "occupation_execut": [15, 16, 17, 18, 20, 24, 27, 28, 29, 129, 130], "manageri": [15, 16, 17, 18, 20, 24, 27, 28, 29, 81, 89, 109, 129, 130], "occupation_oth": [15, 16, 17, 18, 20, 24, 27, 28, 29, 130], "occupation_technician": [15, 16, 17, 18, 20, 24, 27, 28, 29, 129, 130], "engin": [15, 16, 17, 18, 20, 24, 27, 28, 29, 81, 89, 109, 129, 130], "48": [15, 16, 17, 18, 20, 21, 24, 27, 28, 29, 62, 81, 125, 126, 127, 130], "1193": [15, 16, 17, 18, 20, 24, 27, 28, 29, 129], "919": [15, 16, 17, 18, 20, 24, 27, 28, 29], "527": [15, 16, 17, 18, 20, 24, 27, 28, 29], "1721": [15, 16, 17, 18, 20, 24, 27, 28, 29], "150": [15, 16, 17, 18, 20, 24, 27, 28, 29, 62], "65637": [15, 16, 17, 18, 20, 24, 28, 29], "5878": [15, 16, 17, 18, 20, 24, 27, 28, 29, 130], "3300": [15, 16, 17, 18, 20, 24, 27, 28, 29], "65638": [15, 16, 17, 18, 20, 24, 28, 29], "1391": [15, 16, 17, 18, 20, 24, 27, 28, 29], "65639": [15, 16, 17, 18, 20, 24, 28, 29], "185": [15, 16, 17, 18, 20, 24, 27, 28, 29], "65640": [15, 16, 17, 18, 20, 24, 28, 29], "2232": [15, 16, 17, 18, 20, 24, 27, 28, 29], "65641": [15, 16, 17, 18, 20, 24, 28, 29], "426": [15, 16, 17, 18, 20, 24, 27, 28, 29, 123, 130], "65642": [15, 16, 17, 18, 20, 24, 27, 28, 29], "userinfo_index": [15, 16, 17, 18, 21, 24, 26, 27, 28, 29, 125, 126, 130], "sanda": [15, 17, 18, 21, 22, 26, 27, 28, 29], "iloc": [15, 17, 18, 20, 21, 22, 23, 26, 27, 28, 29, 40, 50, 71, 122, 123, 124, 125, 126, 128, 129, 130, 131], "s_learner": [15, 21, 22, 26], "max_depth": [15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 71, 123, 125, 126, 128, 130], "sanda_all1": [15, 21, 26], "copi": [15, 21, 26, 60, 71, 122, 123, 125, 126, 128, 129, 130], "sanda_all0": [15, 21, 26], "ate_dm": [15, 21], "sum": [15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 33, 60, 62, 64, 87, 108, 109, 117, 125, 126, 129, 130], "inclin": [15, 26, 28, 29, 125, 126], "higher": [15, 19, 26, 28, 29, 40, 64, 81, 85, 89, 109, 125, 126, 130], "fiction": [15, 26, 28, 29], "145": [15, 40, 125, 126, 128], "invers": [15, 21, 60, 69, 74], "aipw": [15, 60], "proce": [15, 76], "bigg": [15, 17, 21, 40], "flip": 15, "role": [15, 91, 92, 93], "a_ir_i": 15, "logisticregress": [15, 16, 18, 20, 21, 22, 23, 24, 25, 29, 125, 126], "ps_model": [15, 16, 21, 24, 25], "pi_": [15, 21, 79, 119], "predict_proba": [15, 21, 22, 29, 125, 126], "ate_i": [15, 21], "7765291578583513": 15, "watch": [15, 26, 27, 60, 84], "356": [15, 123], "third": [15, 63, 74, 95, 97, 98], "misspecif": [15, 45, 64, 77, 82, 95, 99, 105], "term": [15, 20, 25, 63, 64, 69, 71, 74, 79, 81, 88, 92, 93], "correct": [15, 32], "correctli": [15, 64, 92], "prove": [15, 16, 20, 21, 25, 48, 63, 64, 70], "mild": [15, 16, 19, 25, 63], "semi": [15, 99, 100, 102, 107, 108, 118], "parametr": [15, 17, 74], "converg": [15, 17, 19, 20, 25, 50, 63, 64, 67, 68, 74, 132], "found": [15, 45, 61, 77, 95, 97, 98, 99, 100, 102, 104, 105, 106, 107, 130, 132, 133], "3021046776851372e": 15, "ate_dr": [15, 21], "slightli": [15, 22, 32, 74, 76, 120, 130], "sequenti": [15, 32, 45, 60, 71, 76, 77, 80, 85, 88, 90, 91, 92, 93, 101, 109], "681": 15, "694": 15, "v": [15, 16, 17, 18, 19, 20, 23, 24, 25, 32, 48, 50, 59, 63, 70, 74, 75, 76, 83, 91, 92, 93, 96, 97, 98, 100, 103, 104, 105, 106, 107, 108, 119], "chetverikov": [15, 17], "demir": [15, 17], "duflo": [15, 17], "hansen": [15, 17], "w": [15, 17, 22, 37, 38, 45, 50, 59, 76, 77, 78, 79, 80, 81, 83, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 118, 119, 124], "newei": [15, 17], "kennedi": [16, 19, 20, 25], "extend": [16, 25, 48, 69, 74], "oracl": [16, 19, 20, 24, 25], "theorem": [16, 17, 25, 74, 102, 119], "nuisanc": [16, 18, 20, 23, 25, 60, 63, 64, 69, 74], "i_": [16, 20, 25, 64], "mu_a": [16, 25], "phi": [16, 25, 45, 77, 82, 86, 88, 90, 95, 97, 99, 102, 104, 105, 111, 129, 131], "_a": [16, 20, 25, 83], "_1": [16, 25, 60, 64, 71, 124], "_0": [16, 25, 60], "i_2": [16, 20, 25, 64], "yield": [16, 17, 22, 25, 28, 32, 33, 50, 60, 63, 64, 69, 74], "tau": [16, 18, 19, 20, 22, 23, 24, 25, 26, 28, 29, 33, 38, 60, 64, 119], "_n": [16, 20, 24, 25, 60], "single_stag": [16, 17, 18, 20, 24, 25, 134], "drlearner": [16, 25, 134], "filterwarn": [16, 17, 20, 24], "drop": [16, 17, 20, 24, 27, 28, 29, 60, 79, 122, 129, 130], "n_fold": [16, 20, 24, 25], "y_model": [16, 20, 24, 25], "rlearner_model": [16, 24, 25], "hte_dr_learn": [16, 25], "to_numpi": [16, 17, 22, 23, 24, 25, 26, 130], "fold": [16, 24, 25, 60], "r2": [16, 24, 25], "baselearn": [16, 25], "pslearner": [16, 25], "735": 16, "038": 16, "037": [16, 21], "734": [16, 24], "1000": [16, 17, 20, 22, 24, 26, 28, 29, 48, 60, 62, 97, 104, 105, 107, 108, 130, 131], "5000": [16, 17, 24, 26, 27, 28, 29, 130], "05672212": 16, "73726057": 16, "09360586": 16, "ate_dr_learn": 16, "3541": 16, "conclus": [16, 17, 18, 20, 22, 24, 25, 26, 28, 29, 125, 126, 130], "xinkun": [16, 19, 20, 24, 25], "nie": [16, 19, 20, 24, 25, 124, 128], "stefan": [16, 18, 19, 20, 23, 24, 25, 35, 39, 41, 42, 43], "wager": [16, 18, 19, 20, 23, 24, 25, 35, 39, 41, 42, 43], "quasi": [16, 19, 20, 24, 25, 33], "108": [16, 19, 20, 24, 25, 27, 40, 122, 123], "299": [16, 19, 20, 24, 25], "319": [16, 19, 20, 24, 25], "robinson": [16, 19, 20, 24, 25], "root": [16, 19, 20, 24, 25], "econometrica": [16, 19, 20, 24, 25], "econometr": [16, 19, 20, 24, 25, 33], "societi": [16, 19, 20, 24, 25, 45, 77], "931": [16, 19, 20, 24, 25, 129], "954": [16, 19, 20, 24, 25], "edward": [16, 19, 20, 25], "h": [16, 19, 20, 25, 45, 50, 79, 80, 88, 89, 90, 91, 92, 93, 95, 96, 97, 99, 102, 103, 104, 105, 108, 109, 117, 118], "2004": [16, 19, 20, 25, 45, 77], "14497": [16, 19, 20, 25], "der": [16, 19, 20, 25, 37, 124], "laan": [16, 19, 20, 25, 37, 124], "biostatist": [16, 19, 20, 25, 45, 77], "lee": [16, 19, 20, 25], "okui": [16, 19, 20, 25], "whang": [16, 19, 20, 25], "uniform": [16, 19, 20, 25, 60], "band": [16, 19, 20, 25], "1207": [16, 19, 20, 25], "1225": [16, 19, 20, 25], "foster": [16, 19, 20, 25], "syrgkani": [16, 19, 20, 25], "orthogon": [16, 19, 20, 25, 80, 109], "1901": [16, 19, 20, 25], "09036": [16, 19, 20, 25], "guarante": [17, 19, 33, 76, 132, 133], "asymptot": [17, 48, 60, 63, 64, 74, 92, 119], "dml": [17, 18, 23], "plug": [17, 21, 22, 26, 50, 63, 64, 67, 74], "att": 17, "despit": [17, 50, 125, 126], "versatil": 17, "choic": [17, 21, 71, 80, 96, 97, 103, 109, 118, 123, 128], "ml": 17, "seem": [17, 125, 126], "criteria": [17, 27, 125, 126, 127], "qualiti": [17, 19], "angl": 17, "innov": 17, "discard": 17, "irrelev": 17, "start": [17, 24, 25, 32, 40, 75, 79, 82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 110, 111, 116, 117, 125, 126, 130], "minimum": [17, 33], "tmle": 17, "imporv": 17, "finit": [17, 48, 59, 64, 69, 74, 79, 84, 87, 90, 109, 110, 117, 128], "stabil": [17, 132], "amd": 17, "word": [17, 45, 59, 75, 76, 77, 79, 81, 85, 89, 108, 109, 118, 130], "head": [17, 27, 33, 40, 62, 77, 122, 124, 125, 126, 128, 129], "archetectur": 17, "ipython": [17, 21, 33], "singlestag": 17, "png": [17, 21, 33, 131], "width": 17, "500": [17, 21, 60, 85, 89, 99, 100, 102, 107, 124], "layer": 17, "resourc": [17, 33], "core": [17, 71, 122, 126], "object": [17, 21, 24, 45, 48, 59, 60, 77, 79, 81, 85, 86, 96, 108, 109, 111, 116, 119, 125, 126], "theta": [17, 20, 25, 82, 84, 86, 88, 95, 96, 97, 98, 99, 100, 102, 104, 105, 106, 108, 110, 111, 116, 118, 119, 124], "arg": [17, 20, 24, 25, 40, 45, 48, 59, 60, 63, 67, 68, 75, 76, 77, 79, 82, 83, 86, 87, 95, 97, 98, 99, 100, 102, 103, 104, 105, 106, 117, 119, 129, 130], "min_": [17, 20, 24, 25, 40, 60, 63, 67, 68, 119], "nn": [17, 120], "alpha": [17, 18, 23, 40, 60, 64, 70, 75, 76, 82, 83, 88, 90, 95, 98, 106, 111, 119, 131], "crossentropi": 17, "hyperparamet": 17, "tild": [17, 22, 29, 64, 77, 79, 82, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 111, 116], "minim": [17, 19, 63, 64, 74, 75, 76, 80, 85, 97, 102, 104, 109], "extra": [17, 130], "beta": [17, 18, 23, 24, 25, 45, 59, 60, 71, 79, 82, 86, 88, 90, 97, 98, 104, 106, 116, 123, 124, 128, 132], "solut": [17, 18, 23, 48, 50, 67, 68, 75, 119, 133], "claudiashi57": 17, "check": [17, 32], "test_output": 17, "train_output": 17, "train_and_predict_dragon": 17, "targeted_regular": 17, "output_dir": 17, "master": [17, 40], "knob_loss": 17, "dragonnet_loss_binarycross": 17, "ratio": [17, 21, 27, 63, 64, 69, 74, 125, 126, 127, 128], "val_split": 17, "64": [17, 18, 23, 59, 62, 79, 128], "am": 17, "2023": [71, 123], "04": [60, 124], "01": [18, 45, 59, 60, 62, 77, 124, 128, 131], "58": 62, "465481": [], "tensorflow": [], "platform": 60, "cpu_feature_guard": [], "cc": 26, "193": [], "oneapi": [], "librari": [], "onednn": [], "cpu": [82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 130], "instruct": [91, 92, 93], "sse4": [], "rebuild": [], "compil": [], "flag": [82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 130], "keyboardinterrupt": 123, "ipykernel_69061": [], "2268767057": [], "y_unscal": [], "324": [21, 80, 123], "325": 123, "326": [21, 45, 77, 123], "x_train": 128, "yt_train": [], "callback": [], "adam_callback": [], "327": 123, "validation_split": [], "328": 123, "kera": [], "traceback_util": [], "error_handl": [], "kwarg": [82, 83, 129, 130], "filtered_tb": [], "none": [18, 21, 23, 27, 40, 59, 62, 71, 79, 84, 88, 96, 110, 116, 123, 128, 129, 130, 131], "63": [18, 60, 62, 128], "fn": [], "65": [27, 40, 45, 50, 59, 60, 62, 77, 79, 128, 131], "pylint": [], "disabl": [], "66": [59, 60, 62, 79, 125, 128], "_process_traceback_fram": [], "__traceback__": [], "self": [45, 59, 63, 69, 74, 77, 79, 82, 83, 122, 123, 126, 128, 129, 130, 131], "verbos": [18, 23, 129], "validation_data": [], "shuffl": [], "class_weight": [], "sample_weight": 128, "initial_epoch": [], "steps_per_epoch": [], "validation_step": [], "validation_batch_s": [], "validation_freq": [], "max_queue_s": [], "worker": [], "use_multiprocess": [], "1407": [], "_r": [20, 25], "1408": [], "on_train_batch_begin": [], "1409": [], "tmp_log": [], "train_funct": [], "iter": [60, 64, 67, 77, 79, 88, 97, 102, 104, 119, 129], "1410": [], "data_handl": [], "should_sync": [], "1411": [], "async_wait": [], "python": [18, 23, 33, 82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 129, 130, 133], "148": [21, 125], "149": [21, 40, 60, 130], "151": [40, 100, 101, 108, 118, 130], "152": [125, 126, 128], "eager": [], "def_funct": [], "__call__": [], "kwd": 129, "913": [], "914": [], "optionalxlacontext": [], "_jit_compil": [], "915": [], "_call": [], "916": [], "917": [], "new_tracing_count": [], "experimental_get_tracing_count": [], "945": [], "creat": [27, 129], "946": 25, "defun": [], "never": 33, "947": 25, "_stateless_fn": [], "callabl": [], "948": 25, "elif": 123, "_stateful_fn": [], "949": [], "releas": [], "earli": [59, 79, 91, 92, 93, 130], "thread": 130, "2451": [], "graph_funct": [], "2452": [], "filtered_flat_arg": [], "_maybe_define_funct": [], "2453": [], "_call_flat": [], "2454": [], "captured_input": [], "protect": [64, 92], "access": [27, 125, 126, 127, 133], "2455": [], "cancellation_manag": [], "1858": [], "executing_eagerli": [], "1859": [], "tape": [], "1860": [], "_build_call_output": [], "_inference_funct": [], "ctx": [], "1862": [], "forward_backward": [], "_select_forward_and_backward_funct": [], "495": [], "_interpolatefunctionerror": [], "496": 21, "497": [], "execut": [19, 32, 33, 40, 81, 82, 83, 84, 86, 87, 88, 89, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 109, 129, 130, 131], "498": [], "str": [40, 122, 129], "signatur": [], "499": [48, 81], "num_output": [], "_num_output": [], "quick_execut": [], "op_nam": [], "attr": [82, 83, 130], "52": [62, 125], "53": [59, 60, 62, 130], "ensure_initi": [], "54": [60, 62], "tensor": [82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 130], "pywrap_tf": [], "tfe_py_execut": [], "_handl": [], "device_nam": [], "55": [18, 62, 97, 104, 125], "56": [23, 50, 62, 81, 89, 109, 129, 130], "_notokstatusexcept": [], "dict_kei": [17, 27, 130], "q_t0": 17, "q_t1": 17, "ep": 17, "hte_dragonnet": 17, "34005857": 17, "33967185": 17, "46262145": 17, "aaverag": 17, "ate_dragonnet": 17, "3526": 17, "claudia": [17, 19], "blei": [17, 19], "veitch": [17, 19], "33rd": 17, "neurip": 17, "susan": [18, 19, 23, 35, 36, 39, 41, 42, 43], "athei": [18, 19, 23, 35, 36, 39, 41, 42, 43], "juli": [18, 19, 23, 35, 39, 41, 42, 43, 89, 90, 101], "tibshirani": [18, 19, 23, 35, 39, 41, 42, 43], "moment": [18, 23], "psi_": [18, 23, 45, 63, 64, 70, 74, 77], "nu": [18, 23], "o_i": [18, 23, 50], "care": [18, 23, 27, 125, 126, 127, 129], "xi": [18, 23, 63, 74], "induc": [18, 23], "solv": [18, 23, 24, 25, 45, 48, 50, 59, 63, 64, 67, 68, 69, 74, 75, 76, 77, 86, 100, 103, 108, 109, 111, 116, 118, 119], "alpha_i": [18, 23], "otim": [18, 23], "vv": [18, 23], "notic": [18, 23, 82, 98, 99, 106, 111], "formula": [18, 23, 59, 60, 133], "ordinari": [18, 23], "prone": [18, 23], "grf": [18, 19, 23], "quantiti": [18, 23, 38], "grow": [18, 23, 71, 74, 120], "dot": [18, 23, 40, 45, 60, 63, 69, 74, 77, 81, 85, 89, 96, 103, 108, 109, 118, 123, 129, 130, 131, 132], "l_b": [18, 23], "fall": [18, 23, 32, 129], "leaf": [18, 23], "frequenc": [18, 23, 82, 83, 95, 97, 102, 104, 105], "alpha_": [18, 23, 90], "bi": [18, 23], "boldsymbol": [18, 23, 45, 59, 61, 77, 78, 79, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 108, 110, 111, 117, 118, 124, 128], "x_0": [18, 23], "flexibl": [18, 23, 50, 60, 64, 91, 92, 93, 132], "causal_effect_learn": [18, 21, 25], "lprlearner": [18, 20, 25], "ipykernel_69076": 18, "1061371864": 18, "_util_causaldm": [18, 22, 23, 25, 45, 59, 60, 61, 131], "econml": [18, 23], "cp39": 18, "macosx_10_9_x86_64": 18, "whl": [18, 23], "mb": [18, 23], "2k": [18, 23], "90m": [18, 23], "0m": [18, 23], "32m1": 18, "31m2": 18, "eta": [18, 20, 21, 23, 24, 25, 60, 63, 64, 67, 69, 70, 74, 75, 76, 97, 102, 103, 104, 108, 118], "36m0": [18, 23], "0m00": 18, "25hcollect": 18, "shap": [18, 23], "41": [18, 23, 59, 62, 130], "40": [18, 21, 23, 33, 40, 60, 62, 122, 125, 128, 131], "433": 18, "kb": [18, 23], "32m433": 18, "31m3": 18, "25hrequir": [18, 23], "scikit": [18, 23, 60, 61], "scipi": [18, 23, 129, 131], "lightgbm": [18, 23, 25, 125, 126, 130], "spars": [18, 23], "py2": [18, 23], "py3": [18, 23], "32m81": 18, "81": [18, 62], "joblib": [18, 23], "threadpoolctl": [18, 23], "numba": [18, 23], "slicer": [18, 23], "tqdm": [18, 23, 125, 126], "cloudpickl": [18, 23], "patsi": [18, 23], "dateutil": [18, 23], "pytz": [18, 23], "wheel": [18, 23], "35": [18, 21, 33, 40, 60, 62, 129, 131], "llvmlite": [18, 23], "39": [18, 23, 40, 45, 60, 62, 126, 129], "0rc1": 18, "setuptool": [18, 23], "pypars": 18, "six": [18, 23, 132], "successfulli": [18, 23, 60], "demo": [18, 23, 62, 133], "causalforest": [18, 23], "causalivforest": [18, 23], "regressionforest": [18, 23], "causalforestdml": [18, 23], "est": [18, 23], "criterion": [18, 23], "het": [18, 23], "n_estim": [18, 23], "400": [18, 21, 23, 62], "min_samples_leaf": [18, 23], "min_var_fraction_leaf": [18, 23], "min_var_leaf_on_v": [18, 23], "min_impurity_decreas": [18, 23], "max_sampl": [18, 23], "45": [18, 23, 60, 62, 130, 131], "min_balancedness_tol": [18, 23], "warm_start": [18, 23], "fit_intercept": [18, 23, 48], "subforest_s": [18, 23], "honest": [18, 23], "n_job": [18, 23, 48, 128], "random_st": [18, 23, 128], "1235": [18, 23], "hte_grf": [18, 23], "flatten": [18, 21, 23, 71, 123, 128], "900": [18, 20], "3605": 18, "3783": 18, "3646": 18, "ate_grf": 18, "358": [18, 123], "47": [18, 19, 23, 27, 33, 35, 39, 41, 42, 43, 62, 84, 87, 109, 110, 117, 125, 126, 127], "1148": [18, 19, 23, 35, 39, 41, 42, 43], "1178": [18, 19, 23, 35, 39, 41, 42, 43], "setup": [19, 24, 25, 48, 62, 63, 64, 103, 119, 120, 132], "triplet": [19, 75, 76, 132], "trajectori": [19, 40, 69, 74, 75, 76, 119, 132], "imagin": 19, "terminolog": 19, "lot": [19, 60, 75], "recommend": [19, 27, 45, 48, 50, 59, 62, 77, 79, 80, 81, 85, 89, 96, 101, 103, 124, 128, 130, 131], "adversit": 19, "impact": [19, 33, 71, 125, 126, 128], "annual": [19, 38, 40], "incom": [19, 103, 104, 105, 106, 130], "expos": [19, 26, 33, 40], "statu": [19, 21, 27, 32, 60, 92, 93, 125, 126, 127], "pictur": [19, 60], "dress": 19, "femal": [19, 21, 81, 130], "male": [19, 81, 82, 83, 88, 89, 109, 130], "clearli": [19, 132], "granular": 19, "averg": 19, "characsterist": 19, "subsect": [19, 27, 38, 74], "briefli": [19, 38, 80, 109], "lp": 19, "forest": [19, 35, 39, 41, 42, 43], "dragonnet": 19, "paper": [19, 20, 25, 119], "pleas": [19, 20, 22, 25, 29], "easiest": [19, 22, 24, 25, 60], "apporach": 19, "enough": [19, 64, 130, 133], "complic": [19, 22, 28, 64], "worth": [19, 32, 40, 102], "sensibl": 19, "trend": [19, 22, 33, 40, 81, 116, 117, 132], "cancel": 19, "tend": [19, 22, 40], "particularli": [19, 45, 59, 77, 79], "larger": [19, 28, 40, 45, 59, 61, 64, 74, 77, 79], "part": [19, 33, 40, 60, 64, 71, 119, 123, 132, 133], "boost": [19, 60], "acheiv": 19, "alwai": [19, 45, 59, 64, 81, 85, 86, 89, 98, 100, 106, 109, 111, 116, 128], "faster": [19, 50, 64, 74], "might": [19, 62, 63, 125, 126], "computation": [19, 70, 97, 102, 104, 106, 120], "polynomi": [19, 20, 25], "tradeoff": [19, 64], "inherit": 19, "dragon": 19, "net": 19, "outperform": [19, 82, 95, 98, 99, 100, 105, 106, 130], "kunzel": [19, 22, 26, 28, 29], "sekhon": [19, 22, 26, 28, 29], "bickel": [19, 22, 26, 28, 29], "metalearn": [19, 22, 26, 28, 29], "nation": [19, 22, 26, 28, 29], "academi": [19, 22, 26, 28, 29], "116": [19, 22, 26, 28, 29, 36, 40, 45, 59, 91, 92, 93, 122, 123, 124], "4156": [19, 22, 26, 28, 29], "4165": [19, 22, 26, 28, 29], "alicia": 19, "curth": 19, "mihaela": 19, "schaar": 19, "1810": 19, "1818": 19, "residu": [20, 24, 25], "cross": [20, 25, 60], "relax": [20, 25, 32, 64, 132], "breviti": [20, 25], "1b": [20, 25], "basi": [20, 25, 63, 71, 74, 88, 123], "k_": [20, 25], "hs": [20, 25], "bandwidth": [20, 25, 50], "mu_1": [20, 22, 25, 28, 29], "mu_0": [20, 22, 25, 28, 29], "estimt": [20, 25], "_b": [20, 25], "tb": [20, 25], "s_0": [20, 25, 32, 64, 75, 76, 119], "repeat": [20, 25, 79, 109, 119, 123], "twice": [20, 25], "n_": [20, 25, 40], "samplem": [20, 25], "tradit": [20, 25, 33, 69], "milder": [20, 25, 64], "ps_model_a": [20, 25], "ps_model_b": [20, 25], "lprlearner_model": [20, 25], "sample_index": 20, "tolist": [20, 122, 125, 126, 129, 130, 131], "hte_lp_r_learn": [20, 25], "ipykernel_69094": [], "3012518900": [], "91": [60, 62, 122, 123, 124, 125], "92": [40, 62], "ps_learner_a": [], "fold1a": [], "93": 62, "94": [59, 60, 62, 122, 124], "y_learner": [24, 25], "fold1b": [], "_logist": [], "1506": [], "_dtype": [], "float64": [59, 79, 124, 131], "float32": [], "1507": [], "1508": [], "_validate_data": [], "1509": [], "1510": [], "reset": 79, "validate_separ": [], "check_param": [], "579": [], "check_arrai": [], "check_y_param": [], "580": [], "els": [21, 45, 59, 71, 77, 79, 122, 123, 124, 128], "581": [], "check_x_i": [], "582": [], "583": 21, "accept_spars": [], "accept_large_spars": [], "force_all_finit": [], "ensure_2d": [], "allow_nd": [], "multi_output": [], "ensure_min_sampl": [], "ensure_min_featur": [], "y_numer": [], "962": [], "valueerror": [21, 71, 123, 128], "963": [], "964": [], "965": [], "966": 25, "627": [], "628": [], "629": 21, "dtypes_orig": [], "630": 122, "boolean": [122, 126], "__array__": [], "interfac": [], "coerc": [], "bool": 129, "631": 122, "dtype_it": [], "enumer": [], "5745": [], "5746": 27, "_mgr": [], "get_dtyp": [], "5747": [], "_constructor_sl": [], "_info_axi": [], "object_": [], "5748": [], "5749": [], "def": [21, 50, 62, 71, 123, 128, 129, 131], "astyp": [40, 62, 129, 130], "fastpath": [], "458": [], "459": 60, "ndframe": [], "460": [], "461": [], "_set_axi": [], "462": [], "42175269": 20, "52461763": 20, "13400663": 20, "ate_lp_r_learn": 20, "2182": 20, "influnc": 21, "treamtent": 21, "borrow": 21, "necess": 21, "birth": 21, "pill": 21, "incid": 21, "thrombosi": 21, "pregnanc": 21, "want": [21, 59, 60, 77, 79, 98, 133], "sens": [21, 63, 64, 74], "marit": 21, "reliabl": [21, 45, 59, 62, 77, 79], "iid": 21, "treament": 21, "a_0": [21, 64, 71, 76, 119], "a_1": [21, 71, 76, 119, 124, 128], "m_a": 21, "r_": [21, 32, 59, 61, 63, 64, 67, 68, 69, 74, 75, 76, 77, 81, 83, 85, 87, 88, 89, 90, 95, 97, 99, 102, 108, 109, 117, 118, 132], "m_": 21, "imai": 21, "m_0": [21, 24, 25, 71], "int": [21, 40, 62, 129, 130], "suffic": 21, "rho": [21, 60, 63, 69, 74], "p_a": 21, "shift": [21, 48, 119, 132], "tchetgen": [21, 128], "shpitser": [21, 128], "aurora_cel": 21, "survey_r": 21, "hispan": 21, "white": 21, "trauma": 21, "health": [21, 32, 71, 125, 126, 129], "mental": 21, "chronic": 21, "percept": 21, "stress": 21, "neurotic": 21, "childhood": 21, "insomnia": 21, "cont": [21, 50], "peritraumat": 21, "distress": 21, "w2": 21, "acut": 21, "disord": 21, "ptsd": 21, "depress": 21, "month": [21, 61], "hist": [21, 60, 122, 125, 126], "bin": [21, 60, 130], "274": 21, "242": 21, "187": [21, 27, 122, 123], "98": [21, 45, 62, 77], "109": [21, 40, 107, 123], "55287818": 21, "75287818": 21, "95287818": 21, "15287818": 21, "64712182": 21, "44712182": 21, "24712182": 21, "04712182": 21, "84712182": 21, "barcontain": [21, 125, 126], "artist": [21, 125, 126, 129], "aurora_cel_md": 21, "ipykernel_69109": 21, "2568975421": 21, "settingwithcopywarn": [21, 122, 125], "caveat": [21, 122, 125], "pydata": [21, 122, 125], "user_guid": [21, 122, 125], "mediation_analysi": 21, "me_singl": [21, 128], "604871671": 21, "control_polici": [21, 71, 123, 128], "dim_stat": [21, 71, 123, 124, 128], "get_a": [21, 71, 123, 128], "action_valu": [21, 71, 123, 128], "shape": [21, 40, 62, 71, 77, 82, 83, 123, 128, 129, 130], "target_polici": [21, 71, 123, 128], "pa": [21, 33, 71, 123, 128], "prob_arr": [21, 71, 123, 128], "problearner_paramet": [21, 71, 123, 128], "splitter": [21, 71, 123, 128], "direct_est": [21, 123, 128], "r_model": [21, 71, 123, 128], "ol": [21, 59, 71, 123, 128], "truncat": [21, 69, 71, 74, 123, 128], "dim_medi": [21, 71, 123, 124, 128], "expectation_mcmc_it": 21, "nature_decomp": [21, 71, 123, 128], "estimate_de_m": [21, 71, 123, 128], "est_d": [21, 128], "est_m": [21, 128], "est_t": [21, 128], "5699712042262648": 21, "35390067425173": 21, "923871878477995": 21, "ipw_est": [21, 128], "1833766092547435": 21, "0830496488123182": 21, "266426258067062": 21, "robust_est": [21, 71, 123, 128], "082810672178048": 21, "6367679712306544": 21, "7195786434087026": 21, "robust_d": 21, "robust_i": 21, "robust_t": 21, "mediator_1d": 21, "aurora_cel_1d": 21, "mediators_index": 21, "append": [21, 50, 59, 62, 79, 129, 130, 131], "four": [21, 71, 80, 81, 88, 89, 97, 100, 102, 104, 123, 130], "637": 21, "720": [21, 62], "262": 21, "234": 21, "435": [21, 130], "452": 21, "699": 21, "800": 21, "465": 21, "748": [21, 122, 125], "214": [21, 22, 77, 81, 83], "131861": 21, "151941": 21, "741954": 21, "476881": 21, "776439": 21, "879518": 21, "062249": 21, "868139": 21, "848059": 21, "081954": 21, "706881": 21, "223561": 21, "937751": 21, "718046": 21, "393119": 21, "418046": 21, "323119": 21, "241954": 21, "483119": 21, "1489": 21, "641954": 21, "506881": 21, "120482": 21, "1490": 21, "321954": 21, "656881": 21, "1491": 21, "841954": 21, "146881": 21, "1492": [21, 22], "231954": 21, "216881": 21, "1493": 21, "441954": 21, "333119": 21, "1494": 21, "3238214724070896": 21, "583008488326464": 21, "6766993378439592": 21, "0005208102510488": 21, "636768": 21, "719579": 21, "covid19_cel": 21, "292852": 21, "637413": 21, "913318": 21, "513904": 21, "951952": 21, "795226": 21, "010544": 21, "147116": 21, "071851": 21, "266743": 21, "045451": 21, "026626": 21, "794902": 21, "157263": 21, "012273": 21, "940021": 21, "693004": 21, "797915": 21, "500000": [21, 27, 122, 124, 125], "427091": 21, "792291": 21, "098134": 21, "176879": 21, "740606": 21, "069790": 21, "111048": 21, "927152": 21, "917465": 21, "264442": 21, "065442": 21, "042891": 21, "762210": 21, "123276": 21, "971190": 21, "944849": 21, "717563": 21, "782914": 21, "095238": 21, "760591": 21, "172900": 21, "868353": 21, "536234": 21, "939283": 21, "098691": 21, "088660": 21, "262078": 21, "735539": 21, "208682": 21, "955573": 21, "069427": 21, "698803": 21, "084979": 21, "902696": 21, "899230": 21, "633096": 21, "769921": 21, "477273": 21, "454398": 21, "250654": 21, "939562": 21, "149566": 21, "784729": 21, "779052": 21, "719391": 21, "173107": 21, "448533": 21, "226761": 21, "964872": 21, "125997": 21, "729486": 21, "135069": 21, "921326": 21, "925182": 21, "662126": 21, "828047": 21, "400000": [21, 122, 124, 126], "140390": 21, "108600": 21, "047156": 21, "815548": 21, "533363": 21, "173536": 21, "308488": 21, "199351": 21, "838208": 21, "107659": 21, "944363": 21, "028927": 21, "715424": 21, "018883": 21, "925700": 21, "820400": 21, "639058": 21, "878947": 21, "807692": 21, "062158": 21, "586850": 21, "469484": 21, "326334": 21, "479242": 21, "650710": 21, "264352": 21, "682694": 21, "736854": 21, "204114": 21, "037254": 21, "075291": 21, "779771": 21, "060582": 21, "021507": 21, "796522": 21, "680173": 21, "951977": 21, "294326": 21, "530267": 21, "571570": 21, "428835": 21, "473093": 21, "179841": 21, "077723": 21, "149741": 21, "637036": 21, "281233": 21, "046941": 21, "168571": 21, "811361": 21, "052676": 21, "972389": 21, "864756": 21, "701395": 21, "995490": 21, "109589": 21, "897320": 21, "382069": 21, "289806": 21, "041032": 21, "683110": 21, "672166": 21, "529203": 21, "909618": 21, "029841": 21, "250219": 21, "108112": 21, "210270": 21, "863557": 21, "155546": 21, "055981": 21, "000739": 21, "749153": 21, "995393": 21, "192593": 21, "482535": 21, "164017": 21, "656821": 21, "651928": 21, "708246": 21, "588910": 21, "148011": 21, "490420": 21, "440770": 21, "347127": 21, "144951": 21, "270242": 21, "921650": 21, "215292": 21, "102442": 21, "982433": 21, "801220": 21, "037740": 21, "287785": 21, "171677": 21, "030898": 21, "854759": 21, "128409": 21, "576126": 21, "770616": 21, "191284": 21, "435813": 21, "084196": 21, "605906": 21, "307340": 21, "474589": 21, "099494": 21, "373177": 21, "253232": 21, "124960": 21, "867672": 21, "146863": 21, "136656": 21, "894203": 21, "635793": 21, "820545": 21, "845285": 21, "278246": 21, "950636": 21, "930212": 21, "173367": 21, "965229": 21, "370520": 21, "184868": 21, "296518": 21, "052125": 21, "178420": 21, "140642": 21, "001873": 21, "828338": 21, "050149": 21, "080622": 21, "782546": 21, "214282": 21, "914472": 21, "644101": 21, "630285": 21, "992847": 21, "822527": 21, "474421": 21, "188018": 21, "345831": 21, "115597": 21, "228738": 21, "996008": 21, "097064": 21, "981428": 21, "926802": 21, "829375": 21, "990533": 21, "013089": 21, "192243": 21, "280890": 21, "643705": 21, "702932": 21, "017906": 21, "253913": 21, "882940": 21, "059254": 21, "509737": 21, "164002": 21, "993222": 21, "934286": 21, "946955": 21, "993287": 21, "844765": 21, "716947": 21, "736582": 21, "871981": 21, "112732": 21, "649070": 21, "621102": 21, "116686": 21, "858802": 21, "429514": 21, "851297": 21, "776376": 21, "181538": 21, "740580": 21, "935064": 21, "719345": 21, "759164": 21, "641585": 21, "651791": 21, "540918": 21, "933250": 21, "507287": 21, "469476": 21, "082212": 21, "603982": 21, "724633": 21, "303232": 21, "312939": 21, "179535": 21, "980677": 21, "236501": 21, "528457": 21, "656411": 21, "327752": 21, "076134": 21, "299791": 21, "936846": 21, "181952": 21, "839581": 21, "539065": 21, "909695": 21, "693490": 21, "226519": 21, "528723": 21, "417358": 21, "668425": 21, "043352": 21, "848219": 21, "364526": 21, "062001": 21, "410301": 21, "871230": 21, "475528": 21, "144627": 21, "231135": 21, "126969": 21, "357398": 21, "983761": 21, "193422": 21, "097615": 21, "838285": 21, "171171": 21, "876705": 21, "463145": 21, "434180": 21, "511868": 21, "921547": 21, "050862": 21, "366664": 21, "753326": 21, "281971": 21, "309997": 21, "980845": 21, "002650": 21, "022058": 21, "032005": 21, "805918": 21, "060452": 21, "125673": 21, "747338": 21, "035326": 21, "606716": 21, "988680": 21, "813622": 21, "686867": 21, "432760": 21, "928552": 21, "074092": 21, "395144": 21, "947214": 21, "112098": 21, "881150": 21, "896476": 21, "002845": 21, "916207": 21, "701719": 21, "867089": 21, "964613": 21, "667084": 21, "028169": 21, "524647": 21, "808017": 21, "606230": 21, "339734": 21, "215940": 21, "950746": 21, "921715": 21, "220864": 21, "834689": 21, "039230": 21, "792536": 21, "855976": 21, "924145": 21, "838933": 21, "679882": 21, "776855": 21, "864724": 21, "625158": 21, "194203": 21, "376806": 21, "638014": 21, "428127": 21, "903468": 21, "053162": 21, "893333": 21, "826913": 21, "059934": 21, "711601": 21, "905191": 21, "597521": 21, "799891": 21, "754369": 21, "733082": 21, "605912": 21, "650462": 21, "715133": 21, "540011": 21, "086331": 21, "324318": 21, "604902": 21, "240240": 21, "678514": 21, "941771": 21, "853870": 21, "713999": 21, "979322": 21, "616151": 21, "712055": 21, "463547": 21, "557215": 21, "588222": 21, "473332": 21, "490730": 21, "426028": 21, "610805": 21, "424375": 21, "129921": 21, "425470": 21, "787702": 21, "371460": 21, "939302": 21, "995036": 21, "940572": 21, "799697": 21, "127974": 21, "644533": 21, "808024": 21, "487328": 21, "679655": 21, "636077": 21, "505732": 21, "551934": 21, "427194": 21, "720673": 21, "465912": 21, "119910": 21, "512886": 21, "614200": 21, "222873": 21, "902820": 21, "931370": 21, "935323": 21, "742122": 21, "076328": 21, "511175": 21, "659210": 21, "398034": 21, "508583": 21, "481010": 21, "334271": 21, "442130": 21, "314993": 21, "574808": 21, "323708": 21, "012853": 21, "231297": 21, "336565": 21, "064632": 21, "691572": 21, "771898": 21, "755795": 21, "555790": 21, "826524": 21, "377654": 21, "463709": 21, "298825": 21, "384718": 21, "390226": 21, "231304": 21, "293252": 21, "237298": 21, "407236": 21, "208753": 21, "187500": 21, "095703": 21, "326748": 21, "995069": 21, "561226": 21, "689310": 21, "758128": 21, "536836": 21, "751842": 21, "328633": 21, "442843": 21, "317066": 21, "344704": 21, "432572": 21, "222232": 21, "263768": 21, "236682": 21, "413294": 21, "201139": 21, "134615": 21, "112065": 21, "308668": 21, "848588": 21, "496653": 21, "631476": 21, "753268": 21, "488916": 21, "658012": 21, "287518": 21, "452855": 21, "368485": 21, "305532": 21, "549990": 21, "226249": 21, "283597": 21, "255247": 21, "420746": 21, "231887": 21, "174074": 21, "123373": 21, "341781": 21, "936619": 21, "448701": 21, "607144": 21, "780030": 21, "488851": 21, "602057": 21, "247115": 21, "512957": 21, "437562": 21, "307703": 21, "774619": 21, "272419": 21, "290434": 21, "297724": 21, "444755": 21, "256219": 21, "255605": 21, "095412": 21, "440439": 21, "013504": 21, "414357": 21, "610546": 21, "890255": 21, "512341": 21, "571795": 21, "249934": 21, "600437": 21, "716202": 21, "380214": 21, "153991": 21, "348203": 21, "350406": 21, "359122": 21, "605135": 21, "347911": 21, "289157": 21, "086858": 21, "482754": 21, "947506": 21, "316801": 21, "626033": 21, "920290": 21, "583686": 21, "558284": 21, "269568": 21, "595220": 21, "123405": 21, "366314": 21, "195333": 21, "334984": 21, "400108": 21, "395086": 21, "606463": 21, "410411": 21, "271186": 21, "437782": 21, "738454": 21, "033301": 21, "221707": 21, "695304": 21, "084946": 21, "659016": 21, "564570": 21, "292928": 21, "551027": 21, "872629": 21, "374933": 21, "788778": 21, "311137": 21, "351248": 21, "413392": 21, "450814": 21, "372341": 21, "360465": 21, "015837": 21, "396958": 21, "901724": 21, "952949": 21, "620428": 21, "857758": 21, "526792": 21, "436590": 21, "248962": 21, "437627": 21, "522839": 21, "301417": 21, "502103": 21, "274428": 21, "232308": 21, "308740": 21, "295520": 21, "225860": 21, "090909": [21, 125, 126, 128], "995587": 21, "330279": 21, "886270": 21, "834527": 21, "656683": 21, "879530": 21, "525366": 21, "432540": 21, "286967": 21, "518789": 21, "455188": 21, "322412": 21, "449485": 21, "348494": 21, "236520": 21, "295650": 21, "286870": 21, "214488": 21, "873563": 21, "957841": 21, "388632": 21, "875351": 21, "830671": 21, "674438": 21, "940637": 21, "531976": 21, "439182": 21, "316094": 21, "531587": 21, "445144": 21, "340297": 21, "448254": 21, "360742": 21, "249350": 21, "296428": 21, "302875": 21, "213581": 21, "424242": 21, "33": [21, 27, 40, 62, 100], "025266": 21, "409206": 21, "826394": 21, "816610": 21, "645473": 21, "057374": 21, "544352": 21, "409633": 21, "348300": 21, "458590": 21, "384232": 21, "315997": 21, "400205": 21, "328763": 21, "280001": 21, "247244": 21, "280584": 21, "213905": 21, "052632": 21, "34": [21, 33, 40, 50, 60, 62, 88, 89, 90], "847292": 21, "199707": 21, "807311": 21, "791759": 21, "614239": 21, "896800": 21, "520700": 21, "434322": 21, "364986": 21, "516326": 21, "421654": 21, "294775": 21, "432475": 21, "319950": 21, "318913": 21, "210438": 21, "269082": 21, "239209": 21, "000000": [21, 27, 122, 123, 124, 125, 126, 128], "419055": 21, "741241": 21, "908431": 21, "955282": 21, "779803": 21, "225012": 21, "722066": 21, "528898": 21, "528379": 21, "663617": 21, "538099": 21, "322801": 21, "482760": 21, "354683": 21, "398066": 21, "240667": 21, "335632": 21, "288036": 21, "444444": [21, 27], "36": [21, 40, 62, 99], "159110": 21, "644332": 21, "912514": 21, "006085": 21, "814860": 21, "225400": 21, "734929": 21, "505570": 21, "716072": 21, "881734": 21, "582487": 21, "436298": 21, "607565": 21, "509652": 21, "551902": 21, "411350": 21, "418997": 21, "459529": 21, "645161": 21, "37": [21, 40, 45, 48, 59, 60, 62, 125], "304294": 21, "796126": 21, "914522": 21, "095768": 21, "906228": 21, "343434": 21, "856688": 21, "531166": 21, "808380": 21, "997596": 21, "624607": 21, "522742": 21, "600113": 21, "597650": 21, "659275": 21, "439279": 21, "510786": 21, "363636": [21, 125, 126, 128], "movielens_cel_md": 21, "730690894257576": 21, "13369489173373478": 21, "5969960025238406": 21, "143298762540704": 21, "5474864933099358": 21, "595812269230768": 21, "592741884817156": 21, "001726777600432909": 21, "594468662417588": 21, "438": [21, 96, 98], "918": 21, "521": 21, "709": 21, "842": 21, "867": 21, "170": [21, 85, 122, 124], "922": 21, "248": [21, 62], "453": 21, "053": 21, "216": [21, 123], "969": [21, 128], "247": [21, 122], "952": 21, "367": 21, "586": 21, "025": 21, "989": 21, "854": 21, "235": [21, 84, 87, 109, 110, 117, 130], "619": 21, "516": [21, 48], "311": [21, 85, 129], "924": [21, 128], "731": [21, 22, 23, 25], "812": 21, "421": [21, 85, 104, 105], "679": [21, 129], "742": 21, "251": 21, "134": [21, 40], "117": [21, 40, 45, 60, 130], "399": 21, "136": [21, 27, 125], "263": 21, "593": 21, "594": 21, "771": 21, "163": [21, 122, 124], "608": 21, "323": 21, "306": 21, "717": 21, "192": [21, 27], "909": 21, "197": [21, 128], "056": 21, "141": [21, 40], "416": 21, "153": [21, 62, 85, 130], "570": 21, "485": 21, "058": 21, "543": 21, "408": [21, 99], "512": 21, "404": 21, "032": 21, "437": 21, "444": [21, 123], "154": [21, 40, 60, 122, 124], "598": 21, "165": [21, 33], "440": [21, 123], "473": 21, "536": [21, 25, 36, 60], "176": [21, 85, 123], "241": 21, "103": [21, 40, 45, 77, 122, 125], "493": [21, 40], "510": 21, "hick": 21, "raymond": 21, "dustin": 21, "tinglei": 21, "2011": [21, 33, 81, 83, 91, 92, 93, 105], "stata": 21, "605": 21, "hong": [21, 89, 128], "guanglei": 21, "biometr": [21, 48, 128], "alexandria": 21, "va": 21, "usa": 21, "2401": [21, 128], "2415": [21, 128], "kosuk": 21, "luke": 21, "keel": 21, "309": [21, 33, 85, 103, 129], "probabilist": [21, 96, 97, 104], "373": 21, "392": 21, "ilya": 21, "1816": [21, 100, 128], "foundament": [22, 26], "esitm": [22, 26], "supervis": [22, 26, 28, 29], "n0": [22, 23, 25, 60], "mc": [22, 23, 25, 60, 119], "223": [22, 23, 25, 60, 82, 83, 123, 130], "data_behavior": [22, 23, 25], "get_data_simul": [22, 23, 25, 60], "data_target": [22, 23, 25], "hte_tru": [22, 23, 25], "unboundlocalerror": [22, 23], "ipykernel_69115": 22, "2180662469": [22, 23], "227": [22, 23, 122, 124], "229": [22, 23], "referenc": [22, 23], "s1": [22, 25, 60, 62, 128], "s2": [22, 25, 60, 62, 128], "034775": 22, "453145": 22, "167637": 22, "084880": 22, "234459": 22, "553798": 22, "144626": 22, "040543": 22, "956732": 22, "148426": 22, "021139": 22, "095578": 22, "120852": 22, "377594": 22, "323133": 22, "995": [22, 60], "022440": 22, "887551": 22, "797542": 22, "996": [22, 60], "411179": 22, "655833": 22, "722846": 22, "997": [22, 60], "155706": 22, "992197": 22, "140100": 22, "998": [22, 60], "510241": 22, "828438": 22, "167118": 22, "999": [22, 60, 104, 106], "744187": 22, "857147": 22, "458481": 22, "lgbmregressor": [22, 25, 125, 126, 130], "hstack": [22, 26, 45, 62, 77, 122], "hte_s_learn": [22, 26], "1687": 22, "589": 22, "0319": 22, "8354": 22, "5843": 22, "4577": 22, "0791": [22, 100], "2961": [22, 23, 25], "4475": [22, 23, 25], "2863": [22, 23, 25], "4471": [22, 23, 25], "1839": [22, 23, 25], "3869": [22, 23, 25, 130], "238": [22, 23, 25], "bias_s_learn": 22, "variance_s_learn": 22, "2857192464627009": 22, "079505077680185": 22, "toi": 22, "although": [22, 32, 64, 70, 125, 126], "cover": [22, 32], "mu0": [22, 28, 29, 125, 126], "mu1": [22, 28, 29, 62, 125, 126], "hte_t_learn": [22, 28, 125, 126], "glanc": 22, "869": 22, "8733": 22, "6596": 22, "3087": 22, "2298": 22, "5598": 22, "2745": 22, "8211": 22, "bias_t_learn": 22, "variance_t_learn": 22, "29138198450323705": 22, "810391408711312": 22, "overfit": [22, 28], "provabl": [22, 29, 109], "imput": [22, 29], "delta": [22, 29, 33, 88, 90], "tau_1": [22, 29, 33], "tau_0": [22, 29, 33], "s_t0": [22, 29], "s_t1": [22, 29], "r_t0": [22, 29], "r_t1": [22, 29], "unobserv": [22, 29, 120, 132], "origin": [22, 27, 29, 45, 59, 60, 61, 90, 119, 125, 126, 127], "n_t0": [22, 29], "n_t1": [22, 29], "delta0": [22, 29], "delta1": [22, 29], "tau0": [22, 29], "tau1": [22, 29], "hte_x_learn": [22, 29], "9341": 22, "9235": 22, "2944": 22, "4147": 22, "5443": 22, "roughli": [22, 63, 64, 132], "catch": 22, "synthet": [22, 38, 132], "bias_x_learn": 22, "variance_x_learn": 22, "2827518068171628": 22, "7686646616779012": 22, "worst": 22, "ipykernel_69122": 23, "pypi": [23, 134], "pkg": 23, "dev": 23, "colab": 23, "cp38": 23, "manylinux_2_17_x86_64": 23, "manylinux2014_x86_64": 23, "32m3": 23, "31m96": 23, "usr": 23, "dist": 23, "77": [23, 60, 62, 81], "32m77": 23, "31m12": 23, "manylinux2010_x86_64": 23, "571": 23, "32m571": 23, "31m58": 23, "importlib": 23, "0dev0": 23, "57": [23, 60, 62], "zipp": 23, "2344": 23, "612": 23, "7801": 23, "6886": 23, "6297": 23, "2293": 23, "4417": 23, "819": 23, "okai": 23, "bias_grf": 23, "variance_grf": 23, "706857912147952": 23, "198946462195667": 23, "came": [24, 25], "g_0": [24, 25], "u": [24, 25, 64, 87, 117, 130, 133], "manipul": [24, 25], "l_0": [24, 25], "rlearner": [24, 25], "nameerror": [26, 60, 134], "ipykernel_69134": [], "2628946087": [], "hte_r_learn": [24, 25], "ps_learner": [24, 25], "015": [24, 131], "739": 24, "740": 24, "736": 24, "018": 24, "725": [24, 27], "028": [24, 130], "05127254": 24, "08881288": 24, "10304225": 24, "ate_r_learn": 24, "0755": 24, "ipykernel_69139": 25, "1454775972": 25, "942": 25, "943": [25, 100], "958": 25, "951": 25, "957": 25, "932": [25, 129], "950": 25, "944": 25, "683": [25, 122, 123], "584": 25, "659": 25, "705": 25, "677": [25, 129], "667": 25, "642": [25, 27], "669": 25, "551": 25, "4971": 25, "0231": 25, "0514": 25, "0037": 25, "0943": 25, "4128": 25, "1436": 25, "4714": 25, "bias_r_learn": 25, "variance_r_learn": 25, "010664510462813687": 25, "3201771635462656": 25, "amaz": 25, "significantli": [25, 71, 123], "980": [25, 60], "978": 25, "975": 25, "940": 25, "2566": 25, "0408": 25, "8131": 25, "0906": 25, "5665": 25, "7341": 25, "6459": 25, "272": 25, "bias_dr_learn": 25, "variance_dr_learn": 25, "29436318987432813": 25, "011818461500106": 25, "lp_r": 25, "0353": 25, "2368": 25, "0444": 25, "0884": 25, "6845": 25, "6876": 25, "6223": 25, "85": [25, 62], "bias_lp_r_learn": 25, "variance_lp_r_learn": 25, "2909913487561472": 25, "1822936738050482": 25, "incred": 25, "ipykernel_69144": 26, "4157178503": 26, "comparison": [26, 45, 69, 77, 120], "13686218": 26, "52931381": 26, "10841595": 26, "ate_s_learn": 26, "1453": [26, 103, 106, 107], "dislik": 27, "scope": [27, 32], "getcwd": [27, 63, 64, 67, 68, 69, 70, 72, 74, 110, 111, 116, 117, 131], "onlin": [27, 76, 81, 85, 89, 97, 102, 104, 105, 108, 109, 110, 111, 116, 117, 118, 119, 120, 132, 133], "cmab": [27, 82, 83, 130, 131], "_env_realcmab": [27, 82, 83, 130], "env": [27, 82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 107, 110, 111, 116, 117, 130, 131], "get_movielen": [27, 82, 83, 130], "ipykernel_69152": 27, "1573112457": 27, "xs": [27, 82, 83, 88, 97, 102, 104, 105, 129, 130], "mean_ri": [27, 129], "standardized_x": [27, 129], "data_ml": 27, "users_index": 27, "movie_gener": [27, 130], "data_cel": 27, "initi": [27, 45, 48, 50, 59, 60, 62, 64, 67, 68, 69, 74, 75, 76, 79, 83, 84, 87, 107, 110, 117, 119, 124, 128, 130, 131], "concat": [27, 60, 122, 129, 130], "complet": [27, 45, 71, 77, 88, 90, 129], "4220": 27, "2355": 27, "14400": 27, "2918": 27, "16752": 27, "2791": 27, "20195": 27, "2797": 27, "21689": 27, "2321": 27, "393463": 27, "3299": 27, "395410": 27, "892": 27, "396058": 27, "574": [27, 129], "397794": 27, "1812": 27, "400719": 27, "3830": 27, "49563": 27, "data_cel_al": 27, "to_csv": [27, 122, 125, 130], "11057": 27, "25871": 27, "31166": 27, "40383": 27, "303406": 27, "320275": 27, "332011": 27, "382221": 27, "397209": 27, "175": [27, 85, 89, 122, 123, 125], "save": [27, 69, 88, 130, 133], "www": [27, 33], "kaggl": [27, 33, 125, 126, 127], "asjad99": 27, "mimiciii": 27, "center": [27, 125, 126, 127], "databas": [27, 125, 126, 127], "clinic": [27, 32, 33, 80, 109, 125, 126, 127], "61": [27, 59, 60, 62, 125, 126, 127], "532": [27, 125, 126, 127], "admiss": [27, 125, 126, 127], "boston": [27, 125, 126, 127], "teach": [27, 125, 126, 127], "hospit": [27, 125, 126, 127], "demograph": [27, 125, 126, 127], "vital": [27, 91, 92, 93, 125, 126, 127], "lab": [27, 125, 126, 127], "cohort": [27, 125, 126, 127], "sepsi": [27, 125, 126, 127], "meet": [27, 125, 126, 127], "ventil": 27, "particular": [27, 60, 63, 74, 119, 130, 132], "characterist": [27, 132], "physiolog": 27, "whole": [27, 60], "mimic3_sepsis_data": 27, "mimic3_data": [27, 122, 125, 126], "bloc": [27, 122, 123], "icustayid": [27, 71, 122, 123, 125, 126, 128], "charttim": 27, "gender": [27, 81, 89, 109, 130, 131], "elixhaus": 27, "re_admiss": 27, "died_in_hosp": 27, "died_within_48h_of_out_tim": [27, 122, 125, 126, 127], "mortality_90d": 27, "input_tot": 27, "input_4hourli": 27, "output_tot": 27, "output_4hourli": 27, "cumulated_bal": 27, "sofa": [27, 122, 123, 124, 127, 128], "sir": 27, "vaso_input": 27, "iv_input": [27, 122, 123, 124, 125, 126, 128], "7245486000": 27, "17639": 27, "826435": 27, "6527": 27, "0000": 27, "13617": 27, "520": 27, "7090": 27, "884898": 27, "6898241400": 27, "30766": 27, "069028": 27, "383136": 27, "5805732000": 27, "12049": 27, "217303": 27, "976040": 27, "4264269300": 27, "30946": 27, "970000": 27, "1300": 27, "340": 27, "160": [27, 85], "960": [27, 107], "125000": [27, 125, 126, 128], "5707825200": 27, "19793": 27, "588912": 27, "9552": 27, "6830": 27, "540": 27, "2722": 27, "457625": 27, "7214122800": 27, "24524": 27, "747419": 27, "10661": 27, "0483": 27, "360": 27, "4915": 27, "049099": 27, "glucos": [27, 122, 123, 124, 125, 126, 127, 128], "pao2": [27, 122, 125, 126, 127, 128], "pao2_fio2": [27, 122, 123, 124, 125, 126, 127, 128], "mimic3_data_select": 27, "84": [27, 59, 60, 62], "168": [27, 122, 124, 125], "122": [27, 40], "59": [27, 48, 62, 125], "148148": 27, "125": [27, 40, 122, 124], "690": 27, "647482": 27, "110": [27, 40, 122, 123, 125], "727273": 27, "179": [27, 123], "447": [27, 96, 98], "499993": 27, "347": 27, "222222": 27, "4995": 27, "375000": 27, "787683": 27, "206": [27, 122, 123, 125], "005547": 27, "965110": 27, "4996": 27, "333333": 27, "143": [27, 40, 85, 128], "846153": 27, "025000": 27, "4997": 27, "106": [27, 40, 45, 77, 125, 126, 128], "258": 27, "923": 27, "214286": 27, "402531": 27, "4998": 27, "144": [27, 122, 123], "376": [27, 45], "752": [27, 122, 125], "172130": 27, "4999": 27, "113": [27, 60, 123, 125], "269": 27, "999996": 27, "record": [27, 33, 61, 130], "data_cel_select": [27, 125, 126], "oxygen": [27, 125, 126, 127], "fraction": [27, 125, 126, 127], "deliv": [27, 125, 126, 127], "fio2": [27, 125, 126, 127], "organ": [27, 125, 126, 127], "assess": [27, 61, 125, 126, 127], "dysfunct": [27, 125, 126, 127], "iv": [27, 71, 122, 123, 124, 125, 126, 127, 128], "volumn": [27, 125, 126, 127], "fluid": [27, 125, 126, 127], "administ": [27, 125, 126, 127], "addition": 27, "aspect": 27, "3598282": 28, "34648075": 28, "35533324": 28, "ate_t_learn": 28, "3571": 28, "estiamt": 28, "33630057": 29, "31723622": 29, "37261498": 29, "ate_x_learn": 29, "3566": 29, "move": [32, 75], "encount": [32, 82, 83], "scenario": [32, 101, 132], "substanti": [32, 40], "transit": [32, 69, 75, 76, 119, 120], "easier": 32, "ma": [32, 71, 76, 119, 120, 123, 124, 128], "subseteq": [32, 76, 101, 103, 119], "s_": [32, 63, 64, 67, 68, 69, 74, 75, 76, 107, 119, 132], "w_t": [32, 76, 78, 95, 97, 98, 119], "_t": [32, 69, 71, 76, 77, 78, 79, 81, 91, 92, 93, 96, 97, 102, 103, 104, 108, 118, 119], "a_t": [32, 63, 64, 67, 68, 71, 74, 75, 76, 77, 80, 81, 82, 83, 84, 85, 86, 87, 89, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 106, 108, 109, 110, 111, 116, 117, 118, 119, 130, 132], "s_t": [32, 63, 64, 67, 68, 69, 71, 74, 75, 76, 119, 132], "cmia": [32, 76, 119, 120], "y_t": [32, 33, 76, 119], "w_": [32, 76, 96, 97, 119], "tupl": [32, 63, 64, 74, 75, 80, 89, 108, 118, 119, 120], "a_": [32, 45, 61, 63, 64, 67, 68, 69, 74, 75, 76, 77, 78, 79, 84, 87, 88, 89, 90, 95, 97, 99, 100, 102, 103, 108, 109, 110, 117, 118, 119, 132], "equiv": [32, 63, 64, 74, 88, 91, 92, 93, 96], "limit": [32, 40, 50, 60, 64, 69, 71, 74, 87, 117, 119], "pai": [32, 125, 126], "r_t": [32, 63, 67, 68, 71, 74, 75, 80, 81, 82, 84, 85, 86, 87, 89, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 117, 118, 119, 130, 132], "cpl": 32, "restrict": 32, "talk": 32, "cima": 32, "especi": [32, 86, 88, 103, 108, 118, 130, 132], "signific": [32, 40, 63, 71, 123, 125, 126], "effort": 32, "made": [32, 69, 80], "instrument": 32, "proxi": 32, "emploi": [32, 40, 84, 103, 108, 129], "trim": 32, "strict": 32, "ideal": [32, 84, 119], "greater": 32, "depth": 32, "past": [33, 61, 71, 76, 84], "econom": [33, 91, 92, 93, 132], "maker": 33, "sale": [33, 40, 129], "post": [33, 40, 122, 126], "green": 33, "purpl": 33, "orang": 33, "dash": 33, "essens": 33, "parallel": [33, 40], "remain": 33, "untreat": [17, 33, 38], "panel": [33, 36], "att_t": 33, "tau_t": 33, "shortli": 33, "tricki": 33, "diff": 33, "transfer": 33, "dy_t": 33, "foral": [33, 40, 50, 75, 76, 91, 92, 93, 96, 97, 101, 102, 103, 104, 106], "exogen": 33, "won": 33, "nept": 33, "y_1": 33, "y_0": [33, 76, 119], "card": 33, "krueger": 33, "1994": 33, "wage": 33, "employ": 33, "harrywang": 33, "parulpandei": 33, "sandhyakrishnan02": 33, "downloa": 33, "384": 33, "food": 33, "jersei": 33, "pennsylvania": 33, "april": [33, 81, 96, 98], "1992": [33, 128], "stai": [33, 38, 48], "employe": 33, "febuarari": 33, "novemb": [33, 80, 106], "data_employ": 33, "total_emp_feb": 33, "total_emp_nov": 33, "75": [33, 40, 60, 62, 125], "n_pa": 33, "n_nj": 33, "y_pa_feb": 33, "y_pa_nov": 33, "y_nj_feb": 33, "y_nj_nov": 33, "43": [33, 62], "nj": 33, "feb": 33, "g_i": 33, "t_0": [33, 38, 40, 132], "t_1": [33, 64, 75, 76, 132], "g_it_i": 33, "d_": [33, 79], "tr": [33, 40, 64, 123], "y_": [33, 38, 40, 88, 90, 96, 97, 100, 101, 102, 103, 104, 106], "co": [33, 40], "subtract": [33, 132], "lechner": 33, "foundat": [33, 48, 75, 81, 116, 117], "224": [33, 82, 83, 123, 130], "goodman": 33, "bacon": 33, "225": [33, 82, 83, 123, 130], "254": 33, "277": [33, 122, 124], "1716": [36, 40], "1730": 36, "surviv": [37, 60, 124, 126, 128], "dive": [38, 71, 123], "life": 38, "length": [38, 75, 76, 96, 99, 100, 102, 103], "gdp": 38, "countri": [38, 60], "stock": 38, "price": [38, 50, 103, 104, 105, 106], "firm": 38, "chronolog": 38, "aris": 38, "estimand": [38, 69, 74], "ITE": 38, "delta_": 38, "treatement": [38, 124, 128], "ITEs": 38, "stationari": [38, 64, 74, 75, 76, 80], "sc": [38, 132], "unlik": [40, 50, 120], "imbal": 40, "fulfil": 40, "issu": [40, 69, 84, 119], "fund": 40, "reweight": [40, 69], "perspect": [40, 89, 98, 100, 119], "conterfactu": 40, "omega": [40, 45, 63, 64, 69, 74, 77], "sdid": 40, "i0": 40, "ij": 40, "jt": 40, "qquad": 40, "omega_": [40, 77], "abadi": 40, "diamond": 40, "hainmuel": 40, "california": 40, "proposit": 40, "99": [40, 45, 60, 62, 77, 122], "tobacco": 40, "consumpt": 40, "1970": 40, "susanathei": 40, "mcpanel": 40, "examples_from_pap": 40, "smok_outcom": 40, "smoke_x": 40, "smoke_covari": 40, "header": [40, 122, 125, 129], "smoke_a": 40, "smoke_treat": 40, "smoke_r": 40, "smoke_outcom": 40, "linspac": [40, 50, 130], "renam": [40, 122, 124, 128], "89": [40, 62], "124": 40, "120": [40, 77, 122, 124, 125], "155": [40, 128], "102": [40, 45, 77], "114": [40, 62, 85, 123, 130], "132": [40, 45, 59, 122, 124], "1971": 40, "95": [40, 45, 62, 77, 104, 130, 131], "161": [40, 130], "115": [40, 59, 96, 122, 123, 124], "139": 40, "128": 40, "111": [40, 123], "105": [40, 45, 60, 77, 122, 125], "131": 40, "1972": 40, "156": [40, 124], "126": [40, 45, 59, 62, 122, 124], "118": [40, 125, 126, 128], "71": [40, 45, 62, 125], "137": [40, 125, 126], "140": [40, 125], "1973": 40, "119": 40, "72": [40, 62], "1974": 40, "112": [40, 123], "159": [40, 100, 101, 108, 118], "preriod": 40, "element": [40, 80, 96], "t0": [40, 77], "pre_expo_r_ctl": 40, "pre_expo_r_trt": 40, "post_expo_r_ctl": 40, "post_expo_r_trt": 40, "lasso": 40, "clf": [40, 48], "coef_": [40, 130], "intercept_": [40, 130], "03980357": 40, "07157998": 40, "22667637": 40, "02990258": 40, "00037257": 40, "02313041": 40, "09714507": 40, "16905554": 40, "19878875": 40, "06427401": 40, "09209638": 40, "05463154": 40, "post_expo_r_trt_counterfactu": 40, "vline": 40, "ymin": 40, "ymax": 40, "130": 40, "linestyl": 40, "ylabel": [40, 60, 130, 131], "per": [40, 63, 74, 82, 83, 88], "capita": 40, "cigarett": 40, "pack": [40, 63, 64, 67, 68, 69, 70, 72, 74, 110, 111, 116, 117], "legend": [40, 130, 131], "effectli": 40, "longer": [40, 120], "505": 40, "2068": [40, 124], "2069": 40, "2070": 40, "2071": [40, 109], "esti": 40, "mate": 40, "statisticalassoci": 40, "2083": 40, "contrast": [45, 62, 69, 77, 92, 93, 108, 132], "incent": [45, 59, 77, 79], "mainli": [45, 59, 67, 68, 77, 79, 81, 85, 89, 97, 102, 104, 109, 120, 130, 132], "convent": [45, 76, 77, 103], "soon": [45, 69, 77], "multinomi": [45, 59, 61, 77, 79, 104, 105, 106, 108, 118, 131], "constrast": [45, 77], "furthermor": [45, 77, 81, 85, 88, 89, 97, 102, 104, 109], "c_j": 45, "blip": [45, 77], "max_": [45, 60, 68, 75, 76, 77, 79, 82, 83, 86, 87, 95, 97, 98, 99, 100, 102, 103, 104, 105, 106, 117, 119], "psi": [45, 50, 77, 88], "hand": [45, 50, 59, 67, 68, 79, 119, 130], "logist": [45, 60, 69, 74, 82, 83, 88, 95, 97, 104, 105, 111], "substitut": [45, 103, 108, 118], "euqat": 45, "appendix": 45, "bootstrap": [45, 59, 62, 70, 77, 79, 124], "utilz": [45, 77], "boostrap": [45, 59, 77], "resampl": [45, 59, 77, 79], "standard": [45, 59, 62, 63, 64, 69, 70, 74, 77, 79, 82, 86, 88, 90, 92, 98, 99, 100, 103, 105, 106, 107, 111, 124, 132], "cpl13": [45, 48, 50, 59, 60, 77, 79, 124, 128, 131], "disc": [45, 48, 59, 60, 77, 79, 124, 128, 131], "get_data": [45, 59, 61], "target_col": [45, 59, 60, 61], "binary_trt": [45, 59, 61], "2d": 45, "intercept": [45, 59, 60, 62, 79, 95, 97, 99, 102, 104, 105, 130, 131], "newaxi": [45, 62], "model_info": [45, 59, 62, 77, 79, 124, 128, 131], "x_prop": [45, 62, 77], "recenc": [45, 59, 60, 61], "x_q0": [45, 62, 77], "x_c": [45, 62, 77], "action_spac": [45, 59, 62, 77, 79, 124, 128, 131], "phi_": 45, "exp": [45, 62, 88], "gamma_": 45, "j0": 45, "j1": 45, "j2": 45, "attributeerror": [45, 59, 77, 79], "ipykernel_69216": 45, "15241541": 45, "true_prop": [45, 77], "n_b": [45, 59, 62, 77, 79, 124], "boots_fit": [45, 77], "97": [45, 62, 77, 105, 125], "_fit": [45, 77], "fitted_model": [45, 59, 62, 77, 79, 124, 128, 131], "_fit_model": [45, 77], "pseudo_y_prev": [45, 77], "get_pseudo_i": [45, 77], "attribut": [45, 59, 71, 77, 79, 123], "opt_d": [45, 59, 62, 77, 79, 124, 128, 131], "recommend_act": [45, 48, 59, 77, 79, 124, 128, 131], "value_count": [45, 59, 79, 122, 124, 128, 129, 131], "v_hat": [45, 59, 62, 77, 79, 124, 128, 131], "predict_valu": [45, 59, 77, 79, 124, 128, 131], "3389e": 45, "0295e": 45, "3272e": 45, "03": [45, 61, 77, 124, 131], "1025e": 45, "7135e": 45, "7582e": 45, "202": [45, 128], "int64": [45, 59, 62, 79, 122, 124, 126, 128, 129, 131], "18615811062617": 45, "005": 45, "mail": [45, 59, 60, 61], "women": [45, 59, 60, 61, 130], "men": [45, 59, 60, 61, 130], "deviaiton": [45, 59, 62, 77, 79], "amai": [45, 59, 62, 77, 79], "fitted_param": [45, 59, 62, 77, 79], "fitted_valu": [45, 59, 62, 77, 79], "value_avg": [45, 59, 62, 77, 79], "value_std": [45, 59, 62, 77, 79], "param": [45, 59, 62, 77, 79, 131], "predict_value_boot": [45, 59, 77, 79], "value_hat": [45, 59, 62, 77, 79], "133": [45, 50, 122, 125], "07058862299368": 45, "114870661497804": 45, "200": [45, 59, 60, 62, 77, 79, 131], "replic": [45, 59, 130], "37488160184644": 45, "std": [45, 59, 62, 77, 79, 122, 129, 130], "37346454667266": 45, "739458412078504": 45, "placehold": [45, 77, 79], "schult": [45, 77], "institut": [45, 77], "640": [45, 77], "seattl": [45, 77], "symposium": [45, 77], "189": [45, 77], "springer": [45, 77, 80, 81, 109], "york": [45, 77], "ny": [45, 77], "murphi": [45, 59, 77, 79], "royal": [45, 77], "331": [45, 77, 80], "355": [45, 77, 123], "liang": [45, 77, 80, 109], "88": [45, 60, 62, 77, 125, 126, 128], "fan": [45, 77], "46": [45, 62, 77, 102], "925": [45, 77, 128], "close": [48, 63, 69, 74, 86, 119, 129], "behaviour": [48, 69, 74, 103], "share": [48, 64, 69, 74, 88, 89, 97, 102, 104, 119, 133], "min": [48, 50, 60, 84, 129, 130], "neq": 48, "classif": [48, 67, 69, 74], "classifi": [48, 61], "impli": [48, 63, 75, 76, 124, 128], "why": 48, "w_i": 48, "though": 48, "instabl": 48, "svm": 48, "tbd": 48, "owl_simu": 48, "generate_test_cas": [48, 62], "case1": 48, "sigma": [48, 63, 64, 70, 74, 82, 86, 88, 90, 97, 99, 100, 102, 104, 111, 116, 117, 131], "xai": [48, 62], "outcomeweightedlearn": 48, "linearsvc": 48, "svc": 48, "model_select": [48, 128], "gridsearchcv": [48, 128], "cross_val_scor": 48, "cs": [48, 97, 104], "logspac": 48, "param_grid": 48, "dict": [48, 77, 129], "assignment_prob": 48, "your": [48, 60, 133], "notabl": [48, 81], "meantim": [48, 92], "zhao": 48, "yingqi": 48, "107": [48, 122, 123], "1106": 48, "1118": 48, "ying": 48, "regimen": [48, 59, 79], "3776": 48, "3788": 48, "lou": 48, "zhilan": 48, "jun": 48, "shao": 48, "menggang": 48, "74": [48, 62], "506": 48, "stat": 48, "68": [48, 59, 62, 79, 82, 83, 130], "sim": [48, 63, 64, 67, 69, 74, 75, 76, 82, 86, 88, 90, 91, 92, 93, 95, 96, 97, 99, 101, 102, 103, 104, 105, 106, 108, 118, 119, 130], "const": 48, "paid": [50, 132], "domain": [50, 108, 118], "dose": 50, "contin": 50, "discontinu": 50, "i2dr": 50, "idr": 50, "ingredi": 50, "multi": [50, 61, 77, 80, 81, 89, 90, 100, 101, 108, 109, 118, 130, 132], "overcom": 50, "bullet": [50, 64], "densiti": [50, 60, 63, 64, 69, 74, 75], "eqnarrai": [50, 63, 64, 67, 68, 74, 75, 76, 119], "eqn": [50, 63, 64, 67, 69, 70, 74, 75, 76, 88, 96, 97, 102, 104, 108, 118, 119], "almost": [50, 76], "sure": [50, 76], "naiv": 50, "concern": [50, 125, 126, 127], "psi_h": 50, "trade": [50, 69, 76, 85, 91, 92, 93, 98, 109], "decai": [50, 64], "yet": [50, 120], "union": [50, 129], "q_": [50, 60, 77, 79], "dnn": 50, "argmin_": [50, 74], "substack": [50, 67, 68], "gamma_n": 50, "argmax_": [50, 88, 90, 91, 92, 93, 103, 104, 105, 106, 107, 109, 111, 116, 117], "argmax": [50, 130, 131], "value_djq": 50, "warfarin": 50, "deep_jump_learn": 50, "djl_opt": 50, "data_gen": 50, "data_gener": 50, "realdatagener": 50, "file_nam": [50, 125, 126], "real_envir": 50, "djl_partit": 50, "djl_agent": 50, "djlearn_opt": 50, "mlp_max_it": 50, "ipykernel_69234": 50, "799946913": 50, "datetim": [50, 125, 126], "djl": 50, "partit": [50, 128], "033": [50, 106], "067": 50, "167": [50, 79], "333": 50, "minut": 50, "opt_polici": 50, "train_data": 50, "xt": 50, "3333333333333333": 50, "0th": 50, "djl_eval": 50, "pi_evalu": 50, "act_list": 50, "x_max": 50, "org_data": 50, "x_min": 50, "val": [50, 82, 83, 130], "act": [50, 129], "regr_mean": 50, "djlearn_ev": 50, "file": [50, 63, 64, 67, 68, 69, 70, 71, 72, 74, 110, 111, 116, 117, 123, 124, 128, 129, 130, 131, 133], "environ": [50, 67, 80, 81, 85, 89, 91, 92, 93, 108, 109, 118, 125, 126, 130], "omp_num_thread": [50, 125, 126], "calibr": 50, "2111": 50, "08885": 50, "kosorok": [50, 59, 79], "august": 50, "assist": 50, "26th": 50, "sigkdd": 50, "mine": 50, "march": 50, "1243": [50, 60], "1251": 50, "kept": [59, 79], "evolv": [59, 79], "hope": [59, 79], "straightforward": [59, 64, 67, 79, 86, 116, 119], "qlearn": [59, 62, 79, 124, 128, 131], "beta_": [59, 90, 124, 128], "regressionresultswrapp": [59, 79], "0x7fe59064d760": 59, "202956": 59, "239801": 59, "611375": 59, "526133": 59, "152892": 59, "843148": 59, "000549": 59, "007584": 59, "000416": 59, "371": 59, "207": 59, "48792828230138": 59, "0005": [59, 124], "0076": 59, "0004histori": 59, "49": [59, 60, 62], "ipykernel_69263": 59, "3664914869": 59, "mimic3_clip": [59, 79, 124, 128], "regime_sampl": [59, 79], "x_sampl": [59, 79], "a_sampl": [59, 79], "y_sampl": [59, 79], "boot": [59, 79], "v1": [59, 79], "reward_nam": [59, 79], "shold": 59, "set_index": [59, 79, 124, 128], "40675465960962": 59, "22558023415299": 59, "45840507437804": 59, "wang": [59, 60, 71, 79, 80, 100, 101, 108, 109, 118, 123], "zeng": [59, 79], "statistica": [59, 79, 97], "sinica": [59, 79], "901": [59, 79], "todo": [59, 62, 72, 79, 110, 111, 116, 117, 118, 132], "sandwich": 59, "project": 59, "ci": [59, 64, 75, 76, 130, 131], "extendour": 60, "satisfactori": 60, "prolong": 60, "tail": 60, "preval": 60, "heavi": [60, 119, 133], "unstabl": [60, 69], "skew": 60, "median": 60, "moodi": 60, "invert": 60, "cummul": 60, "qunatil": 60, "year": [60, 61, 82, 83, 88, 120], "feasibl": [60, 62, 64, 79, 101, 105, 119, 120], "misspecifi": 60, "pretain": 60, "c_i": 60, "rho_": 60, "beta_1": 60, "fine": 60, "grid": 60, "beta_0": 60, "u_": [60, 87, 109, 117], "1n": 60, "0n": 60, "1i": [60, 77, 78, 79], "0i": 60, "proper": 60, "nelder": 60, "mead": 60, "data_sim": 60, "099183": [], "378686": [], "863998": [], "554794": [], "079151": [], "584181": [], "623858": [], "790925": [], "168116": [], "763942": [], "113611": [], "244854": [], "892514": [], "141471": [], "802501": [], "067782": [], "046976": [], "492633": [], "842005": [], "511072": [], "393355": [], "184507": [], "120187": [], "652197": [], "197235": [], "512423": [], "989282": [], "943434": [], "762223": [], "042247": [], "dr_quantileotr": 60, "quantile_otr": 60, "quantileotr": 60, "x1": 60, "x2": 60, "mocondquant_0": 60, "x_1": 60, "x_2": 60, "mocondquant_1": 60, "ipykernel_69268": [], "1796369087": 60, "api": [60, 82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 130, 133], "smf": 60, "basepolicylearn": 60, "coeffici": [60, 82], "coef_original_scal": 60, "q_est": [60, 62, 123], "dr_qopt": 60, "mopropen": 60, "notbinaryrandom": 60, "termin": [60, 91, 92, 93, 133], "129150": 60, "gradient": [60, 63, 74, 91, 92, 93], "final_simplex": 60, "0401e": 60, "0062e": 60, "3241e": 60, "9385e": 60, "9699e": 60, "9649e": 60, "9516e": 60, "0098e": 60, "7645e": 60, "9178e": 60, "9988e": 60, "6791e": 60, "1197": 60, "fun": 60, "119701027689532": 60, "messag": 60, "nfev": 60, "nit": 60, "success": 60, "0000e": 60, "3468e": 60, "7854e": 60, "06": [60, 100, 124], "sklift": 60, "return_x_y_t": 60, "raw": 60, "history_seg": 60, "zip_cod": [60, 61, 129], "newbi": [60, 61], "142": [60, 122, 125], "surburban": 60, "phone": [60, 61], "350": [60, 85], "329": 60, "08": [60, 124], "rural": [60, 61], "web": [60, 61, 81, 96, 108, 109, 118], "180": [60, 128], "750": [60, 122, 125], "675": 60, "83": [60, 62, 130], "urban": [60, 61], "63995": 60, "63996": 60, "63997": 60, "63998": 60, "552": 60, "multichannel": [60, 61], "63999": 60, "472": 60, "82": [60, 62, 80, 109], "64000": 60, "578": [60, 61, 130], "inplac": [60, 122, 124, 128], "get_dummi": [60, 129], "prefix": [60, 129], "axi": [60, 62, 122, 129, 130, 131, 132], "anymor": 60, "zip_code_rur": 60, "channel_multichannel": 60, "data_r": 60, "zip_code_surburban": [60, 61], "zip_code_urban": [60, 61], "channel_phon": [60, 61], "channel_web": [60, 61], "217": [60, 123], "267": [60, 130], "297": 60, "264": 60, "332": 60, "451": [60, 85], "265": 60, "63466": 60, "63552": 60, "63743": 60, "210": [60, 122, 124], "63876": 60, "215": 60, "63883": 60, "239": 60, "70": [60, 62, 82, 83, 130], "exceed": 60, "502953": 60, "1895e": 60, "7227e": 60, "4110e": 60, "8883e": 60, "3248e": 60, "6189e": 60, "4630e": 60, "8951e": 60, "8789e": 60, "1688e": 60, "1876e": 60, "7185e": 60, "4111e": 60, "9113e": 60, "3260e": 60, "6160e": 60, "5493e": 60, "8964e": 60, "8975e": 60, "1777e": 60, "1816e": 60, "7171e": 60, "4095e": 60, "8872e": 60, "3259e": 60, "6174e": 60, "7327e": 60, "8731e": 60, "9187e": 60, "1762e": 60, "1882e": 60, "7222e": 60, "4113e": 60, "8993e": 60, "3252e": 60, "6171e": 60, "6759e": 60, "9012e": 60, "9038e": 60, "1803e": 60, "1924e": 60, "7234e": 60, "4088e": 60, "8863e": 60, "3250e": 60, "6158e": 60, "4646e": 60, "9095e": 60, "8690e": 60, "2013e": 60, "1900e": 60, "7211e": 60, "4096e": 60, "8999e": 60, "3246e": 60, "6178e": 60, "3607e": 60, "9148e": 60, "9045e": 60, "1516e": 60, "1880e": 60, "9149e": 60, "6187e": 60, "4407e": 60, "9451e": 60, "8686e": 60, "1759e": 60, "1875e": 60, "7196e": 60, "4083e": 60, "9025e": 60, "6157e": 60, "5918e": 60, "9206e": 60, "8949e": 60, "1680e": 60, "1872e": 60, "7252e": 60, "4081e": 60, "8846e": 60, "3243e": 60, "6168e": 60, "4315e": 60, "8960e": 60, "8996e": 60, "1701e": 60, "1925e": 60, "7192e": 60, "4085e": 60, "8711e": 60, "3264e": 60, "6172e": 60, "5903e": 60, "9406e": 60, "8946e": 60, "1745e": 60, "1889e": 60, "7195e": 60, "4101e": 60, "8838e": 60, "3258e": 60, "6177e": 60, "4543e": 60, "9190e": 60, "8917e": 60, "181": [60, 128], "5661e": 60, "6834e": 60, "patch": 60, "facecolor": 60, "blue": 60, "xlabel": 60, "r1": 60, "titl": 60, "histogram": [60, 125, 126], "xlim": 60, "ylim": 60, "face": 60, "_c": 60, "_j": [60, 64, 88, 89, 90], "qdr_qope": 60, "mixtur": 60, "mdn": 60, "gbdt": 60, "futher": 60, "quanatil": 60, "dr_quantileop": 60, "quantileop": 60, "qope_est": 60, "927600463556344": 60, "5961404868027": 60, "lan": 60, "ben": 60, "sherwood": 60, "523": 60, "1254": 60, "erica": 60, "em": 60, "nema": 60, "dean": 60, "ru": 60, "bioscienc": 60, "243": 60, "week": 61, "merchandis": 61, "compris": [61, 132], "nine": 61, "dollar": 61, "suburban": 61, "ident": [61, 71, 82, 86, 88, 97, 99, 102, 104, 105, 107, 110, 111, 116, 117, 123, 130, 131], "flase": 61, "blog": 61, "minethatdata": 61, "2008": [61, 103], "phi1": 62, "phi2": 62, "psi1": 62, "psi2": 62, "random_binari": 62, "450": [62, 79], "a1": [62, 77, 79, 124], "binomi": [62, 97, 131], "60": [62, 131], "a2": [62, 77, 79, 124], "mu2": 62, "y_opt": 62, "opt_tru": 62, "optimal_a": 62, "optimal_v": 62, "250": 62, "1108": 62, "575955081366": 62, "estimate_value_boot": 62, "estimated_contrast": [62, 77], "estimated_prop": 62, "prop": 62, "estimate_valu": 62, "ipykernel_69273": 62, "1171830641": 62, "a0": 62, "232": 62, "8969": 62, "9788": 62, "s1a1": 62, "del": 62, "1102": 62, "524126394967": 62, "554474056899934": 62, "379": 62, "334892": 62, "318229": 62, "628596": 62, "027810": 62, "313279": 62, "716134": 62, "729627": 62, "050612": 62, "335": 62, "294202": 62, "253088": 62, "460437": 62, "091607": 62, "664498": 62, "409741": 62, "410791": 62, "090007": 62, "200070": 62, "071281": 62, "474": 62, "508450": 62, "375403": 62, "517774": 62, "092061": 62, "a_est": 62, "c0": 62, "c1": 62, "vhat": 62, "q0": [62, 79, 124, 128], "q1": [62, 79, 123, 124, 128], "opt_v": 62, "rep": [62, 123, 130, 131], "51": [62, 128], "69": [62, 82, 83, 125, 130], "73": [62, 125], "76": [62, 103, 104, 106, 108, 125], "78": [62, 103, 104, 106, 108], "79": [62, 125], "86": [62, 122], "87": 62, "2674": 62, "9966": 62, "718": 62, "432": 62, "9964": 62, "1119": 62, "7158350462053": 62, "366": [62, 107], "5116": 62, "157": 62, "1218": [62, 129], "7812": 62, "0755e": 62, "4913e": 62, "3333e": 62, "8864e": 62, "1197e": 62, "0288e": 62, "5741e": 62, "1112": 62, "2353635304949": 62, "1120": 62, "4987706735005": 62, "10000": [62, 86], "decent": 63, "short": [63, 69, 71, 120], "op": [60, 63, 67, 69, 71, 74, 75, 76, 132], "fqe": [63, 67, 68, 74], "integr": [63, 74, 130], "bellman": [63, 67, 68, 74, 75, 119], "bellman_q": [63, 67, 74, 75, 119], "wise": [63, 69, 74, 130], "stepi": [63, 69, 74], "stepdr": [63, 74], "i_t": [63, 69, 74, 96], "besid": [63, 67, 68, 69, 74, 119], "recurs": [63, 74, 75], "debia": [63, 64, 74], "reflect": [63, 69, 74, 76, 81, 85, 89, 109, 130], "mi": [63, 64, 74], "suffer": [63, 74, 125, 126], "huge": [63, 74, 119], "avoid": [63, 64, 69, 74, 129], "widetild": [63, 69, 74], "drl": [63, 64, 74], "margin": [63, 64, 69, 74], "infti": [63, 64, 67, 68, 69, 71, 74, 75], "p_t": [63, 64, 69, 74], "p_b": [63, 69, 74], "recal": [63, 64, 69, 70, 74, 119, 120], "manner": [63, 74], "tini": [63, 64, 74], "textrm": [63, 64, 70, 71, 74, 124, 128], "sqrt": [63, 74, 83, 87, 107, 117], "weakli": [63, 69, 74], "lower_bound": [63, 70, 74], "proven": [63, 74], "speak": [63, 64, 74], "publish": [63, 64, 67, 68, 69, 70, 72, 74, 110, 111, 116, 117], "hide": [63, 64, 67, 68, 69, 70, 72, 74, 110, 111, 116, 117], "filenotfounderror": [63, 64, 67, 68, 69, 70, 71, 72, 74, 110, 111, 116, 117, 129, 131], "ipykernel_69278": 63, "2982377520": [63, 67, 68, 72], "errno": [63, 64, 67, 68, 69, 70, 71, 72, 74, 110, 111, 116, 117, 129, 131], "directori": [63, 64, 67, 68, 69, 70, 71, 72, 74, 110, 111, 116, 117, 129, 131], "eqn_omega": [63, 74], "mini": [63, 74], "solvel": [63, 74], "sup_": [63, 74], "simplifi": [63, 74, 75, 91, 92, 93], "reproduc": [63, 74], "hilbert": [63, 74], "rkh": [63, 74], "outer": [63, 74], "descent": [63, 74, 91, 92, 93, 119], "approxim": [63, 69, 74, 88, 90, 95, 97, 99, 104, 105, 132], "still": [64, 69, 74, 88, 120], "slow": 64, "wald": [64, 70, 91, 92], "nomin": 64, "coverag": 64, "weaker": 64, "deeper": 64, "new_drl_term": 64, "dirac": 64, "p_": [64, 74, 91, 92, 93], "event": 64, "numer": [64, 67, 68, 81, 85, 89, 108, 109, 118, 130], "debiasterm": 64, "tripli": 64, "ci_tr": 64, "z_": [64, 70], "nuisans": 64, "i_1": 64, "t_": 64, "disjoint": 64, "t_2": 64, "counterpart": [64, 69], "arbitrari": 64, "ipykernel_69284": 64, "3779975037": [64, 69, 70, 74], "breakthrough": 64, "spirit": 64, "uncorrel": 64, "hoeffd": 64, "decomposit": [64, 71], "degener": 64, "conceptu": [67, 69], "contract": [67, 68, 119], "ell": [67, 68, 119], "until": [67, 68, 69, 88, 90, 103, 104, 105, 106, 107, 119], "ipykernel_69291": 67, "fqi": [68, 119], "ipykernel_69296": 68, "vanilla": 69, "prod_": 69, "immedi": [69, 71, 75, 76, 123], "bias": 69, "exponenti": 69, "forward": 69, "stationar": [69, 75], "sa": [69, 74], "rather": [69, 76], "understood": 69, "trick": [69, 77], "omit": 69, "ipykernel_69301": 69, "principl": [69, 74], "neglig": [69, 71, 74, 123], "harri": [69, 74], "ergod": [69, 74], "chain": [69, 74], "eventu": [69, 74, 130], "mix": [69, 74, 102], "ref": [70, 74], "sec": [70, 74], "adopt": [70, 97], "tighter": 70, "concentr": [70, 71, 101], "inequ": 70, "curse_horizon": [70, 74], "explicitli": [70, 92, 93, 97, 102, 104], "kallus2019effici": [70, 74], "eqref": [70, 74], "ci_drl": 70, "upper": [70, 83, 85, 87, 91, 92, 93, 107, 117, 130, 131], "ipykernel_69306": 70, "mobil": [71, 80], "devis": 71, "encompass": 71, "multipli": [71, 123], "pi_e": 71, "pi_0": 71, "dento": 71, "lim_": 71, "id": [71, 104, 105, 106, 122], "dde": [71, 123], "dme": [71, 123], "ii": [71, 76, 109, 120], "m_t": [71, 77], "iii": [71, 109], "r_1": 71, "depict": [71, 132], "s_1": [71, 76, 119], "ipykernel_69311": 71, "2351773156": 71, "mimic3": [71, 122], "mimic3_mrl_data_dict_v2": [71, 122, 123], "mimic3_mrl": [71, 123], "mrl_df": [71, 122, 123], "mimic3_mrl_df_v2": [71, 122, 123], "died_within_48h": [71, 122, 123, 124, 128], "1006": [71, 122, 123, 125, 126, 128], "me_mdp": [71, 123], "na": [71, 110, 111, 116, 117], "longleaf": [71, 110, 111, 116, 117], "rhel8": 71, "anaconda": 71, "ood": 71, "mcmc": [71, 123, 128], "ratio_ndim": [71, 123], "scaler": [71, 123], "q_set": [71, 123], "product_tensor": [71, 123], "include_intercept": [71, 123], "penalti": [71, 123], "min_l": [71, 123], "t_dependent_q": [71, 123], "l2penalti": [71, 123], "spline": [71, 123], "dimems": [71, 123], "018100205548084617": 71, "006066387157097036": 71, "00486632802292234": 71, "0001815880750934009": 71, "017081734489003318": 71, "est_id": [71, 123], "ide_s": [71, 123], "ime_s": [71, 123], "dde_s": [71, 123], "dme_s": [71, 123], "te_s": [71, 123, 124], "00586890111356167": 71, "002110278954333155": 71, "002770561709397491": 71, "0010678186846428818": 71, "005821662648170317": 71, "dierct": [71, 123], "ind": [71, 122, 123, 129], "inm": [71, 123], "dnde": [71, 123], "nddnme": [71, 123], "tabl": [71, 85, 123, 124, 128], "dnme": [71, 123], "0181": [71, 123], "0059": [71, 123], "0061": [71, 123], "0021": [71, 123], "0049": [71, 123], "0028": [71, 123], "0002": [71, 123, 124], "0011": [71, 123], "0171": [71, 123], "0058": [71, 123], "insignific": [71, 123], "conclud": [71, 123], "wu": [71, 123], "2301": [71, 123], "13348": [71, 123], "ipykernel_69316": 72, "ipykernel_69321": 74, "textit": 74, "citep": 74, "jiang2016doubl": 74, "farajtabar2018mor": 74, "uehara2019minimax": 74, "rotnitzky1995semiparametr": 74, "carefulli": [74, 87, 119], "thomas2016data": 74, "our_method": 74, "superior": [74, 88], "gain": [74, 130], "tang2019doubl": 74, "upon": [74, 81, 132], "vspace": 74, "1cm": 74, "worthi": 74, "denomin": 74, "modif": 74, "throw": 74, "awai": [74, 93], "geometr": [74, 97, 103, 104, 106], "2cm": 74, "mean_": 74, "proof": 74, "cramer": 74, "rao": 74, "bickel1993effici": 74, "van2000asymptot": 74, "liu2018break": 74, "ineffici": [74, 86, 87, 90], "mass": 75, "enter": 75, "throughout": [75, 125, 126], "report": 75, "readi": 75, "t_n": [75, 76], "uniformli": [75, 76], "def_valu": [75, 76], "benefit": [75, 76], "_l": [75, 76], "_u": [75, 76, 123], "opo": [75, 76], "repeatedli": [76, 89], "perspectii": 76, "implicitli": 76, "writ": 76, "ground": [76, 119], "literautr": 76, "subset": [76, 96, 99, 100, 101, 102, 103, 108, 118, 119, 125, 126, 127], "had": [76, 119], "cup_": [76, 119], "determinist": [76, 88, 91, 92, 93, 97, 102, 103, 104, 108, 118], "homogen": 76, "central": [76, 80, 85, 109], "statioanri": 76, "shall": 76, "wors": 76, "ca": 76, "sra": 76, "s_j": 76, "a_j": 76, "y_j": 76, "markovobserv": 76, "robserv": 76, "interchang": 76, "h_": [77, 78, 79, 132], "ti": [77, 78, 79], "till": [77, 78, 79], "q_t": [77, 119], "h_t": 77, "v_": [77, 103, 104, 107], "d_t": 77, "backward": [77, 79], "previous": [77, 82, 83, 84, 86, 87, 88, 90], "eqaut": 77, "accordingli": [77, 82, 86, 87, 98, 100, 106, 111, 116, 117], "m_k": 77, "h_ti": 77, "datamdp_feas": [77, 79], "txt": [77, 79, 129], "sep": [77, 79, 129], "cd4_0": [77, 79], "cd4_6": [77, 79], "cd4_12": [77, 79], "a3": [77, 79, 124], "ipykernel_69336": 77, "2644300625": 77, "5872e": 77, "0493e": 77, "9347e": 77, "2010e": 77, "568": 77, "1057": 77, "8412e": 77, "2479e": 77, "1162": 77, "4662578531918": 77, "3156513295758": 77, "559003921896037": 77, "245571": 77, "595014": 77, "143433": 77, "440232": 77, "3966192806022": 77, "626837283714682": 77, "omega_t": 77, "w_1": 78, "w_2": 78, "multistag": 79, "prepar": [79, 108], "reset_index": [79, 122, 125], "0x7ff75da7df10": 79, "0x7ff75da7dc40": 79, "0x7ff738047760": 79, "q2": [79, 123], "898024": 79, "102009": 79, "116478": 79, "002859": 79, "171": 79, "676661": 79, "454044": 79, "288382": 79, "921595": 79, "015938": 79, "553900": 79, "477566": 79, "551396": 79, "334465": 79, "182": [79, 122, 125, 128, 130], "312429": 79, "703112": 79, "550": 79, "1113": [79, 99, 101], "3004201781757": 79, "ipykernel_69344": 79, "2461346363": 79, "BE": 79, "THE": 79, "AS": 79, "THAT": 79, "OF": 79, "979": 79, "4518636939476": 79, "1558584708713": 79, "2312785208211094": 79, "accuraci": 79, "financ": [80, 85, 109, 132], "slot": 80, "casino": 80, "gambler": 80, "plai": [80, 81, 85, 87, 89, 91, 92, 93, 101], "earn": 80, "payout": 80, "produc": 80, "divid": [80, 132], "adversari": 80, "pacakg": 80, "distinct": 80, "laern": 80, "durand": [80, 109], "achilleo": [80, 109], "iacovid": [80, 109], "strati": [80, 109], "mitsi": [80, 109], "pineau": [80, 109], "mous": [80, 109], "novo": [80, 109], "carcinogenesi": [80, 109], "healthcar": [80, 85, 89, 109], "zha": [80, 109], "portfolio": [80, 109], "twenti": [80, 109], "fourth": [80, 109], "joint": [80, 109], "xu": [60, 80, 109], "811": [80, 109], "821": [80, 109], "bouneffouf": [80, 81, 85, 109], "bouzeghoub": 80, "gan\u00e7arski": 80, "awar": 80, "berlin": [80, 81], "heidelberg": [80, 81], "primarili": 81, "profil": 81, "occup": [81, 89, 109, 130, 131], "season": 81, "temperatur": 81, "aid": 81, "mab": [81, 84, 86, 87, 89, 109], "tast": 81, "film": [81, 129], "ultim": [81, 85, 89, 96, 101, 103, 108, 109, 130], "lipschitz": 81, "linucb": [81, 109, 131, 132], "lint": [81, 109, 130, 131, 132], "static": [81, 88, 97, 102, 133], "nonstationari": 81, "1m": [81, 85, 89, 108, 109, 130], "highest": [81, 84, 85, 86, 87, 89, 96, 97, 98, 99, 100, 102, 108, 109, 110, 111, 116, 117, 130], "colleg": [81, 82, 83, 88, 89, 109, 129, 130], "technician": [81, 89, 109, 129, 130, 131], "academ": [81, 89, 109, 129, 130], "bernoulli": [81, 85, 89, 96, 97, 98, 101, 102, 111, 116], "chu": [81, 83, 109], "reyzin": [81, 83], "schapir": [81, 83, 109], "june": [81, 82, 83, 95, 96, 99, 101, 103, 104, 106, 108, 111], "payoff": [81, 82, 83, 109, 111], "fourteenth": [81, 83], "208": [81, 83, 122, 124], "jmlr": [81, 83], "workshop": [81, 83], "agraw": [81, 82, 103, 104, 105, 106, 107, 108, 109, 111], "goyal": [81, 82, 103, 104, 106, 107, 108, 109, 111], "thompson": [81, 82, 85, 86, 89, 91, 92, 93, 95, 96, 97, 98, 100, 101, 102, 103, 104, 105, 106, 108, 111, 116, 117, 118, 132], "127": [81, 82, 109, 111, 125, 126, 128], "135": [81, 82, 85, 109, 111], "kveton": [81, 82, 88, 89, 90, 95, 96, 99, 101, 108, 109, 111, 118], "zaheer": [81, 82, 88, 89, 90, 95, 109, 111], "szepesvari": [81, 82, 89, 90, 95, 96, 108, 109, 111, 118], "ghavamzadeh": [81, 82, 89, 95, 109, 111], "boutili": [81, 82, 89, 90, 95, 109, 111], "2066": [81, 82, 95, 109, 111], "2076": [81, 82, 95, 109, 111], "rish": [81, 85, 109], "10040": [81, 85, 109], "slivkin": [81, 85, 109], "286": 81, "hazan": 81, "megiddo": 81, "513": 81, "langford": [81, 91, 92, 93, 109], "articl": [81, 109], "19th": [81, 109], "670": [81, 109], "auer": [81, 84, 87, 109, 110, 117], "cesa": [81, 84, 87, 109, 110, 117], "bianchi": [81, 84, 87, 109, 110, 117], "freund": 81, "nonstochast": 81, "multiarm": [81, 84, 87, 109, 110, 117], "siam": 81, "scalabl": [82, 83, 88, 90, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 132], "ucb": [82, 83, 85, 95, 98, 99, 100, 105, 106, 107, 109, 117, 131], "suscept": [82, 95, 99, 105], "avial": [82, 108, 111, 118], "consdier": [82, 111], "ts": [82, 83, 85, 88, 89, 90, 97, 98, 100, 102, 104, 105, 106, 109, 111, 131, 132], "domian": [82, 86, 111, 116], "thecorrespond": [82, 111], "posterior": [82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 109, 111, 116, 130], "greatest": [82, 86, 98, 111, 116], "updat": [82, 83, 84, 86, 87, 88, 90, 92, 95, 97, 98, 99, 100, 102, 104, 105, 106, 107, 110, 111, 116, 117, 119, 129, 132, 133, 134], "distirbut": [82, 86, 98, 100, 106, 111, 116], "rewad": [82, 86, 98, 100, 106, 111, 116], "cpl4": [82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 107, 130, 131], "theano": [82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 130], "configdefault": [82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 130], "unabl": [82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 130], "gpu": [82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 130], "degrad": [82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 130], "cxx": [82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 130], "empti": [82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 130], "string": [82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 130], "bla": [82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 130], "imit": [82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106], "_env": [82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 130], "single_contextual_env": [82, 83, 130], "eoferror": [82, 83, 130], "ipykernel_69354": 82, "1670608188": [82, 83], "_util_onlin": [17, 82, 83, 130], "wrapper": [82, 83, 129, 130], "221": [82, 83, 123, 130], "siev": [82, 83, 130], "222": [82, 83, 123, 130], "setattr": [82, 83, 130], "func": [82, 83, 123, 129, 130], "_autoarg": [82, 83, 130], "leave_drama": [82, 83, 130], "dat": [82, 83, 129, 130], "leave_dram": [82, 83, 130], "data_dir": [82, 83, 130, 134], "fp": [82, 83, 129, 130], "ran": [82, 83, 130], "deviat": [82, 86, 88, 90, 99, 100], "prior_theta_u": [82, 111, 130, 131], "prior_theta_cov": [82, 111, 130, 131], "covarainc": [82, 86], "lints_gaussian_ag": [82, 90, 111], "lints_gaussian": [82, 111, 130, 131], "get_phi": [82, 83, 88, 130, 131], "take_act": [82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 107, 110, 111, 116, 117, 130, 131], "get_reward": [82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 107, 110, 111, 116, 117, 130, 131], "receive_reward": [82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 107, 110, 111, 116, 117, 130, 131], "feature_info": [82, 83, 88, 130], "old": [82, 83, 88], "retrain_freq": [82, 83, 95, 111], "glm": [82, 83, 109, 132], "lints_glm_ag": 82, "lints_glm": 82, "specifci": 83, "gaussain": 83, "theta_a": [83, 84, 86, 110], "u_a": [83, 87, 117], "theta_": [83, 84, 86, 95, 96, 97, 98, 99, 101, 103, 106, 110, 111, 116, 124], "ipykernel_69364": 83, "exploration_t": [83, 131], "linucb_gaussian_ag": 83, "linucb_gaussian": [83, 131], "linucb_glm_ag": 83, "linucb_glm": 83, "domin": [84, 128], "eploit": 84, "epsilon_t": [84, 110], "epsilon_": [84, 88, 90, 109, 110], "pull": [84, 87, 88, 110, 117, 130], "c_a": [84, 87, 110, 117], "decrease_ep": [84, 110], "specfi": [84, 110], "epsilon_greedi": 84, "_env_realmab": [84, 86, 87], "single_gaussian_env": [84, 86, 87, 110, 111, 116, 117, 131], "greedy_ag": [84, 110], "single_bernoulli_env": [84, 86, 87, 111, 116], "fischer": [84, 87, 109, 110, 117], "256": [84, 87, 109, 110, 117], "satisf": [85, 96], "tackl": [85, 109], "preprocess": [85, 89], "045": [85, 130], "288": 85, "204": [85, 128], "096": 85, "312": [85, 129], "287": [85, 122, 130], "076": 85, "313": [85, 129], "305": 85, "278": 85, "455": 85, "553": 85, "420": 85, "07272": [85, 109], "Be": 86, "uncertainti": [86, 87], "dilemma": [86, 109, 111, 116], "greedili": [86, 87, 97, 102, 104, 109, 111, 116, 117, 130], "nearli": [86, 109, 111, 116], "manual": [86, 116, 133], "r_0": 86, "reward_typ": [86, 116, 131], "u_prior_mean": [86, 100, 116, 131], "u_prior_cov": [86, 116, 131], "ts_gaussian_ag": [86, 116], "prior_phi_beta": [86, 116], "ts_bernoulli_ag": [86, 116], "russo": [86, 108, 109, 116, 117, 118], "kazerouni": [86, 108, 109, 116, 117, 118], "osband": [86, 108, 109, 116, 117, 118], "wen": [86, 95, 96, 99, 101, 108, 109, 116, 117, 118], "tutori": [86, 96, 101, 102, 103, 104, 108, 109, 116, 117, 118, 130, 133], "0203": [86, 109], "lattimor": [86, 109], "szepesv": [86, 109], "ari": [86, 109], "cambridg": [86, 109], "radiu": [87, 109, 117], "2log": 87, "ucb1": [87, 109, 131, 132], "log": [87, 117, 119, 130], "ucb_ag": [87, 107, 117], "hierarch": [88, 89, 97, 102, 104], "alignedat": [88, 90, 97, 102, 104], "inter": [88, 96, 97, 101, 102, 103, 104, 132], "mu_": [88, 89, 90, 124], "hierachical_model": 88, "explicit": [88, 90, 97, 104], "pymc3": [88, 90, 97, 104, 105], "mathmet": 88, "simultan": [88, 97, 102, 104], "meta_bandit": [88, 90], "mtts_gaussian": 88, "_env_realmultitask": [88, 90], "multitask_env": [88, 90], "episod": [88, 90], "preced": [88, 90], "concurr": 88, "theta_prior_mean": 88, "theta_prior_cov": 88, "delta_cov": 88, "approximate_solut": 88, "finish": [88, 90], "update_freq": [88, 90, 97, 102, 104, 105, 107], "mtts_gaussian_ag": 88, "mtts_agent": 88, "posterior_u": [88, 90, 116], "posterior_cov_diag": [88, 90], "mtts_binari": 88, "phi_beta": [88, 90, 97, 104, 107, 110, 111, 116], "mtts_binary_ag": 88, "posterior_alpha": [88, 90, 116], "posterior_beta": [88, 90, 116], "29655": [88, 89], "29668": [88, 89], "basu": [88, 89, 90], "szepesv\u00e1ri": [88, 89, 90], "28029": [88, 89, 90], "28041": [88, 89, 90], "acceler": 89, "arbitrati": 89, "decsion": 89, "lack": [89, 132], "integ": [89, 108, 118], "a_k": 89, "r_k": 89, "konobeev": [89, 90], "hsu": [89, 90], "mladenov": [89, 90], "5884": [89, 90], "5893": [89, 90], "7724": 89, "7741": 89, "maintain": [90, 119], "demonstr": 90, "categor": [90, 132], "accommod": [90, 99], "meta_ts_gaussian": 90, "sigma_0": 90, "sigma_q": 90, "meta_ts_gaussian_ag": 90, "meta_ts_ag": 90, "episode_finish": 90, "meta_post": 90, "candid": [90, 95, 97, 98, 99, 100, 102, 104, 105, 106], "candi_mean": 90, "entri": [90, 96], "meta_ts_binari": 90, "meta_ts_binary_ag": 90, "ongo": [91, 92, 93], "crucial": [91, 92, 93], "exposit": [91, 92, 93], "link": [91, 92, 93, 133], "dud\u00edk": [91, 92, 93], "suvta": [91, 92, 93], "dr_est": [91, 92, 93], "2110": [91, 92, 93], "15501": [91, 92, 93], "240": [91, 92, 93, 122], "255": [91, 92, 93], "534": [91, 92, 93], "708": [91, 92, 93], "719": [91, 92, 93], "1103": [91, 92, 93], "4601": [91, 92, 93], "dream": 92, "architectur": [92, 120], "tripl": 92, "x_t": 92, "buffer": [92, 119], "pi_b": 92, "pi_t": 92, "histor": [92, 93, 120], "kappa_t": [92, 93], "pr": [92, 93], "kappa": [92, 93], "overlap": 93, "zong": [95, 96], "laplac": 95, "mid": [95, 97, 98, 99, 100, 102, 103, 104, 105, 106, 109, 117], "inroduct": [95, 97, 98, 99, 100, 102, 104, 105, 106], "cascad": [95, 97, 98, 108, 118, 132], "structured_bandit": [95, 97, 98, 99, 100, 102, 104, 105, 106, 107], "_env_realcascad": [95, 97, 98], "cascading_env": [95, 97, 98], "itm": [95, 97, 98, 99, 100, 102, 104, 105, 106], "considerd": [95, 99, 102], "lints_ag": [95, 99, 105], "fisrt": [95, 99, 102], "restatur": [95, 97, 98, 99, 100, 102, 104, 105, 106], "1301": 95, "2087": 95, "1123": 95, "unfortun": [95, 97, 98], "ni": [95, 96], "sung": [95, 96], "ke": [95, 96], "1603": [95, 96], "05359": [95, 96], "sort": 96, "slate": [96, 101, 103, 106], "f_r": [96, 97, 102, 104, 108, 118], "bottom": [96, 108], "she": 96, "latent": 96, "visibl": 96, "theta_i": [96, 97, 98, 100, 101, 102, 103, 104, 105, 106], "mathmat": 96, "model_cascad": [96, 97], "permut": 96, "ts_cascad": 96, "cascadelint": [96, 132], "mtss_cascad": 96, "chuklin": 96, "rijk": 96, "synthesi": 96, "lectur": 96, "retriev": [96, 108, 130], "2202": [96, 97, 101, 102, 103, 104, 108], "13227": [96, 97, 101, 102, 103, 104, 108], "ashkan": [96, 99, 101, 108, 118], "767": [96, 108, 118], "776": [96, 106, 108, 118], "cheung": [96, 98], "tan": [96, 98], "zhong": [96, 98], "22nd": [96, 98], "mtss": [97, 102, 104, 132], "general_hierach": [97, 102, 104], "mtt": [97, 102, 104], "subsum": [97, 102, 104, 108, 118], "full": [97, 102, 132], "enjoi": [97, 104], "conjug": [97, 98, 104, 106, 116], "facilit": [97, 102, 104], "deploy": [97, 102, 104], "gamma_prior_mean": [97, 102, 104, 105], "gamma_prior_cov": [97, 102, 104, 105], "coverainc": [97, 104, 105], "n_init": [97, 104, 105, 107], "draw": [97, 104, 105], "mtss_agent": [97, 102, 104], "were": [60, 97], "diverg": 97, "tune": 97, "target_accept": 97, "reparameter": 97, "2189": 97, "1610": 97, "1206": 97, "forcina": 97, "franconi": 97, "rivista": 97, "di": [97, 122, 123, 125, 126, 128], "applicata": 97, "salvati": [97, 104], "wiecki": [97, 104], "fonnesbeck": [97, 104], "peerj": [97, 104], "e55": [97, 104], "doi": [97, 104], "7717": [97, 104], "u_prior_alpha": [98, 106], "u_prior_beta": [98, 106], "ts_agent": [98, 100, 106], "2690": 98, "reach": 99, "kalman": 99, "filter": 99, "exact": 99, "Of": [99, 100, 102], "cours": [99, 100, 102], "welcom": [99, 100, 102], "combinatorial_semi": [99, 100, 102], "_env_realcomb": [99, 100, 102], "combsemi_env": [99, 100, 102], "prior_gamma_mu": 99, "prior_gamma_cov": [99, 102], "lints_semi": 99, "tot_r": [99, 100, 102], "480": 99, "1895": 99, "1700": 99, "2219": 99, "2807": 99, "1593": 99, "2784": 99, "172": [99, 122, 124, 125], "2831": 99, "1523": [99, 102], "8214": 99, "2055": 99, "0487": 99, "8551": 99, "1778": 99, "595": 99, "9068": 99, "6194": 99, "9444": [99, 102], "3574891974648375": 99, "1122": [99, 101], "began": 100, "famili": 100, "sub": [100, 119], "bay": [100, 102], "u_prior_cov_diag": 100, "diagon": 100, "ts_semi": 100, "1054": 100, "2060": 100, "494": 100, "1488": 100, "1351": 100, "898": 100, "1587": 100, "1114": [100, 102], "321": 100, "8094": 100, "8462": 100, "8306": 100, "6929": 100, "6706": 100, "6444": 100, "5902": 100, "5764": [100, 102], "0607550383245": 100, "yuan": [100, 101, 108, 118], "februari": 100, "perrault": 100, "boursier": 100, "valko": 100, "perchet": 100, "5429": 100, "5440": 100, "alloc": [101, 108, 118], "pali": 101, "sigma_2": [101, 102], "combt": [101, 132], "comblint": [101, 132], "mtss_comb": 101, "sankararaman": 101, "5114": 101, "5122": 101, "lmm": 102, "sigma_1": 102, "prior_gamma_mean": 102, "mtss_semi": 102, "686": [102, 122, 123], "2132": 102, "689": 102, "1645": 102, "1733": 102, "2671": 102, "1611": 102, "2099": 102, "1668": 102, "9462": 102, "4307": 102, "9867": 102, "846": 102, "504": 102, "3613": 102, "6928": 102, "45535406270607": 102, "pari": 102, "golrezaei": 102, "ssrn": 102, "3651397": 102, "mnl": [103, 104, 105, 106, 107, 108, 132], "arguabl": 103, "eta_0": 103, "eta_1": 103, "eta_": [103, 104, 105, 106, 107], "eta_k": 103, "revenu": [103, 104, 105, 106], "convention": 103, "v_i": 103, "mnldist": 103, "cup": 103, "v_0": 103, "intract": [103, 106], "appear": [103, 104, 105, 106, 107], "matter": 103, "ts_mnl": 103, "ts_contextual_mnl": 103, "mtss_mnl": 103, "pentico": 103, "european": 103, "190": [103, 122, 125], "295": 103, "luce": [103, 118], "courier": [103, 118], "corpor": [103, 118], "avadhanula": [103, 104, 105, 106, 107, 108], "zeevi": [103, 104, 106, 107, 108], "oh": [103, 104, 105], "iyengar": [103, 104, 105], "1485": [103, 106, 107], "ou": [103, 105], "1805": [103, 105], "02971": [103, 105], "concret": 104, "eqn1": 104, "logit": [104, 105, 106, 108, 118], "_env_realmnl": [104, 105, 106], "mnl_env": [104, 105, 106, 107], "same_reward": [104, 105, 106, 107], "clip": [104, 106], "275": 104, "448": [104, 105], "836": [104, 105], "9493188224156814": 104, "framwork": 105, "realtionship": 105, "mnl_ts_contextu": 105, "298": 105, "9729194890231303": 105, "tulabandhula": 105, "tractabl": [105, 106], "14033": 105, "multinomila": 106, "nice": [106, 116], "ts_mnl_beta": 106, "mnl_t": 106, "864": 106, "394": [106, 123, 125, 126], "911": 106, "430": [106, 125, 126], "03330462654669619": 106, "dong": 106, "switch": [106, 133], "2607": 106, "2615": 106, "48log": 107, "_env_mnl": 107, "ipykernel_69552": 107, "3115157464": 107, "20000": [107, 130], "update_freq_linear": 107, "with_intercept": [107, 110, 111, 116, 117, 131], "x_mu": [107, 110, 111, 116, 117], "x_sigma": [107, 110, 111, 116, 117], "sigma_gamma": [107, 110, 111, 116, 117], "mu_gamma": 107, "exp_r": 107, "519": 107, "906": 107, "main_raw_model": [108, 118], "cardin": [108, 118], "exclud": [108, 118], "appeal": 108, "brows": 108, "02038": [108, 118], "2015a": [108, 118], "strike": 109, "unfamiliar": 109, "guaasian": [109, 132], "glmt": 109, "guassian": [109, 132], "writer": [109, 129], "2080": 109, "home": [110, 111, 116, 117], "lge": [110, 111, 116, 117], "ipykernel_69571": 110, "3636065689": [110, 111, 116, 117], "sigma_theta": [110, 111, 116, 117], "mu_theta": [110, 111, 116, 117], "specifii": 110, "cnt": [110, 111], "rewrit": 111, "ipykernel_69576": 111, "lints_bernoulli_ag": 111, "lints_bernoulli": 111, "breward": 116, "ipykernel_69581": 116, "4375": 116, "ipykernel_69586": 117, "rs": 117, "1249": 117, "cook": 118, "vast": 119, "disucss": 119, "hear": 119, "reader": [119, 129], "materi": 119, "recap": 119, "appraoch": 119, "mont": 119, "carlo": 119, "td": 119, "wait": 119, "paradigm": [119, 120], "trasit": 119, "schema": 119, "trpo": 119, "ppo": 119, "simplist": 119, "descient": 119, "around": [119, 125, 126], "fortun": [119, 120], "bigtriangledown_": 119, "abil": 119, "dqn": 119, "replai": 119, "scratch": 119, "Such": 119, "q_0": 119, "effiic": 119, "a2c": 119, "sac": 119, "a3c": 119, "pomdp_comparison": 120, "valuabl": 120, "infeas": 120, "horiozn": 120, "quickli": 120, "belief": 120, "subset_rl_data_final_cont": [122, 125], "mimic3_bas": [122, 125], "lambda": [122, 131], "ipykernel_69607": 122, "4058168275": 122, "loc": [122, 125, 130, 131], "row_index": [122, 125], "col_index": [122, 125], "173913": [122, 123, 125], "98685": [122, 125], "142857": [122, 125], "749": [122, 125], "200000": [122, 124, 125, 126, 128], "751": [122, 125], "545455": [122, 125], "030303": [122, 125, 126], "196": [122, 125, 128], "666667": [122, 124, 125], "753": 122, "mimic_fin": [122, 125], "692": [122, 125], "selected_id": 122, "dtr_data": 122, "concaten": [122, 123, 130, 131], "varnam": 122, "varname_format": 122, "bloc_1": 122, "bloc_2": 122, "bloc_3": 122, "died_within_48h_1": 122, "died_within_48h_2": 122, "icustayid_2": 122, "icustayid_3": 122, "died_within_48h_3": 122, "mimic3_dtr_3stage_v2": 122, "iv_input_3": [122, 124], "icustayid_1": 122, "glucose_1": [122, 124], "pao2_fio2_1": [122, 124], "iv_input_1": [122, 124], "sofa_1": [122, 124], "glucose_2": [122, 124], "pao2_fio2_2": [122, 124], "iv_input_2": [122, 124], "sofa_2": [122, 124], "glucose_3": [122, 124], "pao2_fio2_3": [122, 124], "sofa_3": [122, 124], "31005": 122, "833333": [122, 124], "364": [122, 124], "439": [122, 124], "310339": [122, 124], "10989": 122, "714286": [122, 124], "164": [122, 124], "174": [122, 124, 125, 126, 128], "4132": [122, 125, 126, 128], "266": [122, 124], "600000": [122, 124, 125, 126], "388889": [122, 124], "37528": 122, "260": [122, 124], "777778": [122, 124], "257": [122, 124], "857143": [122, 124], "191": [122, 124, 130], "935482": [122, 124], "86428": 122, "mrl_data": 122, "mdtr_data": [122, 124], "mimic3_mdtr_data_dict_3stage_v2": [122, 124], "wb": [122, 125, 129], "dump": [122, 125, 129], "mdtr_df": 122, "mimic3_mdtr_3stage_v2": [122, 124], "234036": [122, 123], "next_stat": [122, 123], "s0": 122, "time_idx": [122, 123], "vstack": 122, "next_glucos": [122, 123], "next_pao2_fio2": [122, 123], "682": [122, 123], "684": [122, 123], "685": [122, 123], "687": [122, 123], "keyerror": [122, 126], "3741024878": 122, "listcomp": [122, 123], "frame": [122, 126], "__getitem__": [122, 126], "3509": [122, 126], "is_iter": [122, 126], "3510": [122, 126], "3511": [122, 126], "_get_indexer_strict": [122, 126], "3512": [122, 126], "3513": [122, 126], "axis_nam": [122, 126], "5794": [122, 126], "keyarr": [122, 126], "new_index": [122, 126], "_reindex_non_uniqu": [122, 126], "5795": [122, 126], "5796": [122, 126], "_raise_if_miss": [122, 126], "5797": [122, 126], "5798": [122, 126], "5857": [122, 126], "5858": [122, 126], "not_found": [122, 126], "ensure_index": [122, 126], "missing_mask": [122, 126], "nonzero": [122, 126], "5859": [122, 126], "5860": [122, 126], "5861": [122, 126], "overload": [122, 126, 129], "next_pao2": 122, "next_sofa": 122, "rl_df": 122, "mimic3_rl_df": 122, "499996": 122, "427": [122, 123], "632": 122, "633": 122, "634": 122, "97782": 122, "201": [122, 128], "635": 122, "within": [122, 123, 125, 126, 128, 133], "48h": [122, 123, 125, 126, 128], "mimic3_multi_stag": [122, 125], "lag_k": [122, 125], "new_sofa": [122, 125], "mimic3_sampl": [122, 125], "groupbi": [122, 125, 129], "mimic3_single_stag": [122, 125, 126, 128], "ipykernel_69613": 123, "1713212044": 123, "data_num": 123, "177": 123, "_q_term": 123, "178": 123, "er_sa0": 123, "er_sa": 123, "_er_sa0_sa": 123, "rho_sam": 123, "est_q4": 123, "est_q5": 123, "est_qdiff": 123, "q1_diff": 123, "eta_pi": 123, "q5_diff": 123, "eta_a0": 123, "qlearner_linear": 123, "q2_diff": 123, "q3_diff": 123, "q4_diff_1": 123, "q4_diff_2": 123, "_q_diff": 123, "_er_sa0m": 123, "354": 123, "pie_a_": 123, "q1_snext_am_mc": 123, "q2_snext_am_mc": 123, "q3_snext_am_mc": 123, "q4_snext_am_mc": 123, "q5_snext_am_mc": 123, "q4_s_am_mc": 123, "cal_q_am_mc": 123, "357": 123, "q1_snext_am": 123, "pie_a_sprim": 123, "425": 123, "update_q1235_snext_am_mc": 123, "428": 123, "429": [123, 130], "q4_snext_am_mc_astar": 123, "update_q4_snext_am_mc_astar": 123, "m_snext_a": 123, "pmlearner": 123, "sample_m": 123, "441": 123, "action_list": 123, "442": 123, "out_q1": 123, "out_q2": 123, "out_q3": 123, "out_q5": 123, "cal_newq_1235": 123, "443": 123, "update_exp": 123, "395": 123, "396": 123, "qs": 123, "q_1235": 123, "397": 123, "398": 123, "q1_est_beta": 123, "q2_est_beta": 123, "include_eta": 123, "prod": 123, "zip": [123, 129], "bspline": 123, "218": 123, "220": 123, "0058689011135968135": 123, "002110278954293422": 123, "002770561709572756": 123, "0010678186846614852": 123, "005821662648181514": 123, "mimic3_mdtr": 124, "parenthesi": 124, "nde": [124, 128], "213": 124, "695": 124, "647": 124, "057": 124, "284": 124, "mediated_qlearn": 124, "mediatedqlearn": 124, "regime_control": 124, "regime_target": 124, "est_nde_ni": 124, "155758": 124, "212838": 124, "05708": 124, "_predict_value_boot": 124, "nie_s": 124, "nde_s": 124, "6474": 124, "6946": 124, "2835": 124, "q_1": 124, "q_2": 124, "a_2": 124, "_2": 124, "q_3": 124, "a_3": 124, "07": 124, "_3": 124, "polic": [124, 128], "policy1": [124, 128], "8991": 124, "policy2": [124, 128], "8246": 124, "0745": 124, "mortal": [124, 125, 126, 127, 128], "s1_1": 124, "s1_2": 124, "s1_3": 124, "s3_1": 124, "s3_2": 124, "s3_3": 124, "s4_1": 124, "s4_2": 124, "s4_3": 124, "8990981941216672": 124, "8246053645689109": 124, "0001": 124, "0012": [124, 128], "0551": 124, "00001": 124, "0070": 124, "0721": 124, "0008": 124, "0114": 124, "appl": [124, 128], "9637": 124, "summari": [124, 128, 132], "9637185597953756": 124, "privaci": [125, 126, 127], "he": [125, 126, 127], "hour": [125, 126, 127], "diagram": [125, 126], "load_ext": [125, 126], "autoreload": [125, 126], "randn": [125, 126, 131], "rseed": [125, 126], "npseed": [125, 126], "math": [125, 126], "multiprocess": [125, 126], "pool": [125, 126], "functool": [125, 126], "ipykernel_69648": 125, "1368811484": 125, "000": [125, 130], "625": 125, "428571": 125, "758782": 125, "818182": [125, 126, 128], "2718509362": 125, "081590": [125, 126], "800000": [125, 126, 128], "1204": [125, 126, 128], "794872": [125, 126, 128], "782051": [125, 126, 128], "668956": [125, 126], "153846": [125, 126, 128], "364286": [125, 126, 128], "956461": [125, 126, 128], "252": [125, 126], "883864": [125, 126], "4201": [125, 126, 128], "580087": [125, 126, 128], "083333": [125, 126, 128], "539": [125, 126], "065657": [125, 126], "5170": [125, 126, 128], "525000": [125, 126, 128], "147": [125, 126, 128], "350198": [125, 126, 128], "616727": [125, 126], "437500": [125, 126, 128], "6504": [125, 126, 128], "081169": [125, 126, 128], "836364": [125, 126, 128], "423": [125, 126], "mimic3_data_fin": [125, 126], "smaple_demo": 125, "est_mt": [125, 126], "w_threshold": [125, 126], "refit": [125, 126], "demo_res_net": [125, 126], "topo_list": [125, 126], "topological_sort": [125, 126], "topolog": [125, 126], "buttom": [125, 126], "administrait": [125, 126], "35384615": [125, 126], "70769231": [125, 126], "06153846": [125, 126], "41538462": [125, 126], "76923077": [125, 126], "12307692": [125, 126], "47692308": [125, 126], "83076923": [125, 126], "18461538": [125, 126], "53846154": [125, 126], "gap": [125, 126], "intak": [125, 126], "death": [125, 126], "administr": [125, 126], "gradientboostingclassifi": [125, 126], "42850795": 125, "04122985": 125, "37054069": 125, "0055272": 125, "10384686": 125, "01457029": 125, "16909439": 125, "28221447": 125, "05764574": 125, "008193": 125, "30211856": 125, "0551675": 125, "01006845": 125, "09689565": 125, "10600407": 125, "18238777": 125, "44978522": 125, "19716563": 125, "289073": 125, "03827421": 125, "22619666": 125, "1875545": 125, "23778146": 125, "20841167": 125, "73958005": 125, "11909299": 125, "09661241": 125, "15624675": 125, "3466977": 125, "42682439": 125, "353852": 125, "12244475": 125, "53581201": 125, "38763738": 125, "00624024": 125, "02708992": 125, "08227609": 125, "09644005": 125, "19550407": 125, "30207966": 125, "03525717": 125, "34339108": 125, "30668368": 125, "11740263": 125, "23538089": 125, "41147115": 125, "46029296": 125, "10346963": 125, "51161134": 125, "04498817": 125, "18302802": 125, "21907476": 125, "54002382": 125, "23518752": 125, "06635588": 125, "83090637": 125, "3999141": 125, "counterintuit": [125, 126], "remind": [125, 126], "20399937380848096": 125, "49003107": 125, "50057977": 125, "20914573": 125, "66345884": 125, "23977303": 125, "0794276": 125, "34455499": 125, "36109094": 125, "19848057": 125, "58006391": 125, "11359767": 125, "23537098": 125, "18899855": 125, "64967052": 125, "63723815": 125, "05042186": 125, "26366224": 125, "00872736": 125, "32914701": 125, "51474347": 125, "41667122": 125, "54158338": 125, "71321121": 125, "26489405": 125, "0774718": 125, "52229178": 125, "61766863": 125, "57557176": 125, "94774448": 125, "55186488": 125, "29666119": 125, "35960446": 125, "20136832": 125, "77408578": 125, "19227108": 125, "11463203": 125, "35932623": 125, "29545405": 125, "86337085": 125, "95171379": 125, "61272862": 125, "00475441": 125, "06064992": 125, "64206127": 125, "75432718": 125, "20535944": 125, "37009124": 125, "35431129": 125, "78816905": 125, "76940612": 125, "68175408": 125, "74628053": 125, "10881984": 125, "17531085": 125, "07151351": 125, "82140618": 125, "01038676": 125, "bad": [125, 126], "08642818615808806": 125, "086": 125, "sample_demo": 126, "ipykernel_69660": 126, "2233535502": 126, "692308": 126, "636364": 126, "625000": 126, "45322357": 126, "12551825": 126, "31095315": 126, "06658004": 126, "14936954": 126, "13404695": 126, "32144405": 126, "41540906": 126, "11657287": 126, "0605553": 126, "41204992": 126, "350003": 126, "07587157": 126, "1937542": 126, "29406602": 126, "27231197": 126, "44362365": 126, "08949383": 126, "4349184": 126, "13355717": 126, "16845723": 126, "0938565": 126, "30817118": 126, "06978495": 126, "50736663": 126, "20295236": 126, "17239035": 126, "27745005": 126, "2927717": 126, "31615833": 126, "3621005": 126, "19816815": 126, "29745249": 126, "31014128": 126, "00821821": 126, "19483265": 126, "16912685": 126, "20077837": 126, "37305844": 126, "24538905": 126, "20552501": 126, "38095327": 126, "38948743": 126, "2780394": 126, "11502808": 126, "45806054": 126, "29489358": 126, "18854476": 126, "06531642": 126, "22022294": 126, "22806464": 126, "31916684": 126, "05725299": 126, "37429873": 126, "16776177": 126, "30377136": 126, "44658451": 126, "harm": 126, "21392525739350662": 126, "33471421": 126, "58750923": 126, "69769602": 126, "50468707": 126, "04119141": 126, "08032529": 126, "24677671": 126, "46879497": 126, "14228685": 126, "40913012": 126, "26967209": 126, "10424795": 126, "15469547": 126, "86680554": 126, "01699509": 126, "50534554": 126, "50120394": 126, "0832772": 126, "4053538": 126, "61938348": 126, "63167011": 126, "53840976": 126, "10602297": 126, "04338229": 126, "18159866": 126, "77996324": 126, "7988097": 126, "94550731": 126, "28227784": 126, "9895861": 126, "34582444": 126, "63707457": 126, "67745798": 126, "16396444": 126, "3173255": 126, "41720785": 126, "66927895": 126, "09861153": 126, "9408872": 126, "21402004": 126, "85013445": 126, "61804279": 126, "67352783": 126, "06219661": 126, "78217875": 126, "87809129": 126, "81120382": 126, "61344813": 126, "6384825": 126, "26478542": 126, "95845848": 126, "14744284": 126, "86349984": 126, "74704598": 126, "2168899": 126, "97526792": 126, "68596023": 126, "4460136626503026": 126, "446": 126, "single_data": 128, "single_dataset": 128, "2133": 128, "0030": 128, "2104": 128, "2332": 128, "2276": 128, "0164": 128, "2440": 128, "_valid": 128, "372": 128, "fitfailedwarn": 128, "490": 128, "fail": [128, 133], "debug": 128, "error_scor": 128, "680": [128, 129], "_fit_and_scor": 128, "y_train": 128, "fit_param": 128, "_class": 128, "937": 128, "super": 128, "203": 128, "check_classification_target": 128, "multiclass": 128, "y_type": 128, "some_fits_failed_messag": 128, "_search": 128, "ipykernel_69685": 128, "2289951171": 128, "palearn": 128, "pie_a": 128, "problearn": 128, "regressor": 128, "decisiontreeclassifi": 128, "183": 128, "best_param": 128, "best_params_": 128, "184": 128, "refit_start_tim": 128, "926": 128, "best_estimator_": 128, "927": 128, "928": 128, "check_input": 128, "x_idx_sort": 128, "935": 128, "936": 128, "938": 128, "939": 128, "is_classif": 128, "205": 128, "195": 128, "multilabel": 128, "199": 128, "23320671819000469": 128, "22762835456807218": 128, "01638548320515956": 128, "24401383777323174": 128, "9999": 128, "7646": 128, "2353": 128, "9999999999999999": 128, "764561656518231": 128, "0004": 128, "5510": 128, "greenland": 128, "exchang": 128, "epidemiolog": [128, 132], "latin": 129, "cleric": 129, "admin": 129, "farmer": 129, "homemak": 129, "lawyer": 129, "programm": 129, "retir": 129, "scientist": 129, "tradesman": 129, "craftsman": 129, "unemploi": 129, "ipykernel_69704": 129, "407324603": 129, "parserwarn": 129, "back": 129, "regex": 129, "char": 129, "_decor": 129, "stacklevel": 129, "310": 129, "io": [129, 133], "parser": 129, "filepath_or_buff": 129, "delimit": 129, "index_col": 129, "usecol": 129, "squeez": 129, "mangle_dupe_col": 129, "true_valu": 129, "false_valu": 129, "skipinitialspac": 129, "skiprow": 129, "skipfoot": 129, "nrow": 129, "na_valu": 129, "keep_default_na": 129, "na_filt": 129, "skip_blank_lin": 129, "parse_d": 129, "infer_datetime_format": 129, "keep_date_col": 129, "date_pars": 129, "dayfirst": 129, "cache_d": 129, "chunksiz": 129, "compress": 129, "decim": 129, "linetermin": 129, "quotechar": 129, "quot": 129, "doublequot": 129, "escapechar": 129, "comment": 129, "encoding_error": 129, "dialect": 129, "error_bad_lin": 129, "warn_bad_lin": 129, "on_bad_lin": 129, "delim_whitespac": 129, "low_memori": 129, "memory_map": 129, "float_precis": 129, "storage_opt": 129, "676": 129, "kwds_default": 129, "678": 129, "_read": 129, "573": 129, "575": 129, "textfileread": 129, "576": 129, "577": 129, "930": 129, "iohandl": 129, "_engin": 129, "_make_engin": 129, "933": 129, "934": 129, "1214": 129, "pathlik": 129, "readcsvbuff": 129, "byte": 129, "1215": 129, "1216": 129, "get_handl": 129, "1217": 129, "path_or_buf": 129, "is_text": 129, "784": 129, "ioarg": 129, "785": 129, "786": 129, "787": 129, "788": 129, "timestamp": 129, "movie_titl": 129, "adventur": 129, "anim": 129, "children": 129, "crime": 129, "documentari": 129, "fantasi": 129, "noir": 129, "horror": 129, "music": 129, "mysteri": 129, "romanc": 129, "war": 129, "western": 129, "temp": 129, "idx_of_genr": 129, "idx": 129, "final_data": 129, "merg": 129, "flew": 129, "cuckoo": 129, "1975": 129, "1000209": 129, "movielens_1m": 129, "popular_genr": 129, "sort_valu": 129, "ascend": 129, "popular_occup": 129, "col": [129, 130], "movielens_1m_popular": 129, "isin": 129, "119103": 129, "96564": 129, "77955": 129, "66745": 129, "54408": 129, "414775": 129, "gender_f": 129, "single_genr": 129, "multi_genr": 129, "nuniqu": 129, "movielens_cleaned_1m": 129, "linalg": [129, 131], "block_diag": [129, 131], "movielens_bandit": 129, "get_sum_r": 129, "denom": 129, "25182431": 129, "52394863": 129, "20922347": 129, "32501066": 129, "20043842": 129, "deepcopi": 129, "movielens_mtts_1m_gaussian": 129, "19933493": 129, "8245542": 129, "39117662": 129, "67363023": 129, "31367902": 129, "6491084": 129, "float": 129, "movielens_mtts_1m_bernoulli": 129, "iteract": 130, "logged_data": 130, "get_logged_dat": [130, 131], "ipykernel_69709": 130, "791222544": 130, "685706": 130, "2042": 130, "499683": 130, "2424": 130, "694860": 130, "330": 130, "207691": 130, "169": 130, "3671": 130, "425839": 130, "213638": 130, "4140": 130, "242271": 130, "717322": 130, "4411": 130, "910": 130, "345927": 130, "870113": 130, "1226": 130, "406": 130, "data_cel_sampl": 130, "1286": 130, "models_cel": 130, "whitespac": 130, "feature_nam": 130, "underlin": 130, "info": 130, "overhead": 130, "000062": 130, "force_row_wis": 130, "And": 130, "force_col_wis": 130, "339901": 130, "inf": 130, "000009": 130, "393": 130, "483461": 130, "000039": 130, "319149": 130, "000035": 130, "319527": 130, "000018": 130, "951807": 130, "thev": 130, "age_rang": 130, "itertool": 130, "1224": 130, "0439": 130, "7664": 130, "5822": 130, "6663": 130, "6364": 130, "1312": 130, "result_cel_nonlinear": 130, "122379": 130, "576471": 130, "066448": 130, "583382": 130, "133766": 130, "043862": 130, "205939": 130, "232727": 130, "766441": 130, "910281": 130, "336623": 130, "717603": 130, "160268": 130, "687924": 130, "331463": 130, "345233": 130, "377340": 130, "649888": 130, "039056": 130, "923635": 130, "1307": 130, "297553": 130, "090110": 130, "024221": 130, "658442": 130, "151436": 130, "1308": 130, "612166": 130, "695911": 130, "608458": 130, "740830": 130, "1309": 130, "582210": 130, "165707": 130, "552889": 130, "1310": 130, "666311": 130, "283311": 130, "129195": 130, "1311": 130, "636355": 130, "103647": 130, "115987": 130, "read": 130, "te_femal": 130, "500268": 130, "309777": 130, "562432": 130, "605472": 130, "960134": 130, "te_mal": 130, "365749": 130, "321332": 130, "256846": 130, "447365": 130, "schi": 130, "lowest": 130, "models_cel_linear": 130, "result_cel_linear": 130, "323169": 130, "453650": 130, "692167": 130, "482883": 130, "357668": 130, "325782": 130, "098945": 130, "628177": 130, "145705": 130, "886814": 130, "578237": 130, "666234": 130, "464250": 130, "392727": 130, "691633": 130, "580850": 130, "311529": 130, "400261": 130, "055549": 130, "220779": 130, "530090": 130, "566701": 130, "455929": 130, "741310": 130, "570002": 130, "494923": 130, "259652": 130, "899359": 130, "006980": 130, "469963": 130, "444164": 130, "514824": 130, "955027": 130, "692742": 130, "819186": 130, "446776": 130, "160120": 130, "891038": 130, "355564": 130, "348332": 130, "699231": 130, "727408": 130, "727111": 130, "602585": 130, "153151": 130, "701844": 130, "372704": 130, "663122": 130, "265407": 130, "682297": 130, "te_female_linear": 130, "579924": 130, "402675": 130, "282099": 130, "511989": 130, "082199": 130, "te_male_linear": 130, "445089": 130, "423679": 130, "073189": 130, "236301": 130, "957766": 130, "cel_result": 130, "mean_error": 130, "genere_dat": 130, "genere_error": 130, "ddof": 130, "05i": 130, "sigma1": [130, 131], "cum_reward_inform": 130, "informative_t": 130, "cum_reward_informative_t": 130, "rec_action_informative_t": 130, "cumsum": [130, 131], "1000i": 130, "cum_reward_uninform": 130, "uninformative_t": 130, "cum_reward_uninformative_t": 130, "rec_action_uninformative_t": 130, "sole": 130, "cum_reward_greedi": [130, 131], "cum_reward_greedy_t": [130, 131], "rec_action_greedy_t": 130, "884": 130, "010": 130, "011": 130, "391": 130, "674": 130, "061": 130, "041": 130, "088": 130, "algo": [130, 131], "lineplot": [130, 131], "hue": [130, 131], "n_boot": [130, 131], "linewidth": [130, 131], "marker": [130, 131], "bbox_to_anchor": [130, 131], "borderaxespad": [130, 131], "autoarg": 131, "true_model": 131, "logged_dat": 131, "randint": 131, "user_info": 131, "r_mean": 131, "optimal_action_reward": 131, "rec_genr": 131, "ipykernel_69720": 131, "2393233947": 131, "true_model_1": 131, "scifi": 131, "inercept": 131, "to_markdown": 131, "338373e": 131, "553173e": 131, "916054e": 131, "419341e": 131, "574240e": 131, "646757e": 131, "578371e": 131, "303934e": 131, "339018e": 131, "560132e": 131, "625256e": 131, "893010e": 131, "984154e": 131, "818640e": 131, "184398e": 131, "816416e": 131, "784788e": 131, "145633e": 131, "053477e": 131, "396107e": 131, "478043e": 131, "337961e": 131, "061687e": 131, "295411e": 131, "821867e": 131, "000000e": 131, "0039255479596445": 131, "33837": 131, "0564676": 131, "362526": 131, "81642": 131, "47804": 131, "89155": 131, "0193161": 131, "03163": 131, "85992": 131, "25443": 131, "0739259": 131, "329217": 131, "58364": 131, "58031": 131, "0130774": 131, "23706": 131, "81737": 131, "880949": 131, "0499074": 131, "880965": 131, "87681": 131, "995856": 131, "estimated_gamma": 131, "cum_reward_infolint": 131, "cum_reward_uninfolint": 131, "cum_reward_uninfolinucb": 131, "cum_reward_t": 131, "cum_reward_ucb": 131, "info_lint": 131, "cum_reward_infolints_t": 131, "uninfo_lint": 131, "cum_reward_uninfolints_t": 131, "uninfo_linucb": 131, "cum_reward_uninfolinucb_t": 131, "uninfo_t": 131, "cum_reward_ts_t": 131, "uninfo_ucb": 131, "cum_reward_ucb_t": 131, "tight_layout": 131, "savefig": 131, "movielens_contextu": 131, "432x288": 131, "workflow": 132, "merit": 132, "downsid": 132, "miscellan": 132, "wish": 132, "ccc": 132, "hline": 132, "vdot": 132, "hdashlin": 132, "ct": 132, "bs": 132, "unrel": 132, "correpond": 132, "conjunct": 132, "bowl": 132, "quatil": 132, "otr": 132, "jump": 132, "comb": 132, "practition": 133, "handbook": 133, "complement": 133, "unifi": 133, "desktop": 133, "branch": 133, "visiabl": 133, "_build": 133, "commit": 133, "push": 133, "cd": 133, "password": 133, "gh": 133, "reinstal": 133, "credenti": 133, "token": 133, "cname": 133, "restart": 134, "200940": [], "860076": [], "429924": [], "567775": [], "773225": [], "757968": [], "492155": [], "995205": [], "788571": [], "010011": [], "330366": [], "338528": [], "244661": [], "584258": [], "041915": [], "080423": [], "200256": [], "779331": [], "424088": [], "658939": [], "120684": [], "690309": [], "192955": [], "192424": [], "349678": [], "490935": [], "157418": [], "381966": [], "161022": [], "397795": [], "ipykernel_69931": [], "2212": 60, "14466": 60, "848432": 60, "094492": 60, "461446": 60, "408936": 60, "551120": 60, "381643": 60, "506465": 60, "111141": 60, "951119": 60, "692756": 60, "029846": 60, "850486": 60, "475040": 60, "545858": 60, "278642": 60, "374928": 60, "025845": 60, "272796": 60, "530463": 60, "881486": 60, "874465": 60, "311966": 60, "739413": 60, "225175": 60, "103833": 60, "696629": 60, "292097": 60, "497187": 60, "677902": 60, "992124": 60, "ipykernel_69961": 60, "_env_getdata_cel": [16, 17, 20, 24], "ipykernel_71130": 16, "2332491731": 16, "get_movielens_cel": [16, 17, 20, 24], "ipykernel_71135": 17, "1311581033": 17, "elapsed_tim": 17, "285": 17, "40207719802856": 17, "2031": 17, "2s": 17, "898u": 17, "964u": 17, "7404845356941223": 17, "7264252305030823": 17, "ipykernel_71142": 20, "3497684307": 20, "ipykernel_71149": 24, "778938008": 24, "ipykernel_71156": 134, "3830966291": 134, "pathlib": 134, "data_folder_path": 134, "resolv": 134, "csv_file_path": 134, "project_fold": 134, "pers1_fb": 134, "posixpath": 134, "current_script_dir": 134, "dirnam": 134, "abspath": 134, "__file__": 134, "ipykernel_66398": 134, "1270737390": 134}, "objects": {}, "objtypes": {}, "objnames": {}, "titleterms": {"learner": [0, 9, 10, 11, 13, 14, 16, 20, 22, 24, 25, 26, 28, 29, 42, 43, 50, 51, 71, 82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106], "name": [0, 132], "singl": [0, 19, 27, 45, 59, 61, 62, 109, 122, 128], "multipl": [0, 21, 37, 77, 78, 79, 129], "stage": [0, 19, 27, 37, 45, 59, 61, 77, 78, 79, 122, 124, 128], "infinit": [0, 63, 69, 72, 74, 123], "horizon": [0, 63, 69, 72, 74, 123], "main": [0, 11, 14, 19, 45, 48, 50, 59, 60, 63, 64, 67, 68, 69, 70, 71, 72, 74, 77, 79, 82, 83, 84, 86, 87, 88, 90, 91, 92, 93, 95, 97, 98, 99, 100, 102, 104, 105, 106, 107, 110, 111, 116, 117], "idea": [0, 11, 14, 19, 45, 48, 50, 59, 60, 63, 64, 67, 68, 69, 70, 71, 72, 74, 77, 79, 82, 83, 84, 86, 87, 88, 90, 91, 92, 93, 95, 97, 98, 99, 100, 102, 104, 105, 106, 107, 110, 111, 116, 117], "algorithm": [0, 11, 13, 14, 40, 45, 59, 60, 77, 79, 80, 84, 86, 87, 96, 97, 101, 102, 103, 104, 107, 109, 110, 111, 116, 117], "detail": [0, 9, 11, 13, 14, 45, 50, 59, 77, 79, 84, 86, 87, 97, 102, 104, 107, 110, 111, 116, 117], "kei": [0, 45, 59, 77, 79, 82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 107, 110, 111, 116, 117], "step": [0, 45, 59, 77, 79, 82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 107, 110, 111, 116, 117, 133], "demo": [0, 11, 13, 14, 21, 33, 40, 45, 48, 50, 59, 60, 63, 64, 67, 68, 69, 70, 71, 74, 77, 79, 82, 83, 84, 86, 87, 88, 90, 91, 92, 93, 95, 97, 98, 99, 100, 102, 104, 105, 106, 107, 110, 111, 116, 117, 125, 126], "code": [0, 5, 11, 13, 14, 45, 50, 59, 71, 77, 79, 82, 83, 84, 86, 87, 88, 90, 91, 92, 93, 95, 97, 98, 99, 100, 102, 104, 105, 106, 107, 110, 111, 116, 117], "1": [0, 2, 9, 11, 12, 13, 14, 15, 17, 21, 22, 26, 27, 45, 50, 59, 72, 77, 79, 91, 92, 93, 109, 132, 133], "polici": [0, 2, 7, 45, 50, 56, 59, 60, 63, 64, 65, 66, 69, 71, 72, 73, 74, 75, 76, 77, 79, 91, 92, 93, 94, 119, 120, 124, 128, 131, 132], "learn": [0, 1, 2, 3, 27, 37, 45, 47, 48, 50, 52, 55, 59, 62, 63, 71, 72, 77, 79, 96, 119, 120, 125, 126, 130, 132], "2": [0, 2, 9, 11, 12, 13, 14, 15, 17, 21, 22, 27, 28, 32, 45, 50, 59, 72, 77, 79, 91, 92, 93, 122, 132, 133], "evalu": [0, 7, 45, 50, 59, 60, 63, 64, 65, 66, 67, 69, 72, 74, 75, 76, 77, 79, 91, 92, 93, 94, 119, 124, 128], "refer": [0, 2, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 33, 35, 36, 37, 39, 40, 41, 42, 43, 45, 48, 50, 59, 60, 63, 64, 67, 68, 69, 70, 71, 74, 75, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 116, 117, 118, 119, 120, 123, 124, 128, 132], "causal": [1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 27, 76, 125, 126, 130, 132], "effect": [1, 4, 6, 10, 12, 21, 27, 71, 125, 126, 130, 132], "cel": [1, 27, 123, 124, 128, 132], "clinic": [1, 2], "trial": 1, "advertis": 1, "market": 1, "more": 1, "beyond": 1, "cpl": [2, 124, 128, 132], "scenario": 2, "fix": [2, 132], "independ": [2, 132], "state": [2, 132], "person": [2, 12], "incent": 2, "ad": [2, 5], "target": [2, 17, 71], "bid": 2, "markovian": [2, 119, 120, 132], "transit": [2, 132], "mobil": 2, "health": 2, "3": [2, 9, 11, 12, 13, 14, 15, 21, 22, 29, 38, 91, 92, 93, 122, 124, 132], "non": [2, 11, 120, 132], "healthcar": 2, "trail": 2, "multi": [2, 85, 88, 113], "touch": 2, "attribut": 2, "4": [2, 24, 25, 132], "adapt": [2, 54, 132], "recommend": [2, 82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 108, 109, 118], "system": 2, "onlin": [2, 91, 92, 93, 94, 96, 101, 130, 131], "dynam": [2, 71, 103], "price": 2, "5": [2, 16, 25, 129, 132], "6": [2, 20, 25, 132], "structur": [3, 9, 11, 13, 14, 81, 85, 108, 132], "csl": [3, 132], "spread": 3, "covid": 3, "19": 3, "gene": 3, "express": 3, "trait": 3, "yeast": 3, "infer": [4, 5, 6], "101": [4, 5], "potenti": [4, 6, 76, 133], "outcom": [4, 6, 48, 52, 76, 125, 126], "assumpt": [4, 6, 15, 33], "averag": [4, 6], "regress": 4, "model": [4, 9, 11, 13, 14, 119, 120, 130, 131], "propens": 4, "score": [4, 13], "stratif": 4, "invers": [4, 93], "weight": [4, 48, 93], "doubli": [4, 15, 63, 92], "robust": [4, 15, 21, 63, 92], "estim": [4, 15, 19, 21, 33, 63, 65, 71, 130], "what": [5, 132], "myst": 5, "ar": 5, "role": 5, "direct": [5, 15, 21, 91], "us": [5, 48], "citat": 5, "execut": 5, "your": 5, "markdown": 5, "file": 5, "preliminari": [6, 8, 12, 75, 76], "do": [6, 58], "oper": 6, "treatment": [6, 10, 12, 21, 60], "heterogen": [6, 12], "optim": [7, 60, 72, 73, 75, 76, 101, 103, 119, 124, 128, 131], "discoveri": [9, 10, 11, 13, 14, 125, 126], "gener": [9, 11, 12, 13, 14, 18, 23, 82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 122], "graph": [9, 11, 12, 13, 14], "terminolog": [9, 11, 12, 13, 14], "overview": [9, 13, 50, 80, 82, 83, 84, 86, 87, 88, 90, 92, 95, 97, 98, 99, 100, 102, 104, 105, 106, 132], "popular": 9, "graphic": [9, 11, 13, 14, 81, 85], "linear": [9, 11, 13, 14, 130], "equat": [9, 11, 13, 14], "addit": [9, 11, 13], "nois": [9, 11, 13], "lsem": [9, 13], "method": [9, 15, 109], "To": [9, 58], "Be": 9, "For": 9, "paradigm": [9, 27, 32, 38, 132], "mediat": [10, 12, 21, 71, 122, 123, 124, 128], "analysi": [10, 12, 21, 71, 123, 124, 128, 130], "from": 10, "tabl": 10, "anoc": 10, "cvae": 10, "cai": 10, "et": [10, 13], "al": [10, 13], "2020": 10, "function": [11, 71, 75], "base": [11, 13, 14, 51, 70, 119], "goal": [11, 13, 14], "applic": [11, 13, 14], "gaussian": [11, 14, 109], "gaussain": 11, "synthet": [11, 13, 14, 40, 41, 42, 43], "dataset": [11, 13, 14, 60, 122, 129], "ica": 11, "lingam": 11, "summari": [11, 13, 14], "result": [11, 13, 14, 130], "under": [11, 13, 14, 76, 91, 92, 93, 129], "differ": [11, 13, 14, 19, 33], "exampl": 12, "decis": [12, 32, 72, 75, 76], "make": 12, "real": [12, 27, 60, 61, 78, 81, 85, 89, 96, 101, 103, 108, 109, 118], "case": 12, "sepsi": 12, "intens": 12, "care": 12, "unit": 12, "icu": 12, "toi": 12, "remark": 12, "notear": 13, "zheng": 13, "2018": 13, "test": [14, 62], "pc": 14, "ATE": [15, 30], "identif": [15, 21], "import": [15, 69, 71, 74, 82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 133], "sampl": [15, 69, 74, 88, 90, 109], "dr": [16, 25], "movielen": [16, 17, 18, 20, 24, 26, 28, 29, 130], "data": [16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 38, 54, 57, 60, 61, 71, 78, 81, 85, 89, 96, 101, 103, 108, 109, 118, 122, 129, 132], "8": [17, 23], "dragon": [17, 23], "net": [17, 23], "part": 17, "dragonnet": 17, "regular": 17, "7": [18, 23], "random": [18, 23], "forest": [18, 23], "hte": [19, 31], "approach": [19, 23], "The": 19, "advantag": 19, "lp": [20, 25], "r": [20, 24, 25, 39], "definit": [21, 33], "ipw": 21, "mr": 21, "aurora": 21, "covid19": 21, "meta": [22, 89, 90, 115], "s": [22, 26], "t": [22, 28], "x": [22, 29, 43], "other": 23, "movi": [27, 129], "len": 27, "pre": 27, "process": [27, 32, 60, 75, 76], "final": 27, "select": 27, "mimic3": [27, 125, 126, 127], "markov": [32, 75, 76], "background": [33, 40], "time": [33, 57], "vari": 33, "att": 33, "extens": 34, "h1sl": 35, "h2sl": 35, "matrix": 36, "complet": 36, "mediatedq": 37, "panel": [38, 132], "did": [39, 41], "control": [40, 71], "miscellan": 44, "A": [45, 62, 77, 132], "reduct": 46, "classif": 46, "problem": [46, 61, 78, 81, 85, 89, 96, 101, 103, 108, 109, 118], "entropi": 47, "when": [48, 133], "should": 48, "i": [48, 132], "owl": 48, "spars": 48, "a1": 48, "deriv": 48, "continu": [49, 50], "action": [49, 50, 53], "space": [49, 53], "deep": 50, "jump": 50, "difficulti": 50, "kernel": 51, "discret": 53, "collect": 54, "concord": 55, "assist": 55, "search": 56, "event": 57, "plan": 58, "q": [59, 67, 68, 72, 79], "quantil": 60, "regim": 60, "motiv": 60, "simul": [60, 109, 131], "calcul": 60, "off": [60, 64, 75, 76], "set": [61, 78, 81, 85, 89, 96, 101, 103, 108, 109, 118], "doubl": 63, "reinforc": [63, 71], "stationari": [63, 69], "distribut": [63, 69, 70], "todo": [63, 64, 67, 68, 69, 70, 74], "note": [63, 64, 69, 70, 74], "deepli": 64, "debias": 64, "valu": [65, 75, 119], "fit": [67, 68, 130], "iter": 68, "break": 69, "curs": 69, "confid": [70, 109], "interv": 70, "op": 70, "asymptot": 70, "ci": 70, "drl": 70, "load": 71, "observ": [71, 129], "specifi": [71, 82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 131], "hyperparamet": [71, 82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106], "defin": 71, "obtain": 71, "each": 71, "compon": 71, "standard": 71, "error": [71, 133], "framework": [76, 91, 92, 93], "identifi": 76, "dtr": [78, 122], "bandit": [80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 96, 101, 103, 108, 109, 129, 132], "contextu": 81, "lint": [82, 111], "environ": [82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106, 119, 120, 131], "interact": [82, 83, 84, 86, 87, 88, 90, 95, 97, 98, 99, 100, 102, 104, 105, 106], "bernoulli": [82, 83, 84, 86, 87, 88, 90, 109, 129], "linucb": [83, 112], "epsilon": [84, 109], "greedi": [84, 109, 130], "arm": 85, "mab": [85, 131], "ts": [86, 91, 92, 93, 115, 116, 130], "ucb": [87, 91, 92, 93], "task": [88, 113], "thompson": [88, 90, 109], "mtt": [88, 114], "eg": [91, 92, 93], "probabl": [92, 93], "explor": [92, 93], "cascadelint": 95, "rank": 96, "cascad": 96, "support": [96, 101, 103, 109], "mtss_cascad": 97, "ts_cascad": 98, "comblint": 99, "combt": 100, "combinatori": 101, "semi": 101, "mtss_comb": 102, "assort": 103, "multinomi": 103, "logit": 103, "mtss_mnl": 104, "ts_contextual_mnl": 105, "ts_mnl": 106, "ucb_mnl": 107, "slate": [108, 118], "item": 109, "claasic": 109, "upper": 109, "bound": 109, "epsilon_greedi": 110, "ucb1": 117, "oolin": [119, 120], "gradient": 119, "approxim": 119, "dp": 119, "actor": 119, "critic": 119, "mimic": [121, 123, 124, 128], "iii": [121, 123, 124, 128], "mrl": 122, "rl": 122, "creat": 122, "regard": [125, 126], "died_within_48h": [125, 126], "variabl": [125, 126, 129], "sofa": [125, 126], "ver2": 126, "read": 129, "keep": 129, "onli": 129, "top": 129, "occup": 129, "genr": 129, "convert": 129, "gender": 129, "dummi": 129, "subset": 129, "user": 129, "least": 129, "500": 129, "format": 129, "nonlinear": 130, "sigma": 130, "boldsymbol": 130, "gamma": 130, "run": [130, 133], "inform": 130, "uninform": 130, "true": 131, "offlin": 131, "introduct": 132, "author": 132, "expect": 132, "sl": 132, "ml": 132, "case1": 132, "d": 132, "pl": 132, "case2": 132, "case3": 132, "case4": 132, "case5": 132, "case6": 132, "appendix": 132, "singeldtr": 132, "mdp": 132, "b": 132, "multidtr": 132, "c": 132, "content": 133, "everi": 133, "notebook": 133, "how": 133, "contribut": 133, "compil": 133, "new": 133, "version": 133, "option": 133, "publish": 133, "messag": 133, "ghp": 133}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinxcontrib.bibtex": 9, "sphinx": 56}})
=======
Search.setIndex({"docnames": ["0_Learner Template", "0_Motivating_Examples/CEL", "0_Motivating_Examples/CPL", "0_Motivating_Examples/CSL", "1_Preliminary/(old) Causal Inference 101", "1_Preliminary/Causal Inference 101_old", "1_Preliminary/Causal Inference Preliminary", "1_Preliminary/Policy Evaluation and Optimization", "1_Preliminary/Preliminary", "2_Causal_Structure_Learning/Causal Discovery", "2_Causal_Structure_Learning/Causal Mediation Analysis", "2_Causal_Structure_Learning/Functional-based Learner", "2_Causal_Structure_Learning/Preliminaries of Causal Graphs", "2_Causal_Structure_Learning/Score-based Learner", "2_Causal_Structure_Learning/Testing-based Learner", "3_Causal_Effect_Learning/Scenario 1/ATE", "3_Causal_Effect_Learning/Scenario 1/DR-Learner", "3_Causal_Effect_Learning/Scenario 1/Dragonnet", "3_Causal_Effect_Learning/Scenario 1/GRF", "3_Causal_Effect_Learning/Scenario 1/HTE", "3_Causal_Effect_Learning/Scenario 1/Lp-R-Learner", "3_Causal_Effect_Learning/Scenario 1/Mediation Analysis", "3_Causal_Effect_Learning/Scenario 1/Meta Learners", "3_Causal_Effect_Learning/Scenario 1/Other Approaches", "3_Causal_Effect_Learning/Scenario 1/R-Learner", "3_Causal_Effect_Learning/Scenario 1/R-Learner, DR-Learner, Lp-R-Learner", "3_Causal_Effect_Learning/Scenario 1/S-learner", "3_Causal_Effect_Learning/Scenario 1/Single Stage", "3_Causal_Effect_Learning/Scenario 1/T-learner", "3_Causal_Effect_Learning/Scenario 1/X-learner", "3_Causal_Effect_Learning/Scenario 2/ATE", "3_Causal_Effect_Learning/Scenario 2/HTE", "3_Causal_Effect_Learning/Scenario 2/underMDP", "3_Causal_Effect_Learning/Scenario 3/DiD", "3_Causal_Effect_Learning/Scenario 3/Extensions", "3_Causal_Effect_Learning/Scenario 3/H1SL_H2SL", "3_Causal_Effect_Learning/Scenario 3/Matrix Completion", "3_Causal_Effect_Learning/Scenario 3/MediatedQ-learning_Multiple", "3_Causal_Effect_Learning/Scenario 3/Panel Data", "3_Causal_Effect_Learning/Scenario 3/R-DiD", "3_Causal_Effect_Learning/Scenario 3/Synthetic Control", "3_Causal_Effect_Learning/Scenario 3/Synthetic DiD", "3_Causal_Effect_Learning/Scenario 3/Synthetic Learner", "3_Causal_Effect_Learning/Scenario 3/Synthetic X-Learner", "3_Causal_Effect_Learning/Scenario 4/Miscellaneous", "4_Causal_Policy_Learning/Scenario1/A-learning_Single", "4_Causal_Policy_Learning/Scenario1/Classification", "4_Causal_Policy_Learning/Scenario1/Classification/E-learning", "4_Causal_Policy_Learning/Scenario1/Classification/O-Learning", "4_Causal_Policy_Learning/Scenario1/Continuous", "4_Causal_Policy_Learning/Scenario1/Continuous/Deep Jump Learner", "4_Causal_Policy_Learning/Scenario1/Continuous/Kernel-Based Learner", "4_Causal_Policy_Learning/Scenario1/Continuous/Outcome Learning", "4_Causal_Policy_Learning/Scenario1/Discrete", "4_Causal_Policy_Learning/Scenario1/Micellaneous/Adaptively Collected Data", "4_Causal_Policy_Learning/Scenario1/Micellaneous/Concordance", "4_Causal_Policy_Learning/Scenario1/Micellaneous/Policy Search", "4_Causal_Policy_Learning/Scenario1/Micellaneous/Survival", "4_Causal_Policy_Learning/Scenario1/PlanToDo", "4_Causal_Policy_Learning/Scenario1/Q-learning_Single", "4_Causal_Policy_Learning/Scenario1/Quantile/QuantileOTR_test", "4_Causal_Policy_Learning/Scenario1/Single Stage", "4_Causal_Policy_Learning/Scenario1/Test/A_Q test", "4_Causal_Policy_Learning/Scenario2/DR_Infinite", "4_Causal_Policy_Learning/Scenario2/Deeply_Debiased", "4_Causal_Policy_Learning/Scenario2/Evaluation", "4_Causal_Policy_Learning/Scenario2/FQE", "4_Causal_Policy_Learning/Scenario2/FQI", "4_Causal_Policy_Learning/Scenario2/IPW_Infinite", "4_Causal_Policy_Learning/Scenario2/Inference", "4_Causal_Policy_Learning/Scenario2/MediationRL", "4_Causal_Policy_Learning/Scenario2/Model_based_Infinite", "4_Causal_Policy_Learning/Scenario2/Optimization", "4_Causal_Policy_Learning/Scenario2/Spatial_temporal_DR", "4_Causal_Policy_Learning/Scenario2/archive/archive_preliminary_MDP", "4_Causal_Policy_Learning/Scenario2/preliminary_MDP-potential-outcome", "4_Causal_Policy_Learning/Scenario3/A-learning_Multiple", "4_Causal_Policy_Learning/Scenario3/Multi Stage", "4_Causal_Policy_Learning/Scenario3/Q-learning_Multiple", "4_Causal_Policy_Learning/Scenario4/Bandits", "4_Causal_Policy_Learning/Scenario4/Contextual_Bandits/Contextual_Bandits", "4_Causal_Policy_Learning/Scenario4/Contextual_Bandits/LinTS", "4_Causal_Policy_Learning/Scenario4/Contextual_Bandits/LinUCB", "4_Causal_Policy_Learning/Scenario4/MAB/Epsilon_Greedy", "4_Causal_Policy_Learning/Scenario4/MAB/MAB", "4_Causal_Policy_Learning/Scenario4/MAB/TS", "4_Causal_Policy_Learning/Scenario4/MAB/UCB", "4_Causal_Policy_Learning/Scenario4/Meta_Bandits/MTTS", "4_Causal_Policy_Learning/Scenario4/Meta_Bandits/Meta_Bandits", "4_Causal_Policy_Learning/Scenario4/Meta_Bandits/Meta_TS", "4_Causal_Policy_Learning/Scenario4/OnlineEval/Direct Online Policy Evaluator", "4_Causal_Policy_Learning/Scenario4/OnlineEval/Doubly Robust Online Policy Evaluator", "4_Causal_Policy_Learning/Scenario4/OnlineEval/Inverse Probability Weighted Online Policy Evaluator", "4_Causal_Policy_Learning/Scenario4/OnlineEval/Online Policy Evaluation", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/CascadeLinTS", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/Learning to rank", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/MTSS_Cascade", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/TS_Cascade", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/CombLinTS", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/CombTS", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/Combinatorial Optimization", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/MTSS_Comb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/Assortment Optimization", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/MTSS_MNL", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/TS_Contextual_MNL", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/TS_MNL_Beta", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/UCB-MNL", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Structured_Bandit", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single-Item Recommendation", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/Epsilon Greedy", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/LinTS", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/LinUCB", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/Multi-Task", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/MultiTask/MTTS", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/MultiTask/Meta-TS", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/TS", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/UCB1", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Slate Recommendation", "4_Causal_Policy_Learning/Scenario5/OnlineRL_Markov", "4_Causal_Policy_Learning/Scenario6/OnlineRL_non_Markov", "5_Case_Study/MIMIC3/Case_Study_1", "5_Case_Study/MIMIC3/Create_DTR_RL_MIMIC_Data_V2", "5_Case_Study/MIMIC3/Infinite_Horizon", "5_Case_Study/MIMIC3/Longitudinal", "5_Case_Study/MIMIC3/MIMIC3-Demo", "5_Case_Study/MIMIC3/MIMIC3-Demo-Ver2", "5_Case_Study/MIMIC3/MIMIC3_intro", "5_Case_Study/MIMIC3/Single_Stage", "5_Case_Study/MovieLens/Data_Preprocessing", "5_Case_Study/MovieLens/MovieLens", "5_Case_Study/MovieLens/MovieLens_simulation", "Overview", "README", "_old files(to delete)/Map"], "filenames": ["0_Learner Template.ipynb", "0_Motivating_Examples\\CEL.ipynb", "0_Motivating_Examples\\CPL.ipynb", "0_Motivating_Examples\\CSL.ipynb", "1_Preliminary\\(old) Causal Inference 101.ipynb", "1_Preliminary\\Causal Inference 101_old.md", "1_Preliminary\\Causal Inference Preliminary.ipynb", "1_Preliminary\\Policy Evaluation and Optimization.md", "1_Preliminary\\Preliminary.md", "2_Causal_Structure_Learning\\Causal Discovery.ipynb", "2_Causal_Structure_Learning\\Causal Mediation Analysis.ipynb", "2_Causal_Structure_Learning\\Functional-based Learner.ipynb", "2_Causal_Structure_Learning\\Preliminaries of Causal Graphs.ipynb", "2_Causal_Structure_Learning\\Score-based Learner.ipynb", "2_Causal_Structure_Learning\\Testing-based Learner.ipynb", "3_Causal_Effect_Learning\\Scenario 1\\ATE.ipynb", "3_Causal_Effect_Learning\\Scenario 1\\DR-Learner.ipynb", "3_Causal_Effect_Learning\\Scenario 1\\Dragonnet.ipynb", "3_Causal_Effect_Learning\\Scenario 1\\GRF.ipynb", "3_Causal_Effect_Learning\\Scenario 1\\HTE.ipynb", "3_Causal_Effect_Learning\\Scenario 1\\Lp-R-Learner.ipynb", "3_Causal_Effect_Learning\\Scenario 1\\Mediation Analysis.ipynb", "3_Causal_Effect_Learning\\Scenario 1\\Meta Learners.ipynb", "3_Causal_Effect_Learning\\Scenario 1\\Other Approaches.ipynb", "3_Causal_Effect_Learning\\Scenario 1\\R-Learner.ipynb", "3_Causal_Effect_Learning\\Scenario 1\\R-Learner, DR-Learner, Lp-R-Learner.ipynb", "3_Causal_Effect_Learning\\Scenario 1\\S-learner.ipynb", "3_Causal_Effect_Learning\\Scenario 1\\Single Stage.ipynb", "3_Causal_Effect_Learning\\Scenario 1\\T-learner.ipynb", "3_Causal_Effect_Learning\\Scenario 1\\X-learner.ipynb", "3_Causal_Effect_Learning\\Scenario 2\\ATE.md", "3_Causal_Effect_Learning\\Scenario 2\\HTE.md", "3_Causal_Effect_Learning\\Scenario 2\\underMDP.md", "3_Causal_Effect_Learning\\Scenario 3\\DiD.ipynb", "3_Causal_Effect_Learning\\Scenario 3\\Extensions.md", "3_Causal_Effect_Learning\\Scenario 3\\H1SL_H2SL.ipynb", "3_Causal_Effect_Learning\\Scenario 3\\Matrix Completion.ipynb", "3_Causal_Effect_Learning\\Scenario 3\\MediatedQ-learning_Multiple.ipynb", "3_Causal_Effect_Learning\\Scenario 3\\Panel Data.md", "3_Causal_Effect_Learning\\Scenario 3\\R-DiD.ipynb", "3_Causal_Effect_Learning\\Scenario 3\\Synthetic Control.ipynb", "3_Causal_Effect_Learning\\Scenario 3\\Synthetic DiD.ipynb", "3_Causal_Effect_Learning\\Scenario 3\\Synthetic Learner.ipynb", "3_Causal_Effect_Learning\\Scenario 3\\Synthetic X-Learner.ipynb", "3_Causal_Effect_Learning\\Scenario 4\\Miscellaneous.md", "4_Causal_Policy_Learning\\Scenario1\\A-learning_Single.ipynb", "4_Causal_Policy_Learning\\Scenario1\\Classification.md", "4_Causal_Policy_Learning\\Scenario1\\Classification\\E-learning.ipynb", "4_Causal_Policy_Learning\\Scenario1\\Classification\\O-Learning.ipynb", "4_Causal_Policy_Learning\\Scenario1\\Continuous.md", "4_Causal_Policy_Learning\\Scenario1\\Continuous\\Deep Jump Learner.ipynb", "4_Causal_Policy_Learning\\Scenario1\\Continuous\\Kernel-Based Learner.md", "4_Causal_Policy_Learning\\Scenario1\\Continuous\\Outcome Learning.md", "4_Causal_Policy_Learning\\Scenario1\\Discrete.md", "4_Causal_Policy_Learning\\Scenario1\\Micellaneous\\Adaptively Collected Data.ipynb", "4_Causal_Policy_Learning\\Scenario1\\Micellaneous\\Concordance.ipynb", "4_Causal_Policy_Learning\\Scenario1\\Micellaneous\\Policy Search.ipynb", "4_Causal_Policy_Learning\\Scenario1\\Micellaneous\\Survival.ipynb", "4_Causal_Policy_Learning\\Scenario1\\PlanToDo.md", "4_Causal_Policy_Learning\\Scenario1\\Q-learning_Single.ipynb", "4_Causal_Policy_Learning\\Scenario1\\Quantile\\QuantileOTR_test.ipynb", "4_Causal_Policy_Learning\\Scenario1\\Single Stage.md", "4_Causal_Policy_Learning\\Scenario1\\Test\\A_Q test.ipynb", "4_Causal_Policy_Learning\\Scenario2\\DR_Infinite.ipynb", "4_Causal_Policy_Learning\\Scenario2\\Deeply_Debiased.ipynb", "4_Causal_Policy_Learning\\Scenario2\\Evaluation.md", "4_Causal_Policy_Learning\\Scenario2\\FQE.ipynb", "4_Causal_Policy_Learning\\Scenario2\\FQI.ipynb", "4_Causal_Policy_Learning\\Scenario2\\IPW_Infinite.ipynb", "4_Causal_Policy_Learning\\Scenario2\\Inference.ipynb", "4_Causal_Policy_Learning\\Scenario2\\MediationRL.ipynb", "4_Causal_Policy_Learning\\Scenario2\\Model_based_Infinite.ipynb", "4_Causal_Policy_Learning\\Scenario2\\Optimization.md", "4_Causal_Policy_Learning\\Scenario2\\Spatial_temporal_DR.ipynb", "4_Causal_Policy_Learning\\Scenario2\\archive\\archive_preliminary_MDP.ipynb", "4_Causal_Policy_Learning\\Scenario2\\preliminary_MDP-potential-outcome.ipynb", "4_Causal_Policy_Learning\\Scenario3\\A-learning_Multiple.ipynb", "4_Causal_Policy_Learning\\Scenario3\\Multi Stage.md", "4_Causal_Policy_Learning\\Scenario3\\Q-learning_Multiple.ipynb", "4_Causal_Policy_Learning\\Scenario4\\Bandits.md", "4_Causal_Policy_Learning\\Scenario4\\Contextual_Bandits\\Contextual_Bandits.ipynb", "4_Causal_Policy_Learning\\Scenario4\\Contextual_Bandits\\LinTS.ipynb", "4_Causal_Policy_Learning\\Scenario4\\Contextual_Bandits\\LinUCB.ipynb", "4_Causal_Policy_Learning\\Scenario4\\MAB\\Epsilon_Greedy.ipynb", "4_Causal_Policy_Learning\\Scenario4\\MAB\\MAB.ipynb", "4_Causal_Policy_Learning\\Scenario4\\MAB\\TS.ipynb", "4_Causal_Policy_Learning\\Scenario4\\MAB\\UCB.ipynb", "4_Causal_Policy_Learning\\Scenario4\\Meta_Bandits\\MTTS.ipynb", "4_Causal_Policy_Learning\\Scenario4\\Meta_Bandits\\Meta_Bandits.ipynb", "4_Causal_Policy_Learning\\Scenario4\\Meta_Bandits\\Meta_TS.ipynb", "4_Causal_Policy_Learning\\Scenario4\\OnlineEval\\Direct Online Policy Evaluator.ipynb", "4_Causal_Policy_Learning\\Scenario4\\OnlineEval\\Doubly Robust Online Policy Evaluator.ipynb", "4_Causal_Policy_Learning\\Scenario4\\OnlineEval\\Inverse Probability Weighted Online Policy Evaluator.ipynb", "4_Causal_Policy_Learning\\Scenario4\\OnlineEval\\Online Policy Evaluation.md", "4_Causal_Policy_Learning\\Scenario4\\Structured_Bandits\\Cascade\\CascadeLinTS.ipynb", "4_Causal_Policy_Learning\\Scenario4\\Structured_Bandits\\Cascade\\Learning to rank.ipynb", "4_Causal_Policy_Learning\\Scenario4\\Structured_Bandits\\Cascade\\MTSS_Cascade.ipynb", "4_Causal_Policy_Learning\\Scenario4\\Structured_Bandits\\Cascade\\TS_Cascade.ipynb", "4_Causal_Policy_Learning\\Scenario4\\Structured_Bandits\\Combinatorial-Semi\\CombLinTS.ipynb", "4_Causal_Policy_Learning\\Scenario4\\Structured_Bandits\\Combinatorial-Semi\\CombTS.ipynb", "4_Causal_Policy_Learning\\Scenario4\\Structured_Bandits\\Combinatorial-Semi\\Combinatorial Optimization.ipynb", "4_Causal_Policy_Learning\\Scenario4\\Structured_Bandits\\Combinatorial-Semi\\MTSS_Comb.ipynb", "4_Causal_Policy_Learning\\Scenario4\\Structured_Bandits\\MNL\\Assortment Optimization.ipynb", "4_Causal_Policy_Learning\\Scenario4\\Structured_Bandits\\MNL\\MTSS_MNL.ipynb", "4_Causal_Policy_Learning\\Scenario4\\Structured_Bandits\\MNL\\TS_Contextual_MNL.ipynb", "4_Causal_Policy_Learning\\Scenario4\\Structured_Bandits\\MNL\\TS_MNL_Beta.ipynb", "4_Causal_Policy_Learning\\Scenario4\\Structured_Bandits\\MNL\\UCB-MNL.ipynb", "4_Causal_Policy_Learning\\Scenario4\\Structured_Bandits\\Structured_Bandit.ipynb", "4_Causal_Policy_Learning\\Scenario4\\_old_docs(to delete)\\Single-Item Recommendation.ipynb", "4_Causal_Policy_Learning\\Scenario4\\_old_docs(to delete)\\Single\\Epsilon Greedy.ipynb", "4_Causal_Policy_Learning\\Scenario4\\_old_docs(to delete)\\Single\\LinTS.ipynb", "4_Causal_Policy_Learning\\Scenario4\\_old_docs(to delete)\\Single\\LinUCB.md", "4_Causal_Policy_Learning\\Scenario4\\_old_docs(to delete)\\Single\\Multi-Task.md", "4_Causal_Policy_Learning\\Scenario4\\_old_docs(to delete)\\Single\\MultiTask\\MTTS.md", "4_Causal_Policy_Learning\\Scenario4\\_old_docs(to delete)\\Single\\MultiTask\\Meta-TS.md", "4_Causal_Policy_Learning\\Scenario4\\_old_docs(to delete)\\Single\\TS.ipynb", "4_Causal_Policy_Learning\\Scenario4\\_old_docs(to delete)\\Single\\UCB1.ipynb", "4_Causal_Policy_Learning\\Scenario4\\_old_docs(to delete)\\Slate Recommendation.ipynb", "4_Causal_Policy_Learning\\Scenario5\\OnlineRL_Markov.ipynb", "4_Causal_Policy_Learning\\Scenario6\\OnlineRL_non_Markov.ipynb", "5_Case_Study\\MIMIC3\\Case_Study_1.md", "5_Case_Study\\MIMIC3\\Create_DTR_RL_MIMIC_Data_V2.ipynb", "5_Case_Study\\MIMIC3\\Infinite_Horizon.ipynb", "5_Case_Study\\MIMIC3\\Longitudinal.ipynb", "5_Case_Study\\MIMIC3\\MIMIC3-Demo.ipynb", "5_Case_Study\\MIMIC3\\MIMIC3-Demo-Ver2.ipynb", "5_Case_Study\\MIMIC3\\MIMIC3_intro.ipynb", "5_Case_Study\\MIMIC3\\Single_Stage.ipynb", "5_Case_Study\\MovieLens\\Data_Preprocessing.ipynb", "5_Case_Study\\MovieLens\\MovieLens.ipynb", "5_Case_Study\\MovieLens\\MovieLens_simulation.ipynb", "Overview.md", "README.md", "_old files(to delete)\\Map.md"], "titles": ["Learner Name (Single/Multiple Stages/Infinite Horizon)", "Causal Effect Learning (CEL)", "Causal Policy Learning (CPL)", "Causal Structure Learning (CSL)", "Causal Inference 101", "Causal Inference 101", "Causal Inference Preliminary", "Policy Evaluation and Optimization", "Preliminary", "Causal Discovery", "Causal Mediation Analysis", "Functional-based Learner", "Preliminaries of Causal Graphs", "Score-based Learner", "Testing-based Learner", "ATE Estimation", "<strong>5. DR-learner</strong>", "<strong>8. Dragon Net</strong>", "<strong>7. Generalized Random Forest</strong>", "HTE Estimation", "<strong>6. Lp-R-learner</strong>", "Mediation Analysis", "<strong>Meta Learners</strong>", "<strong>Other Approaches</strong>", "<strong>4. R learner</strong>", "<strong>R-Learner, DR-Learner, and Lp-R-Learner</strong>", "<strong>1. S-learner</strong>", "<strong>Single Stage \u2013 Paradigm 1</strong>", "<strong>2. T-learner</strong>", "<strong>3. X-learner</strong>", "ATE", "HTE", "Markov Decision Processes \u2013 Paradigm 2", "<strong>Difference in Difference</strong>", "Extensions", "<strong>H1SL and H2SL</strong>", "<strong>Matrix Completion</strong>", "MediatedQ-Learning (Multiple Stages)", "Panel Data  \u2013 Paradigm 3", "<strong>R-DiD</strong>", "<strong>Synthetic Control</strong>", "<strong>Synthetic DiD</strong>", "<strong>Synthetic Learner</strong>", "<strong>Synthetic X-Learner</strong>", "Miscellaneous", "A-Learning", "Reduction to Classification Problems", "Entropy learning", "Outcome Weighted Learning", "Continuous Action Space", "Deep Jump Learner for Continuous Actions", "Kernel-Based Learner", "Outcome Learning", "Discrete Action Space", "Adaptively Collected Data", "Concordance-assisted learning", "Policy Search", "Time-to-Event Data", "Plan To Do", "Q-Learning", "Quantile Optimal Treatment Regime", "Single Stage", "Test A-Learning Single", "Doubly Robust Estimator for Policy Evaluation (Infinite Horizon)", "Deeply-Debiased Off-Policy Evaluation", "Policy Evaluation\u2013Value Estimation", "Fitted-Q Evaluation", "Fitted-Q Iteration", "Importance Sampling for Policy Evaluation (Infinite Horizon)", "Confidence Interval in OPE", "Dynamic Mediation Analysis in Reinforcement Learning", "Q-Learning (Infinite Horizon)", "Policy Optimization", "Infinite Horizon Importance Sampling for Policy Evaluation", "Preliminary: Off-policy Evaluation and Optimization in Markov Decision Processes", "Preliminary: Off-policy Evaluation and Optimization in Markov Decision Processes", "A-Learning", "Multiple Stages (DTR)", "Q-Learning", "Overview: Bandits ALgorithm", "Contextual Bandits", "LinTS", "LinUCB", "<span class=\"math notranslate nohighlight\">\\(\\epsilon\\)</span>-Greedy", "Multi-Armed Bandits (MAB)", "TS", "UCB", "Multi-Task Thompson Sampling (MTTS)", "Meta Bandits", "Meta Thompson Sampling", "Direct Online Policy Evaluator", "Doubly Robust Online Policy Evaluator", "Inverse Probability Weighted Online Policy Evaluator", "Online Policy Evaluation", "CascadeLinTS", "Online Learning to Rank (Cascading Bandit)", "MTSS_Cascade", "TS_Cascade", "CombLinTS", "CombTS", "Online Combinatorial Optimization (Combinatorial Semi-Bandit)", "MTSS_Comb", "Dynamic Assortment Optimization (Multinomial Logit Bandit)", "MTSS_MNL", "TS_Contextual_MNL", "TS_MNL", "UCB_MNL", "Structured Bandit (Slate Recommendation)", "Single-Item Recommendation", "Epsilon_Greedy", "LinTS", "LinUCB", "Multi-Task", "MTTS", "Meta-TS", "TS", "UCB1", "Slate Recommendation", "Ooline Policy Learning and Evaluation in Markovian Environments", "Ooline Policy Learning in Non-Markovian Environments", "MIMIC III", "Generating 3-stage-DTR dataset", "MIMIC III (Infinite Horizon)", "MIMIC III (3-Stages)", "Mimic3 Demo", "Mimic3 Demo-Ver2", "Mimic3", "MIMIC III (Single-Stage)", "Read in Data", "MovieLens", "Specifying the Simulation Environments", "Overview", "Content of every notebook", "&lt;no title&gt;"], "terms": {"an": [0, 1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 22, 23, 25, 27, 28, 29, 32, 33, 45, 48, 49, 50, 59, 60, 61, 64, 65, 66, 67, 68, 69, 70, 73, 74, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 115, 116, 117, 118, 119, 121, 122, 123, 125, 127, 129, 130, 131, 132], "overview": [0, 10, 11, 12, 14], "includ": [0, 2, 5, 9, 27, 32, 38, 40, 59, 61, 70, 75, 76, 77, 78, 79, 80, 84, 85, 88, 90, 91, 92, 94, 96, 98, 99, 100, 101, 103, 104, 105, 107, 108, 109, 110, 115, 116, 117, 118, 122, 123, 124, 125, 126, 129, 131], "brief": [0, 119, 131], "introduct": [0, 5, 29, 32, 74, 75, 80, 83, 84, 94, 96, 97, 98, 99, 101, 103, 104, 105, 106, 108, 109, 118, 119], "evolut": 0, "i": [0, 1, 2, 4, 6, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 32, 33, 38, 40, 45, 50, 59, 60, 61, 63, 64, 66, 67, 68, 69, 70, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 110, 115, 116, 117, 118, 119, 121, 122, 123, 127, 128, 129], "e": [0, 1, 2, 4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 38, 40, 45, 48, 50, 59, 60, 61, 63, 64, 66, 67, 68, 70, 73, 74, 75, 76, 78, 79, 80, 81, 82, 83, 85, 87, 88, 89, 90, 91, 92, 94, 96, 97, 98, 99, 101, 102, 103, 104, 105, 108, 110, 115, 116, 118, 119, 127, 131], "when": [0, 2, 4, 5, 6, 10, 12, 13, 14, 15, 17, 19, 21, 22, 27, 28, 32, 38, 40, 50, 60, 63, 64, 66, 68, 73, 74, 75, 81, 85, 87, 89, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 110, 115, 117, 119, 124, 125, 127, 129, 131], "first": [0, 5, 9, 10, 14, 15, 17, 18, 19, 20, 21, 22, 23, 25, 26, 32, 33, 38, 40, 48, 59, 60, 63, 64, 66, 70, 73, 80, 86, 87, 91, 92, 94, 96, 97, 105, 116, 118, 122, 123, 127, 129, 131, 132], "develop": [0, 1, 2, 9, 14, 18, 23, 32, 48, 50, 88, 99, 104, 105], "ani": [0, 4, 5, 6, 9, 10, 11, 13, 15, 18, 19, 21, 22, 23, 26, 28, 29, 32, 33, 40, 50, 60, 63, 64, 68, 73, 74, 75, 77, 79, 80, 86, 88, 94, 95, 96, 97, 107, 117, 118, 119, 123, 127, 128, 131], "altern": [0, 15, 45, 76, 102, 118], "extens": [0, 5, 19, 20, 25, 32, 45, 59, 63, 64, 73, 76, 78, 80, 84, 108, 118, 119, 131], "applic": [0, 1, 2, 3, 9, 10, 12, 32, 37, 38, 48, 50, 63, 66, 68, 70, 74, 75, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 117, 123], "situat": [0, 11, 13, 14, 40, 50, 63, 66, 68, 80, 81, 82, 83, 85, 86, 87, 89, 90, 91, 92, 94, 96, 97, 98, 99, 101, 103, 104, 105, 106], "describ": [0, 6, 10, 27, 107, 124, 125, 126, 132], "data": [0, 2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 19, 22, 23, 25, 32, 33, 36, 40, 45, 48, 50, 59, 63, 64, 65, 68, 73, 74, 75, 76, 78, 81, 82, 83, 85, 86, 87, 89, 90, 91, 92, 106, 118, 122, 123, 124, 125, 126, 127, 129, 130], "structur": [0, 2, 5, 10, 12, 15, 17, 19, 21, 32, 38, 45, 48, 59, 64, 70, 76, 77, 78, 79, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 118, 122, 123, 127], "can": [0, 1, 2, 4, 5, 6, 9, 10, 11, 13, 15, 17, 18, 19, 20, 21, 22, 23, 25, 26, 29, 32, 33, 38, 40, 45, 48, 50, 59, 60, 61, 63, 64, 66, 67, 68, 69, 70, 71, 73, 75, 76, 78, 79, 81, 83, 85, 87, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 109, 110, 115, 116, 117, 118, 122, 124, 125, 127, 128, 129, 131, 132], "analyz": [0, 70, 122, 123, 127], "make": [0, 4, 5, 6, 9, 10, 15, 17, 32, 50, 59, 60, 78, 79, 80, 83, 90, 91, 92, 118, 119, 131, 132], "connect": [0, 12, 75, 118], "between": [0, 1, 2, 4, 6, 9, 14, 15, 19, 22, 29, 32, 33, 40, 45, 50, 59, 62, 68, 73, 75, 76, 82, 85, 87, 91, 92, 96, 97, 103, 104, 105, 108, 131], "real": [0, 2, 3, 9, 17, 18, 19, 20, 23, 25, 32, 33, 38, 45, 50, 59, 76, 78, 79, 90, 91, 92, 94, 99, 106, 129], "mention": [0, 73, 131], "motiv": [0, 2, 4, 15, 59, 63, 64, 66, 67, 73, 74, 78, 80, 84, 88, 94, 95, 100, 102, 118, 124, 125], "exampl": [0, 1, 2, 4, 5, 6, 9, 14, 17, 18, 19, 21, 22, 23, 32, 33, 38, 40, 45, 59, 60, 63, 64, 73, 76, 78, 79, 80, 81, 83, 84, 85, 86, 88, 95, 96, 100, 101, 102, 103, 110, 115, 118, 123, 127, 131], "we": [0, 1, 2, 3, 4, 6, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 32, 33, 38, 40, 45, 48, 49, 50, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 115, 116, 117, 118, 119, 122, 123, 124, 125, 126, 127, 129, 131, 132], "us": [0, 1, 2, 4, 6, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 28, 29, 33, 40, 45, 50, 59, 60, 61, 62, 64, 65, 67, 68, 70, 73, 74, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 101, 103, 104, 105, 106, 107, 108, 109, 110, 115, 116, 117, 118, 119, 121, 122, 123, 124, 125, 127, 129, 130, 131, 132], "advantag": [0, 11, 13, 14, 45, 50, 60, 63, 64, 66, 68, 69, 76, 81, 82, 83, 85, 86, 87, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 108, 129, 131, 132], "descript": [0, 95, 100, 102, 117], "clear": [0, 129], "definit": [0, 10, 27, 45, 64, 66, 74, 75, 76, 95, 124, 125, 126], "concept": [0, 19, 75, 95], "abstract": 0, "pseudo": [0, 16, 25, 60, 76, 78, 132], "In": [0, 1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 38, 40, 45, 48, 49, 50, 53, 59, 60, 62, 63, 64, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 78, 79, 80, 81, 82, 84, 85, 88, 89, 90, 91, 92, 94, 95, 97, 98, 99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 110, 115, 116, 117, 118, 119, 121, 122, 123, 124, 125, 127, 128, 129, 130, 131], "follow": [0, 2, 3, 4, 5, 9, 10, 11, 13, 14, 15, 19, 22, 24, 25, 27, 29, 33, 38, 40, 45, 48, 50, 59, 60, 61, 63, 64, 66, 67, 68, 69, 70, 73, 74, 75, 76, 78, 79, 80, 84, 90, 91, 92, 96, 97, 101, 103, 106, 107, 108, 117, 118, 123, 124, 125, 126, 127, 129, 131], "exhibit": [0, 45, 50, 59, 76, 78, 90, 91, 92, 106], "how": [0, 1, 2, 3, 9, 12, 17, 22, 27, 40, 45, 48, 50, 59, 60, 61, 62, 63, 70, 73, 76, 78, 79, 80, 88, 90, 91, 92, 106, 107, 117, 118], "appli": [0, 10, 11, 16, 17, 19, 20, 25, 45, 50, 59, 60, 63, 64, 68, 73, 76, 78, 84, 87, 89, 90, 91, 92, 106, 108, 118, 119, 121, 123, 127, 130, 131], "do": [0, 5, 10, 12, 15, 21, 24, 25, 32, 45, 48, 50, 59, 60, 76, 78, 82, 86, 97, 99, 105, 116, 118, 123, 127, 131], "respect": [0, 4, 6, 9, 13, 45, 50, 59, 60, 63, 66, 68, 73, 74, 75, 76, 78, 90, 91, 92, 118], "import": [0, 1, 2, 3, 10, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 40, 45, 48, 50, 59, 60, 61, 62, 63, 64, 66, 67, 69, 71, 75, 76, 78, 106, 109, 110, 115, 116, 119, 121, 122, 123, 124, 125, 127, 128, 129, 130], "from": [0, 1, 2, 3, 4, 6, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 40, 45, 48, 50, 59, 60, 61, 62, 63, 64, 68, 70, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 115, 116, 117, 118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131], "causaldm": [0, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 40, 45, 48, 50, 59, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 73, 76, 78, 81, 82, 83, 85, 86, 87, 89, 94, 96, 97, 98, 99, 101, 103, 104, 105, 106, 109, 110, 115, 116, 122, 123, 127, 129, 130, 132], "alearn": [0, 45, 62, 76], "test": [0, 1, 9, 10, 11, 12, 13, 16, 20, 24, 25, 27, 40, 45, 48, 59, 76, 78, 124, 125, 126, 127, 129, 131], "shared_simul": [0, 48, 62, 76, 78], "numpi": [0, 10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 33, 40, 45, 48, 62, 70, 76, 78, 81, 82, 83, 85, 86, 87, 89, 94, 96, 97, 98, 99, 101, 103, 104, 105, 106, 109, 110, 115, 116, 121, 122, 123, 124, 125, 127, 128, 129, 130], "np": [0, 10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 40, 45, 48, 50, 60, 62, 70, 76, 78, 81, 82, 83, 85, 86, 87, 89, 94, 96, 97, 98, 99, 101, 103, 104, 105, 106, 109, 110, 115, 116, 121, 122, 123, 124, 125, 127, 128, 129, 130], "importerror": [0, 62, 106], "traceback": [0, 10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 40, 45, 50, 60, 62, 63, 64, 66, 67, 68, 69, 70, 71, 73, 76, 106, 109, 110, 115, 116, 121, 122, 125, 127, 128, 129, 130], "most": [0, 2, 5, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 40, 45, 48, 50, 60, 62, 63, 64, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 80, 83, 84, 87, 88, 89, 94, 98, 99, 100, 101, 102, 106, 107, 108, 109, 110, 115, 116, 117, 118, 121, 122, 124, 125, 127, 128, 129, 130, 131], "recent": [0, 2, 3, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 40, 45, 50, 60, 62, 63, 64, 66, 67, 68, 69, 70, 71, 73, 76, 79, 80, 88, 97, 99, 104, 105, 106, 108, 109, 110, 115, 116, 119, 121, 122, 125, 127, 128, 129, 130, 132], "call": [0, 4, 5, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 40, 45, 48, 50, 60, 62, 63, 64, 66, 67, 68, 69, 70, 71, 73, 76, 106, 109, 110, 115, 116, 121, 122, 125, 127, 128, 129, 130, 132], "last": [0, 9, 10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 40, 45, 50, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 73, 74, 76, 91, 92, 106, 109, 110, 115, 116, 121, 122, 125, 127, 128, 129, 130, 131], "var": [9, 21, 121], "folder": [21, 132], "9j": 21, "vb5nb4rd5bx0gr1q5ytx9q600000gn": 21, "t": [2, 4, 5, 6, 10, 11, 15, 17, 18, 19, 20, 21, 23, 25, 29, 32, 33, 38, 40, 45, 59, 60, 62, 63, 64, 66, 67, 68, 69, 70, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 115, 116, 117, 118, 122, 123, 124, 125, 127, 129, 130, 131], "ipykernel_68957": [], "261550316": [], "py": [0, 9, 10, 11, 14, 21, 22, 23, 45, 50, 62, 70, 76, 106, 121, 122, 124, 125, 127, 128, 129, 130], "modul": [10, 11, 13, 14, 18, 25, 50], "3": [0, 1, 5, 10, 16, 17, 18, 20, 23, 24, 25, 26, 27, 28, 33, 40, 45, 48, 50, 59, 60, 62, 70, 76, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 115, 116, 117, 118, 119, 122, 124, 125, 126, 127, 128, 129, 130], "4": [0, 3, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 29, 33, 40, 45, 48, 50, 59, 60, 62, 64, 70, 73, 76, 78, 79, 80, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 95, 96, 100, 101, 102, 103, 106, 107, 108, 109, 110, 115, 116, 117, 118, 121, 122, 123, 124, 125, 127, 128, 129, 130], "cannot": [0, 2, 4, 6, 11, 14, 15, 62, 64, 75, 106, 119], "user": [2, 4, 6, 15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 33, 40, 45, 48, 59, 60, 76, 78, 80, 81, 82, 83, 84, 87, 88, 89, 95, 98, 99, 101, 102, 103, 104, 105, 107, 108, 109, 117, 121, 124, 129], "alinaxu": [15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 33, 40, 60], "opt": [10, 11, 18, 45, 59, 62, 76, 78, 123, 127, 130], "anaconda3": [0, 10, 11, 18, 22, 23, 45, 50, 62, 70, 76, 106, 121, 122, 125, 127, 128, 129, 130], "lib": [0, 10, 11, 18, 22, 23, 45, 50, 62, 70, 76, 106, 121, 122, 125, 127, 128, 129, 130], "python3": [11, 18, 23], "9": [5, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 21, 23, 26, 27, 28, 29, 33, 45, 59, 60, 62, 70, 73, 76, 108, 110, 115, 118, 121, 122, 123, 124, 125, 127, 128, 129, 130], "site": [0, 2, 10, 11, 18, 22, 23, 45, 50, 62, 70, 76, 106, 121, 122, 125, 127, 128, 129, 130], "packag": [0, 9, 10, 11, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 45, 48, 50, 61, 62, 70, 76, 96, 103, 106, 121, 122, 124, 125, 127, 128, 129, 130, 132], "__init__": [0, 62, 70, 106, 122, 127, 128, 130], "find": [0, 2, 4, 6, 9, 14, 15, 27, 33, 45, 50, 59, 60, 70, 76, 78, 79, 80, 84, 85, 88, 90, 91, 92, 95, 98, 99, 100, 101, 102, 107, 108, 110, 115, 118, 122, 123, 127, 129, 132], "optim": [0, 2, 5, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 25, 45, 48, 50, 59, 62, 63, 64, 66, 67, 68, 73, 76, 78, 79, 80, 84, 85, 88, 90, 91, 92, 95, 96, 98, 99, 101, 103, 105, 106, 107, 108, 109, 110, 115, 116, 117, 119, 122, 129, 131, 132], "regim": [0, 2, 15, 19, 45, 50, 59, 62, 76, 78, 109, 110, 115, 116, 123, 127, 130, 131], "appropri": [0, 11, 60, 63, 66, 68, 73, 87, 96, 99, 103, 132], "interpret": [0, 3, 10, 13, 45, 50, 59, 70, 81, 82, 83, 85, 86, 87, 89, 94, 96, 97, 98, 99, 101, 103, 104, 105, 109, 110, 115, 116, 128], "A": [0, 1, 2, 3, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 32, 33, 40, 48, 50, 53, 59, 60, 61, 63, 64, 70, 73, 74, 75, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 115, 116, 117, 118, 121, 122, 123, 124, 125, 127, 128, 129, 130], "sentenc": [0, 109, 110, 115, 116], "analysi": [0, 3, 9, 11, 13, 14, 27, 33, 37, 38, 50, 83, 86, 96, 102, 108, 109, 110, 115, 116, 117, 124, 125, 126, 131], "result": [0, 2, 4, 5, 10, 15, 17, 18, 19, 20, 21, 22, 23, 25, 27, 28, 29, 45, 50, 59, 62, 63, 64, 66, 68, 70, 73, 76, 78, 94, 96, 97, 100, 109, 110, 115, 116, 122, 124, 125, 126, 130, 131], "estim": [0, 1, 2, 5, 6, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 32, 38, 40, 45, 48, 50, 59, 60, 62, 64, 66, 67, 68, 69, 73, 74, 75, 76, 78, 82, 83, 86, 90, 91, 92, 96, 97, 99, 106, 108, 109, 110, 115, 116, 118, 119, 122, 123, 124, 125, 127, 130, 131], "fix": [0, 45, 59, 60, 66, 67, 70, 76, 78, 80, 83, 90, 91, 92, 109, 118, 119, 122, 123, 127], "valu": [0, 2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 20, 21, 22, 23, 25, 27, 32, 40, 45, 48, 50, 59, 60, 61, 62, 63, 64, 66, 67, 68, 73, 75, 76, 78, 80, 83, 84, 88, 90, 91, 92, 95, 108, 109, 121, 122, 123, 124, 125, 126, 127, 129, 130], "subfield": 1, "infer": [1, 2, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 25, 26, 27, 32, 37, 38, 40, 59, 60, 64, 75, 90, 91, 92, 102, 105, 118, 119, 123, 131], "aim": [1, 2, 6, 11, 13, 14, 15, 17, 18, 19, 21, 22, 23, 28, 32, 33, 40, 45, 59, 61, 66, 67, 75, 76, 78, 80, 84, 88, 95, 100, 102, 107, 117, 118, 129, 131], "identifi": [1, 3, 9, 10, 11, 13, 14, 15, 17, 18, 21, 22, 23, 26, 33, 38, 70, 127], "conduct": [1, 27, 38, 60, 122, 123, 127, 129], "statist": [1, 2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 16, 18, 19, 20, 21, 23, 25, 33, 35, 36, 39, 40, 41, 42, 43, 45, 48, 50, 60, 63, 64, 68, 69, 70, 73, 76, 80, 81, 82, 88, 90, 91, 92, 94, 95, 97, 99, 108, 110, 118, 119, 122, 127, 131], "specif": [1, 2, 3, 4, 5, 6, 10, 15, 17, 18, 19, 21, 22, 23, 26, 27, 32, 33, 38, 40, 45, 59, 60, 63, 64, 67, 68, 69, 70, 73, 74, 75, 78, 79, 81, 83, 85, 87, 88, 89, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 107, 108, 109, 110, 115, 117, 122, 127, 129, 131], "intervent": [1, 2, 4, 6, 10, 12, 15, 27, 33], "system": [1, 5, 9, 10, 11, 12, 13, 14, 17, 19, 50, 68, 73, 74, 79, 80, 84, 87, 88, 89, 95, 96, 99, 101, 102, 103, 104, 107, 108, 119], "It": [1, 2, 4, 5, 19, 25, 32, 40, 66, 67, 68, 73, 75, 81, 82, 83, 85, 86, 87, 94, 96, 97, 98, 99, 100, 101, 103, 104, 108, 110, 115, 118, 119], "tri": 1, "answer": [1, 2, 17, 33], "question": [1, 2, 17, 33, 63, 73], "what": [1, 2, 32, 33, 76, 78, 79, 102], "have": [1, 2, 3, 4, 6, 10, 12, 15, 27, 32, 33, 40, 48, 60, 61, 63, 68, 73, 74, 75, 77, 79, 80, 87, 88, 89, 94, 104, 107, 108, 117, 118, 124, 125, 126, 129, 131, 132], "done": [1, 118], "someth": [1, 62], "differ": [1, 2, 3, 4, 5, 6, 12, 15, 22, 28, 32, 38, 40, 45, 59, 60, 61, 62, 68, 73, 74, 75, 76, 78, 80, 81, 84, 85, 87, 88, 89, 91, 92, 96, 97, 99, 100, 101, 103, 104, 107, 108, 110, 115, 118, 119, 128, 129, 131], "s": [1, 2, 3, 5, 6, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 27, 28, 29, 32, 33, 38, 40, 45, 59, 60, 61, 63, 64, 66, 67, 68, 70, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 87, 88, 89, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 118, 123, 127, 128, 129, 130, 131], "consequ": [1, 4, 15, 50, 63, 73], "excecut": 1, "polici": [1, 5, 15, 19, 21, 22, 23, 25, 32, 33, 48, 49, 53, 62, 66, 67, 69, 80, 83, 122, 129, 132], "quantifi": [1, 2, 3, 10, 40, 70, 86, 91, 92, 95, 124, 125], "etc": [1, 2, 17, 19, 32, 38, 45, 59, 80, 100, 107, 117], "suppos": [1, 9, 10, 11, 12, 13, 14, 19, 33, 38, 40, 45, 61, 76, 77, 80, 81, 82, 83, 84, 85, 86, 95, 100, 102, 109, 110, 115, 116, 118], "you": [1, 5, 45, 48, 59, 60, 78, 97, 123, 127, 128, 129, 132], "ar": [1, 2, 3, 4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 28, 29, 32, 33, 38, 40, 45, 48, 53, 60, 61, 63, 64, 66, 68, 70, 73, 74, 75, 76, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 107, 108, 109, 110, 115, 116, 117, 118, 121, 122, 123, 124, 125, 127, 128, 129, 131, 132], "medic": [1, 15], "research": [1, 2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 21, 32, 33, 63, 67, 73, 99, 102, 105, 106], "who": [1, 2, 4, 6, 15, 27, 33, 61, 81, 82, 87, 88, 124, 125, 126], "just": [1, 10, 18, 20, 22, 23, 25, 28, 32, 40, 118], "fictiti": 1, "hopefulli": 1, "allevi": 1, "patient": [1, 2, 27, 32, 50, 60, 88, 123, 124, 125, 126, 127], "symptom": 1, "hypertens": 1, "sinc": [1, 4, 10, 15, 21, 32, 61, 64, 68, 79, 80, 84, 90, 91, 92, 102, 108, 115, 118, 119, 131], "thi": [1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 15, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 32, 33, 38, 40, 48, 49, 50, 53, 60, 61, 63, 64, 65, 66, 67, 68, 69, 71, 72, 73, 74, 75, 79, 80, 83, 84, 86, 88, 95, 100, 101, 102, 103, 107, 108, 109, 110, 115, 116, 117, 118, 119, 122, 123, 124, 125, 127, 128, 129, 131, 132], "newli": [1, 50, 70], "drug": [1, 3], "must": [1, 2, 5], "go": [1, 33, 132], "through": [1, 2, 5, 9, 10, 11, 12, 14, 15, 17, 21, 33, 75, 80, 84, 87, 88, 95, 102, 105, 107, 108, 117, 118, 124, 125, 129], "preclin": 1, "bitro": 1, "vivo": 1, "three": [1, 6, 9, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 24, 25, 26, 28, 29, 32, 33, 60, 70, 79, 80, 81, 82, 83, 85, 86, 89, 90, 91, 92, 94, 96, 97, 98, 101, 103, 104, 105, 107, 108, 117, 118, 119, 123, 131], "phase": 1, "final": [1, 2, 17, 19, 20, 21, 22, 25, 28, 29, 59, 60, 63, 64, 66, 67, 73, 74, 76, 78, 80, 81, 82, 85, 96, 103, 104, 105, 110, 115, 118, 122, 123, 127, 129, 131], "approv": 1, "confirm": [1, 4, 6, 15], "potenti": [1, 2, 15, 19, 21, 22, 28, 29, 32, 33, 45, 59, 60, 64, 66, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 90, 91, 92, 95, 97, 98, 99, 100, 101, 102, 107, 118, 124, 125, 131], "side": [1, 66, 67, 118], "dure": [1, 2, 3, 10, 61], "procedur": [1, 6, 11, 15, 16, 17, 19, 25, 60, 64, 69], "usual": [1, 2, 15, 60, 68, 73], "evalu": [1, 5, 10, 11, 13, 14, 15, 18, 21, 22, 23, 27, 32, 33, 40, 67, 69, 70, 80, 108, 122, 131], "mesur": 1, "well": [1, 9, 11, 13, 19, 22, 27, 32, 38, 48, 60, 66, 68, 73, 74, 75, 83, 84, 94, 98, 100, 101, 108, 109, 118, 119, 131], "perform": [1, 9, 13, 17, 18, 19, 20, 22, 23, 25, 28, 48, 60, 63, 66, 67, 68, 73, 80, 81, 82, 83, 85, 86, 87, 89, 90, 91, 92, 108, 109, 118, 129], "compar": [1, 3, 15, 16, 18, 20, 22, 23, 25, 40, 63, 70, 73, 83, 89, 118, 122, 123, 127, 129, 131], "placebo": 1, "other": [1, 2, 3, 4, 5, 6, 9, 10, 13, 15, 17, 19, 21, 22, 25, 27, 28, 40, 45, 50, 59, 64, 73, 74, 75, 76, 78, 79, 80, 81, 84, 88, 94, 97, 98, 99, 100, 101, 104, 105, 107, 108, 117, 118, 128, 129, 130, 131], "exist": [1, 2, 4, 5, 6, 9, 10, 11, 12, 13, 17, 19, 21, 32, 45, 50, 59, 63, 70, 75, 95, 102, 107, 117, 118, 131], "treatment": [1, 2, 4, 9, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 38, 40, 45, 48, 50, 59, 61, 64, 65, 70, 72, 75, 76, 78, 79, 88, 108, 118, 122, 123, 124, 125, 127, 131], "method": [1, 2, 5, 10, 12, 13, 17, 19, 21, 22, 28, 29, 32, 33, 36, 38, 40, 45, 50, 59, 60, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 76, 78, 89, 90, 91, 92, 118, 119, 122, 127, 131, 132], "experiment": [1, 4, 6, 15, 33, 131], "design": [1, 17, 18, 19, 23, 63, 64, 73, 96, 101, 103, 118], "wide": [1, 2, 9, 15, 19, 32, 33, 63, 68, 73, 79, 80, 83, 84, 88, 94, 96, 100, 101, 103, 107, 108, 109, 129, 131], "known": [1, 2, 3, 9, 12, 15, 21, 22, 26, 32, 45, 68, 73, 74, 75, 76, 79, 84, 85, 87, 88, 89, 90, 91, 92, 95, 96, 100, 101, 102, 103, 108, 110, 115, 118, 119, 131], "b": [1, 2, 9, 10, 11, 13, 14, 15, 16, 18, 19, 20, 22, 23, 25, 26, 28, 29, 45, 48, 50, 53, 59, 60, 63, 68, 73, 74, 75, 76, 78, 79, 80, 81, 85, 87, 88, 89, 94, 95, 98, 100, 101, 107, 108, 110, 115, 116, 117, 128], "randomli": [1, 2, 4, 6, 16, 17, 18, 20, 24, 26, 28, 29, 83, 109], "assign": [1, 2, 4, 6, 12, 15, 19, 22, 23, 32, 33, 38, 48, 59, 70, 75, 78], "one": [1, 2, 4, 5, 6, 15, 19, 21, 22, 26, 32, 33, 40, 45, 48, 60, 63, 64, 66, 68, 73, 75, 76, 80, 84, 85, 88, 94, 95, 96, 97, 102, 103, 104, 105, 107, 108, 110, 115, 118, 123, 127, 129], "two": [1, 2, 3, 4, 5, 6, 10, 14, 15, 16, 17, 21, 22, 25, 26, 28, 29, 32, 33, 40, 60, 61, 63, 64, 68, 73, 75, 79, 80, 84, 85, 88, 90, 91, 92, 96, 101, 103, 108, 115, 118, 123, 124, 125, 127, 131, 132], "group": [1, 2, 4, 6, 15, 19, 22, 28, 29, 33, 38, 40, 45, 60, 76, 84, 100, 108, 124, 125, 127, 131], "receiv": [1, 2, 4, 6, 15, 32, 33, 40, 59, 61, 74, 75, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 115, 116, 117, 123, 127, 129, 131], "measur": [1, 3, 4, 6, 9, 10, 11, 12, 13, 14, 15, 19, 33, 38, 64, 68, 70, 75, 118, 131], "sbp": 1, "systol": 1, "blood": 1, "pressur": [1, 27, 124, 125, 126], "each": [1, 2, 3, 4, 6, 9, 10, 11, 13, 14, 18, 19, 20, 21, 22, 23, 25, 28, 32, 33, 40, 45, 50, 59, 61, 68, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 115, 116, 117, 122, 123, 124, 125, 127, 129, 131], "both": [1, 4, 5, 6, 10, 11, 13, 14, 15, 17, 22, 28, 50, 60, 63, 64, 68, 70, 73, 75, 83, 87, 89, 96, 101, 103, 109, 115, 118, 123, 127, 129, 131], "befor": [1, 10, 11, 15, 16, 22, 23, 25, 33, 38, 89], "after": [1, 2, 3, 10, 11, 13, 14, 15, 17, 24, 25, 27, 33, 38, 40, 61, 63, 64, 66, 67, 68, 69, 71, 73, 74, 78, 81, 83, 85, 86, 97, 109, 110, 115, 116, 118, 124, 125, 126], "By": [1, 17, 19, 45, 59, 61, 64, 74, 75, 78, 83, 87, 107, 109], "analys": 1, "abl": [1, 4, 6, 15, 17, 19, 33, 85, 87, 124, 125], "determin": [1, 9, 12, 14, 72, 83, 87, 96, 101, 102, 103, 104, 105, 107, 117], "treat": [1, 17, 27, 33, 38, 40, 107, 124, 125, 131], "shop": [1, 19], "websit": [1, 2, 19, 27, 77, 80, 84, 88, 107, 108, 129, 132], "seller": 1, "often": [1, 4, 6, 17, 22, 28, 32, 40, 60, 131], "veri": [1, 3, 5, 19, 22, 26, 28, 33, 38, 60, 131], "cautiou": 1, "about": [1, 2, 4, 5, 6, 15, 17, 18, 20, 22, 23, 25, 29, 32, 40, 60, 61, 80, 85, 88, 89, 127], "custom": [1, 2, 19, 60, 61, 87, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 128], "purchas": [1, 2, 61, 102, 103, 104, 105, 106], "experi": [1, 4, 6, 15, 19, 48, 75, 80, 84, 88, 90, 91, 92, 107, 108, 129], "whenev": [1, 2, 80, 84, 95, 102], "consum": [1, 10, 33], "satisfi": [1, 9, 15, 17, 18, 23, 24, 25, 63, 64, 68, 73, 80, 84, 88, 98, 99, 100, 101, 107, 108, 117, 118, 129], "item": [1, 2, 79, 80, 81, 83, 84, 85, 86, 87, 88, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 109, 110, 116, 117, 128, 131], "thei": [1, 2, 4, 5, 6, 32, 33, 68, 73, 75, 80, 84, 88, 107, 108, 129], "bought": 1, "order": [1, 2, 9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 23, 25, 32, 60, 64, 87, 88, 89, 94, 95, 96, 97, 98, 99, 101, 103, 104, 105, 107, 117, 124, 125], "wrong": [1, 62], "size": [1, 22, 23, 25, 45, 50, 59, 62, 70, 98, 99, 100, 101, 122, 129, 130, 131], "cloth": [1, 19], "broken": 1, "miss": [1, 5, 75], "sever": [1, 2, 16, 17, 19, 21, 24, 25, 27, 32, 38, 107, 124, 125, 126, 131], "option": [1, 10, 18, 20, 23, 25, 45, 50, 59, 62, 76, 78, 80, 81, 82, 83, 85, 86, 109, 110, 115, 116, 128], "provid": [1, 2, 12, 14, 15, 19, 27, 28, 29, 32, 40, 45, 59, 62, 64, 70, 73, 75, 76, 78, 83, 87, 90, 91, 92, 104, 109, 118, 119, 122, 123, 127, 131, 132], "address": [1, 2, 17, 19, 32, 50, 83, 87, 118, 131], "problem": [1, 2, 3, 10, 17, 18, 19, 23, 24, 25, 32, 33, 38, 48, 59, 60, 63, 64, 66, 67, 68, 73, 78, 79, 83, 85, 86, 94, 96, 97, 98, 99, 101, 103, 104, 105, 106, 109, 116, 118, 119, 124, 125, 131, 132], "For": [1, 2, 3, 4, 5, 6, 10, 17, 19, 20, 22, 25, 27, 29, 32, 33, 38, 45, 59, 60, 61, 63, 68, 73, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 115, 116, 118, 124, 125, 126, 129, 131], "mai": [1, 2, 3, 4, 6, 10, 15, 18, 19, 21, 23, 32, 48, 60, 75, 80, 81, 88, 110, 124, 125, 132], "offer": [1, 2, 64, 83, 102, 103, 104, 105, 106, 107, 117], "1": [1, 4, 5, 6, 10, 16, 18, 19, 20, 23, 24, 25, 28, 29, 32, 33, 38, 40, 48, 53, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 73, 74, 75, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 109, 110, 115, 116, 117, 118, 119, 121, 122, 123, 124, 125, 127, 128, 129, 130], "fulli": [1, 80, 84, 87, 88, 108, 118, 129], "refund": 1, "without": [1, 10, 22, 40, 74, 75, 92, 131], "return": [1, 2, 10, 21, 22, 23, 45, 50, 59, 62, 70, 76, 78, 118, 121, 122, 124, 127, 128, 130], "2": [1, 10, 16, 18, 19, 20, 23, 24, 25, 26, 29, 33, 35, 37, 39, 40, 41, 42, 43, 48, 60, 61, 62, 63, 64, 66, 67, 68, 69, 70, 73, 74, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 115, 116, 117, 118, 119, 122, 123, 124, 125, 127, 128, 129, 130], "discount": [1, 64, 73, 74, 75, 118], "next": [1, 10, 15, 19, 22, 29, 38, 60, 68, 73, 74, 75, 91, 92, 124, 125, 132], "compens": 1, "level": [1, 3, 4, 5, 6, 19, 60, 118, 124, 125, 131], "vari": [1, 37, 80, 123], "accord": [1, 2, 4, 6, 12, 17, 27, 32, 33, 64, 66, 68, 70, 75, 85, 87, 105, 108, 110, 115, 124, 125, 131], "primari": [1, 3, 17, 61, 79, 131], "goal": [1, 2, 3, 17, 27, 40, 48, 60, 64, 74, 75, 80, 84, 88, 90, 91, 92, 100, 102, 107, 108, 129, 131, 132], "outcom": [1, 2, 3, 10, 12, 15, 16, 17, 19, 20, 21, 22, 24, 25, 28, 29, 32, 33, 37, 38, 40, 45, 50, 59, 60, 61, 70, 76, 78, 79, 87, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 118, 123, 127, 131], "so": [1, 2, 4, 5, 9, 10, 11, 13, 15, 17, 24, 25, 27, 60, 74, 75, 78, 83, 86, 108, 109, 116, 124, 125], "examin": [1, 95, 123, 127, 131], "which": [1, 2, 3, 4, 5, 6, 10, 12, 15, 17, 18, 19, 21, 22, 23, 24, 25, 27, 28, 29, 32, 33, 38, 40, 45, 48, 50, 53, 59, 60, 63, 67, 68, 70, 73, 74, 75, 76, 78, 79, 80, 81, 84, 85, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 115, 117, 118, 119, 122, 124, 125, 126, 127, 131], "take": [1, 11, 13, 14, 22, 29, 32, 33, 48, 60, 64, 70, 74, 78, 80, 83, 84, 85, 87, 88, 89, 94, 96, 98, 99, 100, 101, 103, 104, 105, 106, 108, 109, 121, 122, 125, 129, 131], "histori": [1, 2, 27, 45, 59, 60, 61, 75, 83, 90, 91, 92, 108, 109, 118, 119, 131], "maxim": [1, 2, 27, 48, 50, 59, 60, 78, 79, 80, 84, 88, 95, 107, 108, 118, 123, 127], "profit": [1, 2, 102, 107, 117], "asid": [1, 19, 33, 60], "abov": [1, 4, 6, 9, 10, 11, 15, 16, 17, 18, 19, 21, 22, 23, 25, 29, 32, 33, 40, 50, 102, 118, 123, 124, 125, 127, 132], "idea": [1, 17, 20, 22, 24, 25, 26, 33, 40, 118, 132], "fundament": 1, "ha": [1, 2, 3, 5, 9, 10, 13, 18, 19, 21, 23, 33, 38, 48, 50, 60, 63, 64, 68, 69, 70, 73, 77, 81, 84, 85, 86, 87, 88, 96, 99, 100, 102, 103, 107, 108, 110, 115, 116, 118, 122, 127, 131], "broad": [1, 38], "our": [1, 2, 4, 6, 15, 17, 18, 23, 32, 33, 38, 40, 50, 53, 60, 64, 68, 69, 70, 73, 75, 78, 88, 90, 91, 92, 118], "daili": 1, "live": 1, "leverag": [1, 14, 18, 20, 23, 25, 50, 89, 118], "studi": [1, 2, 3, 4, 5, 6, 9, 13, 15, 19, 21, 27, 32, 40, 60, 61, 63, 66, 73, 80, 84, 88, 107, 108, 119, 123, 127, 129, 131], "new": [1, 2, 4, 6, 17, 32, 33, 45, 60, 61, 76, 78, 80, 87, 88, 89, 100, 107, 108, 117, 118, 128, 129, 131], "catalyst": 1, "rate": [1, 2, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 24, 25, 26, 27, 28, 29, 50, 63, 64, 73, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 95, 107, 108, 109, 118, 123, 124, 125, 127, 128, 129], "chemic": 1, "reaction": 1, "smoke": [1, 40], "risk": 1, "lung": 1, "cancer": 1, "ad": [1, 4, 6, 19, 45, 76, 90, 91, 92, 100, 107, 117], "exposur": [1, 2, 3, 10, 19, 37, 40, 70, 123], "convers": [1, 2, 19], "bui": [1, 103, 104, 105], "product": [1, 2, 33, 102, 107, 117, 129], "extracurricular": 1, "remedi": 1, "class": [1, 4, 9, 10, 24, 25, 50, 60, 63, 64, 66, 73, 79, 80, 86, 88, 96, 101, 103, 107, 108, 116, 117, 119, 130, 131], "improv": [1, 2, 5, 16, 17, 18, 19, 20, 24, 26, 28, 29, 60, 94, 118, 119], "student": [1, 16, 17, 18, 20, 24, 27, 80, 81, 82, 87, 88, 108, 128, 129, 130], "grade": 1, "cdot": [1, 4, 6, 9, 10, 11, 12, 13, 14, 15, 18, 20, 21, 23, 24, 25, 33, 45, 50, 61, 63, 64, 66, 67, 68, 70, 73, 74, 75, 76, 77, 78, 79, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92, 94, 96, 97, 98, 99, 101, 102, 103, 104, 105, 106, 109, 110, 115, 116, 118, 131], "social": [1, 131], "phenomena": 1, "natur": [1, 2, 5, 10, 12, 21, 24, 25, 48, 60, 70, 118, 122, 123, 124, 125, 127, 129], "quantif": 1, "allow": [1, 2, 4, 5, 6, 10, 48, 50, 59, 60, 64, 75, 78, 131], "understand": [1, 10, 19, 59, 78, 83, 118], "relationship": [1, 3, 4, 6, 9, 10, 11, 12, 13, 14, 40, 48, 59, 68, 81, 96, 103, 105, 110, 118, 131], "methodolog": [1, 9, 12, 38, 45, 70, 76, 131], "onli": [1, 2, 4, 5, 6, 10, 12, 15, 17, 26, 33, 38, 40, 60, 61, 63, 64, 68, 69, 73, 74, 75, 79, 89, 94, 95, 96, 97, 102, 103, 104, 105, 118, 131, 132], "scientif": [1, 4, 6], "also": [1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 19, 21, 22, 24, 25, 26, 33, 45, 59, 60, 62, 63, 66, 67, 68, 70, 73, 75, 76, 78, 85, 87, 88, 96, 97, 98, 99, 100, 101, 102, 103, 105, 108, 110, 115, 119, 124, 125, 129, 131], "practic": [1, 2, 50, 59, 64, 78, 80, 81, 83, 84, 85, 87, 90, 91, 92, 94, 96, 97, 98, 99, 101, 103, 104, 105, 108, 109, 110, 115, 118], "where": [1, 2, 4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 38, 40, 45, 48, 50, 59, 60, 61, 63, 64, 66, 68, 69, 70, 73, 74, 75, 76, 78, 79, 80, 81, 83, 84, 85, 87, 88, 89, 90, 91, 92, 95, 96, 98, 100, 101, 102, 103, 107, 108, 109, 117, 118, 122, 123, 124, 125, 127, 128, 129, 131, 132], "seek": 1, "growth": 2, "engag": 2, "critic": [2, 5, 27, 40, 63, 73, 75, 124, 125, 126], "fast": [2, 9, 10, 11, 12, 13, 14, 33, 63, 131], "chang": [2, 22, 27, 32, 33, 38, 50, 68, 76, 98, 123, 124, 125, 127, 131, 132], "market": [2, 33, 128], "campaign": [2, 61], "internet": 2, "compani": [2, 19, 33], "encourag": [2, 48], "The": [2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 35, 38, 39, 40, 41, 42, 43, 45, 48, 50, 59, 60, 61, 63, 64, 66, 67, 68, 70, 73, 74, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 115, 116, 117, 118, 119, 122, 123, 124, 125, 126, 127, 129, 131, 132], "posit": [2, 4, 6, 10, 11, 13, 14, 15, 21, 22, 26, 32, 33, 45, 59, 70, 76, 78, 88, 107, 117, 129], "effect": [2, 3, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 28, 29, 32, 33, 38, 40, 48, 61, 64, 78, 102, 107, 117, 122, 123, 127], "desir": [2, 3, 60], "busi": 2, "lead": [2, 19, 64], "surplu": 2, "oper": [2, 10, 12, 15, 64, 102, 105, 106], "cost": [2, 25, 48, 105], "increas": [2, 50, 64, 79, 83, 90, 91, 92, 108, 123, 124, 125, 127], "impel": 2, "carri": 2, "out": [2, 10, 16, 17, 18, 19, 20, 24, 26, 28, 29, 59, 75, 127], "more": [2, 3, 4, 5, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 25, 26, 28, 29, 32, 45, 50, 60, 61, 63, 64, 66, 67, 68, 69, 71, 73, 75, 76, 80, 82, 83, 89, 98, 99, 101, 104, 105, 108, 109, 110, 115, 116, 118, 127, 132], "refin": 2, "strategi": 2, "acquisit": 2, "retent": 2, "associ": [2, 4, 5, 6, 9, 11, 13, 21, 36, 40, 48, 50, 60, 75, 79, 90, 91, 92, 119, 124, 125, 127, 131], "massiv": [2, 19], "scale": [2, 9, 20, 25, 40, 50, 66, 70, 79, 94, 95, 96, 98, 100, 101, 103, 104, 108, 131], "promot": 2, "balanc": [2, 74, 85, 108], "increment": [2, 33, 118], "sustain": 2, "invest": [2, 45, 59, 76, 78], "roi": [2, 85, 107, 108, 115, 116, 117], "requir": [2, 9, 11, 14, 17, 18, 23, 32, 45, 48, 50, 63, 64, 73, 75, 76, 78, 88, 118, 131], "predict": [2, 5, 15, 18, 21, 22, 23, 26, 28, 29, 40, 50, 59, 70, 78, 118, 124, 125, 129], "caus": [2, 4, 6, 9, 11, 12, 13, 14, 19, 21, 32, 33, 48, 60, 124, 125], "action": [2, 4, 6, 10, 16, 17, 18, 19, 20, 21, 24, 27, 28, 29, 32, 33, 45, 48, 59, 61, 62, 63, 64, 66, 67, 68, 70, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 115, 116, 117, 118, 119, 121, 122, 123, 124, 125, 127, 128, 129, 130, 131], "uplift": [2, 60, 61], "model": [2, 6, 10, 12, 15, 17, 21, 22, 24, 25, 26, 28, 29, 36, 45, 50, 59, 60, 62, 63, 64, 66, 73, 74, 75, 76, 78, 79, 81, 82, 87, 88, 90, 91, 92, 94, 95, 96, 98, 101, 102, 103, 104, 105, 107, 108, 110, 117, 123, 127, 131], "heterogen": [2, 9, 15, 16, 18, 19, 20, 22, 23, 24, 25, 26, 28, 29, 33, 38, 87, 95, 96, 100, 101, 102, 103, 131], "attent": [2, 3, 9, 11, 12, 13, 14, 32, 50, 79, 90, 91, 92, 108, 124, 125, 131], "literatur": [2, 9, 15, 19, 21, 32, 50, 63, 69, 70, 73, 75, 88, 105, 118, 119, 122, 131, 132], "book": [2, 5, 78, 118, 131, 132], "sampl": [2, 4, 6, 16, 17, 18, 20, 22, 23, 25, 32, 45, 48, 50, 59, 60, 63, 64, 69, 74, 80, 81, 83, 84, 85, 88, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 109, 110, 115, 116, 117, 118, 129, 131], "code": [2, 9, 10, 17, 18, 23, 33, 48, 62, 117, 123, 127, 132], "relat": [2, 9, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 40, 45, 68, 74, 75, 76, 79, 80, 88, 108, 118, 124, 125, 126, 129, 131], "under": [2, 3, 4, 5, 6, 9, 10, 15, 16, 17, 19, 20, 21, 22, 25, 26, 28, 29, 32, 33, 45, 48, 50, 59, 63, 64, 65, 66, 68, 70, 73, 80, 87, 89, 96, 101, 102, 103, 104, 105, 108, 123, 124, 125, 127, 129, 131, 132], "set": [2, 3, 5, 9, 10, 11, 12, 13, 14, 18, 21, 23, 27, 32, 50, 60, 62, 64, 68, 70, 73, 74, 75, 78, 83, 89, 90, 91, 92, 94, 96, 97, 98, 99, 101, 103, 104, 105, 109, 118, 119, 121, 122, 123, 124, 125, 127, 129, 130, 131, 132], "point": [2, 15, 16, 17, 18, 20, 23, 24, 26, 28, 29, 32, 33, 48, 50, 59, 61, 66, 67, 68, 69, 74, 75, 76, 78, 84, 88, 118, 119, 129], "interest": [2, 3, 4, 6, 10, 12, 17, 18, 19, 21, 23, 32, 33, 38, 45, 50, 59, 60, 61, 70, 73, 76, 78, 94, 95, 96, 97, 118, 122, 123, 124, 125, 127, 129, 131], "dataset": [2, 3, 15, 19, 26, 27, 33, 40, 45, 50, 59, 61, 70, 74, 75, 77, 78, 80, 84, 88, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 117, 118, 122, 124, 125, 126, 127, 129], "space": [2, 9, 21, 27, 45, 50, 59, 61, 63, 68, 73, 74, 75, 76, 78, 81, 82, 83, 85, 86, 88, 89, 90, 91, 92, 98, 99, 101, 107, 109, 110, 115, 116, 117], "should": [2, 10, 12, 17, 76, 78, 81, 94, 96, 97, 98, 99, 101, 103, 104, 132], "variou": [2, 3, 11, 13, 38, 59, 63, 73, 78, 89, 98, 107, 131], "email": [2, 45, 59], "sent": 2, "total": [2, 10, 12, 19, 21, 33, 38, 40, 50, 60, 61, 70, 76, 80, 83, 84, 86, 87, 94, 96, 97, 98, 99, 101, 103, 104, 105, 107, 108, 109, 116, 117, 122, 127, 129, 131], "amount": [2, 17, 32, 95, 124, 125], "spent": [2, 50, 61], "fetch_hillstrom": [2, 60, 61], "discret": [2, 4, 5, 6, 27, 45, 50, 60, 74, 75, 76, 81, 82, 83, 85, 86, 123, 124, 125, 127, 131], "q": [2, 5, 9, 17, 32, 45, 50, 60, 62, 63, 64, 73, 74, 75, 76, 79, 83, 85, 87, 89, 96, 101, 103, 105, 108, 109, 118, 123, 127, 131], "much": [2, 3, 19], "spend": [2, 45, 59, 60, 61], "averag": [2, 9, 12, 15, 16, 17, 19, 20, 22, 25, 29, 33, 38, 40, 45, 59, 64, 68, 69, 70, 76, 78, 83, 86, 109, 116, 118, 122, 124, 125, 129, 130, 131], "add": [2, 5, 10, 45, 59, 70, 87, 95, 100, 102, 122, 130, 132], "quantil": [2, 69, 131], "continu": [2, 4, 6, 9, 10, 11, 12, 13, 14, 45, 59, 60, 68, 73, 74, 76, 78, 83, 85, 86, 87, 89, 98, 99, 100, 101, 124, 125, 127, 129, 131, 132], "owl": [2, 131], "john": [2, 5, 74, 75, 118], "wanamak": 2, "onc": [2, 5, 87, 89, 95], "phrase": 2, "half": 2, "monei": [2, 61], "advertis": [2, 19, 33, 98, 99, 100, 101], "wast": 2, "troubl": 2, "don": [2, 10, 60, 103, 104, 105], "know": [2, 19, 60], "indic": [2, 4, 6, 11, 13, 14, 15, 27, 33, 50, 83, 91, 92, 95, 102, 103, 104, 105, 107, 124, 125], "high": [2, 3, 4, 9, 10, 11, 12, 13, 14, 15, 32, 40, 45, 76, 118, 124, 125, 130], "intent": 2, "convert": [2, 4, 6, 10, 11, 13, 14, 129], "todai": 2, "digit": 2, "techniqu": [2, 40, 63, 73, 131], "enabl": [2, 9, 10, 12, 96, 101, 103], "lift": 2, "via": [2, 3, 4, 9, 10, 11, 12, 13, 14, 15, 40, 60, 63, 64, 66, 73, 74, 87, 90, 91, 92, 96, 101, 102, 103, 118, 119], "random": [2, 4, 6, 9, 11, 12, 13, 14, 15, 16, 19, 20, 21, 24, 26, 35, 39, 41, 42, 43, 60, 62, 69, 70, 74, 75, 80, 81, 82, 83, 84, 85, 87, 88, 89, 94, 96, 97, 98, 99, 101, 103, 104, 105, 108, 109, 110, 122, 124, 125, 127, 129, 130], "control": [2, 3, 4, 5, 6, 9, 12, 15, 16, 19, 20, 21, 22, 24, 25, 27, 28, 29, 32, 33, 38, 45, 76, 118, 122, 123, 124, 125, 127, 131], "select": [2, 10, 26, 40, 48, 50, 61, 74, 79, 80, 81, 82, 83, 84, 85, 86, 88, 94, 96, 97, 98, 99, 101, 102, 103, 105, 106, 108, 109, 110, 115, 116, 118, 119, 124, 125, 126, 129], "form": [2, 10, 11, 15, 63, 67, 73, 74, 81, 85, 87, 89, 96, 103, 118], "interven": [2, 4, 6, 9, 12, 33], "base": [2, 4, 5, 9, 10, 12, 15, 17, 18, 19, 21, 22, 23, 32, 33, 45, 48, 50, 59, 63, 64, 66, 67, 68, 70, 73, 75, 76, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92, 94, 96, 97, 98, 99, 101, 102, 103, 104, 105, 106, 108, 109, 110, 115, 116, 119, 121, 123, 124, 125, 127, 129, 130, 131], "collect": [2, 3, 4, 6, 17, 18, 19, 23, 27, 40, 60, 74, 75, 80, 84, 88, 102, 107, 108, 118, 124, 125, 126, 129, 131], "converion": 2, "even": [2, 15, 32, 40, 119, 131], "win": 2, "impress": [2, 19], "those": [2, 5, 48, 75, 81, 82, 83, 85, 86, 87, 89], "With": [2, 45, 48, 68, 96, 103, 107, 123, 127], "wearabl": 2, "devic": 2, "easili": [2, 22, 28, 81, 85, 90, 96, 97, 99, 103, 104, 110, 115], "keep": [2, 6, 10, 12, 102, 105], "track": [2, 9], "own": [2, 88, 131], "meanwhil": [2, 74], "util": [2, 10, 11, 13, 14, 17, 33, 59, 60, 63, 64, 68, 69, 73, 78, 80, 81, 82, 87, 88, 94, 96, 102, 103, 104, 105, 107, 118, 119, 124, 125, 126, 127, 128, 129], "manag": [2, 132], "increasingli": 2, "hot": 2, "topic": [2, 32, 118], "among": [2, 4, 9, 10, 11, 12, 13, 14, 40, 60, 66, 73, 79, 80, 84, 87, 88, 96, 101, 103, 108, 127, 129, 131], "them": [2, 6, 15, 21, 22, 28, 32, 60, 73, 84, 95, 102, 104, 108, 127], "decid": [2, 18, 23, 94, 96, 97, 98, 99, 100, 101], "biggest": 2, "challeng": [2, 3, 10, 40, 64, 69, 118, 119], "given": [2, 4, 6, 11, 13, 14, 15, 16, 17, 21, 22, 24, 25, 26, 27, 29, 32, 33, 45, 50, 59, 60, 63, 64, 66, 69, 73, 74, 75, 76, 78, 79, 81, 82, 90, 91, 92, 96, 101, 103, 118, 131], "activ": 2, "suggest": [2, 4, 45, 66, 79, 86, 107, 108, 116], "help": [2, 10, 27, 78, 80, 84, 88, 107, 108, 129], "regul": [2, 3, 10, 12, 21], "psycholog": [2, 21], "howev": [2, 4, 6, 9, 12, 15, 18, 19, 21, 22, 23, 25, 28, 32, 40, 45, 63, 64, 68, 69, 73, 76, 78, 85, 108, 110, 115, 118, 119], "send": [2, 45, 59, 98, 99, 101], "written": [2, 5, 9, 14, 15, 19, 20, 21, 25, 32], "intuit": [2, 48, 80, 83, 108, 109], "asleep": 2, "intens": [2, 19], "workout": 2, "rare": [2, 69], "exercis": 2, "would": [2, 4, 19, 21, 22, 26, 32, 33, 38, 45, 48, 59, 60, 61, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 88, 89, 90, 91, 92, 95, 100, 102, 107, 108, 110, 115, 117, 118, 119, 123, 127, 131], "decreas": [2, 3, 64, 83, 108, 109, 124, 125], "To": [2, 13, 15, 17, 18, 22, 23, 33, 40, 50, 60, 63, 64, 68, 70, 73, 74, 83, 89, 95, 96, 103, 118, 129, 132], "number": [2, 4, 9, 11, 13, 14, 22, 23, 25, 27, 33, 40, 45, 48, 50, 60, 68, 70, 76, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 116, 117, 124, 125, 129, 131], "formal": [2, 3, 4, 15, 17, 24, 25, 73, 75, 95, 100], "reinforc": [2, 5, 9, 10, 11, 12, 13, 14, 59, 66, 67, 68, 73, 74, 75, 78, 83, 108, 109, 118, 119, 122], "mdp": [2, 32, 63, 68, 70, 73, 74, 75, 118, 119], "seri": [2, 5, 9, 18, 23, 45, 68, 73, 76], "stage": [2, 16, 17, 25, 32, 33, 49, 53, 76, 122, 129, 131], "condit": [2, 4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 25, 32, 33, 45, 50, 60, 63, 64, 75, 76, 87, 90, 91, 92, 96, 101, 103, 107, 118, 119], "affect": [2, 3, 4, 6, 12, 15, 21, 33, 48, 131], "previou": [2, 17, 19, 75, 80, 86, 88, 90, 91, 92, 96, 101, 103, 107, 108, 117, 129, 131], "delai": [2, 70, 78, 122], "current": [2, 3, 60, 70, 74, 75, 79, 90, 91, 92, 118, 131], "decis": [2, 5, 9, 10, 15, 33, 45, 50, 59, 60, 61, 70, 76, 78, 79, 88, 90, 91, 92, 102, 118, 119, 127, 131, 132], "subsequ": [2, 4, 6, 107], "regard": [2, 19, 64, 66, 68, 73, 80, 131], "cumul": [2, 68, 74, 75, 79, 80, 84, 88, 96, 101, 103, 107, 108, 118, 129], "sequenc": [2, 77, 79, 88, 107, 117, 119, 127], "longitudin": [2, 32, 37, 38, 123], "subject": [2, 4, 6, 15, 19, 22, 33, 45, 59, 76, 78], "experienc": 2, "entir": [2, 5, 17, 32, 96, 101, 103, 124, 125, 131], "formul": [2, 9, 13, 75, 101, 131], "illustr": [2, 17, 18, 21, 23, 27, 40, 60, 64, 70, 79, 84, 90, 91, 92, 108, 118, 124, 125, 126, 131], "context": [2, 10, 21, 33, 38, 50, 79, 80, 90, 91, 92, 131], "hiv": 2, "infect": [2, 3], "time": [2, 5, 9, 10, 11, 13, 14, 19, 21, 25, 32, 37, 38, 40, 45, 50, 60, 64, 68, 70, 73, 74, 75, 76, 80, 83, 84, 86, 87, 88, 90, 91, 92, 107, 108, 109, 116, 118, 119, 122, 123, 124, 125, 127, 129, 131], "datamdp": [2, 76, 77, 78], "cd4": 2, "count": [2, 10, 83, 86, 109, 116, 128], "wa": [2, 4, 9, 10, 13, 15, 21, 24, 25, 27, 32, 33, 40, 48, 59, 60, 76, 78, 119, 129], "all": [2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 24, 25, 26, 27, 28, 29, 32, 33, 38, 40, 45, 48, 59, 60, 64, 70, 73, 75, 76, 77, 78, 80, 87, 88, 90, 91, 92, 95, 98, 99, 100, 101, 104, 106, 107, 108, 117, 118, 119, 122, 123, 124, 125, 127, 129, 131], "interact": [2, 20, 25, 88, 107, 117], "same": [2, 4, 5, 6, 10, 15, 18, 19, 21, 22, 23, 28, 29, 33, 45, 48, 59, 64, 75, 76, 78, 89, 98, 99, 102, 103, 104, 105, 107, 118], "possibl": [2, 4, 6, 9, 13, 22, 29, 40, 64, 98, 99, 101, 129, 131], "style": [2, 14, 106], "mani": [2, 3, 5, 9, 10, 12, 48, 66, 73, 74, 75, 90, 91, 92, 96, 101, 103, 107, 117, 118], "channel": [2, 60], "distribut": [2, 4, 6, 9, 14, 21, 22, 23, 25, 48, 60, 61, 64, 73, 74, 75, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 110, 115, 118, 119, 129, 131], "credit": 2, "correspond": [2, 4, 6, 10, 12, 32, 40, 45, 48, 50, 59, 60, 63, 64, 68, 69, 70, 73, 75, 76, 78, 80, 83, 84, 85, 86, 87, 88, 89, 95, 96, 99, 102, 103, 104, 105, 107, 108, 109, 110, 115, 116, 117, 118, 119, 131], "contribut": [2, 3, 10], "becom": [2, 15, 24, 25, 32, 40, 64, 68, 119], "rule": [2, 48, 50, 99], "simpl": [2, 18, 23, 33, 66, 67, 68, 79, 83, 88, 101, 108, 109, 130, 131], "been": [2, 4, 6, 9, 13, 15, 18, 23, 27, 32, 33, 50, 60, 63, 68, 69, 73, 79, 84, 85, 87, 88, 99, 104, 108, 110, 115, 124, 125, 126, 131], "long": [2, 32, 63, 68, 70, 73, 102, 131], "ever": 2, "enhanc": 2, "capabl": 2, "driven": 2, "attempt": 2, "popular": [2, 50, 67, 95, 96, 102, 105, 107, 108, 117, 118, 128, 129], "framework": [2, 4, 6, 15, 70, 80, 81, 87, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 117, 122], "classic": [2, 4, 6, 9, 14, 21, 22, 24, 25, 32, 50, 59, 66, 78, 80, 84, 85, 108, 115, 119, 131, 132], "bandit": [2, 5, 90, 91, 92, 94, 96, 97, 98, 99, 101, 103, 104, 105, 106, 109, 110, 116, 117, 119, 129], "prefer": [2, 19, 22, 28], "click": [2, 19, 95, 103, 104, 105, 107], "overal": [2, 19, 21, 22, 23, 25, 33, 45, 59, 60, 76, 78, 80, 84, 95, 96, 100, 101, 102, 103, 108, 124, 125, 131], "repres": [2, 4, 6, 9, 10, 11, 12, 13, 14, 15, 27, 38, 50, 118, 124, 125, 126, 131], "movi": [2, 26, 80, 83, 84, 88, 103, 104, 105, 107, 108, 117, 129], "youtub": 2, "netflix": 2, "agent": [2, 60, 74, 75, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 110, 115, 117, 118, 129], "list": [2, 10, 11, 13, 14, 32, 40, 62, 76, 89, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 107, 117, 121, 124, 125, 128, 129, 131], "video": [2, 60], "visit": [2, 32, 50, 64, 68, 80, 84, 88, 95, 102, 107, 108, 118, 129], "either": [2, 4, 6, 15, 27, 45, 53, 59, 61, 63, 66, 67, 73, 76, 78, 80, 83, 85, 86, 87, 89, 91, 94, 96, 97, 98, 99, 101, 102, 103, 104, 105, 107, 108, 109, 116, 118, 119, 131], "leav": [2, 3, 32, 84, 88, 95, 107, 131], "typic": [2, 40, 63, 68, 69, 73, 79, 80, 84, 100, 101, 118, 131], "larg": [2, 17, 19, 27, 40, 48, 62, 63, 64, 66, 68, 70, 73, 75, 79, 83, 85, 86, 87, 88, 89, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 108, 116, 124, 125, 126], "avail": [2, 4, 6, 9, 10, 13, 14, 17, 33, 61, 75, 80, 84, 88, 94, 95, 101, 102, 107, 108, 117, 124, 125, 126, 129], "therefor": [2, 17, 32, 40, 45, 59, 64, 66, 67, 68, 80, 84, 85, 88, 89, 95, 98, 99, 101, 108, 110, 115, 118, 123, 127, 129, 131], "explor": [2, 22, 32, 60, 63, 64, 66, 67, 68, 69, 71, 72, 73, 78, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 94, 97, 108, 109, 110, 115, 116, 118, 129], "exploit": [2, 19, 83, 84, 85, 86, 90, 91, 92, 97, 108, 109, 110, 115, 116], "inform": [2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 17, 19, 22, 27, 29, 33, 40, 45, 50, 61, 68, 73, 76, 77, 79, 80, 81, 82, 85, 87, 88, 89, 91, 92, 94, 95, 96, 98, 99, 101, 102, 103, 104, 107, 108, 110, 115, 117, 119, 122, 123, 127, 130, 131, 132], "far": [2, 83, 86, 108, 109], "approach": [2, 3, 4, 6, 15, 16, 17, 18, 21, 22, 25, 32, 33, 45, 48, 59, 63, 64, 66, 67, 68, 69, 73, 76, 78, 79, 80, 102, 104, 105, 106, 108, 118, 119, 131], "As": [2, 15, 20, 22, 25, 26, 29, 32, 40, 63, 64, 66, 70, 73, 74, 75, 79, 81, 82, 86, 87, 89, 94, 96, 97, 108, 110, 116, 118, 122, 123, 124, 125, 127, 131], "chapter": [2, 61, 75, 80, 84, 88, 94, 96, 97, 98, 99, 101, 103, 104, 105, 107, 108, 117, 118, 119, 131], "genr": [2, 26, 80, 84, 88, 107, 108, 129], "five": [2, 103, 104, 105, 107, 129], "whose": [2, 3, 75, 131], "unknown": [2, 9, 12, 13, 65, 68, 73, 79, 80, 84, 85, 87, 89, 90, 91, 92, 96, 101, 103, 108, 110, 115, 127, 131], "over": [2, 3, 15, 22, 33, 38, 50, 63, 64, 68, 70, 73, 89, 90, 91, 92, 105, 108, 118, 124, 128, 131], "satisfact": [2, 27, 80, 84, 88, 107, 108, 129], "movielen": [2, 15, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 102, 103, 104, 105, 107, 108, 117, 128], "arm": [2, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 99, 100, 107, 108, 109, 116, 117, 128, 129, 131], "contextu": [2, 40, 79, 81, 82, 84, 90, 91, 92, 102, 103, 104, 108, 110, 129, 131], "meta": [2, 19, 29, 79, 87, 95, 96, 100, 101, 102, 103, 107, 131], "multipl": [2, 9, 10, 11, 12, 13, 14, 32, 45, 48, 60, 62, 76, 79, 89, 119, 127, 131], "million": [2, 3, 9, 10, 11, 12, 13, 14], "try": [2, 10, 16, 21, 25, 27, 108, 121, 124, 127, 132], "assort": [2, 103, 105, 106, 107, 117, 131], "rank": [2, 94, 96, 97, 107, 117, 131], "top": [2, 9, 10, 11, 12, 13, 14, 40, 75, 80, 84, 88, 94, 95, 96, 97, 105, 107, 108, 118, 124, 125], "restaur": [2, 33, 94, 95, 96, 97], "true": [2, 3, 10, 11, 13, 14, 17, 18, 21, 22, 23, 25, 45, 48, 59, 60, 61, 62, 64, 66, 70, 76, 78, 81, 82, 83, 85, 87, 89, 91, 103, 105, 106, 107, 108, 109, 110, 115, 116, 121, 122, 123, 124, 127, 129], "expect": [2, 15, 16, 17, 18, 20, 22, 23, 24, 25, 26, 28, 29, 32, 38, 45, 48, 50, 59, 63, 68, 70, 73, 74, 75, 76, 78, 80, 81, 82, 85, 87, 88, 89, 91, 92, 97, 99, 108, 123, 124, 125, 127, 129], "yelp": [2, 94, 95, 96, 97], "discuss": [2, 9, 32, 68, 73, 74, 75, 89, 118, 131, 132], "offlin": [2, 27, 32, 50, 60, 65, 91, 118, 119, 131], "prevent": 2, "unnecessari": [2, 124, 125], "essenti": [2, 3, 73, 87, 119], "variant": [2, 3, 68, 83, 108, 109, 118, 128], "frequent": [2, 40], "commerci": 2, "googl": 2, "displai": [2, 5, 17, 21, 33, 94, 95, 96, 97], "twitter": 2, "view": [2, 3, 21, 73, 91, 92, 121, 124], "bipartit": 2, "match": [2, 33, 63, 68, 91, 92, 100, 103, 104, 105, 107, 117, 128], "need": [2, 10, 20, 25, 33, 45, 50, 60, 68, 76, 80, 84, 85, 86, 88, 89, 95, 100, 102, 107, 108, 110, 115, 117, 118, 119, 122, 132], "show": [2, 4, 10, 15, 19, 40, 60, 63, 73, 75, 83, 91, 94, 96, 97, 100, 102, 108, 109, 129], "like": [2, 5, 19, 21, 22, 26, 27, 28, 38, 45, 48, 59, 60, 64, 78, 80, 84, 88, 107, 108, 123, 127, 129], "attract": [2, 3, 4, 9, 11, 12, 13, 14, 15, 22, 60, 90, 91, 92, 95, 96, 97, 98, 99, 100, 101, 107], "while": [2, 6, 10, 12, 22, 28, 32, 33, 38, 45, 48, 60, 70, 76, 79, 80, 89, 96, 101, 103, 104, 122, 129, 131], "adher": 2, "budget": 2, "constraint": [2, 5, 9, 10, 13, 40, 66, 98, 99, 100, 101, 107, 117], "feedback": [2, 79, 80, 81, 84, 88, 90, 91, 92, 96, 100, 101, 103, 107, 108, 110, 115, 117], "achiev": [2, 17, 19, 20, 25, 33, 48, 63, 64, 73, 85, 89], "whom": 2, "its": [2, 5, 9, 11, 13, 17, 19, 20, 22, 25, 48, 50, 60, 63, 64, 67, 68, 73, 74, 75, 80, 85, 87, 88, 91, 94, 108, 110, 115, 118, 131, 132], "chanc": 2, "accept": [2, 5, 121, 125], "adult": [2, 98, 99, 100, 101], "combinatori": [2, 96, 98, 99, 101, 103, 106, 107, 117, 131], "world": [2, 79, 80, 84, 88, 94, 99, 108], "across": [2, 38, 87, 88, 98], "retail": 2, "adjust": [2, 21, 89], "period": [2, 11, 32, 33, 40, 124, 125, 131], "rideshar": 2, "servic": [2, 95, 128], "weather": 2, "occur": [2, 10, 75, 118], "outsid": [2, 3, 10, 21, 32], "airlin": 2, "rais": [2, 10, 21, 33, 70, 121, 122, 125, 127], "ticket": 2, "farewel": 2, "date": [2, 87, 89], "rise": [2, 15], "low": [2, 5, 63, 68, 73, 105, 107, 119, 124, 125, 130], "evalut": 2, "section": [2, 4, 6, 15, 17, 19, 20, 21, 22, 25, 32, 33, 38, 49, 53, 65, 68, 69, 72, 73, 75, 118, 122, 124, 125, 127, 129, 131, 132], "harper": 2, "f": [2, 10, 63, 73, 89, 95, 96, 101, 103, 107, 117, 121, 125, 128, 132], "m": [2, 5, 10, 12, 15, 16, 17, 19, 20, 21, 24, 25, 33, 37, 38, 45, 50, 59, 60, 63, 64, 66, 70, 74, 76, 78, 80, 81, 87, 88, 89, 90, 91, 92, 94, 95, 99, 102, 103, 104, 108, 110, 122, 123, 127, 128, 131], "konstan": 2, "j": [2, 9, 11, 13, 14, 15, 16, 17, 19, 20, 21, 22, 25, 26, 28, 29, 40, 45, 60, 64, 70, 73, 75, 76, 79, 80, 87, 88, 89, 90, 91, 92, 96, 102, 103, 104, 105, 106, 108, 115, 116, 118, 122, 127], "acm": [2, 50], "transact": 2, "intellig": [2, 5, 19, 50, 79, 80, 81, 82, 88, 94, 95, 97, 108, 110, 118, 119], "tii": 2, "19": [2, 5, 10, 21, 40, 45, 50, 62, 63, 121, 124], "2015": [2, 5, 48, 59, 68, 73, 78, 79, 95, 98, 100, 108, 118], "asghar": 2, "n": [2, 4, 6, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 38, 40, 45, 48, 50, 59, 60, 61, 62, 63, 64, 66, 67, 68, 70, 73, 74, 75, 76, 77, 78, 80, 81, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 98, 100, 101, 102, 103, 104, 106, 107, 108, 109, 110, 116, 117, 118, 122, 123, 124, 125, 127, 128, 129, 131, 132], "review": [2, 9, 12, 17, 19, 45, 50, 68, 69, 73, 76, 84, 96, 101, 103, 107, 108, 132], "arxiv": [2, 5, 9, 10, 11, 12, 13, 14, 16, 19, 20, 25, 50, 60, 63, 66, 70, 80, 84, 85, 90, 91, 92, 94, 95, 96, 100, 101, 102, 103, 104, 107, 108, 117, 118, 119, 122], "preprint": [2, 5, 9, 10, 11, 12, 13, 14, 16, 19, 20, 25, 50, 60, 63, 66, 70, 80, 84, 85, 90, 91, 92, 94, 95, 96, 100, 101, 102, 103, 104, 107, 108, 117, 118, 119, 122], "1605": 2, "05362": 2, "2016": [2, 5, 63, 68, 73, 94, 95, 96, 100, 103, 118], "asuncion": 2, "newman": 2, "d": [0, 2, 5, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 23, 24, 25, 32, 33, 45, 50, 53, 59, 60, 62, 64, 68, 70, 73, 74, 75, 76, 78, 79, 80, 84, 85, 88, 89, 95, 102, 106, 107, 108, 115, 116, 117, 118, 121, 122, 125, 127, 128, 129, 130], "uci": 2, "machin": [2, 5, 9, 10, 11, 12, 13, 14, 15, 17, 19, 22, 26, 28, 29, 63, 64, 67, 68, 69, 73, 79, 80, 81, 83, 86, 88, 89, 95, 98, 99, 100, 105, 107, 108, 109, 110, 115, 116, 117, 118], "repositori": [2, 9, 10, 11, 13, 132], "2007": [2, 9, 10, 11, 12, 13, 14, 80], "tsiati": [2, 15, 45, 76, 131], "davidian": [2, 15, 45, 76, 131], "hollowai": [2, 131], "laber": [2, 15, 45, 76, 131], "2019": [2, 3, 5, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 22, 23, 25, 26, 28, 29, 35, 39, 41, 42, 43, 63, 66, 80, 84, 95, 97, 102, 103, 104, 105, 106, 108, 131], "precis": [2, 19, 81, 85, 87, 89, 96, 103, 131], "medicin": [2, 19, 48, 90, 91, 92, 131], "chapman": [2, 131], "hall": [2, 131], "crc": [2, 131], "era": [3, 10], "revolut": [3, 10], "area": [3, 10, 32, 38, 48, 84, 90, 91, 92, 108, 118], "gener": [3, 4, 6, 10, 19, 21, 22, 27, 32, 35, 39, 40, 41, 42, 43, 48, 50, 59, 60, 63, 66, 68, 69, 73, 74, 75, 78, 79, 80, 84, 88, 90, 91, 92, 100, 107, 108, 110, 116, 117, 125, 128, 129, 131, 132], "graph": [3, 10, 70, 131], "direct": [3, 9, 10, 11, 12, 13, 14, 60, 64, 66, 67, 70, 73, 79, 102, 105, 118, 122, 123, 127], "indirect": [3, 10, 12, 21, 70, 123, 127], "mediat": [3, 9, 11, 13, 14, 32, 37, 75], "intermedi": 3, "variabl": [3, 4, 6, 9, 10, 11, 12, 13, 14, 16, 19, 20, 21, 22, 23, 25, 27, 32, 48, 49, 59, 69, 70, 75, 77, 78, 80, 84, 88, 95, 108, 118, 119, 129, 131], "instanc": [3, 32, 48, 62, 89, 96, 103], "outbreak": 3, "coronaviru": [3, 10], "diseas": 3, "chines": [3, 10, 21], "govern": 3, "taken": [3, 38, 61, 64, 77, 88, 91, 92, 131], "extrem": [3, 22, 28], "stop": [3, 10, 90, 91, 92, 95, 107], "viru": 3, "lock": 3, "wuhan": 3, "down": 3, "jan": [3, 9, 10, 11, 12, 13, 14], "23rd": 3, "2020": [3, 5, 9, 11, 12, 13, 14, 16, 18, 19, 20, 21, 24, 25, 40, 50, 80, 81, 85, 94, 99, 101, 104, 105, 108, 110, 118, 119], "12": [3, 5, 9, 10, 11, 12, 13, 14, 17, 21, 23, 27, 45, 50, 59, 60, 62, 70, 80, 108, 119, 121, 122, 123, 124, 127, 128, 129], "citi": [3, 10, 21], "hubei": [3, 10, 21], "lockdown": [3, 10, 21], "directli": [3, 5, 12, 17, 27, 45, 59, 60, 63, 64, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 97, 101, 105, 109, 110, 115, 116, 118, 119, 122, 127], "block": [3, 5, 123, 127], "peopl": [3, 15, 26, 27, 28, 29], "stimul": [3, 60], "quarantin": 3, "further": [3, 10, 12, 20, 25, 33, 60, 64, 70, 96, 98, 99, 101, 103, 107, 117, 122, 123, 127, 129, 131], "migrat": 3, "countrywid": 3, "china": [3, 10, 21], "thu": [3, 9, 12, 15, 17, 18, 20, 23, 25, 38, 50, 60, 75, 88, 90, 91, 92], "indirectli": 3, "reduc": [3, 10, 12, 21, 40, 60, 64], "great": [3, 19, 95], "crisi": 3, "mechan": [3, 10, 75], "individu": [3, 4, 6, 10, 15, 22, 27, 29, 33, 38, 45, 48, 50, 59, 61, 64, 76, 77, 78, 102, 117, 123, 127, 128], "decad": [3, 33], "discoveri": [3, 12, 50], "disentangl": [3, 9, 11, 12, 13, 14], "complex": [3, 5, 9, 11, 12, 13, 14, 22, 28, 32, 50, 64, 98, 99, 101, 105, 119, 131], "field": [3, 45, 76, 79], "5": [3, 9, 10, 11, 12, 13, 14, 15, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 33, 37, 40, 45, 48, 50, 59, 60, 62, 63, 64, 66, 67, 68, 69, 70, 71, 73, 76, 78, 80, 84, 85, 88, 89, 95, 100, 102, 103, 104, 105, 106, 108, 109, 110, 115, 116, 121, 122, 123, 124, 125, 127, 129, 130], "singl": [3, 22, 26, 28, 32, 40, 49, 50, 53, 59, 63, 70, 73, 76, 78, 109, 110, 115, 116, 124, 125, 126, 131], "nucleotid": 3, "polymorph": 3, "snp": 3, "person": [3, 9, 32, 45, 50, 59, 76, 78, 80, 108, 132], "genom": 3, "fewer": [3, 131], "non": [3, 9, 10, 12, 13, 14, 17, 19, 21, 27, 45, 48, 59, 60, 76, 78, 91, 92, 127], "spuriou": 3, "protein": 3, "systemat": [3, 132], "phenotyp": 3, "focu": [3, 4, 6, 12, 16, 17, 18, 19, 20, 24, 26, 28, 29, 45, 53, 66, 76, 79, 80, 84, 88, 90, 91, 92, 101, 102, 103, 108, 118, 129, 131], "brem": 3, "kruglyak": 3, "2005": [3, 5, 10, 59, 67, 78, 119], "discov": [3, 107], "featur": [3, 4, 6, 12, 15, 27, 48, 50, 61, 70, 80, 81, 82, 87, 88, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 110, 117, 118, 122, 124, 125, 126, 129, 131], "explain": 3, "104": [3, 10, 21, 45, 76, 84], "segreg": 3, "simul": [3, 6, 10, 12, 17, 27, 80, 84, 88, 107, 129], "genet": 3, "divers": [3, 59, 78, 131], "strain": 3, "by4716": 3, "rm11": 3, "1a": [3, 20, 25], "contain": [3, 4, 6, 9, 11, 12, 13, 14, 15, 17, 19, 27, 33, 40, 50, 61, 77, 89, 90, 91, 92, 95, 107, 117, 129, 131, 132], "thousand": [3, 128], "genotyp": 3, "rich": 3, "influenc": [3, 10, 12, 21, 40, 64, 131], "target": [3, 10, 22, 23, 25, 32, 50, 59, 60, 63, 66, 68, 73, 74, 75, 78, 91, 100, 122, 123, 127, 131], "herit": 3, "due": [3, 14, 32, 40, 63, 64, 66, 67, 68, 69, 70, 105, 118, 119, 122, 124, 125, 126, 129, 131], "dimension": [3, 4, 9, 10, 11, 12, 13, 14, 15, 18, 23, 40, 45, 64, 76, 88, 107, 117, 119, 131], "name": [3, 5, 9, 10, 11, 13, 14, 17, 18, 21, 25, 32, 33, 45, 50, 60, 62, 63, 66, 73, 79, 84, 86, 88, 100, 106, 108, 116, 118, 121, 125, 128], "quantit": 3, "loci": 3, "qtl": 3, "involv": [3, 53, 79, 118], "parsimoni": 3, "reveal": 3, "necessari": [3, 4, 6, 81, 96, 97, 98, 99, 103, 104], "depend": [3, 5, 50, 60, 64, 68, 73, 75, 79, 80, 90, 91, 92, 100, 101, 102, 105, 107, 117, 118, 119, 131], "present": [3, 10, 64, 74, 94, 96, 97, 98, 99, 101, 103, 104, 105, 131], "toward": [3, 64, 95, 96, 100, 101, 102, 103, 107], "yer124c": 3, "daughter": 3, "cell": [0, 3, 5, 10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 40, 45, 50, 60, 62, 63, 64, 66, 67, 68, 69, 70, 71, 73, 76, 106, 109, 110, 115, 116, 121, 122, 125, 127, 128, 129, 130], "particip": 3, "pathwai": 3, "wall": 3, "metabol": 3, "delet": [3, 11, 13, 14], "separ": [3, 15, 19, 21, 22, 28, 29, 63, 73, 100, 128], "divis": 3, "sensit": [3, 21, 45, 48, 76, 127], "against": [3, 64], "consid": [4, 6, 9, 11, 12, 13, 14, 19, 26, 32, 33, 45, 59, 60, 61, 63, 64, 66, 67, 68, 70, 73, 74, 75, 76, 78, 80, 81, 84, 85, 87, 88, 89, 94, 95, 96, 98, 99, 101, 102, 103, 104, 107, 110, 115, 117, 122, 123, 127, 130, 131], "popul": [4, 6, 15, 33], "doe": [4, 6, 9, 11, 12, 13, 14, 80, 94, 96, 97, 119, 121, 123, 125, 127, 128, 131], "y": [4, 6, 10, 12, 16, 17, 19, 20, 21, 25, 40, 45, 48, 50, 59, 60, 62, 76, 78, 79, 80, 90, 91, 92, 95, 96, 99, 100, 101, 102, 103, 105, 107, 108, 117, 127, 129, 130, 131], "establish": [4, 6, 14, 40, 59, 64, 78], "respons": [4, 5, 6, 15, 22, 26, 28, 102, 103, 104, 105, 119], "advoc": [4, 6], "neyman": [4, 6], "rubin": [4, 6], "robin": [4, 6, 15, 17, 45, 76, 127], "denot": [4, 6, 9, 11, 13, 19, 20, 21, 22, 25, 27, 28, 32, 33, 38, 40, 50, 60, 63, 64, 66, 67, 68, 70, 73, 74, 75, 79, 80, 84, 87, 88, 90, 91, 92, 95, 100, 102, 107, 108, 117, 118, 124, 125, 131], "vector": [4, 6, 9, 11, 12, 13, 14, 20, 25, 75, 80, 81, 85, 88, 95, 96, 101, 102, 103, 107, 110, 115, 117, 118, 119, 131], "simplic": [4, 6, 22, 68, 98, 99, 101, 131], "simplest": [4, 5, 6, 60], "case": [4, 6, 9, 11, 13, 14, 15, 19, 22, 24, 25, 28, 32, 40, 45, 48, 59, 60, 76, 78, 86, 115, 117, 130, 131, 132], "binari": [4, 6, 21, 27, 45, 48, 53, 59, 61, 76, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 97, 100, 102, 103, 104, 105, 108, 123, 124, 125, 127, 128, 129, 131], "0": [4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 38, 40, 45, 48, 50, 53, 59, 60, 61, 62, 63, 64, 66, 67, 68, 70, 73, 74, 75, 76, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 115, 116, 118, 121, 122, 123, 124, 125, 127, 128, 129, 130, 131], "sai": [4, 6, 9, 11, 13, 14], "versu": [4, 6, 17, 21, 27, 32, 121, 124, 131], "acquir": [4, 6], "app": [4, 6], "download": [4, 6, 17, 18, 23], "baselin": [4, 6, 11, 13, 14, 15, 22, 27, 68, 70, 73, 80, 87, 88, 108, 122, 129], "observ": [4, 5, 6, 9, 11, 13, 15, 17, 19, 20, 21, 22, 23, 25, 26, 32, 33, 38, 40, 48, 50, 59, 61, 63, 64, 66, 68, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 88, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 103, 106, 107, 108, 109, 116, 117, 118, 119, 122, 123, 127, 129, 131], "summar": [4, 6, 9, 10, 17, 19, 22, 26, 28, 29, 60, 70, 84, 119, 122, 123, 127, 129, 131], "z_i": [4, 6, 9, 11, 12, 13, 14, 20, 25], "x_i": [4, 15, 48, 50, 60], "t_i": [4, 33, 74, 75], "y_i": [4, 33, 48, 50, 60], "th": [4, 6, 15, 18, 23, 40, 64, 68, 69, 70, 74, 75, 88, 95, 122], "covari": [4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 25, 33, 87, 89, 98, 99, 101, 124, 125], "prior": [4, 6, 11, 79, 80, 81, 85, 87, 88, 89, 96, 97, 98, 99, 101, 103, 104, 105, 108, 110, 115, 122, 129], "assum": [4, 6, 9, 10, 11, 13, 24, 25, 45, 48, 59, 68, 74, 75, 76, 78, 79, 80, 81, 82, 84, 85, 87, 88, 89, 94, 96, 97, 98, 99, 101, 102, 103, 104, 105, 107, 108, 110, 115, 117, 119, 129, 131], "chosen": [4, 6, 16, 17, 18, 19, 20, 24, 26, 28, 29, 66, 75, 80, 91, 92, 95, 96, 100, 102, 103, 104, 105], "henc": [4, 6, 10, 15, 27, 48, 63, 68, 73, 80, 84, 88, 96, 103, 108, 118, 119, 129], "sometim": [4, 6, 118], "refer": [4, 5, 6, 132], "counterfactu": [4, 6, 33, 40, 75, 118, 131], "becaus": [4, 6, 128], "realiti": [4, 6], "hypothet": [4, 6], "contrari": [4, 6, 129], "fact": [4, 6, 63, 64, 66, 67, 73, 74, 80, 118], "actual": [4, 6, 15, 119], "than": [4, 6, 10, 15, 19, 22, 25, 26, 28, 29, 50, 63, 64, 68, 69, 73, 75, 80, 82, 84, 88, 108, 129], "notion": [4, 6], "defin": [4, 5, 6, 10, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 32, 33, 38, 45, 50, 59, 60, 63, 64, 68, 69, 73, 74, 75, 76, 78, 83, 90, 91, 92, 95, 100, 107, 108, 109, 117, 123, 127, 131], "now": [4, 6, 22, 40, 60, 107, 118, 130], "deduc": [4, 6], "x": [4, 6, 15, 17, 18, 19, 21, 23, 24, 25, 40, 45, 48, 50, 60, 62, 70, 76, 79, 81, 82, 87, 89, 90, 91, 92, 97, 98, 108, 110, 117, 121, 122, 127, 129, 130], "sutva": [4, 6, 15, 32, 33, 75], "stabl": [4, 6, 15, 21, 121, 124], "unit": [4, 6, 15, 33, 38, 40, 131], "begin": [4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 32, 33, 40, 45, 48, 50, 59, 60, 63, 64, 66, 67, 68, 69, 70, 73, 74, 75, 76, 78, 81, 82, 83, 85, 86, 87, 89, 90, 91, 92, 94, 95, 96, 98, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 116, 117, 118, 123, 127, 131], "align": [4, 6, 15, 17, 21, 24, 25, 32, 33, 40, 45, 48, 59, 63, 64, 68, 70, 73, 74, 76, 78, 81, 82, 83, 85, 86, 105, 109, 110, 116, 118, 123, 127], "end": [4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 32, 33, 40, 45, 48, 50, 59, 60, 63, 64, 66, 67, 68, 69, 70, 73, 74, 75, 76, 78, 81, 82, 83, 85, 86, 87, 89, 90, 91, 92, 94, 95, 96, 98, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 115, 116, 117, 118, 123, 127, 131], "That": [4, 6, 15, 19, 24, 25, 26, 33, 60], "regardless": [4, 6, 15], "interfer": [4, 6, 15, 32], "No": [4, 6, 9, 11, 13, 14, 15, 18, 21, 25, 33, 45, 50, 59, 60, 70, 87, 88, 89, 102, 122, 127, 128, 129, 131], "unmeasur": [4, 6, 9, 11, 13, 14, 15, 21, 22, 26, 32, 75, 119], "confound": [4, 5, 6, 9, 11, 12, 13, 14, 15, 21, 22, 26, 32, 75, 119, 122, 123, 127, 131], "strong": [4, 6, 14, 15, 18, 23, 32, 68, 73], "ignor": [4, 6, 15, 16, 17, 20, 24, 68, 73, 90, 91, 92, 128, 132], "perp": [4, 6, 15, 21, 75], "refut": [4, 6, 15], "believ": [4, 6, 15, 131], "relev": [4, 6, 15, 68], "reason": [4, 6, 9, 12, 14, 15, 19], "p": [4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 17, 19, 20, 21, 22, 25, 26, 28, 29, 32, 45, 48, 50, 62, 70, 73, 74, 75, 76, 80, 81, 82, 83, 86, 87, 89, 94, 96, 98, 99, 100, 101, 103, 104, 106, 108, 109, 110, 115, 116, 118, 122, 127, 128, 129, 130, 131, 132], "ensur": [4, 6, 9, 15, 75], "similar": [4, 5, 6, 10, 15, 21, 33, 48, 63, 64, 67, 68, 73, 75, 76, 79, 81, 82, 83, 85, 86, 87, 88, 89, 94, 95, 110, 118, 131], "vice": [4, 6, 15], "versa": [4, 6, 15], "text": [4, 5, 6, 10, 12, 15, 16, 17, 19, 21, 22, 25, 26, 28, 29, 32, 33, 40, 48, 59, 61, 63, 66, 67, 74, 78, 86, 87, 89, 96, 101, 103, 104, 118], "ATE": [4, 6, 12, 17, 19, 21, 26, 32, 38, 70, 122], "There": [4, 5, 6, 19, 38, 40, 60, 61, 86, 118], "deriv": [4, 6, 18, 21, 22, 23, 29, 32, 45, 50, 64, 69, 70, 78, 101, 122], "confoun": 4, "come": [4, 33, 98, 99, 131], "consider": 4, "e_x": 4, "quad": [4, 15, 18, 22, 23, 29, 45, 76, 87, 89, 90, 91, 92, 96, 101, 103], "similarli": [4, 10, 15, 33, 45, 63, 64, 73, 74, 75, 76, 87, 89, 100, 101, 107, 122, 124, 125], "mu": [4, 15, 16, 21, 22, 25, 26, 81, 85, 87, 88, 89, 90, 91, 92, 94, 96, 101, 103, 123], "gamma": [4, 15, 17, 20, 25, 32, 45, 63, 64, 66, 67, 68, 73, 74, 75, 76, 81, 82, 87, 89, 94, 96, 98, 101, 103, 104, 110, 118], "paramet": [4, 9, 10, 11, 15, 17, 18, 20, 23, 25, 50, 60, 81, 83, 86, 87, 89, 96, 101, 102, 103, 105, 108, 109, 110, 122, 127], "mle": 4, "least": [4, 15, 20, 22, 25, 80, 84, 88, 102, 107, 108, 129], "squar": [4, 15, 20, 25], "Then": [4, 9, 10, 11, 12, 13, 14, 15, 18, 23, 69, 70, 76, 78, 80, 84, 86, 88, 90, 91, 92, 96, 101, 103, 107, 108, 116, 117, 118, 129, 132], "hat": [4, 15, 16, 17, 18, 20, 22, 23, 24, 25, 26, 28, 29, 33, 40, 45, 59, 60, 63, 66, 68, 73, 74, 75, 76, 78, 82, 83, 87, 94, 98, 106, 118, 129], "sum_": [4, 15, 17, 18, 21, 23, 32, 33, 40, 45, 50, 59, 60, 63, 64, 66, 67, 68, 69, 70, 73, 74, 75, 76, 80, 84, 86, 88, 90, 91, 92, 94, 95, 96, 100, 101, 102, 103, 104, 105, 106, 108, 116, 118], "anoth": [4, 5, 9, 10, 17, 19, 40, 60, 68, 69, 73, 118, 123, 127], "pi": [4, 15, 16, 20, 25, 32, 48, 59, 60, 63, 64, 66, 67, 68, 69, 70, 73, 74, 75, 78, 90, 91, 92, 118], "get": [4, 15, 16, 17, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 33, 38, 45, 59, 61, 62, 76, 78, 81, 82, 83, 84, 85, 86, 87, 89, 94, 96, 97, 98, 99, 101, 103, 104, 105, 117, 123, 127, 128, 129, 130], "function": [4, 5, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 32, 45, 48, 50, 59, 60, 63, 64, 66, 67, 68, 73, 75, 76, 80, 81, 82, 83, 85, 86, 87, 89, 90, 91, 92, 94, 96, 97, 98, 99, 101, 102, 103, 104, 105, 107, 108, 109, 117, 118, 129, 130, 131], "One": [4, 15, 63, 73, 118, 127, 128, 132], "difficult": [4, 15, 83], "build": [4, 5, 70, 73, 80, 122, 127, 131, 132], "simpli": [4, 60, 88, 98], "stratifi": 4, "choos": [4, 10, 16, 17, 18, 20, 24, 26, 27, 28, 29, 63, 64, 73, 79, 80, 84, 86, 88, 90, 91, 92, 96, 100, 101, 102, 103, 107, 108, 116, 117, 129], "cutoff": 4, "c_0": 4, "c_1": 4, "c_k": 4, "belong": [4, 27, 40, 66, 131], "k": [4, 5, 9, 10, 11, 12, 13, 14, 20, 25, 40, 50, 60, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 115, 116, 117, 118, 128, 129, 130], "c_": [4, 45, 76, 83, 86, 109, 116], "le": [4, 5, 50, 63, 64, 66, 67, 74, 75, 95], "bar": [4, 18, 23, 32, 68, 75, 77, 78, 118], "_": [4, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 28, 29, 32, 40, 45, 48, 50, 59, 60, 61, 63, 64, 66, 67, 68, 69, 73, 74, 75, 76, 77, 78, 81, 85, 87, 88, 89, 90, 91, 92, 94, 96, 97, 98, 99, 101, 103, 104, 105, 106, 107, 108, 110, 115, 116, 117, 118, 121, 124, 125, 131], "1k": 4, "0k": 4, "n_k": 4, "theoret": [4, 19, 64, 75, 89, 102, 117, 132], "justif": 4, "semiparametr": [4, 16, 19, 20, 21, 24, 25, 63, 64, 73, 127], "theori": [4, 17, 19, 20, 21, 25, 45, 48, 64, 76, 80, 102, 103, 105, 107, 127], "augment": [4, 15, 48, 64], "ipw": [4, 15, 60, 70, 127], "probabl": [4, 15, 21, 48, 50, 60, 63, 64, 68, 73, 74, 83, 84, 89, 102, 107, 108, 109, 127], "everi": [4, 15, 63, 68, 73, 80, 84, 87, 88, 89, 94, 96, 101, 103, 104, 108, 118, 129], "themselv": [4, 15], "did": [4, 15, 33, 38, 40, 76, 78, 131], "frac": [4, 15, 16, 17, 18, 20, 21, 23, 25, 33, 45, 48, 50, 59, 60, 63, 64, 68, 70, 73, 76, 83, 86, 102, 103, 104, 105, 106, 108, 109, 116], "ty": 4, "unbias": [4, 15, 68], "left": [4, 15, 18, 20, 23, 24, 25, 45, 50, 60, 63, 73, 76, 90, 91, 92, 129, 130, 131], "right": [4, 9, 12, 15, 18, 20, 23, 24, 25, 45, 50, 60, 63, 66, 67, 73, 76, 90, 91, 92, 118, 131], "t_iy_i": 4, "combin": [4, 15, 20, 21, 22, 25, 28, 29, 60, 63, 64, 73, 86, 88, 118, 129], "obtain": [4, 9, 11, 13, 15, 17, 18, 20, 21, 22, 23, 24, 25, 28, 29, 32, 60, 64, 68, 78, 99, 100, 118, 129, 131], "whether": [5, 33, 91, 92, 103, 104, 105, 124, 125, 128], "write": [5, 15, 18, 23], "content": [5, 20, 25, 32, 131], "jupyt": [5, 132], "notebook": [5, 122, 123, 127], "ipynb": [5, 9, 14], "regular": [5, 10, 50, 73, 87], "md": 5, "ll": [5, 27, 129], "flavor": 5, "stand": [5, 45, 76, 102], "markedli": 5, "slight": 5, "variat": [5, 9, 33], "commonmark": 5, "small": [5, 48, 124, 125], "syntax": 5, "sphinx": 5, "ecosystem": 5, "power": [5, 20, 25, 132], "tool": [5, 15], "kind": [5, 32, 69], "markup": 5, "languag": [5, 79], "serv": [5, 15, 17, 27, 75], "purpos": [5, 15, 27, 33, 38, 124, 125, 126], "line": [0, 5, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 40, 45, 50, 60, 62, 63, 64, 66, 67, 68, 69, 70, 71, 73, 76, 106, 109, 110, 115, 116, 121, 122, 125, 127, 128, 129, 130, 132], "wherea": [5, 70, 75, 122], "span": 5, "input": [0, 5, 10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 33, 40, 45, 50, 60, 62, 63, 64, 66, 67, 68, 69, 70, 71, 73, 76, 106, 109, 110, 115, 116, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131], "being": [5, 83, 86, 88, 89, 95, 96, 101, 102, 103, 105, 107, 109, 116, 124, 125, 126, 129], "At": [5, 74, 76, 78, 80, 81, 83, 85, 86, 95, 96, 98, 101, 103, 108, 109, 110, 115, 116, 123], "insert": [5, 129], "mydirectivenam": 5, "my": [5, 19], "work": [5, 9, 13, 17, 21, 32, 45, 60, 64, 70, 76, 78], "alreadi": [5, 18, 23], "doesn": [5, 32, 131], "pre": [5, 11, 21, 33, 40, 75, 83, 107, 108, 109], "note": [5, 10, 11, 13, 14, 17, 19, 22, 29, 32, 38, 40, 45, 48, 59, 60, 61, 74, 75, 76, 78, 81, 83, 85, 86, 87, 88, 89, 94, 96, 97, 98, 99, 101, 102, 103, 104, 107, 110, 115, 117, 119], "box": 5, "here": [5, 9, 10, 11, 12, 13, 14, 17, 18, 19, 23, 45, 48, 50, 64, 74, 76, 78, 81, 82, 83, 85, 86, 87, 88, 89, 91, 92, 94, 96, 97, 98, 99, 101, 103, 104, 105, 107, 108, 109, 115, 117, 122, 123, 127, 129], "built": [5, 48, 73], "see": [5, 9, 10, 11, 13, 14, 20, 21, 22, 25, 26, 40, 64, 73, 80, 84, 89, 107, 108, 121, 124, 125, 131], "document": [5, 10, 15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 33, 40, 60, 121, 124, 132], "less": [5, 19, 45, 50, 76, 118], "pattern": [5, 123, 127], "some": [5, 15, 16, 19, 21, 22, 25, 28, 32, 33, 38, 45, 50, 60, 63, 64, 73, 75, 76, 89, 90, 91, 92, 96, 107, 117, 124, 125, 131], "rolenam": 5, "again": [5, 78, 123, 127], "valid": [5, 64, 69, 75, 118], "doc": [5, 21, 121, 124], "page": [5, 16, 19, 20, 24, 25, 68, 79, 100, 107, 108, 117, 119, 132], "rel": [5, 22, 28, 68, 73, 88, 131], "path": [5, 10, 21, 70], "intro": 5, "cite": [5, 73], "store": [5, 91], "bibtex": 5, "holdgraf_evidence_2014": 5, "render": 5, "moreov": [5, 15, 19, 32, 63, 64, 73], "bibliographi": 5, "properli": [5, 9], "bib": 5, "look": [5, 19, 23, 33, 64], "egw05": [5, 67], "damien": [5, 67], "ernst": [5, 67], "pierr": [5, 67], "geurt": [5, 67], "loui": [5, 67], "wehenkel": [5, 67], "tree": [5, 18, 19, 23, 38, 60, 67, 70, 127], "batch": [5, 66, 67, 96, 101, 103, 118], "mode": [5, 10, 67, 96, 101, 103, 128], "learn": [5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 25, 26, 28, 29, 32, 38, 40, 49, 53, 60, 64, 66, 67, 68, 69, 73, 74, 75, 79, 80, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 94, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 115, 116, 117, 122, 123, 127, 132], "journal": [5, 9, 10, 11, 12, 13, 14, 16, 19, 20, 21, 24, 25, 33, 36, 37, 40, 45, 48, 60, 67, 75, 76, 80, 90, 91, 92, 102, 119, 123], "hzal18": [5, 118], "tuoma": [5, 118], "haarnoja": [5, 118], "aurick": [5, 118], "zhou": [5, 50, 60, 63, 68, 79, 105, 108, 118], "pieter": [5, 118], "abbeel": [5, 118], "sergei": [5, 118], "levin": [5, 118], "soft": [5, 118], "actor": 5, "off": [5, 50, 63, 66, 68, 69, 70, 73, 84, 90, 91, 92, 97, 108, 118, 119, 132], "maximum": [5, 60, 76, 78, 82, 83, 86, 87, 100, 107, 109, 116, 117, 118], "entropi": [5, 15, 118], "deep": [5, 17, 19, 45, 60, 70, 76, 118, 119, 122, 131], "stochast": [5, 63, 73, 74, 75, 79, 80, 84, 88, 90, 91, 92, 107, 108, 117, 118], "intern": [5, 9, 10, 11, 12, 13, 14, 16, 19, 20, 25, 45, 50, 63, 64, 68, 69, 73, 76, 79, 80, 81, 82, 88, 89, 94, 95, 97, 98, 99, 100, 105, 107, 108, 110, 117, 118, 119, 122, 129, 130, 132], "confer": [5, 9, 10, 11, 12, 13, 14, 17, 19, 50, 63, 64, 68, 69, 73, 79, 80, 81, 82, 88, 89, 94, 95, 97, 98, 99, 100, 102, 103, 105, 107, 108, 110, 117, 118, 119], "1861": [5, 10, 118], "1870": [5, 118], "pmlr": [5, 19, 50, 63, 64, 68, 69, 73, 79, 80, 81, 88, 89, 94, 95, 97, 98, 99, 100, 102, 103, 105, 107, 108, 110, 117, 118], "2018": [5, 9, 10, 11, 12, 14, 15, 17, 45, 48, 50, 60, 68, 73, 74, 75, 76, 79, 83, 100, 102, 104, 108, 109, 115, 116, 118], "hk20": [5, 119], "yichun": [5, 10, 21, 119], "hu": [5, 119], "nathan": [5, 63, 119], "kallu": [5, 50, 63, 119], "dtr": [5, 78, 119, 131], "adapt": [5, 17, 18, 19, 20, 23, 25, 48, 50, 59, 75, 78, 79, 83, 96, 97, 99, 101, 103, 104, 106, 108, 109, 118, 119], "regret": [5, 45, 74, 75, 76, 79, 84, 87, 88, 89, 96, 98, 101, 103, 108, 119], "02791": [5, 119], "jl16": [5, 63, 68], "nan": [5, 10, 21, 63, 66, 68, 127], "jiang": [5, 63, 66, 68, 73, 79, 108], "lihong": [5, 63, 68], "li": [5, 15, 33, 40, 50, 63, 68, 73, 80, 81, 82, 90, 91, 92, 94, 102, 104, 105, 108, 110, 118, 119], "doubli": [5, 6, 16, 19, 20, 25, 45, 50, 60, 64, 68, 73, 76, 90, 92], "robust": [5, 16, 19, 20, 25, 32, 45, 50, 60, 64, 68, 70, 73, 76, 87, 90, 92, 95, 96, 100, 101, 102, 103, 107, 122, 127, 131], "652": [5, 63, 68, 73], "661": [5, 63, 68, 73, 80, 108], "ku19": [5, 63], "masatoshi": [5, 63], "uehara": [5, 63], "effici": [5, 15, 16, 19, 21, 22, 25, 29, 63, 64, 66, 67, 68, 69, 71, 73, 82, 87, 88, 89, 94, 96, 98, 99, 100, 101, 102, 103, 105, 109, 110, 115, 116, 118, 127, 129], "break": [5, 63, 73], "curs": [5, 18, 23, 63, 64, 73], "horizon": [5, 32, 64, 70, 74, 75, 98, 99, 101, 118, 119, 131], "doubl": [5, 15, 17, 20, 25, 32, 73, 91, 118], "1909": [5, 63], "05850": [5, 63], "lvy19": [5, 66], "hoang": [5, 63, 66], "cameron": [5, 63, 66], "voloshin": [5, 63, 66], "yisong": [5, 63, 66], "yue": [5, 9, 10, 11, 12, 13, 14, 60, 63, 66], "1903": [5, 66], "08738": [5, 66], "lltz18": [5, 68], "qiang": [5, 63, 68], "liu": [5, 48, 63, 68, 73], "ziyang": [5, 63, 68], "tang": [5, 63, 68, 73], "dengyong": [5, 63, 68], "infinit": [5, 32, 64, 70, 74, 75, 80, 118, 119, 131], "advanc": [5, 9, 10, 11, 12, 13, 14, 19, 22, 50, 68, 73, 87, 88, 89, 99, 102, 103, 104, 132], "neural": [5, 9, 10, 11, 12, 13, 14, 17, 19, 50, 68, 73, 79, 87, 88, 89, 99, 102, 103, 104, 108], "process": [5, 9, 10, 11, 12, 13, 14, 17, 19, 38, 50, 63, 68, 73, 79, 87, 88, 89, 98, 99, 101, 102, 103, 104, 107, 108, 118, 119, 122, 131], "5356": [5, 68], "5366": [5, 68], "mgkulic21": [5, 119], "lingheng": [5, 119], "meng": [5, 119], "rob": [5, 119], "gorbet": [5, 119], "dana": [5, 119], "kuli": [5, 119], "\u0107": [5, 119], "memori": [5, 119, 129], "pomdp": [5, 32, 119, 131], "2021": [5, 9, 13, 16, 19, 20, 24, 25, 33, 36, 50, 64, 69, 87, 88, 89, 90, 91, 92, 119], "ieee": [5, 119], "rsj": [5, 119], "robot": [5, 119], "iro": [5, 119], "5619": [5, 119], "5626": [5, 22, 119], "mbm": [5, 118], "16": [5, 10, 18, 21, 50, 62, 76, 118, 121, 124, 129, 130], "volodymyr": [5, 118], "mnih": [5, 118], "adria": [5, 118], "puigdomenech": [5, 118], "badia": [5, 118], "mehdi": [5, 118], "mirza": [5, 118], "alex": [5, 118], "grave": [5, 118], "timothi": [5, 118], "lillicrap": [5, 118], "tim": [5, 118], "harlei": [5, 118], "david": [5, 9, 10, 11, 12, 13, 14, 17, 19, 118], "silver": [5, 118], "korai": [5, 118], "kavukcuoglu": [5, 118], "asynchron": [5, 118], "1928": [5, 118], "1937": [5, 118], "mk": [5, 118], "15": [5, 10, 18, 21, 23, 27, 40, 59, 62, 76, 118, 124, 128, 129, 130], "andrei": [5, 118], "rusu": [5, 118], "joel": [5, 118], "veness": [5, 118], "marc": [5, 118], "g": [5, 9, 10, 11, 12, 13, 14, 17, 22, 27, 29, 45, 60, 63, 64, 66, 68, 70, 73, 74, 75, 79, 83, 87, 89, 96, 101, 102, 103, 104, 108, 109, 118, 119, 122, 127, 131], "bellemar": [5, 118], "martin": [5, 75, 118], "riedmil": [5, 118], "andrea": [5, 118], "fidjeland": [5, 118], "georg": [5, 118], "ostrovski": [5, 118], "human": [5, 118], "518": [5, 118], "7540": [5, 118], "529": [5, 118], "533": [5, 90, 91, 92, 118], "pre00": [5, 68], "doina": [5, 68], "precup": [5, 68, 73], "elig": [5, 68, 73, 118], "trace": [5, 68, 73, 118], "comput": [5, 9, 13, 19, 68, 73, 80, 87, 96, 102, 103, 104, 105, 118], "scienc": [5, 9, 10, 11, 12, 13, 14, 15, 19, 22, 26, 28, 29, 45, 68, 73, 76, 96, 103, 131], "depart": [5, 68, 73], "faculti": [5, 68, 73], "public": [5, 23, 68, 73], "80": [5, 18, 45, 60, 62, 68, 73, 76], "2000": [5, 9, 10, 11, 12, 13, 14, 40, 59, 68, 73, 78, 109, 110, 115, 116], "put14": [5, 75], "l": [5, 24, 25, 50, 60, 63, 70, 73, 74, 75, 79, 80, 81, 82, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 110, 122], "puterman": [5, 74, 75], "markov": [5, 9, 11, 13, 14, 68, 95, 118, 119, 131], "dynam": [5, 9, 15, 45, 48, 50, 59, 74, 75, 76, 78, 103, 105, 106, 107, 117, 118, 119, 122, 131], "program": [5, 40, 74, 75, 96, 102, 103, 105], "wilei": [5, 74, 75], "son": [5, 74, 75], "2014": [5, 9, 10, 11, 12, 13, 14, 45, 60, 74, 75, 76], "sla": [5, 118], "schulman": [5, 118], "michael": [5, 33, 118], "jordan": [5, 118], "philipp": [5, 118], "moritz": [5, 118], "trust": [5, 118], "region": [5, 118], "1889": [5, 118], "1897": [5, 118], "swd": [5, 118], "17": [5, 10, 21, 50, 60, 62, 76, 118, 121, 124, 128, 129], "filip": [5, 118], "wolski": [5, 118], "prafulla": [5, 118], "dhariw": [5, 118], "alec": [5, 118], "radford": [5, 118], "oleg": [5, 118], "klimov": [5, 118], "proxim": [5, 70, 118], "algorithm": [5, 9, 10, 12, 19, 20, 22, 25, 26, 28, 29, 48, 63, 67, 74, 75, 80, 81, 84, 87, 88, 89, 90, 91, 92, 94, 97, 98, 99, 104, 105, 118, 123, 127, 129, 131, 132], "1707": [5, 85, 107, 108, 117, 118], "06347": [5, 118], "2017": [5, 9, 10, 11, 12, 13, 14, 16, 19, 20, 23, 25, 37, 79, 85, 102, 103, 105, 107, 108, 117, 118, 119, 123], "swcs21": [5, 64], "chengchun": [5, 64, 118, 119], "shi": [5, 17, 19, 45, 50, 60, 64, 69, 70, 75, 76, 118, 119, 122], "runzh": [5, 64], "wan": [5, 64, 69, 87, 88, 95, 96, 100, 101, 102, 103, 107], "victor": [5, 17, 19, 64], "chernozhukov": [5, 15, 17, 64, 69], "rui": [5, 9, 10, 11, 12, 13, 14, 48, 60, 64, 118, 119], "song": [5, 9, 10, 11, 12, 13, 14, 45, 48, 50, 59, 60, 64, 70, 76, 78, 87, 88, 90, 91, 92, 95, 96, 100, 101, 102, 103, 107, 118, 119, 122], "deepli": [5, 69], "debias": [5, 15, 17, 69], "interv": [5, 18, 23, 50, 59, 60, 64, 74, 75, 90, 91, 92, 118, 119], "9580": [5, 64, 69], "9591": [5, 64, 69], "swl": [5, 75], "20": [5, 9, 10, 14, 18, 21, 23, 33, 45, 50, 59, 60, 62, 75, 101, 103, 104, 121, 124, 129, 130], "shi2020reinforc": [5, 75], "szls20": [5, 118], "sheng": [5, 118], "zhang": [5, 15, 79, 105, 108, 118], "wenbin": [5, 9, 10, 11, 12, 13, 14, 118], "lu": [5, 9, 10, 11, 12, 13, 14, 45, 50, 76, 90, 91, 92, 108, 118], "2001": [5, 27, 118, 124, 125, 126], "04515": [5, 118], "szy": [5, 119], "22": [5, 10, 18, 21, 23, 45, 59, 62, 118, 119], "jin": [5, 102, 104, 119], "zhu": [5, 9, 10, 11, 12, 13, 14, 50, 102, 104, 119], "shen": [5, 79, 90, 91, 92, 108, 119], "ye": [5, 9, 119, 131], "shikai": [5, 119], "luo": [5, 60, 119], "hongtu": [5, 119], "confid": [5, 16, 19, 20, 25, 59, 82, 84, 86, 90, 91, 92, 106, 116, 118, 119], "american": [5, 21, 36, 40, 48, 60, 90, 91, 92, 119, 127], "2022": [5, 18, 21, 23, 60, 88, 95, 96, 100, 101, 102, 103, 107, 119], "ss96": [5, 118], "satind": [5, 118], "singh": [5, 118], "richard": [5, 9, 10, 11, 12, 13, 14, 75, 118], "sutton": [5, 74, 75, 83, 108, 109, 118], "replac": [5, 10, 12, 45, 50, 60, 64, 68, 73, 118, 129], "123": [5, 118, 121, 123, 124, 125, 127], "158": [5, 21, 76, 78, 118], "1996": [5, 118], "spa12": [5, 119], "matthij": [5, 119], "tj": [5, 76, 119], "spaan": [5, 119], "partial": [5, 10, 12, 24, 25, 27, 32, 45, 76, 98, 99, 101, 119, 124, 125, 126, 131], "state": [5, 6, 11, 13, 14, 19, 21, 22, 27, 28, 32, 33, 40, 60, 63, 64, 66, 67, 68, 70, 73, 74, 75, 118, 119, 121, 122, 123, 127, 129], "art": [5, 11, 13, 14, 19, 60, 63, 73, 119, 131], "387": [5, 21, 119], "414": [5, 119], "2012": [5, 21, 27, 48, 79, 102, 117, 119, 124, 125, 126, 127], "sut88": [5, 118], "tempor": [5, 9, 10, 68, 73, 118], "44": [5, 60, 62, 118, 124], "1988": [5, 16, 19, 20, 24, 25, 40, 96, 118], "sb18": [5, 75, 118], "andrew": [5, 33, 75, 118], "barto": [5, 74, 75, 83, 108, 109, 118], "mit": [5, 74, 75, 83, 108, 109, 118], "press": [5, 74, 75, 83, 85, 108, 109, 118], "tfl": [5, 63], "yihao": [5, 63], "feng": [5, 63], "bia": [5, 15, 21, 22, 23, 25, 32, 48, 50, 60, 63, 64, 66, 68, 73, 119, 124, 125, 131], "reduct": [5, 63, 119], "represent": [5, 9, 10, 11, 12, 13, 14, 48, 63], "tb16": [5, 63], "philip": [5, 63, 68], "thoma": [5, 63, 68, 73], "emma": [5, 63], "brunskil": [5, 63], "2139": [5, 63], "2148": [5, 63], "tho15": [5, 68], "safe": [5, 68, 73], "doctor": [5, 12, 32, 68, 128], "dissert": [5, 68], "univers": [5, 68, 85, 108], "massachusett": [5, 68], "amherst": [5, 68], "uhj19": [5, 63], "jiawei": [5, 63], "huang": [5, 63], "minimax": [5, 63, 64], "weight": [5, 9, 10, 11, 12, 13, 14, 15, 17, 18, 20, 21, 22, 23, 25, 29, 40, 63, 64, 68, 73, 100, 107, 117, 127, 131], "1910": [5, 63], "12809": [5, 63], "vhgs16": [5, 118], "hado": [5, 118], "van": [5, 16, 19, 20, 25, 37, 85, 101, 107, 108, 115, 116, 117, 118, 123], "hasselt": [5, 118], "arthur": [5, 118], "guez": [5, 118], "proceed": [5, 19, 21, 22, 26, 28, 29, 45, 50, 76, 80, 82, 108, 118, 127], "aaai": [5, 118], "artifici": [5, 19, 50, 79, 80, 81, 82, 88, 94, 95, 97, 108, 110, 118], "volum": [5, 118], "30": [5, 10, 21, 27, 62, 118], "vljy19": [5, 63, 66], "empir": [5, 63, 66, 68, 75, 80, 84, 108], "1911": [5, 63, 66], "06854": [5, 63, 66], "zlpm17": [5, 119], "pengfei": [5, 119], "xin": [5, 119], "pascal": [5, 119], "poupart": [5, 119], "guanghui": [5, 119], "miao": [5, 119], "On": [5, 33, 48, 50, 119, 129], "1704": [5, 119], "07978": [5, 119], "If": [5, 10, 15, 59, 76, 78, 87, 88, 94, 98, 101, 107, 117, 127, 132], "insid": 5, "jupytext": 5, "metadata": [5, 23, 87, 88], "run": [5, 10, 14, 118], "command": [5, 132], "init": 5, "print": [5, 10, 11, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 40, 45, 59, 62, 76, 78, 123, 124, 125, 127, 129, 130], "default": [5, 9, 10, 11, 59, 60, 87, 89, 94, 118, 128, 130, 132], "kernel": [5, 18, 19, 20, 23, 25, 32, 48, 50, 63, 73, 74, 75, 118, 131], "output": [5, 11, 17, 50, 70, 122, 129], "rest": [5, 6, 10, 12, 17, 38, 40, 80, 88, 90, 91, 92, 124, 125, 129], "nb": 5, "r": [6, 10, 12, 15, 16, 17, 18, 19, 21, 22, 23, 26, 28, 29, 32, 33, 38, 45, 50, 59, 60, 61, 63, 68, 69, 70, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 115, 116, 117, 118, 121, 122, 123, 124, 127, 129, 130, 131], "s_i": [6, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 29, 33, 38, 131], "a_i": [6, 15, 17, 18, 19, 20, 21, 23, 24, 25, 48, 50, 60, 61, 90, 91, 92, 131], "r_i": [6, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 29, 45, 61, 76, 77, 90, 91, 92, 131], "equival": [6, 9, 10, 11, 12, 13, 14, 48, 64, 79, 84, 108], "pearl": [6, 9, 10, 11, 12, 13, 14, 21], "spirt": [6, 9, 10, 11, 12, 13, 14], "mathemat": [6, 10, 12, 45, 76, 100, 107, 117], "physic": [6, 10, 12, 21, 131], "hold": [6, 10, 12, 21, 32, 68, 73, 74, 75], "constant": [6, 10, 12, 22, 28, 48], "unchang": [6, 10, 12], "regress": [6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 22, 24, 25, 28, 29, 40, 45, 59, 60, 66, 68, 73, 76, 78, 96, 123, 127], "propens": [6, 12, 15, 16, 17, 20, 21, 22, 24, 25, 29, 33, 45, 50, 60, 68, 73, 76], "score": [6, 9, 12, 15, 16, 17, 20, 21, 22, 24, 25, 27, 29, 33, 45, 50, 60, 68, 73, 76, 124, 125, 126, 127, 129, 131], "roust": 6, "introduc": [6, 15, 17, 18, 19, 20, 21, 22, 23, 25, 26, 29, 33, 38, 45, 63, 64, 68, 69, 70, 73, 74, 75, 76, 78, 79, 80, 86, 87, 89, 90, 91, 92, 95, 102, 105, 108, 116, 118, 119, 131, 132], "cel": [6, 16, 17, 20, 21, 24, 32, 33, 70, 129], "detail": [6, 10, 12, 15, 16, 17, 19, 20, 22, 25, 29, 32, 38, 40, 61, 64, 84, 108, 127, 131, 132], "hte": [6, 15, 16, 17, 18, 20, 22, 23, 24, 25, 26, 28, 29, 32, 38, 124, 125], "captur": [6, 9, 17, 18, 22, 23, 50, 70, 91, 92], "heterogenieti": 6, "quit": [6, 17, 19, 22, 68, 73, 131], "few": [6, 19, 63, 73, 75, 80, 84, 88, 100, 108, 131], "deal": [6, 32, 40, 96, 97, 101, 103, 106, 131], "reli": [9, 12, 13, 63, 73], "locat": [9, 12], "reward": [9, 12, 15, 19, 21, 22, 23, 25, 27, 32, 40, 48, 59, 60, 61, 68, 70, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 115, 116, 117, 118, 121, 122, 123, 127, 128, 129, 130, 131], "conveni": [9, 12], "violat": [9, 12, 32, 64], "emerg": [9, 12], "basic": [9, 15, 16, 22, 25, 26, 40, 45, 98, 99, 101, 131], "wai": [9, 22, 24, 25, 29, 60, 63, 64, 66, 67, 68, 69, 70, 71, 73, 78, 109, 110, 115, 116, 118], "mathcal": [9, 10, 11, 12, 13, 14, 21, 32, 33, 45, 50, 63, 64, 68, 73, 74, 75, 76, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 115, 116, 117, 118, 129, 131], "mathbf": [9, 10, 11, 12, 13, 14], "z": [9, 10, 11, 12, 13, 14, 16, 17, 19, 25, 70, 73, 85, 94, 95, 97, 98, 100, 107, 108, 115, 116, 117, 122], "node": [9, 11, 12, 13, 14, 131], "edg": [9, 10, 11, 12, 13, 14], "said": [9, 11, 12, 13, 14], "parent": [9, 11, 12, 13, 14, 132], "z_j": [9, 11, 12, 13, 14], "let": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 28, 29, 50, 59, 63, 64, 68, 70, 73, 74, 75, 77, 80, 84, 88, 95, 100, 102, 107, 108, 117, 118], "pa_": [9, 11, 12, 13, 14], "cycl": [9, 11, 12, 13, 14], "acycl": [9, 10, 11, 12, 13, 14], "dag": [9, 10, 11, 12, 13, 14, 124, 125], "character": [9, 10, 11, 12, 13, 14, 67, 74, 91, 92, 94, 96, 102, 107, 117], "z_1": [9, 11, 12, 13, 14], "z_2": [9, 11, 12, 13, 14], "z_d": [9, 11, 12, 13, 14], "rightarrow": [9, 11, 12, 13, 14, 20, 21, 25, 32], "mean": [9, 11, 12, 13, 14, 19, 32, 45, 50, 60, 62, 63, 68, 70, 73, 75, 78, 81, 83, 85, 86, 87, 89, 90, 91, 92, 96, 98, 99, 100, 101, 103, 104, 108, 109, 110, 115, 116, 118, 121, 122, 124, 129, 131], "propos": [9, 10, 13, 14, 17, 21, 32, 48, 50, 60, 63, 64, 68, 69, 70, 73, 76, 90, 91, 92, 94, 122, 123, 127, 131], "plusibl": 9, "up": [9, 13, 18, 20, 23, 25, 75, 79, 87, 89, 118, 131], "markovian": 9, "unless": [9, 10, 14], "certain": [9, 17, 60, 75, 119], "assumpt": [9, 11, 13, 14, 16, 17, 19, 21, 22, 25, 26, 32, 40, 48, 64, 68, 70, 73, 75, 79, 80, 91, 95, 96, 101, 103, 118, 119, 131], "specifi": [9, 10, 11, 15, 18, 23, 24, 25, 45, 48, 59, 61, 64, 75, 76, 78, 91, 108, 109, 110, 115, 123, 127, 128], "type": [9, 10, 15, 32, 38, 61, 63, 64, 66, 67, 68, 69, 73, 80, 84, 85, 88, 90, 91, 102, 103, 104, 105, 106, 108, 127, 128, 131, 132], "focus": [9, 19, 32, 60, 68, 84, 95, 107, 108, 117, 118, 131], "local": [9, 10, 14, 18, 19, 20, 22, 23, 25, 121, 124, 128, 130, 132], "independ": [9, 10, 11, 12, 13, 14, 15, 20, 21, 25, 32, 60, 61, 75, 98, 118], "skeleton": [9, 131], "orient": [9, 10, 14], "pc": [9, 10, 11, 12, 13, 131], "et": [9, 11, 12, 14, 15, 16, 21, 25, 36, 48, 60, 63, 64, 68, 69, 73, 75, 83, 86, 90, 91, 92, 94, 98, 108, 109, 116, 118], "al": [9, 11, 12, 14, 15, 16, 21, 25, 36, 48, 60, 63, 64, 68, 69, 73, 75, 83, 86, 90, 91, 92, 94, 98, 108, 109, 116, 118], "kalisch": [9, 10, 11, 12, 13, 14], "b\u00fchlmann": [9, 10, 11, 12, 13, 14], "easi": [9, 14, 19, 22, 24, 25, 26, 59, 66, 68, 78, 83, 102], "shah": [9, 10, 11, 12, 13, 14], "peter": [9, 10, 11, 12, 13, 14, 16, 19, 20, 24, 25], "second": [9, 15, 21, 22, 28, 45, 50, 64, 76, 94, 96, 97, 118, 129, 131], "ica": [9, 13, 14], "lingam": [9, 13, 14, 131], "shimizu": [9, 10, 11, 12, 13, 14], "2006": [9, 10, 11, 12, 13, 14, 16, 19, 20, 25, 97], "cam": [9, 10, 11, 12, 13, 14], "greedi": [9, 10, 11, 12, 13, 14, 84, 90, 91, 92, 109, 118, 130, 131], "search": [9, 10, 11, 12, 13, 14, 95, 118], "ge": [9, 32, 63, 64, 68, 70, 73, 74, 75, 87, 88, 95, 96, 100, 101, 102, 103, 107, 118, 122], "chicker": [9, 10, 11, 12, 13, 14], "2002": [9, 10, 11, 12, 13, 14, 80, 83, 86, 108, 109, 116], "fge": 9, "ramsei": [9, 10, 11, 12, 13, 14], "bayesian": [9, 10, 11, 12, 13, 14, 87, 88, 96, 97, 99, 101, 103], "zheng": [9, 10, 11, 12, 14, 37, 123], "open": [9, 10, 27, 70, 121, 122, 123, 124, 125, 126, 128, 132], "construct": [9, 10, 11, 12, 13, 14, 16, 20, 21, 22, 25, 26, 33, 63, 64, 66, 68, 69, 70, 73, 87, 118], "notear": [9, 11, 14, 124, 125, 131], "vae": [9, 13], "parameter": [9, 13, 87, 89, 96, 101, 103, 118], "network": [9, 10, 11, 12, 13, 14, 17, 19, 50, 60], "yu": [9, 10, 11, 12, 13, 14, 19, 22, 26, 28, 29, 48, 60], "friendli": [9, 13], "gnn": [9, 10, 11, 12, 13, 14], "chen": [9, 10, 11, 12, 13, 14, 90, 91, 92, 99, 100, 107, 117], "cai": [9, 11, 12, 13, 14, 50, 90, 91, 92], "cut": [9, 13], "support": [9, 20, 25, 70, 75, 80, 85, 86, 89, 118, 128, 131], "train": [9, 10, 16, 17, 18, 19, 20, 23, 24, 25, 45, 48, 59, 62, 76, 78, 81, 82, 94, 123, 127, 129, 130, 131], "free": [9, 66, 131], "gaussian": [9, 10, 12, 13, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 98, 99, 101, 110, 115, 130, 131], "o": [9, 10, 11, 12, 13, 14, 15, 17, 131], "max": [9, 50, 59, 60, 63, 73, 78, 128, 129, 131], "adjac": [9, 10, 11, 13, 14, 131], "b_": [9, 11, 13, 14], "leq": [9, 11, 13, 14, 32, 33, 40, 90, 91, 92, 100, 102, 131], "matrix": [9, 10, 11, 13, 14, 21, 40, 70, 81, 85, 87, 96, 98, 99, 101, 103, 104, 107, 122, 124, 125, 127], "otherwis": [9, 11, 13, 14, 59, 61, 78, 83, 89, 95, 109, 132], "nest": [9, 11, 13, 14, 45, 76, 128], "faith": [9, 11, 13, 14], "suffici": [9, 11, 13, 14, 17, 63, 68], "pair": [9, 11, 13, 14, 63, 64, 68, 73, 75, 81, 85, 96, 97, 99, 103, 104, 105, 110, 115], "epsilon": [9, 11, 13, 14, 17, 24, 25, 84, 90, 91, 92, 109, 118, 131], "label": [9, 10, 11, 13, 14, 40, 48, 50, 63, 64, 66, 68, 69, 73, 74, 75, 87, 90, 91, 92, 95, 96, 101, 102, 103, 107, 117, 118, 127], "lsem_x": [9, 11, 13, 14], "jointli": [9, 11, 13, 14, 45, 76], "error": [9, 10, 11, 13, 14, 19, 45, 59, 76, 78, 123, 127, 128], "plu": [9, 11, 13], "n_i": [9, 11, 13], "anm": [9, 11, 13], "f_i": [9, 11, 13], "special": [9, 11, 13, 32, 131], "handl": [9, 10, 11, 13, 14, 19, 22, 50, 60, 68, 73, 108, 121, 124, 128, 131], "version": [9, 11, 13, 18, 23, 63, 64, 68, 73, 80, 83, 84, 102, 108, 109, 119], "f_2": [9, 13], "f_1": [9, 13], "nonlinear": [9, 13, 22, 28], "transform": [9, 13, 45], "fisher": [9, 14], "implement": [9, 11, 13, 14, 15, 18, 19, 22, 23, 26, 40, 48, 50, 59, 60, 66, 68, 78, 81, 82, 83, 85, 86, 87, 89, 90, 91, 92, 94, 96, 97, 98, 99, 101, 103, 104, 105, 129, 130, 131, 132], "http": [9, 10, 11, 13, 14, 17, 21, 23, 27, 33, 40, 61, 121, 124, 132], "github": [9, 10, 11, 13, 14, 17, 40, 130, 132], "com": [9, 10, 11, 13, 14, 17, 27, 33, 40, 61, 132], "bd2kccd": [9, 14], "highli": [9, 14], "java": [9, 14], "blob": [9, 14, 40], "20pc": [9, 14], "20in": [9, 14], "20action": [9, 14], "recov": [9, 11], "hyper": [9, 11, 86, 122], "cdt15": [9, 11], "xunzheng": [9, 13], "incorpor": [9, 10, 19, 83, 85, 108, 109], "auto": [9, 129], "encod": [9, 128], "modifi": [9, 12, 17, 81, 85, 96, 97, 98, 99, 101, 103, 104, 110, 115, 122], "smooth": [9, 50], "evid": 9, "lower": [9, 11, 13, 14, 15, 60, 63, 68, 73, 91, 98, 123, 127], "bound": [9, 19, 20, 21, 25, 63, 64, 73, 74, 75, 82, 84, 86, 89, 90, 91, 92, 98, 106, 116, 127], "loss": [9, 17, 19, 40, 74, 75, 131], "fishmoon1234": 9, "pytorch": 9, "paszk": 9, "anoc": [9, 11, 12, 13, 14], "cvae": 9, "constrain": [9, 10, 11, 12, 13, 14], "novel": [9, 10, 17, 70, 73], "identif": [9, 10, 11, 12, 13, 14, 131, 132], "publicli": [9, 10, 124, 125, 126], "anonym": [9, 10, 27, 124, 125, 126], "granger": 9, "1969": [9, 10], "entner": 9, "hoyer": [9, 10, 11, 12, 13, 14], "2010": [9, 21, 40, 80, 108, 127], "momentari": 9, "mci": 9, "rung": 9, "autoregress": 9, "hyv\u00e4rinen": [9, 10, 11, 12, 13, 14], "timino": 9, "2013": [9, 11, 13, 14, 15, 22, 80, 81, 99, 100, 107, 108, 110, 117], "dynotear": 9, "pamfil": 9, "contemporan": 9, "intra": [9, 87], "slice": [9, 21, 121, 124], "lag": [9, 119, 121, 124], "interslic": 9, "nt": [9, 21, 63, 64, 69, 70, 73, 122, 127], "sun": [9, 60], "nonparametr": [9, 19, 73], "along": [9, 33, 70, 79, 131], "properti": [9, 19, 60, 105, 115], "judea": [9, 10, 11, 12, 13, 14, 21], "survei": [9, 10, 11, 12, 13, 14, 80, 84, 100, 102, 108, 132], "96": [9, 10, 11, 12, 13, 14, 62, 70, 115, 116, 121, 122, 124], "146": [9, 10, 11, 12, 13, 14, 84, 121, 123, 128], "2009": [9, 10, 11, 12, 13, 14], "pater": [9, 10, 11, 12, 13, 14], "clark": [9, 10, 11, 12, 13, 14], "glymour": [9, 10, 11, 12, 13, 14], "schein": [9, 10, 11, 12, 13, 14], "stuart": [9, 10, 11, 12, 13, 14], "kauffman": [9, 10, 11, 12, 13, 14], "valerio": [9, 10, 11, 12, 13, 14], "aimal": [9, 10, 11, 12, 13, 14], "frank": [9, 10, 11, 12, 13, 14], "wimberli": [9, 10, 11, 12, 13, 14], "gene": [9, 10, 11, 12, 13, 14], "express": [9, 10, 11, 12, 13, 14, 18, 22, 23, 33, 63, 73, 79, 85], "microarrai": [9, 10, 11, 12, 13, 14], "marku": [9, 10, 11, 12, 13, 14], "8": [9, 10, 11, 12, 13, 14, 15, 18, 19, 21, 22, 25, 26, 28, 29, 33, 40, 45, 50, 59, 60, 62, 70, 78, 80, 108, 110, 115, 121, 122, 123, 124, 125, 127, 128, 130], "mar": [9, 10, 11, 12, 13, 14], "613": [9, 10, 11, 12, 13, 14], "636": [9, 10, 11, 12, 13, 14], "rajen": [9, 10, 11, 12, 13, 14], "jona": [9, 10, 11, 12, 13, 14], "hard": [9, 10, 11, 12, 13, 14], "generalis": [9, 10, 11, 12, 13, 14], "1804": [9, 10, 11, 12, 13, 14], "07203": [9, 10, 11, 12, 13, 14], "shohei": [9, 10, 11, 12, 13, 14], "patrik": [9, 10, 11, 12, 13, 14], "aapo": [9, 10, 11, 12, 13, 14], "antti": [9, 10, 11, 12, 13, 14], "kerminen": [9, 10, 11, 12, 13, 14], "7": [9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 25, 26, 27, 28, 29, 40, 45, 50, 60, 62, 63, 64, 66, 67, 68, 69, 70, 71, 73, 80, 95, 102, 108, 109, 121, 122, 123, 124, 125, 127, 128, 130], "oct": [9, 10, 11, 12, 13, 14], "2003": [9, 10, 11, 12, 13, 14, 45, 76], "2030": [9, 10, 11, 12, 13, 14], "6": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 26, 27, 28, 29, 40, 45, 48, 50, 60, 62, 63, 64, 66, 67, 68, 69, 70, 71, 73, 76, 80, 102, 107, 108, 109, 110, 115, 116, 121, 122, 123, 124, 125, 127, 128, 129, 130], "ernest": [9, 10, 11, 12, 13, 14], "penal": [9, 10, 11, 12, 13, 14, 19, 48, 59, 78], "annal": [9, 10, 11, 12, 13, 14, 18, 19, 21, 23, 35, 39, 41, 42, 43, 45, 76, 127], "42": [9, 10, 11, 12, 13, 14, 60, 62, 81, 82, 83, 85, 86, 87, 89, 109, 110, 115, 116, 130], "2526": [9, 10, 11, 12, 13, 14], "2556": [9, 10, 11, 12, 13, 14], "maxwel": [9, 10, 11, 12, 13, 14], "nov": [9, 10, 11, 12, 13, 14, 33], "507": [9, 10, 11, 12, 13, 14, 97], "554": [9, 10, 11, 12, 13, 14], "joseph": [9, 10, 11, 12, 13, 14], "madelyn": [9, 10, 11, 12, 13, 14], "ruben": [9, 10, 11, 12, 13, 14], "sanchez": [9, 10, 11, 12, 13, 14], "romero": [9, 10, 11, 12, 13, 14], "magnet": [9, 10, 11, 12, 13, 14], "reson": [9, 10, 11, 12, 13, 14], "imag": [9, 10, 11, 12, 13, 14, 17, 21, 33], "analyt": [9, 10, 11, 12, 13, 14, 61], "121": [9, 10, 11, 12, 13, 14, 27], "129": [9, 10, 11, 12, 13, 14, 121, 123, 124, 125, 127], "xun": [9, 10, 11, 12, 13, 14], "bryon": [9, 10, 11, 12, 13, 14], "aragam": [9, 10, 11, 12, 13, 14], "pradeep": [9, 10, 11, 12, 13, 14], "ravikumar": [9, 10, 11, 12, 13, 14], "eric": [9, 10, 11, 12, 13, 14, 21], "xing": [9, 10, 11, 12, 13, 14], "tear": [9, 10, 11, 12, 13, 14], "pp": [9, 10, 11, 12, 13, 14, 21, 45, 50, 76, 79, 80, 81, 82, 88, 89, 94, 95, 97, 98, 99, 100, 102, 103, 105, 107, 110, 127], "9472": [9, 10, 11, 12, 13, 14], "9483": [9, 10, 11, 12, 13, 14], "10": [9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 21, 22, 23, 25, 26, 28, 29, 33, 45, 48, 50, 59, 60, 62, 70, 82, 96, 98, 99, 101, 103, 108, 121, 122, 123, 124, 125, 127, 128], "jie": [9, 10, 11, 12, 13, 14], "tian": [9, 10, 11, 12, 13, 14], "gao": [9, 10, 11, 12, 13, 14], "mo": [9, 10, 11, 12, 13, 14], "1904": [9, 10, 11, 12, 13, 14, 80, 84, 108], "10098": [9, 10, 11, 12, 13, 14], "11": [9, 10, 11, 12, 13, 14, 17, 21, 26, 27, 28, 29, 33, 45, 59, 60, 62, 73, 108, 115, 116, 121, 122, 123, 124, 127, 129, 130], "shengyu": [9, 10, 11, 12, 13, 14], "zhitang": [9, 10, 11, 12, 13, 14], "1906": [9, 10, 11, 12, 13, 14], "04477": [9, 10, 11, 12, 13, 14], "hengrui": [9, 10, 11, 12, 13, 14], "demand": [10, 40], "kei": [10, 17, 27, 33, 48, 50, 68, 95, 121, 125, 128, 129, 131, 132], "factor": [10, 68, 74, 75, 95, 96, 97, 98, 99, 101, 102, 107], "guid": [10, 82, 85, 87, 89, 108, 110, 115, 118], "downstream": 10, "task": [10, 64, 66, 68, 73, 75, 79, 84, 88, 89, 108, 128], "m_1": [10, 12, 70], "m_2": [10, 12], "m_p": [10, 12], "dimens": [10, 12, 119], "give": [10, 15, 18, 23, 26, 28, 29, 74, 80, 84, 88, 108, 123, 127, 129], "te": [10, 12, 21, 70, 122, 123, 127], "de": [10, 12, 21, 64, 79, 108], "ie": [10, 12, 21], "equat": [10, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 32, 33, 40, 50, 60, 63, 64, 66, 67, 68, 69, 73, 74, 76, 87, 89, 90, 91, 92, 94, 95, 96, 98, 100, 101, 102, 103, 104, 105, 106, 107, 108, 116, 117, 118], "split": [10, 12, 15, 18, 23, 33, 63, 64, 73, 94, 95, 96, 100, 101, 103, 107, 117, 118, 124, 125, 128, 129], "remov": [10, 11, 12, 48, 129], "citet": [10, 69, 73], "pearl2009caus": 10, "dm": [10, 15, 21, 63, 66, 73], "dm_i": 10, "big": [10, 15, 16, 17, 18, 20, 21, 23, 25, 32, 33, 45, 48, 50, 63, 64, 66, 67, 68, 73, 74, 76, 87, 91, 94, 103, 118], "m_i": [10, 21], "_i": [10, 22, 29, 40, 45, 60, 61, 81, 90, 91, 92, 96, 101, 103, 107, 110, 117, 129], "omega_i": 10, "setminu": 10, "except": [10, 40, 76, 129], "im": [10, 70, 122], "def_im": 10, "im_i": 10, "firstli": [10, 86, 108, 116], "sourc": [10, 132], "degre": [10, 11, 13, 14, 19, 20, 25, 40, 94], "freedom": 10, "smaller": [10, 22, 25, 124, 125], "decompos": [10, 64, 70, 96, 101, 103, 122], "compon": [10, 11, 59, 63, 73, 74, 122, 123, 127, 131], "row": [10, 17, 18, 21, 22, 27, 33, 60, 79, 121, 124, 128, 129, 130], "compos": 10, "investig": [10, 33, 65, 80], "spread": [10, 21], "major": [10, 21, 59, 70, 80, 85, 96, 101, 103, 108, 110, 115, 118, 122], "panda": [10, 11, 15, 16, 17, 18, 20, 21, 23, 24, 26, 27, 28, 29, 33, 40, 62, 70, 76, 78, 121, 122, 123, 124, 125, 127, 128, 129], "pd": [10, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 33, 40, 45, 59, 60, 62, 70, 76, 78, 121, 122, 123, 124, 125, 127, 128, 129, 130], "os": [10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 33, 40, 50, 60, 63, 64, 66, 67, 68, 69, 71, 73, 109, 110, 115, 116, 124, 125, 130], "pickl": [10, 27, 50, 70, 121, 122, 123, 124, 125, 128], "data_typ": 10, "realdata": 10, "real_data_fil": 10, "covid19": [10, 33], "pkl": 10, "epoch": [10, 102, 103, 104, 105, 106], "100": [10, 15, 45, 50, 60, 62, 70, 76, 87, 101, 103, 104, 108, 121, 122, 124, 125, 127, 130], "node_numb": 10, "32": [10, 16, 19, 20, 21, 25, 62, 80, 102, 103, 104, 124, 125, 129, 130], "sample_s": 10, "38": [10, 18, 21, 23, 33, 40, 60, 62, 129, 130], "batch_siz": [10, 17], "rep_numb": 10, "namespac": 10, "simu_g_fil": 10, "s1_trueg": [], "graph_degre": 10, "a_typ": [10, 11, 13, 14], "seed": [10, 11, 13, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 48, 50, 60, 62, 70, 81, 82, 83, 85, 86, 87, 89, 94, 96, 97, 98, 99, 101, 103, 104, 105, 106, 108, 109, 110, 115, 116, 122, 124, 125, 127, 129, 130], "2333": 50, "k_max_it": 10, "original_lr": 10, "003": 45, "torch": [], "lr_schedul": [], "138": [124, 125, 127], "userwarn": 127, "detect": 50, "step": [16, 17, 20, 22, 24, 25, 26, 28, 29, 40, 48, 60, 62, 63, 64, 68, 73, 77, 90, 91, 92, 118, 129], "later": [15, 27, 32, 45, 63, 64, 66, 67, 68, 69, 71, 73, 76, 109, 110, 115, 116], "opposit": 48, "failur": [27, 124, 125, 126, 127], "skip": 10, "schedul": [87, 89, 103, 106], "org": [21, 23, 121, 124], "html": [21, 61, 121, 124, 132], "warn": [16, 17, 20, 24, 45, 50, 59, 60, 62, 76, 78, 81, 82, 83, 85, 86, 87, 89, 94, 96, 97, 98, 99, 101, 103, 104, 105, 127, 128, 129, 130], "best": [17, 21, 50, 59, 70, 78, 80, 107, 122, 127, 129], "elbo": [], "2604245517164468": [], "nll": [], "001169236510424758": [], "mse": [], "307728190154737e": [], "05": [18, 23, 33, 60, 123], "seaborn": [10, 129, 130], "sn": [10, 129, 130], "matplotlib": [10, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 40, 124, 125, 128, 129], "pyplot": [10, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 40, 124, 125, 128, 129], "plt": [10, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 40, 60, 121, 124, 125, 128, 129, 130], "load": [10, 27, 33, 40, 122, 123, 128], "join": [10, 60], "anoce_result": 10, "rb": [10, 70, 122, 123, 128], "calcul": [10, 17, 19, 33, 40, 63, 66, 73, 76, 78, 81, 82, 83, 86, 87, 89, 103, 105, 108, 109, 110, 116, 122, 123, 127, 129], "calculate_effect": 10, "plot": [10, 11, 13, 14, 40, 124, 125], "covid": [10, 21], "matshow": 10, "cmap": 10, "bwr": 10, "vmin": 10, "vmax": 10, "fig1": 10, "gcf": 10, "colorbar": 10, "df": [10, 11, 13, 14, 21], "datafram": [10, 14, 21, 22, 23, 45, 59, 60, 62, 76, 78, 121, 123, 124, 125, 127, 128, 129, 130], "arrai": [10, 15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 45, 48, 50, 60, 62, 70, 76, 94, 97, 98, 99, 101, 103, 104, 105, 106, 109, 110, 115, 116, 121, 122, 123, 124, 125, 127, 128, 129, 130, 131], "read_csv": [10, 15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 33, 40, 70, 76, 78, 121, 122, 123, 124, 125, 127, 128, 129], "csv": [10, 15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 33, 40, 70, 121, 122, 123, 124, 125, 127, 129], "column": [10, 14, 15, 16, 17, 18, 20, 21, 22, 24, 26, 27, 28, 29, 33, 40, 45, 60, 62, 94, 96, 98, 101, 103, 104, 121, 123, 124, 125, 127, 128, 129, 130], "31": [10, 11, 13, 21, 40, 62, 73, 130], "round": [10, 11, 13, 14, 16, 17, 18, 20, 21, 24, 26, 28, 29, 33, 45, 59, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 109, 110, 115, 116, 117, 129], "reshap": [10, 11, 13, 14, 17, 21, 22, 26, 50, 70, 121, 122, 127, 130], "shenzhen": [10, 21], "198": 27, "027": 10, "guangzhou": [10, 21], "099": [], "059": [], "beij": [10, 21], "036": 16, "039": [10, 16, 129], "chengdu": [10, 21], "081": [10, 21, 84], "019": 24, "shanghai": [10, 21], "016": 21, "063": 129, "dongguan": [10, 21], "066": [], "023": [10, 129], "suzhou": [10, 21], "064": [], "xian": [10, 21], "051": [], "042": 10, "hangzhou": [10, 21], "097": 10, "083": 21, "zhengzhou": [10, 21], "069": [], "062": [21, 129], "chongq": [10, 21], "021": 10, "changsha": [10, 21], "073": [], "034": 10, "nanj": [10, 21], "094": [], "044": [], "13": [10, 11, 13, 14, 18, 21, 23, 27, 33, 62, 108, 123, 124, 127, 129], "kunm": [10, 21], "006": [10, 62], "040": 129, "14": [10, 11, 13, 14, 18, 21, 23, 27, 50, 62, 76, 121, 124, 129], "tianjin": [10, 21], "075": [], "049": [], "hefei": [10, 21], "020": [10, 24], "007": [], "046": 10, "wenzhou": [10, 21], "302": [70, 122], "030": 24, "18": [10, 21, 40, 60, 62, 76, 80, 88, 108, 121, 128, 129], "nanchang": [10, 21], "050": [], "004": [62, 129], "zhoukou": [10, 21], "008": [10, 129], "013": [], "fuyang": [10, 21], "21": [10, 18, 21, 23, 33, 45, 59, 60, 62, 96, 125], "shangqiu": [10, 21], "yueyang": [10, 21], "002": [10, 21, 103], "012": [], "23": [10, 21, 23, 33, 45, 59, 62, 123], "zhumadian": [10, 21], "024": [10, 24], "24": [10, 21, 33, 59, 62, 125, 128], "changd": [10, 21], "001": [10, 21, 129], "25": [10, 11, 13, 14, 17, 18, 21, 23, 27, 33, 59, 60, 62, 78, 81, 82, 87, 124, 125, 128, 129, 130], "nanyang": [10, 21], "029": [10, 24, 129], "26": [10, 21, 48, 62], "022": [], "27": [10, 21, 62], "xinyang": [10, 21], "031": 24, "28": [10, 21, 33, 60, 62, 99, 121, 128], "anq": [10, 21], "009": 10, "29": [10, 21, 45, 60, 62, 76], "jiujiang": [10, 21], "017": [21, 24], "mt_data": 10, "zero": [10, 11, 13, 14, 15, 21, 22, 26, 27, 45, 50, 60, 63, 70, 73, 76, 81, 87, 94, 96, 97, 98, 99, 101, 106, 109, 110, 115, 116, 122, 128, 129, 130], "fig": [10, 131], "figur": [10, 17, 33, 40, 130, 131], "figsiz": [10, 40], "ax": [10, 130], "add_subplot": 10, "cax": 10, "shrink": 10, "horizont": 10, "cities_nam": 10, "set_xtick": 10, "arang": [10, 20, 76], "len": [10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 24, 26, 28, 29, 33, 40, 45, 48, 50, 59, 60, 70, 76, 78, 80, 84, 88, 89, 107, 108, 121, 122, 123, 124, 125, 127, 128, 129, 130], "set_ytick": 10, "set_xticklabel": 10, "rotat": 10, "90": [10, 45, 60, 62, 76, 122], "set_yticklabel": 10, "linear": [10, 12, 19, 24, 25, 48, 80, 81, 82, 90, 91, 92, 94, 98, 101, 102, 103, 104, 105, 108, 110, 123, 127], "addit": [10, 12, 14, 22, 63, 64, 68, 69, 73, 74, 75, 89, 129], "graphic": [10, 12], "uniqu": [11, 13, 14, 50, 66, 67, 74, 75, 118, 121, 125, 128], "invari": [11, 13, 14, 131], "trasform": [11, 13, 14], "disadvantag": [11, 13, 14, 81, 82, 83, 85, 86, 87, 89, 94, 96, 97, 98, 99, 101, 103, 104, 105], "knowledg": [11, 50, 80, 81, 85, 88, 89, 110, 115], "realiz": [11, 13, 14, 68, 85, 129], "underli": [11, 13, 14, 17, 19, 74, 75, 90, 119], "lsem": [11, 14, 124, 125], "g_j": [11, 13], "differenti": [11, 13], "argument": [10, 11, 13, 64, 128], "corollari": [11, 13], "threshold": 11, "synthetic_dataset": [11, 13, 14], "1234": [11, 13, 14], "300": [11, 13, 14, 18, 20, 50, 70, 84, 122], "ground_truth_g": [11, 13, 14], "simulate_random_dag": [11, 13, 14], "graph_typ": [11, 13, 14], "erdo": [11, 13, 14], "renyi": [11, 13, 14], "w_rang": [11, 13, 14], "c": [11, 13, 14, 15, 17, 18, 23, 45, 48, 50, 53, 59, 60, 69, 70, 73, 76, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 94, 95, 96, 97, 98, 99, 101, 103, 104, 105, 106, 107, 108, 109, 110, 116, 117, 121, 122, 124, 128, 129, 130], "ones": [11, 13, 14, 15, 21, 22, 26, 45, 48, 60, 62, 70, 76, 85, 89, 94, 96, 97, 98, 99, 101, 103, 104, 105, 115, 122, 127, 129, 130], "simulate_lsem": [11, 13, 14], "plot_net": [11, 13, 14, 124, 125], "nx": [11, 13, 14, 124, 125], "to_numpy_arrai": [11, 13, 14], "labels_nam": [11, 13, 14, 124, 125], "rang": [11, 13, 14, 21, 45, 50, 62, 70, 76, 100, 122, 127, 128, 129, 130, 131], "modulenotfounderror": [11, 13, 14, 18, 25, 50], "ipykernel_69022": [], "2370726509": [], "pip": [11, 14, 18, 23, 60, 132], "instal": [11, 14, 18, 23, 60, 132], "igraph": 11, "factor_analyz": 11, "directlingam": 11, "fit": [11, 15, 17, 18, 20, 21, 22, 23, 25, 26, 28, 29, 32, 40, 45, 59, 60, 62, 76, 78, 123, 124, 125, 127, 130], "adjacency_matrix_": 11, "ica_r": 11, "ab": [11, 13, 14, 45, 130], "fdr": [11, 13, 14], "tpr": [11, 13, 14], "shd": [11, 13, 14], "count_accuraci": [11, 13, 14], "digraph": [11, 13, 14, 124, 125], "statsmodel": [11, 18, 23, 45, 59, 76, 78], "tsa": 11, "tsa_model": 11, "futurewarn": [11, 128], "int64index": 11, "deprec": [11, 127], "futur": [11, 32, 74, 75], "index": [11, 14, 17, 18, 21, 23, 24, 40, 50, 59, 68, 78, 88, 95, 121, 123, 124, 125, 127, 128, 130, 132], "dtype": [11, 21, 24, 45, 59, 62, 78, 94, 97, 98, 99, 101, 103, 104, 121, 123, 124, 125, 127, 128, 130], "instead": [11, 16, 17, 18, 20, 22, 23, 24, 26, 28, 29, 32, 59, 63, 68, 73, 76, 78, 80, 87, 96, 101, 103, 118, 121, 124, 132], "to_datetim": 11, "datetimeindex": 11, "float64index": 11, "67": [11, 13, 14, 62, 70, 79, 102, 105, 106, 108, 122, 127], "prune": [11, 13, 14], "metric": [11, 13, 14, 48], "fals": [11, 13, 14, 18, 21, 23, 45, 59, 70, 81, 82, 87, 89, 103, 104, 105, 106, 109, 121, 122, 123, 124, 127, 128, 129, 130], "ham": [11, 13, 14], "distanc": [11, 13, 14], "smallest": [11, 13, 14, 22, 50], "revers": [10, 11, 13, 14, 45, 76, 124, 125], "account": [11, 13, 14, 21, 70, 78, 85, 87, 95, 96, 100, 101, 102, 103, 122, 131], "neg": [11, 13, 14, 21, 45, 48, 59, 70, 76, 78, 122, 124, 125, 127], "better": [11, 13, 14, 17, 18, 22, 23, 28, 29, 45, 59, 61, 63, 76, 78, 83, 86, 123, 124, 125, 127], "00": [11, 13, 14, 18, 23, 33, 45, 59, 60, 62, 76, 123, 127, 130], "50": [11, 13, 14, 21, 27, 33, 50, 62, 70, 122, 127, 128, 129], "62": [10, 11, 13, 14, 27, 62, 76, 127], "daggnn": [11, 13, 14], "equal": [11, 13, 14, 50, 63, 64, 68, 73, 74, 95, 98, 99, 101, 102], "varianc": [11, 13, 14, 22, 23, 25, 50, 63, 64, 68, 69, 73, 81, 85, 110, 115, 118], "biometrika": [11, 13, 14, 15, 16, 19, 20, 24, 25], "101": [10, 11, 13, 14, 21, 45, 60, 76], "219": [11, 13, 14, 70, 122], "228": [11, 13, 14], "mooij": [11, 13, 14], "janz": [11, 13, 14], "sch\u00f6lkopf": [11, 13, 14], "cma": 12, "dissect": 12, "transmit": 12, "comprehens": [12, 27, 124, 125, 126], "cate": [12, 19], "moder": 13, "sem": 13, "good": [13, 22, 66, 67, 75, 85, 108, 118, 131], "analysis": 13, "contrain": 13, "ipykernel_69035": [], "notears_linear": [13, 124, 125], "lambda1": [13, 124, 125], "loss_typ": [13, 124, 125], "l2": [13, 124, 125], "notears_r": 13, "author": [14, 17], "nois": [14, 87, 98, 99, 131], "normal": [10, 14, 17, 62, 63, 68, 69, 70, 73, 87, 91, 99, 100], "sparsiti": [14, 48, 80], "teat": 14, "ipykernel_69043": [], "pydot": 14, "git": [14, 132], "pycaus": 14, "start_vm": 14, "tetrad": 14, "tetradrunn": 14, "new_df": 14, "map": [14, 66, 67, 75, 79, 90, 91, 92, 118, 131, 132], "02": [14, 45, 59, 62, 76, 123, 127, 129, 130], "format": [14, 76, 129], "algoid": 14, "testid": 14, "gettetradgraph": 14, "getnod": 14, "dot_str": 14, "tetradgraphtodot": 14, "graph_from_dot_data": 14, "node_a": 14, "fill": 14, "fillcolor": 14, "red": 14, "add_nod": 14, "nx_pydot": 14, "from_pydot": 14, "pc_re": 14, "trial": [15, 32, 33, 79, 108], "ve": [15, 19, 131], "preliminari": [15, 38], "notat": [15, 33, 75, 94, 96, 97, 98, 99, 101, 103, 104, 105, 106, 132], "rl": [15, 64, 74, 75, 118, 119, 131], "main": [15, 20, 24, 25, 40, 118, 131, 132], "mathbb": [15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 32, 33, 38, 45, 48, 50, 60, 63, 64, 66, 67, 68, 73, 74, 75, 76, 90, 91, 92, 118, 131], "common": [15, 19, 22, 26, 98, 100, 128, 131], "causal": [15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 28, 32, 33, 36, 37, 38, 40, 70, 118, 119, 122, 123, 127, 132], "consist": [15, 16, 17, 19, 20, 21, 22, 24, 25, 26, 27, 32, 48, 60, 63, 66, 68, 69, 70, 73, 74, 75, 91, 100, 107, 117, 124, 125, 126, 129], "These": [15, 19, 22, 63, 64, 73, 75], "nuc": [15, 21, 22, 26, 32], "remark": [15, 83, 87, 89, 109], "commonli": [15, 19, 21, 66, 67, 68, 69, 73, 74, 80, 81, 90, 91, 92, 110], "impos": [15, 66, 75], "automat": [15, 68, 73, 75, 89], "behavior": [15, 22, 23, 25, 60, 65, 68, 74, 75, 91, 95, 102, 117], "strictli": [15, 68, 73], "re": [15, 88], "shown": [15, 17, 33, 85, 87, 95, 108, 110, 115], "below": [15, 16, 17, 21, 22, 24, 25, 26, 28, 70, 76, 78, 80, 84, 88, 108, 119, 122, 123, 124, 125, 127, 129, 131], "_s": 15, "_x": 15, "e_": [15, 95, 96], "rh": [15, 118], "rid": 15, "pure": [15, 118], "categori": [15, 63, 66, 73, 108, 131], "IS": [15, 21, 63, 68, 73], "dr": [15, 19, 20, 21, 50, 63, 68, 73], "widehat": [15, 16, 17, 21, 25, 50, 63, 64, 66, 67, 69, 73, 90, 91, 92, 118], "learner": [15, 17, 18, 19, 21, 23, 27, 45, 48, 59, 60, 62, 76, 78, 106, 109, 110, 115, 116, 122, 123, 124, 125, 127, 129, 130, 131], "elabor": [15, 32], "sklearn": [15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 40, 48, 70, 124, 125, 127, 129], "ensembl": [15, 16, 17, 18, 20, 21, 24, 26, 28, 29, 124, 125], "gradientboostingregressor": [15, 16, 17, 18, 20, 21, 24, 26, 28, 29], "linear_model": [15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 40, 59, 78, 124, 125, 129], "linearregress": [15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 124, 125, 129], "chdir": [15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 33, 40, 60, 63, 64, 66, 67, 68, 69, 71, 73, 109, 110, 115, 116, 130], "cdm": [15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 33, 40, 60], "movielens_cel": [15, 16, 17, 18, 20, 24, 26, 27, 28, 29], "pop": [15, 16, 17, 18, 20, 24, 26, 28, 29], "user_id": [17, 18, 27, 128, 129], "movie_id": [17, 18, 27, 128, 129], "ag": [16, 17, 18, 20, 21, 24, 27, 63, 64, 66, 67, 68, 69, 71, 73, 80, 88, 108, 109, 110, 115, 116, 128, 129, 130], "comedi": [16, 17, 18, 20, 24, 27, 28, 29, 80, 83, 84, 86, 87, 88, 107, 108, 128, 129, 130], "drama": [15, 16, 17, 18, 20, 24, 26, 27, 28, 29, 80, 84, 88, 89, 107, 108, 128, 129, 130], "thriller": [16, 17, 18, 20, 24, 27, 28, 29, 80, 81, 82, 83, 84, 85, 87, 88, 89, 107, 108, 128, 129, 130], "sci": [15, 16, 17, 18, 20, 24, 26, 27, 28, 29, 80, 82, 84, 85, 88, 108, 128, 129], "fi": [15, 16, 17, 18, 20, 24, 26, 27, 28, 29, 80, 82, 84, 85, 88, 108, 128, 129], "gender_m": [16, 17, 18, 20, 24, 27, 128, 129], "occupation_academ": [16, 17, 18, 20, 24, 27, 128, 129], "educ": [16, 17, 18, 20, 21, 24, 27, 80, 88, 108, 128, 129, 130], "occupation_colleg": [16, 17, 18, 20, 24, 27, 128, 129], "grad": [16, 17, 18, 20, 24, 27, 80, 81, 82, 87, 88, 108, 128, 129], "occupation_execut": [16, 17, 18, 20, 24, 27, 128, 129], "manageri": [16, 17, 18, 20, 24, 27, 80, 88, 108, 128, 129], "occupation_oth": [16, 17, 18, 20, 24, 27, 129], "occupation_technician": [16, 17, 18, 20, 24, 27, 128, 129], "engin": [10, 16, 17, 18, 20, 24, 27, 80, 88, 108, 128, 129], "48": [17, 18, 21, 27, 62, 80, 124, 125, 126, 129], "1193": [17, 18, 27, 128], "919": [17, 18, 27], "527": [17, 18, 27], "1721": [17, 18, 27], "150": [17, 18, 27, 62], "65637": [17, 18], "5878": [17, 18, 27, 129], "3300": [17, 18, 27], "65638": [17, 18], "1391": [17, 18, 27], "65639": [17, 18], "185": [17, 18, 27], "65640": [17, 18], "2232": [17, 18, 27], "65641": [17, 18], "426": [17, 18, 27, 129], "65642": [17, 18, 27], "userinfo_index": [15, 16, 17, 18, 21, 24, 26, 27, 28, 29, 124, 125, 129], "sanda": [15, 17, 18, 21, 22, 26, 27, 28, 29], "iloc": [15, 17, 18, 20, 21, 22, 23, 26, 27, 28, 29, 40, 50, 70, 121, 122, 123, 124, 125, 127, 128, 129, 130], "s_learner": [15, 21, 22, 26], "max_depth": [15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 70, 122, 124, 125, 127, 129], "sanda_all1": [15, 21, 26], "copi": [15, 21, 26, 60, 70, 121, 122, 124, 125, 127, 128, 129, 130], "sanda_all0": [15, 21, 26], "ate_dm": [15, 21], "sum": [15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 33, 60, 62, 64, 86, 107, 108, 116, 124, 125, 128, 129], "inclin": [15, 26, 28, 29, 124, 125], "higher": [15, 19, 26, 28, 29, 40, 64, 80, 84, 88, 108, 124, 125, 129], "fiction": [15, 26, 28, 29], "145": [15, 124, 125, 127], "invers": [15, 21, 60, 68, 73], "aipw": [15, 60], "proce": [15, 75], "bigg": [15, 17, 21, 40], "flip": 15, "role": [15, 90, 91, 92], "a_ir_i": 15, "logisticregress": [15, 16, 18, 20, 21, 22, 23, 24, 25, 29, 124, 125], "ps_model": [15, 16, 21, 24, 25], "pi_": [15, 21, 78, 118], "predict_proba": [15, 21, 22, 29, 124, 125], "ate_i": [15, 21], "7765291578583513": [], "watch": [15, 26, 27, 60, 83], "356": 15, "third": [15, 63, 73, 94, 96, 97], "misspecif": [15, 45, 64, 76, 81, 94, 98, 104], "term": [15, 20, 25, 63, 64, 68, 70, 73, 78, 80, 87, 91, 92], "correct": [15, 32], "correctli": [15, 64, 91], "prove": [15, 16, 20, 21, 25, 48, 63, 64, 69], "mild": [15, 16, 19, 25, 63], "semi": [15, 98, 99, 101, 106, 107, 117], "parametr": [15, 17, 73], "converg": [15, 17, 19, 20, 25, 50, 63, 64, 66, 67, 73, 131], "found": [15, 45, 61, 76, 94, 96, 97, 98, 99, 101, 103, 104, 105, 106, 129, 131, 132], "3021046776851372e": [], "ate_dr": [15, 21], "slightli": [15, 22, 32, 73, 75, 119, 129], "sequenti": [15, 32, 45, 60, 70, 75, 76, 79, 84, 87, 89, 90, 91, 92, 100, 108], "681": 15, "694": 15, "v": [15, 16, 17, 18, 19, 20, 23, 24, 25, 32, 48, 50, 59, 63, 69, 73, 74, 75, 82, 90, 91, 92, 95, 96, 97, 99, 102, 103, 104, 105, 106, 107, 118], "chetverikov": [15, 17], "demir": [15, 17], "duflo": [15, 17], "hansen": [15, 17], "w": [15, 17, 22, 37, 38, 45, 50, 59, 75, 76, 77, 78, 79, 80, 82, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 108, 117, 118, 123], "newei": [15, 17], "kennedi": [16, 19, 20, 25], "extend": [10, 16, 25, 48, 68, 73], "oracl": [16, 19, 20, 24, 25], "theorem": [16, 17, 25, 73, 101, 118], "nuisanc": [16, 18, 20, 23, 25, 60, 63, 64, 68, 73], "i_": [16, 20, 25, 64], "mu_a": [16, 25], "phi": [16, 25, 45, 76, 81, 85, 87, 89, 94, 96, 98, 101, 103, 104, 110, 122, 128, 130], "_a": [16, 20, 25, 82], "_1": [16, 25, 60, 64, 70, 123], "_0": [16, 25, 60], "i_2": [16, 20, 25, 64], "yield": [10, 16, 17, 22, 25, 28, 32, 33, 50, 60, 63, 64, 68, 73], "tau": [16, 18, 19, 20, 22, 23, 24, 25, 26, 28, 29, 33, 38, 60, 64, 118], "_n": [16, 20, 24, 25, 60], "single_stag": [16, 17, 18, 20, 24, 25], "drlearner": [16, 25], "filterwarn": [16, 17, 20, 24], "drop": [16, 17, 20, 24, 27, 28, 29, 60, 78, 121, 128, 129], "n_fold": [16, 20, 24, 25], "y_model": [16, 20, 24, 25], "rlearner_model": [16, 24, 25], "hte_dr_learn": [16, 25], "to_numpi": [16, 17, 22, 23, 24, 25, 26, 129], "fold": [16, 24, 25, 60], "r2": [16, 24, 25], "baselearn": [16, 25], "pslearner": [16, 25], "735": 16, "038": 16, "037": [16, 21], "734": [16, 24], "1000": [16, 17, 20, 22, 24, 26, 28, 29, 48, 60, 62, 96, 103, 104, 106, 107, 129, 130], "5000": [16, 17, 24, 26, 27, 28, 29, 129], "05672212": 16, "73726057": 16, "09360586": 16, "ate_dr_learn": 16, "3541": 16, "conclus": [16, 17, 18, 20, 22, 24, 25, 26, 28, 29, 124, 125, 129], "xinkun": [16, 19, 20, 24, 25], "nie": [16, 19, 20, 24, 25, 123, 127], "stefan": [16, 18, 19, 20, 23, 24, 25, 35, 39, 41, 42, 43], "wager": [16, 18, 19, 20, 23, 24, 25, 35, 39, 41, 42, 43], "quasi": [16, 19, 20, 24, 25, 33], "108": [16, 19, 20, 24, 25, 27, 121], "299": [16, 19, 20, 24, 25, 70, 122], "319": [10, 16, 19, 20, 24, 25], "robinson": [16, 19, 20, 24, 25], "root": [16, 19, 20, 24, 25], "econometrica": [16, 19, 20, 24, 25], "econometr": [16, 19, 20, 24, 25, 33], "societi": [16, 19, 20, 24, 25, 45, 76], "931": [16, 19, 20, 24, 25], "954": [16, 19, 20, 24, 25], "edward": [16, 19, 20, 25], "h": [10, 16, 19, 20, 25, 45, 50, 79, 87, 88, 89, 90, 91, 92, 94, 95, 96, 98, 101, 102, 103, 104, 107, 108, 116, 117], "2004": [16, 19, 20, 25, 45, 76], "14497": [16, 19, 20, 25], "der": [16, 19, 20, 25, 37, 123], "laan": [16, 19, 20, 25, 37, 123], "biostatist": [16, 19, 20, 25, 45, 76], "lee": [16, 19, 20, 25], "okui": [16, 19, 20, 25], "whang": [16, 19, 20, 25], "uniform": [16, 19, 20, 25, 60], "band": [16, 19, 20, 25], "1207": [16, 19, 20, 25], "1225": [16, 19, 20, 25, 128], "foster": [16, 19, 20, 25], "syrgkani": [16, 19, 20, 25], "orthogon": [16, 19, 20, 25, 79, 108], "1901": [16, 19, 20, 25], "09036": [16, 19, 20, 25], "guarante": [17, 19, 33, 75, 131, 132], "asymptot": [17, 48, 60, 63, 64, 73, 91, 118], "dml": [17, 18, 23], "plug": [17, 21, 22, 26, 50, 63, 64, 66, 73], "att": 17, "despit": [17, 50, 124, 125], "versatil": 17, "choic": [10, 17, 21, 53, 70, 79, 95, 96, 102, 108, 117, 122, 127], "ml": 17, "seem": [17, 124, 125], "criteria": [17, 27, 124, 125, 126], "qualiti": [17, 19], "angl": 17, "innov": 17, "discard": 17, "irrelev": 17, "start": [17, 24, 25, 32, 40, 74, 78, 81, 82, 83, 85, 86, 87, 89, 94, 96, 97, 98, 99, 101, 103, 104, 105, 109, 110, 115, 116, 124, 125, 129], "minimum": [17, 33], "tmle": 17, "imporv": 17, "finit": [17, 48, 59, 64, 68, 73, 78, 83, 86, 89, 108, 109, 116, 127], "stabil": [17, 131], "amd": 17, "word": [17, 45, 59, 74, 75, 76, 78, 80, 84, 88, 107, 108, 117, 129], "head": [10, 17, 27, 33, 40, 62, 76, 121, 123, 124, 125, 127, 128], "archetectur": 17, "ipython": [10, 17, 21, 33], "singlestag": 17, "png": [17, 21, 33, 130], "width": 17, "500": [17, 21, 60, 84, 88, 98, 99, 101, 106, 123], "layer": 17, "resourc": [17, 33], "core": [10, 17, 70, 121, 122, 125], "object": [10, 17, 21, 24, 48, 60, 80, 84, 85, 95, 107, 108, 110, 115, 118, 124, 125], "theta": [17, 20, 25, 81, 83, 85, 87, 94, 95, 96, 97, 98, 99, 101, 103, 104, 105, 107, 109, 110, 115, 117, 118, 123], "arg": [10, 17, 20, 24, 25, 40, 45, 48, 59, 60, 63, 66, 67, 74, 75, 76, 78, 81, 82, 85, 86, 94, 96, 97, 98, 99, 101, 102, 103, 104, 105, 116, 118, 122, 128, 129, 130], "min_": [17, 20, 24, 25, 40, 60, 63, 66, 67, 118], "nn": [17, 119], "alpha": [17, 18, 23, 40, 60, 64, 69, 74, 75, 81, 82, 87, 89, 94, 97, 105, 110, 118, 130], "crossentropi": 17, "hyperparamet": 17, "tild": [17, 22, 29, 64, 76, 78, 81, 87, 89, 94, 96, 97, 98, 99, 101, 103, 104, 105, 110, 115], "minim": [10, 17, 19, 63, 64, 73, 74, 75, 79, 84, 96, 101, 103, 108], "extra": [17, 129], "beta": [17, 18, 23, 24, 25, 45, 59, 60, 70, 78, 81, 85, 87, 89, 96, 97, 103, 105, 115, 122, 123, 127, 131], "solut": [17, 18, 23, 48, 50, 66, 67, 74, 118, 132], "claudiashi57": 17, "check": [10, 17, 32, 128], "test_output": 17, "train_output": 17, "train_and_predict_dragon": 17, "targeted_regular": 17, "output_dir": 17, "master": [17, 40], "knob_loss": 17, "dragonnet_loss_binarycross": 17, "ratio": [17, 21, 27, 63, 64, 68, 73, 124, 125, 126, 127], "val_split": 17, "64": [17, 18, 23, 62, 127], "am": 17, "2023": [70, 122], "04": [60, 123], "01": [18, 45, 59, 60, 62, 76, 123, 127, 130], "58": 62, "465481": [], "tensorflow": [], "platform": 60, "cpu_feature_guard": [], "cc": 26, "193": [], "oneapi": [], "librari": [], "onednn": [], "cpu": [], "instruct": [90, 91, 92], "sse4": [], "rebuild": [], "compil": 10, "flag": [], "keyboardinterrupt": [45, 70, 76, 122, 129, 130], "ipykernel_69061": [], "2268767057": [], "y_unscal": [], "324": [21, 79], "325": [], "326": [21, 45, 76], "x_train": 127, "yt_train": [], "callback": [], "adam_callback": [], "327": [], "validation_split": [], "328": [], "kera": [], "traceback_util": [], "error_handl": [], "kwarg": [10, 45, 76, 122, 128, 129, 130], "filtered_tb": [], "none": [10, 18, 21, 23, 27, 40, 45, 62, 70, 76, 83, 87, 95, 109, 115, 121, 122, 125, 127, 128, 129, 130], "63": [10, 18, 60, 62, 127], "fn": 10, "65": [27, 45, 50, 60, 62, 76, 130], "pylint": [], "disabl": [], "66": [60, 62, 122, 124, 127], "_process_traceback_fram": [], "__traceback__": [], "self": [10, 45, 63, 68, 70, 73, 76, 121, 122, 125, 127, 128, 129, 130], "verbos": [10, 18, 23, 128], "validation_data": [], "shuffl": [], "class_weight": [], "sample_weight": 127, "initial_epoch": [], "steps_per_epoch": [], "validation_step": [], "validation_batch_s": [], "validation_freq": [], "max_queue_s": [], "worker": [], "use_multiprocess": [], "1407": [], "_r": [20, 25], "1408": [], "on_train_batch_begin": [], "1409": [], "tmp_log": [], "train_funct": [], "iter": [10, 60, 64, 66, 76, 78, 87, 96, 101, 103, 118, 128], "1410": [], "data_handl": [], "should_sync": [], "1411": [], "async_wait": [], "python": [18, 23, 33, 96, 103, 128, 132], "148": [21, 124], "149": [21, 60, 129], "151": [99, 100, 107, 117, 129], "152": [124, 125, 127], "eager": [], "def_funct": [], "__call__": [], "kwd": 128, "913": [], "914": [], "optionalxlacontext": [], "_jit_compil": [], "915": [], "_call": [], "916": [], "917": [], "new_tracing_count": [], "experimental_get_tracing_count": [], "945": [], "creat": [27, 128], "946": 25, "defun": [], "never": 33, "947": 25, "_stateless_fn": [], "callabl": [], "948": 25, "elif": [10, 70, 122, 128], "_stateful_fn": [], "949": [], "releas": [], "earli": [59, 78, 90, 91, 92, 129], "thread": 129, "2451": [], "graph_funct": [], "2452": 10, "filtered_flat_arg": [], "_maybe_define_funct": [], "2453": [], "_call_flat": [], "2454": [], "captured_input": [], "protect": [64, 91], "access": [27, 124, 125, 126, 132], "2455": [], "cancellation_manag": [], "1858": 10, "executing_eagerli": [], "1859": 10, "tape": [], "1860": 10, "_build_call_output": [], "_inference_funct": [], "ctx": [], "1862": [], "forward_backward": [], "_select_forward_and_backward_funct": [], "495": [], "_interpolatefunctionerror": [], "496": 21, "497": [], "execut": [10, 19, 32, 33, 40, 80, 88, 108, 128, 129, 130], "498": [], "str": [10, 40, 121, 128], "signatur": [129, 130], "499": [48, 80], "num_output": [], "_num_output": [], "quick_execut": [], "op_nam": [], "attr": [], "52": [62, 124], "53": [59, 60, 62, 129], "ensure_initi": [], "54": [10, 60, 62], "tensor": [81, 82, 83, 85, 86, 87, 89, 94, 96, 97, 98, 99, 101, 103, 104, 105, 129, 130], "pywrap_tf": [], "tfe_py_execut": [], "_handl": [], "device_nam": [], "55": [10, 18, 62, 96, 103, 124], "56": [23, 50, 62, 80, 88, 108, 128, 129], "_notokstatusexcept": [], "dict_kei": [17, 27, 129], "q_t0": 17, "q_t1": 17, "ep": 17, "hte_dragonnet": 17, "34005857": 17, "33967185": 17, "46262145": 17, "aaverag": 17, "ate_dragonnet": 17, "3526": 17, "claudia": [17, 19], "blei": [17, 19], "veitch": [17, 19], "33rd": 17, "neurip": 17, "susan": [18, 19, 23, 35, 36, 39, 41, 42, 43], "athei": [18, 19, 23, 35, 36, 39, 41, 42, 43], "juli": [18, 19, 23, 35, 39, 41, 42, 43, 88, 89, 100], "tibshirani": [18, 19, 23, 35, 39, 41, 42, 43], "moment": [18, 23], "psi_": [18, 23, 45, 63, 64, 69, 73, 76], "nu": [18, 23], "o_i": [18, 23, 50], "care": [18, 23, 27, 124, 125, 126, 128], "xi": [18, 23, 63, 73], "induc": [18, 23], "solv": [18, 23, 24, 25, 45, 48, 50, 59, 63, 64, 66, 67, 68, 73, 74, 75, 76, 85, 99, 102, 107, 108, 110, 115, 117, 118], "alpha_i": [18, 23], "otim": [18, 23], "vv": [18, 23], "notic": [18, 23, 81, 97, 98, 105, 110], "formula": [18, 23, 59, 132], "ordinari": [18, 23], "prone": [18, 23], "grf": [18, 19, 23], "quantiti": [18, 23, 38], "grow": [18, 23, 70, 73, 119], "dot": [18, 23, 40, 45, 60, 63, 68, 73, 76, 80, 84, 88, 95, 102, 107, 108, 117, 128, 129, 130, 131], "l_b": [18, 23], "fall": [18, 23, 32, 128], "leaf": [18, 23], "frequenc": [18, 23, 81, 82, 94, 96, 101, 103, 104], "alpha_": [18, 23, 89], "bi": [18, 23], "boldsymbol": [18, 23, 45, 59, 61, 76, 77, 78, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 101, 102, 103, 104, 105, 107, 109, 110, 116, 117, 123, 127], "x_0": [18, 23], "flexibl": [18, 23, 50, 60, 64, 90, 91, 92, 131], "causal_effect_learn": [18, 21, 25], "lprlearner": [18, 20, 25], "ipykernel_69076": [], "1061371864": [], "_util_causaldm": [18, 22, 23, 25, 45, 59, 60, 61, 130], "econml": [18, 23], "cp39": 18, "macosx_10_9_x86_64": 18, "whl": [18, 23], "mb": [18, 23], "2k": [18, 23], "90m": [18, 23], "0m": [18, 23], "32m1": 18, "31m2": 18, "eta": [18, 20, 21, 23, 24, 25, 60, 63, 64, 66, 68, 69, 73, 74, 75, 96, 101, 102, 103, 107, 117], "36m0": [18, 23], "0m00": 18, "25hcollect": 18, "shap": [18, 23], "41": [18, 23, 59, 62, 129], "40": [18, 21, 23, 33, 40, 60, 62, 76, 121, 124, 127, 129, 130], "433": 18, "kb": [18, 23], "32m433": 18, "31m3": 18, "25hrequir": [18, 23], "scikit": [18, 23, 60, 61], "scipi": [18, 23, 128, 130], "lightgbm": [18, 23, 25, 124, 125, 129], "spars": [18, 23], "py2": [18, 23], "py3": [18, 23], "32m81": 18, "81": [18, 62], "joblib": [18, 23], "threadpoolctl": [18, 23], "numba": [18, 23], "slicer": [18, 23], "tqdm": [18, 23, 124, 125], "cloudpickl": [18, 23], "patsi": [18, 23], "dateutil": [18, 23], "pytz": [18, 23], "wheel": [18, 23], "35": [18, 21, 33, 60, 62, 128, 130], "llvmlite": [18, 23], "39": [18, 23, 40, 45, 60, 62, 125, 128, 129, 130], "0rc1": 18, "setuptool": [18, 23], "pypars": 18, "six": [18, 23, 131], "successfulli": [18, 23, 60], "demo": [18, 23, 62, 132], "causalforest": [18, 23], "causalivforest": [18, 23], "regressionforest": [18, 23], "causalforestdml": [18, 23], "est": [18, 23], "criterion": [18, 23], "het": [18, 23], "n_estim": [18, 23], "400": [18, 21, 23, 62], "min_samples_leaf": [18, 23], "min_var_fraction_leaf": [18, 23], "min_var_leaf_on_v": [18, 23], "min_impurity_decreas": [18, 23], "max_sampl": [18, 23], "45": [18, 23, 60, 62, 129, 130], "min_balancedness_tol": [18, 23], "warm_start": [18, 23], "fit_intercept": [18, 23, 48], "subforest_s": [18, 23], "honest": [18, 23], "n_job": [18, 23, 48, 127], "random_st": [18, 23, 127], "1235": [18, 23], "hte_grf": [18, 23], "flatten": [18, 21, 23, 70, 122, 127], "900": [18, 20, 127], "3605": 18, "3783": 18, "3646": 18, "ate_grf": 18, "358": 18, "47": [18, 19, 23, 27, 33, 35, 39, 41, 42, 43, 62, 83, 86, 108, 109, 116, 124, 125, 126], "1148": [18, 19, 23, 35, 39, 41, 42, 43], "1178": [18, 19, 23, 35, 39, 41, 42, 43], "setup": [19, 24, 25, 48, 62, 63, 64, 102, 118, 119, 131], "triplet": [19, 74, 75, 131], "trajectori": [19, 40, 68, 73, 74, 75, 118, 131], "imagin": 19, "terminolog": 19, "lot": [10, 19, 60, 74], "recommend": [19, 27, 45, 48, 50, 59, 62, 76, 78, 79, 80, 84, 88, 95, 100, 102, 123, 127, 129, 130], "adversit": 19, "impact": [19, 33, 70, 124, 125, 127], "annual": [19, 38, 40], "incom": [19, 102, 103, 104, 105, 129], "expos": [19, 26, 33, 40], "statu": [10, 19, 21, 27, 32, 60, 91, 92, 124, 125, 126], "pictur": [19, 60], "dress": 19, "femal": [19, 21, 80, 129], "male": [19, 80, 81, 82, 87, 88, 108, 129], "clearli": [19, 131], "granular": 19, "averg": 19, "characsterist": 19, "subsect": [19, 27, 38, 73], "briefli": [19, 38, 79, 108], "lp": 19, "forest": [19, 35, 39, 41, 42, 43], "dragonnet": 19, "paper": [19, 20, 25, 118], "pleas": [19, 20, 22, 25, 29], "easiest": [19, 22, 24, 25, 60], "apporach": 19, "enough": [19, 64, 129, 132], "complic": [19, 22, 28, 64], "worth": [19, 32, 40, 101], "sensibl": 19, "trend": [19, 22, 33, 40, 80, 115, 116, 131], "cancel": 19, "tend": [19, 22, 40], "particularli": [19, 45, 59, 76, 78], "larger": [19, 28, 40, 45, 59, 61, 64, 73, 76, 78], "part": [19, 33, 40, 60, 64, 70, 118, 122, 131, 132], "boost": [19, 60], "acheiv": 19, "alwai": [19, 45, 59, 64, 80, 84, 85, 88, 97, 99, 105, 108, 110, 115, 127], "faster": [19, 50, 64, 73], "might": [19, 62, 63, 124, 125], "computation": [19, 69, 96, 101, 103, 105, 119], "polynomi": [19, 20, 25], "tradeoff": [19, 64], "inherit": 19, "dragon": 19, "net": 19, "outperform": [19, 81, 94, 97, 98, 99, 104, 105, 129], "kunzel": [19, 22, 26, 28, 29], "sekhon": [19, 22, 26, 28, 29], "bickel": [19, 22, 26, 28, 29], "metalearn": [19, 22, 26, 28, 29], "nation": [19, 22, 26, 28, 29], "academi": [19, 22, 26, 28, 29], "116": [19, 22, 26, 28, 29, 36, 45, 59, 90, 91, 92, 121, 123], "4156": [19, 22, 26, 28, 29], "4165": [19, 22, 26, 28, 29], "alicia": 19, "curth": 19, "mihaela": 19, "schaar": 19, "1810": 19, "1818": 19, "residu": [20, 24, 25], "cross": [20, 25, 60], "relax": [20, 25, 32, 64, 131], "breviti": [20, 25], "1b": [20, 25], "basi": [20, 25, 63, 70, 73, 87, 122], "k_": [20, 25], "hs": [20, 25], "bandwidth": [20, 25, 50], "mu_1": [20, 22, 25, 28, 29], "mu_0": [20, 22, 25, 28, 29], "estimt": [20, 25], "_b": [20, 25], "tb": [10, 20, 25], "s_0": [20, 25, 32, 64, 74, 75, 118], "repeat": [20, 25, 78, 108, 118], "twice": [20, 25], "n_": [20, 25, 40], "samplem": [20, 25], "tradit": [20, 25, 33, 68], "milder": [20, 25, 64], "ps_model_a": [20, 25], "ps_model_b": [20, 25], "lprlearner_model": [20, 25], "sample_index": 20, "tolist": [20, 121, 124, 125, 128, 129, 130], "hte_lp_r_learn": [20, 25], "ipykernel_69094": [], "3012518900": [], "91": [10, 60, 62, 70, 121, 122, 123, 124], "92": [10, 62, 70, 122], "ps_learner_a": [], "fold1a": [], "93": [62, 70, 122], "94": [59, 60, 62, 70, 121, 123], "y_learner": [24, 25], "fold1b": [], "_logist": [], "1506": [], "_dtype": [], "float64": [59, 78, 123, 130], "float32": [], "1507": [], "1508": [], "_validate_data": [], "1509": [], "1510": [], "reset": 78, "validate_separ": [], "check_param": [], "579": 10, "check_arrai": [], "check_y_param": [], "580": 10, "els": [10, 21, 45, 59, 70, 76, 121, 122, 123, 125, 127, 128, 129, 130], "581": [], "check_x_i": [], "582": [], "583": [10, 21], "accept_spars": [], "accept_large_spars": [], "force_all_finit": [], "ensure_2d": [], "allow_nd": [], "multi_output": [], "ensure_min_sampl": [], "ensure_min_featur": [], "y_numer": [], "962": [], "valueerror": [21, 70, 122, 127], "963": [], "964": [], "965": [], "966": 25, "627": [], "628": [], "629": 21, "dtypes_orig": [], "630": 121, "boolean": [121, 125], "__array__": [], "interfac": [], "coerc": [], "bool": [10, 121, 125, 128], "631": 121, "dtype_it": [], "enumer": [], "5745": [], "5746": 27, "_mgr": [], "get_dtyp": [], "5747": [], "_constructor_sl": [], "_info_axi": [], "object_": [], "5748": [], "5749": [], "def": [10, 21, 50, 62, 70, 122, 127, 128, 130], "astyp": [40, 45, 62, 76, 128, 129, 130], "fastpath": [], "458": [], "459": 60, "ndframe": [], "460": [], "461": [], "_set_axi": [], "462": [], "42175269": 20, "52461763": 20, "13400663": 20, "ate_lp_r_learn": 20, "2182": 20, "influnc": 21, "treamtent": 21, "borrow": 21, "necess": 21, "birth": 21, "pill": 21, "incid": 21, "thrombosi": 21, "pregnanc": 21, "want": [21, 59, 60, 76, 78, 97, 132], "sens": [21, 63, 64, 73], "marit": 21, "reliabl": [21, 45, 59, 62, 76, 78], "iid": 21, "treament": 21, "a_0": [21, 64, 70, 75, 118], "a_1": [21, 70, 75, 118, 123, 127], "m_a": 21, "r_": [21, 32, 59, 61, 63, 64, 66, 67, 68, 73, 74, 75, 76, 80, 82, 84, 86, 87, 88, 89, 94, 96, 98, 101, 107, 108, 116, 117, 131], "m_": 21, "imai": 21, "m_0": [21, 24, 25, 70], "int": [10, 21, 40, 45, 62, 76, 128, 129], "suffic": 21, "rho": [21, 60, 63, 68, 73], "p_a": 21, "shift": [21, 48, 118, 131], "tchetgen": [21, 127], "shpitser": [21, 127], "aurora_cel": 21, "survey_r": 21, "hispan": 21, "white": 21, "trauma": 21, "health": [21, 32, 70, 124, 125, 128], "mental": 21, "chronic": 21, "percept": 21, "stress": 21, "neurotic": 21, "childhood": 21, "insomnia": 21, "cont": [21, 50], "peritraumat": 21, "distress": 21, "w2": 21, "acut": 21, "disord": 21, "ptsd": 21, "depress": 21, "month": [21, 61], "hist": [21, 60, 121, 124, 125], "bin": [21, 60, 129], "274": [21, 70, 122], "242": 21, "187": [21, 27, 70, 121, 122], "98": [10, 21, 62], "109": [21, 106], "55287818": 21, "75287818": 21, "95287818": 21, "15287818": 21, "64712182": 21, "44712182": 21, "24712182": 21, "04712182": 21, "84712182": 21, "barcontain": [21, 124, 125], "artist": [21, 124, 125, 128], "aurora_cel_md": 21, "ipykernel_69109": [], "2568975421": 21, "settingwithcopywarn": [21, 121, 124], "caveat": [21, 121, 124], "pydata": [21, 121, 124], "user_guid": [21, 121, 124], "mediation_analysi": 21, "me_singl": [21, 127], "604871671": [], "control_polici": [21, 70, 122, 127], "dim_stat": [21, 70, 122, 123, 127], "get_a": [21, 70, 122, 127], "action_valu": [21, 70, 122, 127], "shape": [21, 40, 62, 70, 76, 122, 127, 128], "target_polici": [21, 70, 122, 127], "pa": [21, 33, 70, 122, 127], "prob_arr": [21, 70, 122, 127], "problearner_paramet": [21, 70, 122, 127], "splitter": [21, 70, 122, 127], "direct_est": [21, 127], "r_model": [21, 70, 122, 127], "ol": [21, 59, 70, 122, 127], "truncat": [21, 68, 70, 73, 122, 127], "dim_medi": [21, 70, 122, 123, 127], "expectation_mcmc_it": 21, "nature_decomp": [21, 70, 122, 127], "estimate_de_m": [21, 70, 122, 127], "est_d": [21, 127], "est_m": [21, 127], "est_t": [21, 127], "5699712042262648": 21, "35390067425173": 21, "923871878477995": 21, "ipw_est": [21, 70, 122, 127], "1833766092547435": 21, "0830496488123182": 21, "266426258067062": 21, "robust_est": [21, 70, 122, 127], "082810672178048": 21, "6367679712306544": 21, "7195786434087026": 21, "robust_d": 21, "robust_i": 21, "robust_t": 21, "mediator_1d": 21, "aurora_cel_1d": 21, "mediators_index": 21, "append": [21, 45, 50, 62, 76, 128, 129, 130], "four": [21, 70, 79, 80, 87, 88, 96, 99, 101, 103, 122, 129], "637": 21, "720": [21, 62], "262": 21, "234": 21, "435": [21, 129], "452": 21, "699": 21, "800": [10, 21], "465": 21, "748": [21, 121, 124], "214": [21, 22, 70, 76, 80, 82, 122], "131861": 21, "151941": 21, "741954": 21, "476881": 21, "776439": 21, "879518": 21, "062249": 21, "868139": 21, "848059": 21, "081954": 21, "706881": 21, "223561": 21, "937751": 21, "718046": 21, "393119": 21, "418046": 21, "323119": 21, "241954": 21, "483119": 21, "1489": 21, "641954": 21, "506881": 21, "120482": 21, "1490": 21, "321954": 21, "656881": 21, "1491": 21, "841954": 21, "146881": 21, "1492": [21, 22], "231954": 21, "216881": 21, "1493": 21, "441954": 21, "333119": 21, "1494": 21, "3238214724070896": 21, "583008488326464": 21, "6766993378439592": 21, "0005208102510488": 21, "636768": 21, "719579": 21, "covid19_cel": 21, "292852": 21, "637413": 21, "913318": 21, "513904": 21, "951952": 21, "795226": 21, "010544": 21, "147116": 21, "071851": 21, "266743": 21, "045451": 21, "026626": 21, "794902": 21, "157263": 21, "012273": 21, "940021": 21, "693004": 21, "797915": 21, "500000": [21, 27, 121, 123, 124], "427091": 21, "792291": 21, "098134": 21, "176879": 21, "740606": 21, "069790": 21, "111048": 21, "927152": 21, "917465": 21, "264442": 21, "065442": 21, "042891": 21, "762210": 21, "123276": 21, "971190": 21, "944849": 21, "717563": 21, "782914": 21, "095238": 21, "760591": 21, "172900": 21, "868353": 21, "536234": 21, "939283": 21, "098691": 21, "088660": 21, "262078": 21, "735539": 21, "208682": 21, "955573": 21, "069427": 21, "698803": 21, "084979": 21, "902696": 21, "899230": 21, "633096": 21, "769921": 21, "477273": 21, "454398": 21, "250654": 21, "939562": 21, "149566": 21, "784729": 21, "779052": 21, "719391": 21, "173107": 21, "448533": 21, "226761": 21, "964872": 21, "125997": 21, "729486": 21, "135069": 21, "921326": 21, "925182": 21, "662126": 21, "828047": 21, "400000": [21, 121, 123, 125], "140390": 21, "108600": 21, "047156": 21, "815548": 21, "533363": 21, "173536": 21, "308488": 21, "199351": 21, "838208": 21, "107659": 21, "944363": 21, "028927": 21, "715424": 21, "018883": 21, "925700": 21, "820400": 21, "639058": 21, "878947": 21, "807692": 21, "062158": 21, "586850": 21, "469484": 21, "326334": 21, "479242": 21, "650710": 21, "264352": 21, "682694": 21, "736854": 21, "204114": 21, "037254": 21, "075291": 21, "779771": 21, "060582": 21, "021507": 21, "796522": 21, "680173": 21, "951977": 21, "294326": 21, "530267": 21, "571570": 21, "428835": 21, "473093": 21, "179841": 21, "077723": 21, "149741": 21, "637036": 21, "281233": 21, "046941": 21, "168571": 21, "811361": 21, "052676": 21, "972389": 21, "864756": 21, "701395": 21, "995490": 21, "109589": 21, "897320": 21, "382069": 21, "289806": 21, "041032": 21, "683110": 21, "672166": 21, "529203": 21, "909618": 21, "029841": 21, "250219": 21, "108112": 21, "210270": 21, "863557": 21, "155546": 21, "055981": 21, "000739": 21, "749153": 21, "995393": 21, "192593": 21, "482535": 21, "164017": 21, "656821": 21, "651928": 21, "708246": 21, "588910": 21, "148011": 21, "490420": 21, "440770": 21, "347127": 21, "144951": 21, "270242": 21, "921650": 21, "215292": 21, "102442": 21, "982433": 21, "801220": 21, "037740": 21, "287785": 21, "171677": 21, "030898": 21, "854759": 21, "128409": 21, "576126": 21, "770616": 21, "191284": 21, "435813": 21, "084196": 21, "605906": 21, "307340": 21, "474589": 21, "099494": 21, "373177": 21, "253232": 21, "124960": 21, "867672": 21, "146863": 21, "136656": 21, "894203": 21, "635793": 21, "820545": 21, "845285": 21, "278246": 21, "950636": 21, "930212": 21, "173367": 21, "965229": 21, "370520": 21, "184868": 21, "296518": 21, "052125": 21, "178420": 21, "140642": 21, "001873": 21, "828338": 21, "050149": 21, "080622": 21, "782546": 21, "214282": 21, "914472": 21, "644101": 21, "630285": 21, "992847": 21, "822527": 21, "474421": 21, "188018": 21, "345831": 21, "115597": 21, "228738": 21, "996008": 21, "097064": 21, "981428": 21, "926802": 21, "829375": 21, "990533": 21, "013089": 21, "192243": 21, "280890": 21, "643705": 21, "702932": 21, "017906": 21, "253913": 21, "882940": 21, "059254": 21, "509737": 21, "164002": 21, "993222": 21, "934286": 21, "946955": 21, "993287": 21, "844765": 21, "716947": 21, "736582": 21, "871981": 21, "112732": 21, "649070": 21, "621102": 21, "116686": 21, "858802": 21, "429514": 21, "851297": 21, "776376": 21, "181538": 21, "740580": 21, "935064": 21, "719345": 21, "759164": 21, "641585": 21, "651791": 21, "540918": 21, "933250": 21, "507287": 21, "469476": 21, "082212": 21, "603982": 21, "724633": 21, "303232": 21, "312939": 21, "179535": 21, "980677": 21, "236501": 21, "528457": 21, "656411": 21, "327752": 21, "076134": 21, "299791": 21, "936846": 21, "181952": 21, "839581": 21, "539065": 21, "909695": 21, "693490": 21, "226519": 21, "528723": 21, "417358": 21, "668425": 21, "043352": 21, "848219": 21, "364526": 21, "062001": 21, "410301": 21, "871230": 21, "475528": 21, "144627": 21, "231135": 21, "126969": 21, "357398": 21, "983761": 21, "193422": 21, "097615": 21, "838285": 21, "171171": 21, "876705": 21, "463145": 21, "434180": 21, "511868": 21, "921547": 21, "050862": 21, "366664": 21, "753326": 21, "281971": 21, "309997": 21, "980845": 21, "002650": 21, "022058": 21, "032005": 21, "805918": 21, "060452": 21, "125673": 21, "747338": 21, "035326": 21, "606716": 21, "988680": 21, "813622": 21, "686867": 21, "432760": 21, "928552": 21, "074092": 21, "395144": 21, "947214": 21, "112098": 21, "881150": 21, "896476": 21, "002845": 21, "916207": 21, "701719": 21, "867089": 21, "964613": 21, "667084": 21, "028169": 21, "524647": 21, "808017": 21, "606230": 21, "339734": 21, "215940": 21, "950746": 21, "921715": 21, "220864": 21, "834689": 21, "039230": 21, "792536": 21, "855976": 21, "924145": 21, "838933": 21, "679882": 21, "776855": 21, "864724": 21, "625158": 21, "194203": 21, "376806": 21, "638014": 21, "428127": 21, "903468": 21, "053162": 21, "893333": 21, "826913": 21, "059934": 21, "711601": 21, "905191": 21, "597521": 21, "799891": 21, "754369": 21, "733082": 21, "605912": 21, "650462": 21, "715133": 21, "540011": 21, "086331": 21, "324318": 21, "604902": 21, "240240": 21, "678514": 21, "941771": 21, "853870": 21, "713999": 21, "979322": 21, "616151": 21, "712055": 21, "463547": 21, "557215": 21, "588222": 21, "473332": 21, "490730": 21, "426028": 21, "610805": 21, "424375": 21, "129921": 21, "425470": 21, "787702": 21, "371460": 21, "939302": 21, "995036": 21, "940572": 21, "799697": 21, "127974": 21, "644533": 21, "808024": 21, "487328": 21, "679655": 21, "636077": 21, "505732": 21, "551934": 21, "427194": 21, "720673": 21, "465912": 21, "119910": 21, "512886": 21, "614200": 21, "222873": 21, "902820": 21, "931370": 21, "935323": 21, "742122": 21, "076328": 21, "511175": 21, "659210": 21, "398034": 21, "508583": 21, "481010": 21, "334271": 21, "442130": 21, "314993": 21, "574808": 21, "323708": 21, "012853": 21, "231297": 21, "336565": 21, "064632": 21, "691572": 21, "771898": 21, "755795": 21, "555790": 21, "826524": 21, "377654": 21, "463709": 21, "298825": 21, "384718": 21, "390226": 21, "231304": 21, "293252": 21, "237298": 21, "407236": 21, "208753": 21, "187500": 21, "095703": 21, "326748": 21, "995069": 21, "561226": 21, "689310": 21, "758128": 21, "536836": 21, "751842": 21, "328633": 21, "442843": 21, "317066": 21, "344704": 21, "432572": 21, "222232": 21, "263768": 21, "236682": 21, "413294": 21, "201139": 21, "134615": 21, "112065": 21, "308668": 21, "848588": 21, "496653": 21, "631476": 21, "753268": 21, "488916": 21, "658012": 21, "287518": 21, "452855": 21, "368485": 21, "305532": 21, "549990": 21, "226249": 21, "283597": 21, "255247": 21, "420746": 21, "231887": 21, "174074": 21, "123373": 21, "341781": 21, "936619": 21, "448701": 21, "607144": 21, "780030": 21, "488851": 21, "602057": 21, "247115": 21, "512957": 21, "437562": 21, "307703": 21, "774619": 21, "272419": 21, "290434": 21, "297724": 21, "444755": 21, "256219": 21, "255605": 21, "095412": 21, "440439": 21, "013504": 21, "414357": 21, "610546": 21, "890255": 21, "512341": 21, "571795": 21, "249934": 21, "600437": 21, "716202": 21, "380214": 21, "153991": 21, "348203": 21, "350406": 21, "359122": 21, "605135": 21, "347911": 21, "289157": 21, "086858": 21, "482754": 21, "947506": 21, "316801": 21, "626033": 21, "920290": 21, "583686": 21, "558284": 21, "269568": 21, "595220": 21, "123405": 21, "366314": 21, "195333": 21, "334984": 21, "400108": 21, "395086": 21, "606463": 21, "410411": 21, "271186": 21, "437782": 21, "738454": 21, "033301": 21, "221707": 21, "695304": 21, "084946": 21, "659016": 21, "564570": 21, "292928": 21, "551027": 21, "872629": 21, "374933": 21, "788778": 21, "311137": 21, "351248": 21, "413392": 21, "450814": 21, "372341": 21, "360465": 21, "015837": 21, "396958": 21, "901724": 21, "952949": 21, "620428": 21, "857758": 21, "526792": 21, "436590": 21, "248962": 21, "437627": 21, "522839": 21, "301417": 21, "502103": 21, "274428": 21, "232308": 21, "308740": 21, "295520": 21, "225860": 21, "090909": [21, 124, 125, 127], "995587": 21, "330279": 21, "886270": 21, "834527": 21, "656683": 21, "879530": 21, "525366": 21, "432540": 21, "286967": 21, "518789": 21, "455188": 21, "322412": 21, "449485": 21, "348494": 21, "236520": 21, "295650": 21, "286870": 21, "214488": 21, "873563": 21, "957841": 21, "388632": 21, "875351": 21, "830671": 21, "674438": 21, "940637": 21, "531976": 21, "439182": 21, "316094": 21, "531587": 21, "445144": 21, "340297": 21, "448254": 21, "360742": 21, "249350": 21, "296428": 21, "302875": 21, "213581": 21, "424242": 21, "33": [21, 27, 62, 99, 130], "025266": 21, "409206": 21, "826394": 21, "816610": 21, "645473": 21, "057374": 21, "544352": 21, "409633": 21, "348300": 21, "458590": 21, "384232": 21, "315997": 21, "400205": 21, "328763": 21, "280001": 21, "247244": 21, "280584": 21, "213905": 21, "052632": 21, "34": [21, 33, 50, 60, 62, 87, 88, 89, 130], "847292": 21, "199707": 21, "807311": 21, "791759": 21, "614239": 21, "896800": 21, "520700": 21, "434322": 21, "364986": 21, "516326": 21, "421654": 21, "294775": 21, "432475": 21, "319950": 21, "318913": 21, "210438": 21, "269082": 21, "239209": 21, "000000": [21, 27, 70, 121, 122, 123, 124, 125, 127], "419055": 21, "741241": 21, "908431": 21, "955282": 21, "779803": 21, "225012": 21, "722066": 21, "528898": 21, "528379": 21, "663617": 21, "538099": 21, "322801": 21, "482760": 21, "354683": 21, "398066": 21, "240667": 21, "335632": 21, "288036": 21, "444444": [21, 27], "36": [21, 62, 98, 129, 130], "159110": 21, "644332": 21, "912514": 21, "006085": 21, "814860": 21, "225400": 21, "734929": 21, "505570": 21, "716072": 21, "881734": 21, "582487": 21, "436298": 21, "607565": 21, "509652": 21, "551902": 21, "411350": 21, "418997": 21, "459529": 21, "645161": 21, "37": [21, 45, 48, 60, 62, 124, 129, 130], "304294": 21, "796126": 21, "914522": 21, "095768": 21, "906228": 21, "343434": 21, "856688": 21, "531166": 21, "808380": 21, "997596": 21, "624607": 21, "522742": 21, "600113": 21, "597650": 21, "659275": 21, "439279": 21, "510786": 21, "363636": [21, 124, 125, 127], "movielens_cel_md": 21, "730690894257576": 21, "13369489173373478": 21, "5969960025238406": 21, "143298762540704": 21, "5474864933099358": 21, "595812269230768": 21, "592741884817156": 21, "001726777600432909": 21, "594468662417588": 21, "438": [21, 95, 97], "918": 21, "521": 21, "709": 21, "842": 21, "867": 21, "170": [10, 21, 84, 121, 123], "922": 21, "248": [21, 62], "453": 21, "053": 21, "216": [21, 70, 122], "969": [21, 127], "247": [21, 121], "952": 21, "367": 21, "586": 21, "025": [10, 21], "989": 21, "854": [10, 21], "235": [21, 83, 86, 108, 109, 116, 129], "619": 21, "516": [21, 48], "311": [21, 84, 128], "924": [21, 127], "731": [21, 22, 23, 25], "812": 21, "421": [21, 84, 103, 104], "679": 21, "742": 21, "251": [21, 70], "134": 21, "117": [21, 45, 60, 129], "399": 21, "136": [21, 27, 124], "263": 21, "593": 21, "594": 21, "771": 21, "163": [21, 121, 123], "608": 21, "323": 21, "306": [21, 128], "717": 21, "192": [21, 27, 127], "909": 21, "197": [21, 127], "056": [10, 21], "141": 21, "416": 21, "153": [21, 62, 84, 129], "570": 21, "485": 21, "058": [10, 21], "543": 21, "408": [21, 98], "512": 21, "404": 21, "032": [10, 21], "437": 21, "444": [10, 21], "154": [21, 60, 121, 123], "598": 21, "165": [21, 33], "440": [10, 21], "473": 21, "536": [10, 21, 25, 36, 60], "176": [21, 45, 70, 76, 84, 122], "241": [21, 76], "103": [21, 45, 76, 121, 124], "493": [21, 40], "510": 21, "hick": 21, "raymond": 21, "dustin": 21, "tinglei": 21, "2011": [21, 33, 80, 82, 90, 91, 92, 104], "stata": 21, "605": 21, "hong": [21, 88, 127], "guanglei": 21, "biometr": [21, 48, 127], "alexandria": 21, "va": 21, "usa": 21, "2401": [21, 127], "2415": [21, 127], "kosuk": 21, "luke": 21, "keel": 21, "309": [21, 33, 84, 102, 128], "probabilist": [21, 95, 96, 103], "373": 21, "392": 21, "ilya": 21, "1816": [21, 99, 127], "foundament": [22, 26], "esitm": [22, 26], "supervis": [22, 26, 28, 29], "n0": [22, 23, 25, 60], "mc": [22, 23, 25, 60, 118], "223": [22, 23, 25, 60, 129], "data_behavior": [22, 23, 25], "get_data_simul": [22, 23, 25, 60], "data_target": [22, 23, 25], "hte_tru": [22, 23, 25], "unboundlocalerror": [22, 23], "ipykernel_69115": [], "2180662469": [], "227": [22, 23, 121, 123], "229": [22, 23], "referenc": [22, 23], "s1": [22, 23, 25, 60, 62, 127], "s2": [22, 23, 25, 60, 62, 127], "034775": 22, "453145": 22, "167637": 22, "084880": 22, "234459": 22, "553798": 22, "144626": 22, "040543": 22, "956732": 22, "148426": 22, "021139": 22, "095578": 22, "120852": 22, "377594": 22, "323133": 22, "995": [22, 60], "022440": 22, "887551": 22, "797542": 22, "996": [22, 60], "411179": 22, "655833": 22, "722846": 22, "997": [22, 60], "155706": 22, "992197": 22, "140100": 22, "998": [22, 60], "510241": 22, "828438": 22, "167118": 22, "999": [22, 60, 103, 105], "744187": 22, "857147": 22, "458481": 22, "lgbmregressor": [22, 25, 124, 125, 129], "hstack": [22, 26, 45, 62, 76, 121, 122], "hte_s_learn": [22, 26], "1687": 22, "589": 22, "0319": 22, "8354": 22, "5843": 22, "4577": 22, "0791": [22, 99], "2961": [22, 23, 25], "4475": [22, 23, 25], "2863": [22, 23, 25], "4471": [22, 23, 25], "1839": [22, 23, 25], "3869": [22, 23, 25, 129], "238": [22, 23, 25], "bias_s_learn": 22, "variance_s_learn": 22, "2857192464627009": 22, "079505077680185": 22, "toi": 22, "although": [22, 32, 64, 69, 124, 125], "cover": [22, 32], "mu0": [22, 28, 29, 124, 125], "mu1": [22, 28, 29, 62, 124, 125], "hte_t_learn": [22, 28, 124, 125], "glanc": 22, "869": [10, 22], "8733": 22, "6596": 22, "3087": 22, "2298": 22, "5598": 22, "2745": [10, 22], "8211": 22, "bias_t_learn": 22, "variance_t_learn": 22, "29138198450323705": 22, "810391408711312": 22, "overfit": [22, 28, 70, 122], "provabl": [22, 29, 108], "imput": [22, 29], "delta": [22, 29, 33, 45, 87, 89], "tau_1": [22, 29, 33], "tau_0": [22, 29, 33], "s_t0": [22, 29], "s_t1": [22, 29], "r_t0": [22, 29], "r_t1": [22, 29], "unobserv": [22, 29, 119, 131], "origin": [22, 27, 29, 45, 59, 60, 61, 89, 118, 124, 125, 126], "n_t0": [22, 29], "n_t1": [22, 29], "delta0": [22, 29], "delta1": [22, 29], "tau0": [22, 29], "tau1": [22, 29], "hte_x_learn": [22, 29], "9341": 22, "9235": 22, "2944": 22, "4147": 22, "5443": 22, "roughli": [22, 63, 64, 131], "catch": 22, "synthet": [22, 38, 131], "bias_x_learn": 22, "variance_x_learn": 22, "2827518068171628": 22, "7686646616779012": 22, "worst": 22, "ipykernel_69122": [], "pypi": 23, "pkg": 23, "dev": 23, "colab": 23, "cp38": 23, "manylinux_2_17_x86_64": 23, "manylinux2014_x86_64": 23, "32m3": 23, "31m96": 23, "usr": 23, "dist": 23, "77": [23, 60, 62, 80], "32m77": 23, "31m12": 23, "manylinux2010_x86_64": 23, "571": 23, "32m571": 23, "31m58": 23, "importlib": 23, "0dev0": 23, "57": [23, 60, 62], "zipp": 23, "2344": 23, "612": 23, "7801": 23, "6886": 23, "6297": 23, "2293": [10, 23], "4417": 23, "819": 23, "okai": 23, "bias_grf": 23, "variance_grf": 23, "706857912147952": 23, "198946462195667": 23, "came": [24, 25], "g_0": [24, 25], "u": [24, 25, 64, 70, 86, 116, 122, 129, 130, 132], "manipul": [24, 25], "l_0": [24, 25], "rlearner": [24, 25], "nameerror": 60, "ipykernel_69134": [], "2628946087": [], "hte_r_learn": [24, 25], "ps_learner": [24, 25], "015": [24, 130], "739": 24, "740": 24, "736": 24, "018": [10, 24], "725": [24, 27], "028": [24, 129], "05127254": 24, "08881288": 24, "10304225": 24, "ate_r_learn": 24, "0755": 24, "ipykernel_69139": [], "1454775972": [], "942": [25, 127], "943": [25, 99, 127], "958": 25, "951": 25, "957": 25, "932": [25, 128], "950": 25, "944": [25, 127], "683": [25, 70, 121, 122], "584": [10, 25], "659": 25, "705": 25, "677": [25, 128], "667": [25, 128], "642": [25, 27], "669": 25, "551": [10, 25], "4971": 25, "0231": 25, "0514": 25, "0037": 25, "0943": 25, "4128": 25, "1436": 25, "4714": 25, "bias_r_learn": 25, "variance_r_learn": 25, "010664510462813687": 25, "3201771635462656": 25, "amaz": 25, "significantli": [25, 70, 122], "980": [25, 60], "978": 25, "975": 25, "940": [25, 127], "2566": 25, "0408": 25, "8131": 25, "0906": 25, "5665": 25, "7341": 25, "6459": 25, "272": 25, "bias_dr_learn": 25, "variance_dr_learn": 25, "29436318987432813": 25, "011818461500106": 25, "lp_r": 25, "0353": 25, "2368": 25, "0444": 25, "0884": 25, "6845": 25, "6876": 25, "6223": 25, "85": [25, 62], "bias_lp_r_learn": 25, "variance_lp_r_learn": 25, "2909913487561472": 25, "1822936738050482": 25, "incred": 25, "ipykernel_69144": [], "4157178503": [], "comparison": [26, 45, 68, 76, 119], "13686218": 26, "52931381": 26, "10841595": 26, "ate_s_learn": 26, "1453": [26, 102, 105, 106], "dislik": 27, "scope": [27, 32], "getcwd": [27, 63, 64, 66, 67, 68, 69, 71, 73, 109, 110, 115, 116, 130], "onlin": [27, 75, 80, 84, 88, 96, 101, 103, 104, 107, 108, 109, 110, 115, 116, 117, 118, 119, 131, 132], "cmab": [27, 81, 82, 129, 130], "_env_realcmab": [27, 81, 82, 129], "env": [27, 81, 82, 83, 85, 86, 87, 89, 94, 96, 97, 98, 99, 101, 103, 104, 105, 106, 109, 110, 115, 116, 129, 130], "get_movielen": 27, "ipykernel_69152": [], "1573112457": [], "xs": [27, 87, 96, 101, 103, 104, 128], "mean_ri": [27, 128], "standardized_x": [27, 128], "data_ml": 27, "users_index": 27, "movie_gener": [27, 129], "data_cel": 27, "initi": [10, 27, 45, 48, 50, 59, 60, 62, 64, 66, 67, 68, 73, 74, 75, 78, 82, 83, 86, 106, 109, 116, 118, 123, 127, 129, 130], "concat": [27, 60, 121, 128, 129], "complet": [27, 45, 70, 76, 87, 89, 128], "4220": 27, "2355": 27, "14400": 27, "2918": 27, "16752": 27, "2791": 27, "20195": 27, "2797": 27, "21689": 27, "2321": 27, "393463": 27, "3299": 27, "395410": 27, "892": 27, "396058": 27, "574": [27, 128], "397794": 27, "1812": 27, "400719": 27, "3830": 27, "49563": 27, "data_cel_al": 27, "to_csv": [27, 121, 124, 129], "11057": 27, "25871": 27, "31166": 27, "40383": 27, "303406": 27, "320275": 27, "332011": 27, "382221": 27, "397209": 27, "175": [27, 45, 70, 76, 84, 88, 121, 122, 124], "save": [27, 68, 87, 129, 132], "www": [27, 33], "kaggl": [27, 33, 124, 125, 126], "asjad99": 27, "mimiciii": 27, "center": [27, 124, 125, 126], "databas": [27, 124, 125, 126], "clinic": [27, 32, 33, 79, 108, 124, 125, 126], "61": [27, 59, 60, 62, 124, 125, 126], "532": [10, 27, 124, 125, 126], "admiss": [27, 124, 125, 126], "boston": [27, 124, 125, 126], "teach": [27, 124, 125, 126], "hospit": [27, 124, 125, 126], "demograph": [27, 124, 125, 126], "vital": [27, 90, 91, 92, 124, 125, 126], "lab": [27, 124, 125, 126], "cohort": [27, 124, 125, 126], "sepsi": [27, 124, 125, 126], "meet": [27, 124, 125, 126], "ventil": 27, "particular": [27, 60, 63, 73, 118, 129, 131], "characterist": [27, 131], "physiolog": 27, "whole": [27, 60], "mimic3_sepsis_data": 27, "mimic3_data": [27, 121, 124, 125], "bloc": [27, 70, 121, 122], "icustayid": [27, 70, 121, 122, 124, 125, 127], "charttim": 27, "gender": [27, 80, 88, 108, 129, 130], "elixhaus": 27, "re_admiss": 27, "died_in_hosp": 27, "died_within_48h_of_out_tim": [27, 121, 124, 125, 126], "mortality_90d": 27, "input_tot": 27, "input_4hourli": 27, "output_tot": 27, "output_4hourli": 27, "cumulated_bal": 27, "sofa": [27, 70, 121, 122, 123, 126, 127], "sir": 27, "vaso_input": 27, "iv_input": [27, 70, 121, 122, 123, 124, 125, 127], "7245486000": 27, "17639": 27, "826435": 27, "6527": 27, "0000": 27, "13617": 27, "520": 27, "7090": 27, "884898": 27, "6898241400": 27, "30766": 27, "069028": 27, "383136": 27, "5805732000": 27, "12049": 27, "217303": 27, "976040": 27, "4264269300": 27, "30946": 27, "970000": 27, "1300": 27, "340": 27, "160": [27, 84], "960": [27, 106], "125000": [27, 124, 125, 127], "5707825200": 27, "19793": 27, "588912": 27, "9552": 27, "6830": 27, "540": [10, 27], "2722": 27, "457625": 27, "7214122800": 27, "24524": 27, "747419": 27, "10661": 27, "0483": 27, "360": 27, "4915": 27, "049099": 27, "glucos": [27, 70, 121, 122, 123, 124, 125, 126, 127], "pao2": [27, 121, 124, 125, 126, 127], "pao2_fio2": [27, 70, 121, 122, 123, 124, 125, 126, 127], "mimic3_data_select": 27, "84": [27, 59, 60, 62], "168": [27, 121, 123, 124], "122": 27, "59": [27, 48, 62, 124], "148148": 27, "125": [27, 121, 123], "690": 27, "647482": 27, "110": [27, 121, 124], "727273": 27, "179": [27, 45, 70, 122, 127], "447": [10, 27, 95, 97], "499993": 27, "347": 27, "222222": 27, "4995": 27, "375000": 27, "787683": 27, "206": [27, 70, 121, 122, 124, 127], "005547": 27, "965110": 27, "4996": 27, "333333": 27, "143": [27, 84, 127], "846153": 27, "025000": 27, "4997": 27, "106": [27, 124, 125, 127], "258": [27, 122], "923": 27, "214286": 27, "402531": 27, "4998": 27, "144": [27, 70, 121, 122], "376": [27, 45], "752": [27, 121, 124], "172130": 27, "4999": 27, "113": [10, 27, 60, 70, 122, 124], "269": 27, "999996": 27, "record": [10, 27, 33, 61, 129], "data_cel_select": [27, 124, 125], "oxygen": [27, 124, 125, 126], "fraction": [27, 124, 125, 126], "deliv": [27, 124, 125, 126], "fio2": [27, 124, 125, 126], "organ": [27, 124, 125, 126], "assess": [27, 61, 124, 125, 126], "dysfunct": [27, 124, 125, 126], "iv": [27, 70, 121, 122, 123, 124, 125, 126, 127], "volumn": [27, 124, 125, 126], "fluid": [27, 124, 125, 126], "administ": [27, 124, 125, 126], "addition": 27, "aspect": 27, "3598282": 28, "34648075": 28, "35533324": 28, "ate_t_learn": 28, "3571": 28, "estiamt": 28, "33630057": 29, "31723622": 29, "37261498": 29, "ate_x_learn": 29, "3566": 29, "move": [32, 74], "encount": [32, 81, 82], "scenario": [32, 100, 131], "substanti": [32, 40], "transit": [32, 68, 74, 75, 118, 119], "easier": 32, "ma": [32, 70, 75, 118, 119, 122, 123, 127], "subseteq": [32, 75, 100, 102, 118], "s_": [32, 63, 64, 66, 67, 68, 73, 74, 75, 106, 118, 131], "w_t": [32, 75, 77, 94, 96, 97, 118], "_t": [32, 68, 70, 75, 76, 77, 78, 80, 90, 91, 92, 95, 96, 101, 102, 103, 107, 117, 118], "a_t": [32, 63, 64, 66, 67, 70, 73, 74, 75, 76, 79, 80, 81, 82, 83, 84, 85, 86, 88, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 105, 107, 108, 109, 110, 115, 116, 117, 118, 129, 131], "s_t": [32, 63, 64, 66, 67, 68, 70, 73, 74, 75, 118, 131], "cmia": [32, 75, 118, 119], "y_t": [32, 33, 75, 118], "w_": [32, 75, 95, 96, 118], "tupl": [32, 63, 64, 70, 73, 74, 79, 88, 107, 117, 118, 119, 122], "a_": [32, 45, 61, 63, 64, 66, 67, 68, 73, 74, 75, 76, 77, 78, 83, 86, 87, 88, 89, 94, 96, 98, 99, 101, 102, 107, 108, 109, 116, 117, 118, 131], "equiv": [32, 63, 64, 73, 87, 90, 91, 92, 95], "limit": [32, 40, 50, 60, 64, 68, 70, 73, 86, 116, 118], "pai": [32, 124, 125], "r_t": [32, 63, 66, 67, 70, 73, 74, 79, 80, 81, 83, 84, 85, 86, 88, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 108, 116, 117, 118, 129, 131], "cpl": 32, "restrict": 32, "talk": 32, "cima": 32, "especi": [32, 85, 87, 102, 107, 117, 129, 131], "signific": [32, 40, 63, 70, 122, 124, 125], "effort": 32, "made": [10, 32, 68, 79], "instrument": 32, "proxi": 32, "emploi": [32, 40, 83, 102, 107, 128], "trim": 32, "strict": [32, 128], "ideal": [32, 83, 118], "greater": 32, "depth": 32, "past": [33, 61, 70, 75, 83], "econom": [33, 90, 91, 92, 131], "maker": 33, "sale": [33, 40, 128], "post": [33, 40, 121, 125], "green": 33, "purpl": 33, "orang": 33, "dash": 33, "essens": 33, "parallel": [10, 33, 40], "remain": 33, "untreat": [17, 33, 38], "panel": [33, 36], "att_t": 33, "tau_t": 33, "shortli": 33, "tricki": 33, "diff": 33, "transfer": 33, "dy_t": 33, "foral": [33, 40, 50, 74, 75, 90, 91, 92, 95, 96, 100, 101, 102, 103, 105], "exogen": 33, "won": 33, "nept": 33, "y_1": 33, "y_0": [33, 75, 118], "card": 33, "krueger": 33, "1994": 33, "wage": 33, "employ": 33, "harrywang": 33, "parulpandei": 33, "sandhyakrishnan02": 33, "downloa": 33, "384": 33, "food": 33, "jersei": 33, "pennsylvania": 33, "april": [33, 80, 95, 97], "1992": [33, 127], "stai": [33, 38, 48], "employe": 33, "febuarari": 33, "novemb": [33, 79, 105], "data_employ": 33, "total_emp_feb": 33, "total_emp_nov": 33, "75": [33, 60, 62, 124], "n_pa": 33, "n_nj": 33, "y_pa_feb": 33, "y_pa_nov": 33, "y_nj_feb": 33, "y_nj_nov": 33, "43": [33, 62], "nj": 33, "feb": 33, "g_i": 33, "t_0": [33, 38, 40, 131], "t_1": [33, 64, 74, 75, 131], "g_it_i": 33, "d_": [33, 78], "tr": [33, 40, 64, 70, 122], "y_": [33, 38, 40, 87, 89, 95, 96, 99, 100, 101, 102, 103, 105], "co": [33, 40], "subtract": [33, 131], "lechner": 33, "foundat": [33, 48, 74, 80, 115, 116], "224": 33, "goodman": 33, "bacon": 33, "225": 33, "254": [33, 70, 122], "277": [33, 70, 121, 122, 123], "1716": [36, 40], "1730": 36, "surviv": [37, 60, 123, 125, 127], "dive": [38, 70, 122], "life": 38, "length": [38, 74, 75, 95, 98, 99, 101, 102], "gdp": 38, "countri": [38, 60], "stock": 38, "price": [38, 50, 102, 103, 104, 105], "firm": 38, "chronolog": 38, "aris": 38, "estimand": [38, 68, 73], "ITE": 38, "delta_": 38, "treatement": [38, 123, 127], "ITEs": 38, "stationari": [38, 64, 73, 74, 75, 79], "sc": [38, 131], "unlik": [40, 50, 119], "imbal": 40, "fulfil": 40, "issu": [40, 68, 83, 118], "fund": 40, "reweight": [40, 68], "perspect": [40, 88, 97, 99, 118], "conterfactu": 40, "omega": [40, 45, 63, 64, 68, 73, 76], "sdid": 40, "i0": 40, "ij": 40, "jt": 40, "qquad": 40, "omega_": [40, 76], "abadi": 40, "diamond": 40, "hainmuel": 40, "california": 40, "proposit": 40, "99": [10, 40, 60, 62, 121], "tobacco": 40, "consumpt": 40, "1970": [10, 40], "susanathei": 40, "mcpanel": 40, "examples_from_pap": 40, "smok_outcom": 40, "smoke_x": 40, "smoke_covari": 40, "header": [40, 121, 124, 128], "smoke_a": 40, "smoke_treat": 40, "smoke_r": 40, "smoke_outcom": 40, "linspac": [40, 50, 129], "renam": [40, 121, 123, 127], "89": [45, 62, 76, 122], "124": [], "120": [121, 123, 124], "155": 127, "102": [45, 76], "114": [62, 70, 84, 122, 129], "132": [10, 121, 123], "1971": 10, "95": [62, 70, 103, 129, 130], "161": 129, "115": [40, 95, 121, 123], "139": [], "128": [], "111": [70, 122], "105": [40, 45, 60, 76, 121, 124], "131": 59, "1972": 10, "156": 123, "126": [45, 59, 62, 121, 123], "118": [124, 125, 127], "71": [45, 62, 70, 122, 124], "137": [124, 125], "140": 124, "1973": 10, "119": [], "72": [62, 70], "1974": 10, "112": [70, 122], "159": [99, 100, 107, 117], "preriod": 40, "element": [40, 79, 95], "t0": [40, 76], "pre_expo_r_ctl": 40, "pre_expo_r_trt": 40, "post_expo_r_ctl": 40, "post_expo_r_trt": 40, "lasso": 40, "clf": [40, 48], "coef_": [40, 129], "intercept_": [40, 129], "03980357": 40, "07157998": 40, "22667637": 40, "02990258": 40, "00037257": 40, "02313041": 40, "09714507": 40, "16905554": 40, "19878875": 40, "06427401": 40, "09209638": 40, "05463154": 40, "post_expo_r_trt_counterfactu": 40, "vline": 40, "ymin": 40, "ymax": 40, "130": 40, "linestyl": 40, "ylabel": [40, 60, 129, 130], "per": [40, 63, 73, 81, 82, 87], "capita": 40, "cigarett": 40, "pack": [40, 63, 64, 66, 67, 68, 69, 71, 73, 109, 110, 115, 116], "legend": [40, 129, 130], "effectli": 40, "longer": [40, 119], "505": 40, "2068": [10, 40, 123], "2069": 40, "2070": 40, "2071": [40, 108], "esti": 40, "mate": 40, "statisticalassoci": 40, "2083": 40, "contrast": [45, 62, 68, 76, 91, 92, 107, 131], "incent": [45, 59, 76, 78], "mainli": [45, 59, 66, 67, 76, 78, 80, 84, 88, 96, 101, 103, 108, 119, 129, 131], "convent": [45, 75, 76, 102], "soon": [45, 68, 76], "multinomi": [45, 53, 59, 61, 76, 78, 103, 104, 105, 107, 117, 130], "constrast": [45, 76], "furthermor": [45, 76, 80, 84, 87, 88, 96, 101, 103, 108], "c_j": 45, "blip": [45, 76], "max_": [45, 60, 67, 74, 75, 76, 78, 81, 82, 85, 86, 94, 96, 97, 98, 99, 101, 102, 103, 104, 105, 116, 118], "psi": [45, 50, 76, 87], "hand": [45, 50, 59, 66, 67, 78, 118, 129], "logist": [45, 60, 68, 73, 81, 82, 87, 94, 96, 103, 104, 110], "substitut": [45, 102, 107, 117], "euqat": 45, "appendix": 45, "bootstrap": [45, 59, 62, 69, 76, 78, 123], "utilz": [45, 76], "boostrap": [45, 59, 76], "resampl": [45, 59, 76, 78], "standard": [45, 59, 62, 63, 64, 68, 69, 73, 76, 78, 81, 85, 87, 89, 91, 97, 98, 99, 102, 104, 105, 106, 110, 123, 131], "cpl13": [45, 48, 50, 59, 60, 76, 78, 123, 127, 130], "disc": [45, 48, 59, 60, 76, 78, 123, 127, 130], "get_data": [45, 59, 61], "target_col": [45, 59, 60, 61], "binary_trt": [45, 59, 61], "2d": 45, "intercept": [45, 59, 60, 62, 78, 94, 96, 98, 101, 103, 104, 129, 130], "newaxi": [45, 62], "model_info": [45, 59, 62, 76, 78, 123, 127, 130], "x_prop": [45, 62, 76], "recenc": [45, 59, 60, 61], "x_q0": [45, 62, 76], "x_c": [45, 62, 76], "action_spac": [45, 59, 62, 76, 78, 123, 127, 130], "phi_": 45, "exp": [45, 62, 87], "gamma_": 45, "j0": 45, "j1": 45, "j2": 45, "attributeerror": 50, "ipykernel_69216": [], "15241541": [], "true_prop": [45, 76], "n_b": [45, 59, 62, 76, 78, 123], "boots_fit": [], "97": [10, 62, 104, 124], "_fit": [45, 76], "fitted_model": [45, 59, 62, 76, 78, 123, 127, 130], "_fit_model": [45, 76], "pseudo_y_prev": [45, 76], "get_pseudo_i": [], "attribut": [50, 70, 122], "opt_d": [45, 59, 62, 76, 78, 123, 127, 130], "recommend_act": [45, 48, 59, 76, 78, 123, 127, 130], "value_count": [45, 59, 78, 121, 123, 127, 128, 130], "v_hat": [45, 59, 62, 76, 78, 123, 127, 130], "predict_valu": [45, 59, 76, 78, 123, 127, 130], "3389e": 45, "0295e": 45, "3272e": 45, "03": [45, 61, 76, 123, 130], "1025e": 45, "7135e": 45, "7582e": 45, "202": [45, 127], "int64": [45, 59, 62, 78, 94, 97, 98, 99, 101, 103, 104, 121, 123, 124, 125, 127, 128, 130], "18615811062617": 45, "005": [10, 45], "mail": [45, 59, 60, 61], "women": [45, 59, 60, 61, 129], "men": [45, 59, 60, 61, 129], "deviaiton": [45, 59, 62, 76, 78], "amai": [45, 59, 62, 76, 78], "fitted_param": [45, 59, 62, 76, 78], "fitted_valu": [45, 59, 62, 76, 78], "value_avg": [45, 59, 62, 76, 78], "value_std": [45, 59, 62, 76, 78], "param": [45, 59, 62, 76, 78, 130], "predict_value_boot": [45, 59, 76, 78], "value_hat": [45, 59, 62, 76, 78], "133": [50, 121, 124], "07058862299368": [], "114870661497804": [], "200": [45, 59, 60, 62, 76, 78, 127, 130], "replic": [45, 59, 129], "37488160184644": 45, "std": [45, 59, 62, 70, 76, 78, 121, 128, 129], "37346454667266": 45, "739458412078504": 45, "placehold": [45, 76, 78], "schult": [45, 76], "institut": [45, 76], "640": [45, 76], "seattl": [45, 76], "symposium": [45, 76], "189": [45, 76, 127], "springer": [45, 76, 79, 80, 108], "york": [45, 76], "ny": [45, 76], "murphi": [45, 59, 76, 78], "royal": [45, 76], "331": [45, 76, 79], "355": [45, 76], "liang": [45, 76, 79, 108], "88": [45, 60, 62, 76, 124, 125, 127], "fan": [45, 76], "46": [45, 62, 76, 101], "925": [45, 76, 127], "close": [48, 63, 68, 73, 85, 118], "behaviour": [48, 68, 73, 102], "share": [48, 64, 68, 73, 87, 88, 96, 101, 103, 118, 132], "min": [48, 50, 60, 83, 128, 129], "neq": 48, "classif": [48, 66, 68, 70, 73], "classifi": [48, 61, 127], "impli": [48, 63, 74, 75, 123, 127], "why": 48, "w_i": 48, "though": 48, "instabl": 48, "svm": 48, "tbd": 48, "owl_simu": 48, "generate_test_cas": [48, 62], "case1": 48, "sigma": [48, 63, 64, 69, 73, 81, 85, 87, 89, 96, 98, 99, 101, 103, 110, 115, 116, 130], "xai": [48, 62], "outcomeweightedlearn": 48, "linearsvc": 48, "svc": 48, "model_select": [48, 127], "gridsearchcv": [48, 127], "cross_val_scor": 48, "cs": [48, 96, 103], "logspac": 48, "param_grid": 48, "dict": [48, 76, 128], "assignment_prob": 48, "your": [48, 60, 132], "notabl": [48, 80], "meantim": [48, 91], "zhao": 48, "yingqi": 48, "107": [10, 48, 121], "1106": 48, "1118": [10, 48], "ying": 48, "regimen": [48, 59, 78], "3776": 48, "3788": 48, "lou": 48, "zhilan": 48, "jun": 48, "shao": 48, "menggang": 48, "74": [48, 62], "506": 48, "stat": 48, "68": [48, 62, 70, 122], "sim": [48, 63, 64, 66, 68, 73, 74, 75, 81, 85, 87, 89, 90, 91, 92, 94, 95, 96, 98, 100, 101, 102, 103, 104, 105, 107, 117, 118, 129], "const": 48, "paid": [50, 131], "domain": [50, 107, 117], "dose": 50, "contin": 50, "discontinu": 50, "i2dr": 50, "idr": 50, "ingredi": 50, "multi": [50, 61, 76, 79, 80, 88, 89, 99, 100, 107, 108, 117, 129, 131], "overcom": 50, "bullet": [50, 64], "densiti": [50, 60, 63, 64, 68, 73, 74], "eqnarrai": [50, 63, 64, 66, 67, 73, 74, 75, 118], "eqn": [50, 63, 64, 66, 68, 69, 73, 74, 75, 87, 95, 96, 101, 103, 107, 117, 118], "almost": [50, 75], "sure": [50, 75], "naiv": 50, "concern": [50, 124, 125, 126], "psi_h": 50, "trade": [50, 68, 75, 84, 90, 91, 92, 97, 108], "decai": [50, 64], "yet": [50, 119], "union": [10, 50, 128], "q_": [50, 60, 76, 78], "dnn": 50, "argmin_": [50, 73], "substack": [50, 66, 67], "gamma_n": 50, "argmax_": [50, 87, 89, 90, 91, 92, 102, 103, 104, 105, 106, 108, 110, 115, 116], "argmax": [50, 129, 130], "value_djq": 50, "warfarin": 50, "deep_jump_learn": 50, "djl_opt": 50, "data_gen": 50, "data_gener": 50, "realdatagener": 50, "file_nam": [50, 124, 125], "real_envir": 50, "djl_partit": 50, "djl_agent": 50, "djlearn_opt": 50, "mlp_max_it": 50, "ipykernel_69234": [], "799946913": [], "datetim": [50, 124, 125], "djl": 50, "partit": [50, 127], "033": [10, 50, 105], "067": 50, "167": [50, 78], "333": 50, "minut": 50, "opt_polici": 50, "train_data": 50, "xt": 50, "3333333333333333": 50, "0th": 50, "djl_eval": 50, "pi_evalu": 50, "act_list": 50, "x_max": 50, "org_data": 50, "x_min": 50, "val": 50, "act": [50, 128], "regr_mean": 50, "djlearn_ev": 50, "file": [10, 22, 23, 45, 50, 70, 76, 121, 122, 123, 125, 127, 128, 129, 130, 132], "environ": [50, 66, 79, 80, 84, 88, 90, 91, 92, 107, 108, 117, 124, 125, 129], "omp_num_thread": [50, 124, 125], "calibr": 50, "2111": 50, "08885": 50, "kosorok": [50, 59, 78], "august": 50, "assist": 50, "26th": 50, "sigkdd": 50, "mine": 50, "march": 50, "1243": [50, 60], "1251": 50, "kept": [59, 78], "evolv": [59, 78], "hope": [59, 78], "straightforward": [59, 64, 66, 78, 85, 115, 118], "qlearn": [59, 62, 78, 123, 127, 130], "beta_": [59, 89, 123, 127], "regressionresultswrapp": [59, 78], "0x7fe59064d760": [], "202956": 59, "239801": 59, "611375": 59, "526133": 59, "152892": 59, "843148": 59, "000549": 59, "007584": 59, "000416": 59, "371": 59, "207": 59, "48792828230138": [], "0005": [59, 123], "0076": 59, "0004histori": 59, "49": [59, 60, 62], "ipykernel_69263": [], "3664914869": [], "mimic3_clip": [123, 127], "regime_sampl": [45, 76], "x_sampl": [45, 76], "a_sampl": [45, 76], "y_sampl": [45, 76], "boot": [45, 76], "v1": [], "reward_nam": [], "shold": 59, "set_index": [59, 78, 123, 127], "40675465960962": 59, "22558023415299": [], "45840507437804": [], "wang": [59, 60, 70, 78, 79, 99, 100, 107, 108, 117, 122], "zeng": [59, 78], "statistica": [59, 78, 96], "sinica": [59, 78], "901": [59, 78, 127], "todo": [62, 71, 78, 109, 110, 115, 116, 117, 131], "sandwich": 59, "project": 59, "ci": [59, 64, 74, 75, 129, 130], "extendour": 60, "satisfactori": 60, "prolong": 60, "tail": 60, "preval": 60, "heavi": [60, 118, 132], "unstabl": [60, 68], "skew": 60, "median": 60, "moodi": 60, "invert": 60, "cummul": 60, "qunatil": 60, "year": [60, 61, 81, 82, 87, 119], "feasibl": [60, 62, 64, 78, 100, 104, 118, 119], "misspecifi": 60, "pretain": 60, "c_i": 60, "rho_": 60, "beta_1": 60, "fine": 60, "grid": 60, "beta_0": 60, "u_": [60, 86, 108, 116], "1n": 60, "0n": 60, "1i": [60, 76, 77, 78], "0i": 60, "proper": 60, "nelder": 60, "mead": 60, "data_sim": 60, "099183": [], "378686": [], "863998": [], "554794": [], "079151": [], "584181": [], "623858": [], "790925": [], "168116": [], "763942": [], "113611": [], "244854": [], "892514": [], "141471": [], "802501": [], "067782": [], "046976": [], "492633": [], "842005": [], "511072": [], "393355": [], "184507": [], "120187": [], "652197": [], "197235": [], "512423": [], "989282": [], "943434": [], "762223": [], "042247": [], "dr_quantileotr": 60, "quantile_otr": 60, "quantileotr": 60, "x1": 60, "x2": 60, "mocondquant_0": 60, "x_1": 60, "x_2": 60, "mocondquant_1": 60, "ipykernel_69268": [], "1796369087": [], "api": [81, 82, 83, 85, 86, 87, 89, 94, 96, 97, 98, 99, 101, 103, 104, 105, 129, 130, 132], "smf": [], "basepolicylearn": [], "coeffici": [60, 81], "coef_original_scal": 60, "q_est": [60, 62, 70, 122], "dr_qopt": 60, "mopropen": 60, "notbinaryrandom": 60, "termin": [60, 90, 91, 92, 132], "129150": 60, "gradient": [60, 63, 73, 90, 91, 92], "final_simplex": 60, "0401e": 60, "0062e": 60, "3241e": 60, "9385e": 60, "9699e": 60, "9649e": 60, "9516e": 60, "0098e": 60, "7645e": 60, "9178e": 60, "9988e": 60, "6791e": 60, "1197": 60, "fun": 60, "119701027689532": 60, "messag": [10, 60], "nfev": 60, "nit": 60, "success": 60, "0000e": 60, "3468e": 60, "7854e": 60, "06": [60, 99, 123], "sklift": 60, "return_x_y_t": 60, "raw": 60, "history_seg": 60, "zip_cod": [60, 61, 128], "newbi": [60, 61], "142": [60, 121, 124], "surburban": 60, "phone": [60, 61], "350": [60, 84], "329": 60, "08": [60, 123], "rural": [60, 61], "web": [60, 61, 80, 95, 107, 108, 117], "180": 60, "750": [60, 121, 124], "675": 60, "83": [60, 62, 129], "urban": [60, 61], "63995": 60, "63996": 60, "63997": 60, "63998": 60, "552": 60, "multichannel": [60, 61], "63999": 60, "472": 60, "82": [60, 62, 79, 108], "64000": 60, "578": [10, 60, 61, 128, 129], "inplac": [60, 121, 123, 127], "get_dummi": [60, 128], "prefix": [60, 128], "axi": [60, 62, 70, 121, 122, 128, 129, 130, 131], "anymor": 60, "zip_code_rur": 60, "channel_multichannel": 60, "data_r": 60, "zip_code_surburban": [60, 61], "zip_code_urban": [60, 61], "channel_phon": [60, 61], "channel_web": [60, 61], "217": [60, 70, 122], "267": [60, 129], "297": 60, "264": 60, "332": 60, "451": [60, 84], "265": 60, "63466": 60, "63552": 60, "63743": 60, "210": [60, 121, 123], "63876": 60, "215": [60, 70, 122], "63883": 60, "239": 60, "70": [60, 62], "exceed": 60, "502953": 60, "1895e": 60, "7227e": 60, "4110e": 60, "8883e": 60, "3248e": 60, "6189e": 60, "4630e": 60, "8951e": 60, "8789e": 60, "1688e": 60, "1876e": 60, "7185e": 60, "4111e": 60, "9113e": 60, "3260e": 60, "6160e": 60, "5493e": 60, "8964e": 60, "8975e": 60, "1777e": 60, "1816e": 60, "7171e": 60, "4095e": 60, "8872e": 60, "3259e": 60, "6174e": 60, "7327e": 60, "8731e": 60, "9187e": 60, "1762e": 60, "1882e": 60, "7222e": 60, "4113e": 60, "8993e": 60, "3252e": 60, "6171e": 60, "6759e": 60, "9012e": 60, "9038e": 60, "1803e": 60, "1924e": 60, "7234e": 60, "4088e": 60, "8863e": 60, "3250e": 60, "6158e": 60, "4646e": 60, "9095e": 60, "8690e": 60, "2013e": 60, "1900e": 60, "7211e": 60, "4096e": 60, "8999e": 60, "3246e": 60, "6178e": 60, "3607e": 60, "9148e": 60, "9045e": 60, "1516e": 60, "1880e": 60, "9149e": 60, "6187e": 60, "4407e": 60, "9451e": 60, "8686e": 60, "1759e": 60, "1875e": 60, "7196e": 60, "4083e": 60, "9025e": 60, "6157e": 60, "5918e": 60, "9206e": 60, "8949e": 60, "1680e": 60, "1872e": 60, "7252e": 60, "4081e": 60, "8846e": 60, "3243e": 60, "6168e": 60, "4315e": 60, "8960e": 60, "8996e": 60, "1701e": 60, "1925e": 60, "7192e": 60, "4085e": 60, "8711e": 60, "3264e": 60, "6172e": 60, "5903e": 60, "9406e": 60, "8946e": 60, "1745e": 60, "1889e": 60, "7195e": 60, "4101e": 60, "8838e": 60, "3258e": 60, "6177e": 60, "4543e": 60, "9190e": 60, "8917e": 60, "181": [60, 127], "5661e": 60, "6834e": 60, "patch": 60, "facecolor": 60, "blue": 60, "xlabel": 60, "r1": 60, "titl": 60, "histogram": [60, 124, 125], "xlim": 60, "ylim": 60, "face": 60, "_c": 60, "_j": [60, 64, 87, 88, 89], "qdr_qope": 60, "mixtur": 60, "mdn": 60, "gbdt": 60, "futher": 60, "quanatil": 60, "dr_quantileop": 60, "quantileop": 60, "qope_est": 60, "927600463556344": 60, "5961404868027": 60, "lan": 60, "ben": 60, "sherwood": 60, "523": 60, "1254": 60, "erica": 60, "em": 60, "nema": 60, "dean": 60, "ru": 60, "bioscienc": 60, "243": 60, "week": 61, "merchandis": 61, "compris": [61, 131], "nine": 61, "dollar": 61, "suburban": 61, "ident": [61, 70, 81, 85, 87, 96, 98, 101, 103, 104, 106, 109, 110, 115, 116, 122, 129, 130], "flase": 61, "blog": 61, "minethatdata": 61, "2008": [61, 102], "phi1": 62, "phi2": 62, "psi1": 62, "psi2": 62, "random_binari": 62, "450": [62, 78], "a1": [62, 70, 76, 78, 122, 123], "binomi": [62, 96, 130], "60": [10, 62, 127, 130], "a2": [62, 70, 76, 78, 122, 123], "mu2": 62, "y_opt": 62, "opt_tru": 62, "optimal_a": 62, "optimal_v": 62, "250": [62, 70], "1108": 62, "575955081366": 62, "estimate_value_boot": 62, "estimated_contrast": [62, 76], "estimated_prop": 62, "prop": [45, 62, 76], "estimate_valu": 62, "ipykernel_69273": [], "1171830641": [], "a0": 62, "232": 62, "8969": 62, "9788": 62, "s1a1": 62, "del": 62, "1102": 62, "524126394967": 62, "554474056899934": 62, "379": 62, "334892": 62, "318229": 62, "628596": 62, "027810": 62, "313279": 62, "716134": 62, "729627": 62, "050612": 62, "335": 62, "294202": 62, "253088": 62, "460437": 62, "091607": 62, "664498": 62, "409741": 62, "410791": 62, "090007": 62, "200070": 62, "071281": 62, "474": 62, "508450": 62, "375403": 62, "517774": 62, "092061": 62, "a_est": 62, "c0": 62, "c1": 62, "vhat": 62, "q0": [45, 62, 76, 78, 123, 127], "q1": [62, 78, 123, 127], "opt_v": 62, "rep": [62, 70, 122, 129, 130], "51": [62, 127], "69": [62, 70, 122, 124], "73": [62, 124], "76": [62, 102, 103, 105, 107, 124], "78": [62, 102, 103, 105, 107], "79": [62, 124], "86": [45, 62, 76, 121], "87": [45, 62, 76], "2674": 62, "9966": 62, "718": 62, "432": 62, "9964": 62, "1119": [10, 62], "7158350462053": 62, "366": [62, 106], "5116": 62, "157": 62, "1218": [62, 128], "7812": 62, "0755e": 62, "4913e": 62, "3333e": 62, "8864e": 62, "1197e": 62, "0288e": 62, "5741e": 62, "1112": 62, "2353635304949": 62, "1120": 62, "4987706735005": 62, "10000": [62, 85], "decent": 63, "short": [10, 63, 68, 70, 119], "op": [60, 63, 66, 68, 70, 73, 74, 75, 131], "fqe": [63, 66, 67, 73], "integr": [63, 73, 129], "bellman": [63, 66, 67, 73, 74, 118], "bellman_q": [63, 66, 73, 74, 118], "wise": [63, 68, 73, 129], "stepi": [63, 68, 73], "stepdr": [63, 73], "i_t": [63, 68, 73, 95], "besid": [63, 66, 67, 68, 73, 118], "recurs": [63, 73, 74], "debia": [63, 64, 73], "reflect": [63, 68, 73, 75, 80, 84, 88, 108, 129], "mi": [63, 64, 73], "suffer": [63, 73, 124, 125], "huge": [63, 73, 118], "avoid": [63, 64, 68, 70, 73, 122, 128], "widetild": [63, 68, 73], "drl": [63, 64, 73], "margin": [63, 64, 68, 73], "infti": [63, 64, 66, 67, 68, 70, 73, 74], "p_t": [63, 64, 68, 73], "p_b": [63, 68, 73], "recal": [63, 64, 68, 69, 73, 118, 119], "manner": [63, 73], "tini": [63, 64, 73], "textrm": [63, 64, 69, 70, 73, 123, 127], "sqrt": [63, 73, 82, 86, 106, 116], "weakli": [63, 68, 73], "lower_bound": [63, 69, 73], "proven": [63, 73], "speak": [63, 64, 73], "publish": [63, 64, 66, 67, 68, 69, 71, 73, 109, 110, 115, 116], "hide": [63, 64, 66, 67, 68, 69, 71, 73, 109, 110, 115, 116], "filenotfounderror": [15, 16, 17, 20, 21, 24, 26, 27, 28, 29, 33, 40, 60, 63, 64, 66, 67, 68, 69, 71, 73, 109, 110, 115, 116, 128], "ipykernel_69278": [], "2982377520": [], "errno": 128, "directori": 128, "eqn_omega": [63, 73], "mini": [63, 73], "solvel": [63, 73], "sup_": [63, 73], "simplifi": [63, 73, 74, 90, 91, 92], "reproduc": [63, 73], "hilbert": [63, 73], "rkh": [63, 73], "outer": [63, 73], "descent": [63, 73, 90, 91, 92, 118], "approxim": [63, 68, 73, 87, 89, 94, 96, 98, 103, 104, 131], "still": [64, 68, 73, 87, 119], "slow": 64, "wald": [64, 69, 90, 91], "nomin": 64, "coverag": 64, "weaker": 64, "deeper": 64, "new_drl_term": 64, "dirac": 64, "p_": [64, 73, 90, 91, 92], "event": 64, "numer": [64, 66, 67, 80, 84, 88, 107, 108, 117, 129], "debiasterm": 64, "tripli": 64, "ci_tr": 64, "z_": [64, 69], "nuisans": 64, "i_1": 64, "t_": 64, "disjoint": 64, "t_2": 64, "counterpart": [64, 68], "arbitrari": 64, "ipykernel_69284": [], "3779975037": [], "breakthrough": 64, "spirit": 64, "uncorrel": 64, "hoeffd": 64, "decomposit": [64, 70], "degener": 64, "conceptu": [66, 68], "contract": [66, 67, 118], "ell": [66, 67, 118], "until": [66, 67, 68, 87, 89, 102, 103, 104, 105, 106, 118], "ipykernel_69291": [], "fqi": [67, 118], "ipykernel_69296": [], "vanilla": 68, "prod_": 68, "immedi": [68, 70, 74, 75, 122], "bias": 68, "exponenti": 68, "forward": 68, "stationar": [68, 74], "sa": [68, 73], "rather": [68, 75], "understood": 68, "trick": [68, 76], "omit": 68, "ipykernel_69301": [], "principl": [68, 73], "neglig": [68, 70, 73, 122], "harri": [68, 73], "ergod": [68, 73], "chain": [68, 73], "eventu": [68, 73, 129], "mix": [68, 73, 101], "ref": [69, 73], "sec": [69, 73], "adopt": [69, 96], "tighter": 69, "concentr": [49, 69, 70, 100], "inequ": 69, "curse_horizon": [69, 73], "explicitli": [10, 69, 91, 92, 96, 101, 103], "kallus2019effici": [69, 73], "eqref": [69, 73], "ci_drl": 69, "upper": [69, 82, 84, 86, 90, 91, 92, 106, 116, 129, 130], "ipykernel_69306": [], "mobil": [70, 79], "devis": 70, "encompass": 70, "multipli": [70, 122], "pi_e": 70, "pi_0": 70, "dento": 70, "lim_": 70, "id": [10, 70, 103, 104, 105, 121], "dde": [70, 122], "dme": [70, 122], "ii": [70, 75, 108, 119], "m_t": [70, 76], "iii": [70, 108], "r_1": 70, "depict": [70, 131], "s_1": [22, 23, 70, 75, 118], "ipykernel_69311": [], "2351773156": [], "mimic3": 121, "mimic3_mrl_data_dict_v2": [70, 121, 122], "mimic3_mrl": [70, 122], "mrl_df": [70, 121, 122], "mimic3_mrl_df_v2": [70, 121, 122], "died_within_48h": [70, 121, 122, 123, 127], "1006": [70, 121, 122, 124, 125, 127], "me_mdp": [70, 122], "na": [109, 110, 115, 116], "longleaf": [109, 110, 115, 116], "rhel8": [], "anaconda": [], "ood": [], "mcmc": [70, 122, 127], "ratio_ndim": [70, 122], "scaler": [70, 122], "q_set": [70, 122], "product_tensor": [70, 122], "include_intercept": [70, 122], "penalti": [70, 122], "min_l": [70, 122], "t_dependent_q": [70, 122], "l2penalti": [70, 122], "spline": [70, 122], "dimems": [70, 122], "018100205548084617": [], "006066387157097036": [], "00486632802292234": [], "0001815880750934009": [], "017081734489003318": [], "est_id": [70, 122], "ide_s": [70, 122], "ime_s": [70, 122], "dde_s": [70, 122], "dme_s": [70, 122], "te_s": [70, 122, 123], "00586890111356167": [], "002110278954333155": [], "002770561709397491": [], "0010678186846428818": [], "005821662648170317": [], "dierct": [70, 122], "ind": [70, 121, 122, 128], "inm": [70, 122], "dnde": [70, 122], "nddnme": [70, 122], "tabl": [70, 84, 122, 123, 127], "dnme": [70, 122], "0181": [70, 122], "0059": [70, 122], "0061": [70, 122], "0021": [70, 122], "0049": [70, 122], "0028": [70, 122], "0002": [70, 122, 123], "0011": [70, 122], "0171": [70, 122], "0058": [70, 122], "insignific": [70, 122], "conclud": [70, 122], "wu": [70, 122], "2301": [70, 122], "13348": [70, 122], "ipykernel_69316": [], "ipykernel_69321": [], "textit": 73, "citep": 73, "jiang2016doubl": 73, "farajtabar2018mor": 73, "uehara2019minimax": 73, "rotnitzky1995semiparametr": 73, "carefulli": [73, 86, 118], "thomas2016data": 73, "our_method": 73, "superior": [73, 87], "gain": [73, 129], "tang2019doubl": 73, "upon": [73, 80, 131], "vspace": 73, "1cm": 73, "worthi": 73, "denomin": 73, "modif": 73, "throw": 73, "awai": [73, 92], "geometr": [73, 96, 102, 103, 105], "2cm": 73, "mean_": 73, "proof": 73, "cramer": 73, "rao": 73, "bickel1993effici": 73, "van2000asymptot": 73, "liu2018break": 73, "ineffici": [73, 85, 86, 89], "mass": 74, "enter": 74, "throughout": [74, 124, 125], "report": 74, "readi": 74, "t_n": [74, 75], "uniformli": [74, 75], "def_valu": [74, 75], "benefit": [74, 75], "_l": [74, 75], "_u": [74, 75], "opo": [74, 75], "repeatedli": [75, 88], "perspectii": 75, "implicitli": 75, "writ": 75, "ground": [75, 118], "literautr": 75, "subset": [75, 95, 98, 99, 100, 101, 102, 107, 117, 118, 124, 125, 126], "had": [75, 118], "cup_": [75, 118], "determinist": [75, 87, 90, 91, 92, 96, 101, 102, 103, 107, 117], "homogen": 75, "central": [75, 79, 84, 108], "statioanri": 75, "shall": 75, "wors": 75, "ca": 75, "sra": 75, "s_j": 75, "a_j": 75, "y_j": 75, "markovobserv": 75, "robserv": 75, "interchang": 75, "h_": [76, 77, 78, 131], "ti": [76, 77, 78], "till": [76, 77, 78], "q_t": [76, 118], "h_t": 76, "v_": [76, 102, 103, 106], "d_t": 76, "backward": [76, 78], "previous": [10, 76, 81, 82, 83, 85, 86, 87, 89], "eqaut": 76, "accordingli": [76, 81, 85, 86, 97, 99, 105, 110, 115, 116], "m_k": 76, "h_ti": 76, "datamdp_feas": [76, 78], "txt": [76, 78, 128], "sep": [76, 78, 128], "cd4_0": [76, 78], "cd4_6": [76, 78], "cd4_12": [76, 78], "a3": [76, 78, 123], "ipykernel_69336": [], "2644300625": [], "5872e": 76, "0493e": 76, "9347e": 76, "2010e": 76, "568": 76, "1057": 76, "8412e": 76, "2479e": 76, "1162": 76, "4662578531918": 76, "3156513295758": [], "559003921896037": [], "245571": [], "595014": [], "143433": [], "440232": [], "3966192806022": 76, "626837283714682": 76, "omega_t": 76, "w_1": 77, "w_2": 77, "multistag": 78, "prepar": [78, 107], "reset_index": [78, 121, 124], "0x7ff75da7df10": [], "0x7ff75da7dc40": [], "0x7ff738047760": [], "q2": 78, "898024": 78, "102009": 78, "116478": 78, "002859": 78, "171": [10, 78], "676661": 78, "454044": 78, "288382": 78, "921595": 78, "015938": 78, "553900": 78, "477566": 78, "551396": 78, "334465": 78, "182": [78, 121, 124, 127, 129], "312429": 78, "703112": 78, "550": [10, 78], "1113": [78, 98, 100], "3004201781757": [], "ipykernel_69344": [], "2461346363": [], "BE": 78, "THE": 78, "AS": 78, "THAT": 78, "OF": 78, "979": 78, "4518636939476": 78, "1558584708713": [], "2312785208211094": [], "accuraci": [], "financ": [79, 84, 108, 131], "slot": 79, "casino": 79, "gambler": 79, "plai": [79, 80, 84, 86, 88, 90, 91, 92, 100], "earn": 79, "payout": 79, "produc": 79, "divid": [79, 131], "adversari": 79, "pacakg": 79, "distinct": 79, "laern": 79, "durand": [79, 108], "achilleo": [79, 108], "iacovid": [79, 108], "strati": [79, 108], "mitsi": [79, 108], "pineau": [79, 108], "mous": [79, 108], "novo": [79, 108], "carcinogenesi": [79, 108], "healthcar": [79, 84, 88, 108], "zha": [79, 108], "portfolio": [79, 108], "twenti": [79, 108], "fourth": [79, 108], "joint": [79, 108], "xu": [60, 79, 108], "811": [79, 108], "821": [79, 108], "bouneffouf": [79, 80, 84, 108], "bouzeghoub": 79, "gan\u00e7arski": 79, "awar": 79, "berlin": [79, 80], "heidelberg": [79, 80], "primarili": 80, "profil": 80, "occup": [80, 88, 108, 129, 130], "season": 80, "temperatur": 80, "aid": 80, "mab": [80, 83, 85, 86, 88, 108], "tast": 80, "film": [80, 128], "ultim": [80, 84, 88, 95, 100, 102, 107, 108, 129], "lipschitz": 80, "linucb": [80, 108, 130, 131], "lint": [80, 108, 129, 130, 131], "static": [80, 87, 96, 101, 132], "nonstationari": 80, "1m": [80, 84, 88, 107, 108, 129], "highest": [80, 83, 84, 85, 86, 88, 95, 96, 97, 98, 99, 101, 107, 108, 109, 110, 115, 116, 129], "colleg": [80, 81, 82, 87, 88, 108, 128, 129], "technician": [80, 88, 108, 128, 129, 130], "academ": [80, 88, 108, 128, 129], "bernoulli": [80, 84, 88, 95, 96, 97, 100, 101, 110, 115], "chu": [80, 82, 108], "reyzin": [80, 82], "schapir": [80, 82, 108], "june": [80, 81, 82, 94, 95, 98, 100, 102, 103, 105, 107, 110], "payoff": [80, 81, 82, 108, 110], "fourteenth": [80, 82], "208": [80, 82, 121, 123], "jmlr": [80, 82], "workshop": [80, 82], "agraw": [80, 81, 102, 103, 104, 105, 106, 107, 108, 110], "goyal": [80, 81, 102, 103, 105, 106, 107, 108, 110], "thompson": [80, 81, 84, 85, 88, 90, 91, 92, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 107, 110, 115, 116, 117, 131], "127": [80, 81, 108, 110, 124, 125, 127], "135": [80, 81, 84, 108, 110], "kveton": [80, 81, 87, 88, 89, 94, 95, 98, 100, 107, 108, 110, 117], "zaheer": [80, 81, 87, 88, 89, 94, 108, 110], "szepesvari": [80, 81, 88, 89, 94, 95, 107, 108, 110, 117], "ghavamzadeh": [80, 81, 88, 94, 108, 110], "boutili": [80, 81, 88, 89, 94, 108, 110], "2066": [10, 80, 81, 94, 108, 110], "2076": [80, 81, 94, 108, 110], "rish": [80, 84, 108], "10040": [80, 84, 108], "slivkin": [80, 84, 108], "286": 80, "hazan": 80, "megiddo": 80, "513": 80, "langford": [80, 90, 91, 92, 108], "articl": [80, 108], "19th": [80, 108], "670": [80, 108], "auer": [80, 83, 86, 108, 109, 116], "cesa": [80, 83, 86, 108, 109, 116], "bianchi": [80, 83, 86, 108, 109, 116], "freund": 80, "nonstochast": 80, "multiarm": [80, 83, 86, 108, 109, 116], "siam": 80, "scalabl": [81, 82, 87, 89, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 131], "ucb": [81, 82, 84, 94, 97, 98, 99, 104, 105, 106, 108, 116, 130], "suscept": [81, 94, 98, 104], "avial": [81, 107, 110, 117], "consdier": [81, 110], "ts": [81, 82, 84, 87, 88, 89, 96, 97, 99, 101, 103, 104, 105, 108, 110, 130, 131], "domian": [81, 85, 110, 115], "thecorrespond": [81, 110], "posterior": [81, 82, 83, 85, 86, 87, 89, 94, 96, 97, 98, 99, 101, 103, 104, 105, 108, 110, 115, 129], "greatest": [81, 85, 97, 110, 115], "updat": [81, 82, 83, 85, 86, 87, 89, 91, 94, 96, 97, 98, 99, 101, 103, 104, 105, 106, 109, 110, 115, 116, 118, 128, 131, 132], "distirbut": [81, 85, 97, 99, 105, 110, 115], "rewad": [81, 85, 97, 99, 105, 110, 115], "cpl4": [81, 82, 83, 85, 86, 87, 89, 94, 96, 97, 98, 99, 101, 103, 104, 105, 106, 129, 130], "theano": [81, 82, 83, 85, 86, 87, 89, 94, 96, 97, 98, 99, 101, 103, 104, 105, 129, 130], "configdefault": [], "unabl": [], "gpu": [], "degrad": [], "cxx": [], "empti": [], "string": 10, "bla": [81, 82, 83, 85, 86, 87, 89, 94, 96, 97, 98, 99, 101, 103, 104, 105, 129, 130], "imit": [81, 82, 83, 85, 86, 87, 89, 94, 96, 97, 98, 99, 101, 103, 104, 105], "_env": [81, 82, 83, 85, 86, 87, 89, 94, 96, 97, 98, 99, 101, 103, 104, 105, 129], "single_contextual_env": [81, 82, 129], "eoferror": [], "ipykernel_69354": [], "1670608188": [], "_util_onlin": [], "wrapper": 128, "221": [], "siev": [], "222": [], "setattr": [], "func": 128, "_autoarg": [], "leave_drama": [], "dat": 128, "leave_dram": [], "data_dir": [], "fp": 128, "ran": 129, "deviat": [81, 85, 87, 89, 98, 99], "prior_theta_u": [81, 110, 129, 130], "prior_theta_cov": [81, 110, 129, 130], "covarainc": [81, 85], "lints_gaussian_ag": [81, 89, 110], "lints_gaussian": [81, 110, 129, 130], "get_phi": [81, 82, 87, 129, 130], "take_act": [10, 81, 82, 83, 85, 86, 87, 89, 94, 96, 97, 98, 99, 101, 103, 104, 105, 106, 109, 110, 115, 116, 129, 130], "get_reward": [81, 82, 83, 85, 86, 87, 89, 94, 96, 97, 98, 99, 101, 103, 104, 105, 106, 109, 110, 115, 116, 129, 130], "receive_reward": [81, 82, 83, 85, 86, 87, 89, 94, 96, 97, 98, 99, 101, 103, 104, 105, 106, 109, 110, 115, 116, 129, 130], "feature_info": [81, 82, 87, 129], "old": [81, 82, 87], "retrain_freq": [81, 82, 94, 110], "glm": [81, 82, 108, 131], "lints_glm_ag": 81, "lints_glm": 81, "specifci": 82, "gaussain": 82, "theta_a": [82, 83, 85, 109], "u_a": [82, 86, 116], "theta_": [82, 83, 85, 94, 95, 96, 97, 98, 100, 102, 105, 109, 110, 115, 123], "ipykernel_69364": [], "exploration_t": [82, 130], "linucb_gaussian_ag": 82, "linucb_gaussian": [82, 130], "linucb_glm_ag": 82, "linucb_glm": 82, "domin": [83, 127], "eploit": 83, "epsilon_t": [83, 109], "epsilon_": [83, 87, 89, 108, 109], "pull": [83, 86, 87, 109, 116, 129], "c_a": [83, 86, 109, 116], "decrease_ep": [83, 109], "specfi": [83, 109], "epsilon_greedi": 83, "_env_realmab": [83, 85, 86], "single_gaussian_env": [83, 85, 86, 109, 110, 115, 116, 130], "greedy_ag": [83, 109], "single_bernoulli_env": [83, 85, 86, 110, 115], "fischer": [83, 86, 108, 109, 116], "256": [83, 86, 108, 109, 116, 122], "satisf": [84, 95], "tackl": [84, 108], "preprocess": [84, 88], "045": [10, 84, 129], "288": 84, "204": [84, 127], "096": 84, "312": 84, "287": [84, 121, 129], "076": [10, 84], "313": 84, "305": [84, 128], "278": [70, 84, 122], "455": 84, "553": 84, "420": 84, "07272": [84, 108], "Be": 85, "uncertainti": [85, 86], "dilemma": [85, 108, 110, 115], "greedili": [85, 86, 96, 101, 103, 108, 110, 115, 116, 129], "nearli": [85, 108, 110, 115], "manual": [85, 115, 132], "r_0": 85, "reward_typ": [85, 115, 130], "u_prior_mean": [85, 99, 115, 130], "u_prior_cov": [85, 115, 130], "ts_gaussian_ag": [85, 115], "prior_phi_beta": [85, 115], "ts_bernoulli_ag": [85, 115], "russo": [85, 107, 108, 115, 116, 117], "kazerouni": [85, 107, 108, 115, 116, 117], "osband": [85, 107, 108, 115, 116, 117], "wen": [85, 94, 95, 98, 100, 107, 108, 115, 116, 117], "tutori": [85, 95, 100, 101, 102, 103, 107, 108, 115, 116, 117, 129, 132], "0203": [85, 108], "lattimor": [85, 108], "szepesv": [85, 108], "ari": [85, 108], "cambridg": [85, 108], "radiu": [86, 108, 116], "2log": 86, "ucb1": [86, 108, 130, 131], "log": [86, 116, 118, 129], "ucb_ag": [86, 106, 116], "hierarch": [87, 88, 96, 101, 103], "alignedat": [87, 89, 96, 101, 103], "inter": [87, 95, 96, 100, 101, 102, 103, 131], "mu_": [87, 88, 89, 123], "hierachical_model": 87, "explicit": [87, 89, 96, 103], "pymc3": [87, 89, 96, 103, 104], "mathmet": 87, "simultan": [87, 96, 101, 103], "meta_bandit": [87, 89], "mtts_gaussian": 87, "_env_realmultitask": [87, 89], "multitask_env": [87, 89], "episod": [87, 89], "preced": [87, 89], "concurr": 87, "theta_prior_mean": 87, "theta_prior_cov": 87, "delta_cov": 87, "approximate_solut": 87, "finish": [87, 89], "update_freq": [87, 89, 96, 101, 103, 104, 106], "mtts_gaussian_ag": 87, "mtts_agent": 87, "posterior_u": [87, 89, 115], "posterior_cov_diag": [87, 89], "mtts_binari": 87, "phi_beta": [87, 89, 96, 103, 106, 109, 110, 115], "mtts_binary_ag": 87, "posterior_alpha": [87, 89, 115], "posterior_beta": [87, 89, 115], "29655": [87, 88], "29668": [87, 88], "basu": [87, 88, 89], "szepesv\u00e1ri": [87, 88, 89], "28029": [87, 88, 89], "28041": [87, 88, 89], "acceler": 88, "arbitrati": 88, "decsion": 88, "lack": [88, 131], "integ": [88, 107, 117], "a_k": 88, "r_k": 88, "konobeev": [88, 89], "hsu": [88, 89], "mladenov": [88, 89], "5884": [88, 89], "5893": [88, 89], "7724": 88, "7741": 88, "maintain": [89, 118], "demonstr": 89, "categor": [89, 131], "accommod": [89, 98], "meta_ts_gaussian": 89, "sigma_0": 89, "sigma_q": 89, "meta_ts_gaussian_ag": 89, "meta_ts_ag": 89, "episode_finish": 89, "meta_post": 89, "candid": [89, 94, 96, 97, 98, 99, 101, 103, 104, 105], "candi_mean": 89, "entri": [89, 95], "meta_ts_binari": 89, "meta_ts_binary_ag": 89, "ongo": [90, 91, 92], "crucial": [90, 91, 92], "exposit": [90, 91, 92], "link": [90, 91, 92, 132], "dud\u00edk": [90, 91, 92], "suvta": [90, 91, 92], "dr_est": [90, 91, 92], "2110": [90, 91, 92], "15501": [90, 91, 92], "240": [90, 91, 92, 121], "255": [90, 91, 92], "534": [90, 91, 92], "708": [90, 91, 92], "719": [90, 91, 92], "1103": [90, 91, 92], "4601": [90, 91, 92], "dream": 91, "architectur": [91, 119], "tripl": 91, "x_t": 91, "buffer": [91, 118], "pi_b": 91, "pi_t": 91, "histor": [91, 92, 119], "kappa_t": [91, 92], "pr": [91, 92], "kappa": [91, 92], "overlap": 92, "zong": [94, 95], "laplac": 94, "mid": [94, 96, 97, 98, 99, 101, 102, 103, 104, 105, 108, 116], "inroduct": [94, 96, 97, 98, 99, 101, 103, 104, 105], "cascad": [94, 96, 97, 107, 117, 131], "structured_bandit": [94, 96, 97, 98, 99, 101, 103, 104, 105, 106], "_env_realcascad": [94, 96, 97], "cascading_env": [94, 96, 97], "itm": [94, 96, 97, 98, 99, 101, 103, 104, 105], "considerd": [94, 98, 101], "lints_ag": [94, 98, 104], "fisrt": [94, 98, 101], "restatur": [94, 96, 97, 98, 99, 101, 103, 104, 105], "1301": 94, "2087": 94, "1123": 94, "unfortun": [94, 96, 97], "ni": [94, 95], "sung": [94, 95], "ke": [94, 95], "1603": [94, 95], "05359": [94, 95], "sort": 95, "slate": [95, 100, 102, 105], "f_r": [95, 96, 101, 103, 107, 117], "bottom": [10, 95, 107], "she": 95, "latent": 95, "visibl": 95, "theta_i": [95, 96, 97, 99, 100, 101, 102, 103, 104, 105], "mathmat": 95, "model_cascad": [95, 96], "permut": 95, "ts_cascad": 95, "cascadelint": [95, 131], "mtss_cascad": 95, "chuklin": 95, "rijk": 95, "synthesi": 95, "lectur": 95, "retriev": [95, 107, 129], "2202": [95, 96, 100, 101, 102, 103, 107], "13227": [95, 96, 100, 101, 102, 103, 107], "ashkan": [95, 98, 100, 107, 117], "767": [95, 107, 117], "776": [95, 105, 107, 117], "cheung": [95, 97], "tan": [95, 97], "zhong": [95, 97], "22nd": [95, 97], "mtss": [96, 101, 103, 131], "general_hierach": [96, 101, 103], "mtt": [96, 101, 103], "subsum": [96, 101, 103, 107, 117], "full": [10, 96, 101, 131], "enjoi": [96, 103], "conjug": [96, 97, 103, 105, 115], "facilit": [96, 101, 103], "deploy": [96, 101, 103], "gamma_prior_mean": [96, 101, 103, 104], "gamma_prior_cov": [96, 101, 103, 104], "coverainc": [96, 103, 104], "n_init": [96, 103, 104, 106], "draw": [96, 103, 104], "mtss_agent": [96, 101, 103], "were": 60, "diverg": [], "tune": [], "target_accept": [], "reparameter": [], "2189": 96, "1610": 96, "1206": 96, "forcina": 96, "franconi": 96, "rivista": 96, "di": [96, 121, 122, 124, 125, 127], "applicata": 96, "salvati": [96, 103], "wiecki": [96, 103], "fonnesbeck": [96, 103], "peerj": [96, 103], "e55": [96, 103], "doi": [96, 103], "7717": [96, 103], "u_prior_alpha": [97, 105], "u_prior_beta": [97, 105], "ts_agent": [97, 99, 105], "2690": 97, "reach": 98, "kalman": 98, "filter": 98, "exact": 98, "Of": [98, 99, 101], "cours": [98, 99, 101], "welcom": [98, 99, 101], "combinatorial_semi": [98, 99, 101], "_env_realcomb": [98, 99, 101], "combsemi_env": [98, 99, 101], "prior_gamma_mu": 98, "prior_gamma_cov": [98, 101], "lints_semi": 98, "tot_r": [98, 99, 101], "480": 98, "1895": 98, "1700": 98, "2219": 98, "2807": 98, "1593": 98, "2784": 98, "172": [10, 98, 121, 123, 124], "2831": 98, "1523": [98, 101], "8214": 98, "2055": 98, "0487": 98, "8551": 98, "1778": 98, "595": [76, 98], "9068": 98, "6194": 98, "9444": [98, 101], "3574891974648375": 98, "1122": [98, 100], "began": 99, "famili": 99, "sub": [99, 118], "bay": [99, 101], "u_prior_cov_diag": 99, "diagon": 99, "ts_semi": 99, "1054": 99, "2060": 99, "494": 99, "1488": 99, "1351": 99, "898": 99, "1587": 99, "1114": [99, 101], "321": 99, "8094": 99, "8462": 99, "8306": 99, "6929": 99, "6706": 99, "6444": 99, "5902": 99, "5764": [99, 101], "0607550383245": 99, "yuan": [99, 100, 107, 117], "februari": 99, "perrault": 99, "boursier": 99, "valko": 99, "perchet": 99, "5429": 99, "5440": 99, "alloc": [100, 107, 117], "pali": 100, "sigma_2": [100, 101], "combt": [100, 131], "comblint": [100, 131], "mtss_comb": 100, "sankararaman": 100, "5114": 100, "5122": 100, "lmm": 101, "sigma_1": 101, "prior_gamma_mean": 101, "mtss_semi": 101, "686": [70, 101, 121, 122], "2132": 101, "689": 101, "1645": 101, "1733": 101, "2671": 101, "1611": 101, "2099": 101, "1668": 101, "9462": 101, "4307": 101, "9867": 101, "846": 101, "504": 101, "3613": 101, "6928": 101, "45535406270607": 101, "pari": 101, "golrezaei": 101, "ssrn": 101, "3651397": 101, "mnl": [102, 103, 104, 105, 106, 107, 131], "arguabl": 102, "eta_0": 102, "eta_1": 102, "eta_": [102, 103, 104, 105, 106], "eta_k": 102, "revenu": [102, 103, 104, 105], "convention": 102, "v_i": 102, "mnldist": 102, "cup": 102, "v_0": 102, "intract": [102, 105], "appear": [102, 103, 104, 105, 106], "matter": 102, "ts_mnl": 102, "ts_contextual_mnl": 102, "mtss_mnl": 102, "pentico": 102, "european": 102, "190": [102, 121, 124, 127], "295": 102, "luce": [102, 117], "courier": [102, 117], "corpor": [102, 117], "avadhanula": [102, 103, 104, 105, 106, 107], "zeevi": [102, 103, 105, 106, 107], "oh": [102, 103, 104], "iyengar": [102, 103, 104], "1485": [102, 105, 106], "ou": [102, 104], "1805": [102, 104], "02971": [102, 104], "concret": 103, "eqn1": 103, "logit": [103, 104, 105, 107, 117], "_env_realmnl": [103, 104, 105], "mnl_env": [103, 104, 105, 106], "same_reward": [103, 104, 105, 106], "clip": [103, 105], "275": [70, 103, 122], "448": [103, 104], "836": [103, 104], "9493188224156814": 103, "framwork": 104, "realtionship": 104, "mnl_ts_contextu": 104, "298": [70, 104, 122], "9729194890231303": 104, "tulabandhula": 104, "tractabl": [104, 105], "14033": 104, "multinomila": 105, "nice": [10, 105, 115], "ts_mnl_beta": 105, "mnl_t": 105, "864": [10, 105], "394": [105, 124, 125], "911": 105, "430": [105, 124, 125], "03330462654669619": 105, "dong": 105, "switch": [105, 132], "2607": 105, "2615": 105, "48log": 106, "_env_mnl": 106, "ipykernel_69552": [], "3115157464": [], "20000": [106, 129], "update_freq_linear": 106, "with_intercept": [106, 109, 110, 115, 116, 130], "x_mu": [106, 109, 110, 115, 116], "x_sigma": [106, 109, 110, 115, 116], "sigma_gamma": [106, 109, 110, 115, 116], "mu_gamma": 106, "exp_r": 106, "519": 106, "906": 106, "main_raw_model": [107, 117], "cardin": [107, 117], "exclud": [107, 117], "appeal": 107, "brows": 107, "02038": [107, 117], "2015a": [107, 117], "strike": 108, "unfamiliar": 108, "guaasian": [108, 131], "glmt": 108, "guassian": [108, 131], "writer": [108, 128], "2080": 108, "home": [109, 110, 115, 116], "lge": [109, 110, 115, 116], "ipykernel_69571": [], "3636065689": [], "sigma_theta": [109, 110, 115, 116], "mu_theta": [109, 110, 115, 116], "specifii": 109, "cnt": [109, 110], "rewrit": 110, "ipykernel_69576": [], "lints_bernoulli_ag": 110, "lints_bernoulli": 110, "breward": 115, "ipykernel_69581": [], "4375": 115, "ipykernel_69586": [], "rs": 116, "1249": 116, "cook": 117, "vast": 118, "disucss": 118, "hear": 118, "reader": [118, 128], "materi": 118, "recap": 118, "appraoch": 118, "mont": 118, "carlo": 118, "td": 118, "wait": 118, "paradigm": [118, 119], "trasit": 118, "schema": 118, "trpo": 118, "ppo": 118, "simplist": 118, "descient": 118, "around": [118, 124, 125], "fortun": [118, 119], "bigtriangledown_": 118, "abil": 118, "dqn": 118, "replai": 118, "scratch": 118, "Such": 118, "q_0": 118, "effiic": 118, "a2c": 118, "sac": 118, "a3c": 118, "pomdp_comparison": 119, "valuabl": 119, "infeas": 119, "horiozn": 119, "quickli": 119, "belief": 119, "subset_rl_data_final_cont": [121, 124], "mimic3_bas": [121, 124], "lambda": [121, 130], "ipykernel_69607": [], "4058168275": 121, "loc": [10, 70, 121, 124, 129, 130], "row_index": [121, 124], "col_index": [121, 124], "173913": [70, 121, 122, 124], "98685": [121, 124], "142857": [121, 124], "749": [121, 124], "200000": [121, 123, 124, 125, 127], "751": [121, 124], "545455": [121, 124], "030303": [121, 124, 125], "196": [121, 124, 127], "666667": [121, 123, 124], "753": 121, "mimic_fin": [121, 124], "692": [121, 124], "selected_id": 121, "dtr_data": 121, "concaten": [121, 122, 129, 130], "varnam": 121, "varname_format": 121, "bloc_1": 121, "bloc_2": 121, "bloc_3": 121, "died_within_48h_1": 121, "died_within_48h_2": 121, "icustayid_2": 121, "icustayid_3": 121, "died_within_48h_3": 121, "mimic3_dtr_3stage_v2": 121, "iv_input_3": [121, 123], "icustayid_1": 121, "glucose_1": [121, 123], "pao2_fio2_1": [121, 123], "iv_input_1": [121, 123], "sofa_1": [121, 123], "glucose_2": [121, 123], "pao2_fio2_2": [121, 123], "iv_input_2": [121, 123], "sofa_2": [121, 123], "glucose_3": [121, 123], "pao2_fio2_3": [121, 123], "sofa_3": [121, 123], "31005": 121, "833333": [121, 123], "364": [121, 123], "439": [121, 123], "310339": [121, 123], "10989": 121, "714286": [121, 123], "164": [121, 123], "174": [76, 121, 123, 124, 125, 127], "4132": [121, 124, 125, 127], "266": [121, 123], "600000": [121, 123, 124, 125], "388889": [121, 123], "37528": 121, "260": [121, 123], "777778": [121, 123], "257": [121, 123], "857143": [121, 123], "191": [121, 123, 127, 129], "935482": [121, 123], "86428": 121, "mrl_data": 121, "mdtr_data": [121, 123], "mimic3_mdtr_data_dict_3stage_v2": [121, 123], "wb": [121, 124, 128], "dump": [121, 124, 128], "mdtr_df": 121, "mimic3_mdtr_3stage_v2": [121, 123], "234036": [70, 121, 122], "next_stat": 121, "s0": 121, "time_idx": 121, "vstack": 121, "next_glucos": [70, 121, 122], "next_pao2_fio2": [70, 121, 122], "682": [70, 121, 122], "684": [70, 121, 122], "685": [70, 121, 122], "687": [70, 121, 122], "keyerror": [121, 125], "3741024878": [], "listcomp": [70, 121, 122], "frame": [10, 121, 125], "__getitem__": [121, 125], "3509": [121, 125], "is_iter": [121, 125], "3510": [121, 125], "3511": [121, 125], "_get_indexer_strict": [121, 125], "3512": [], "3513": [121, 125], "axis_nam": [121, 125], "5794": [], "keyarr": [121, 125], "new_index": [121, 125], "_reindex_non_uniqu": [121, 125], "5795": [], "5796": [], "_raise_if_miss": [121, 125], "5797": [], "5798": [], "5857": [], "5858": [], "not_found": [121, 125], "ensure_index": [121, 125], "missing_mask": [121, 125], "nonzero": [121, 125], "5859": [], "5860": [], "5861": [], "overload": 128, "next_pao2": 121, "next_sofa": 121, "rl_df": 121, "mimic3_rl_df": 121, "499996": 121, "427": 121, "632": 121, "633": 121, "634": 121, "97782": 121, "201": 121, "635": 121, "within": [121, 122, 124, 125, 127, 132], "48h": [121, 122, 124, 125, 127], "mimic3_multi_stag": [121, 124], "lag_k": [121, 124], "new_sofa": [121, 124], "mimic3_sampl": [121, 124], "groupbi": [121, 124, 128], "mimic3_single_stag": [121, 124, 125, 127], "ipykernel_69613": [], "1713212044": [], "data_num": [70, 122], "177": [45, 70, 76, 122], "_q_term": [70, 122], "178": [45, 70, 122], "er_sa0": [70, 122], "er_sa": [70, 122], "_er_sa0_sa": [70, 122], "rho_sam": [70, 122], "est_q4": [], "est_q5": [], "est_qdiff": [], "q1_diff": [], "eta_pi": [], "q5_diff": [], "eta_a0": [], "qlearner_linear": [70, 122], "q2_diff": [], "q3_diff": [], "q4_diff_1": [], "q4_diff_2": [], "_q_diff": [], "_er_sa0m": [], "354": [], "pie_a_": [], "q1_snext_am_mc": [], "q2_snext_am_mc": [], "q3_snext_am_mc": [], "q4_snext_am_mc": [], "q5_snext_am_mc": [], "q4_s_am_mc": [], "cal_q_am_mc": [], "357": [], "q1_snext_am": [], "pie_a_sprim": [], "425": [], "update_q1235_snext_am_mc": [], "428": [], "429": 129, "q4_snext_am_mc_astar": [], "update_q4_snext_am_mc_astar": [], "m_snext_a": [], "pmlearner": [70, 122], "sample_m": [70, 122], "441": 10, "action_list": [], "442": 10, "out_q1": [], "out_q2": [], "out_q3": [], "out_q5": [], "cal_newq_1235": [], "443": 10, "update_exp": [], "395": [], "396": [], "qs": [], "q_1235": [], "397": [], "398": [], "q1_est_beta": [], "q2_est_beta": [], "include_eta": [70, 122], "prod": [], "zip": 128, "bspline": [], "218": [70, 122], "220": [], "0058689011135968135": [70, 122], "002110278954293422": [70, 122], "002770561709572756": [70, 122], "0010678186846614852": [70, 122], "005821662648181514": [70, 122], "mimic3_mdtr": 123, "parenthesi": 123, "nde": [123, 127], "213": 123, "695": 123, "647": 123, "057": 123, "284": 123, "mediated_qlearn": 123, "mediatedqlearn": 123, "regime_control": 123, "regime_target": 123, "est_nde_ni": 123, "155758": 123, "212838": 123, "05708": 123, "_predict_value_boot": 123, "nie_s": 123, "nde_s": 123, "6474": 123, "6946": 123, "2835": 123, "q_1": 123, "q_2": 123, "a_2": 123, "_2": 123, "q_3": 123, "a_3": 123, "07": 123, "_3": 123, "polic": [123, 127], "policy1": [123, 127], "8991": 123, "policy2": [123, 127], "8246": 123, "0745": 123, "mortal": [123, 124, 125, 126, 127], "s1_1": 123, "s1_2": 123, "s1_3": 123, "s3_1": 123, "s3_2": 123, "s3_3": 123, "s4_1": 123, "s4_2": 123, "s4_3": 123, "8990981941216672": [], "8246053645689109": [], "0001": 123, "0012": [123, 127], "0551": 123, "00001": 123, "0070": 123, "0721": 123, "0008": 123, "0114": 123, "appl": [123, 127], "9637": 123, "summari": [123, 127, 131], "9637185597953756": [], "privaci": [124, 125, 126], "he": [124, 125, 126], "hour": [124, 125, 126], "diagram": [124, 125], "load_ext": [124, 125], "autoreload": [124, 125], "randn": [124, 125, 130], "rseed": [124, 125], "npseed": [124, 125], "math": [124, 125], "multiprocess": [124, 125], "pool": [124, 125], "functool": [124, 125], "ipykernel_69648": [], "1368811484": 124, "000": [124, 129], "625": 124, "428571": 124, "758782": 124, "818182": [124, 125, 127], "2718509362": 124, "081590": [124, 125], "800000": [124, 125, 127], "1204": [124, 125, 127], "794872": [124, 125, 127], "782051": [124, 125, 127], "668956": [124, 125], "153846": [124, 125, 127], "364286": [124, 125, 127], "956461": [124, 125, 127], "252": [70, 122, 124, 125], "883864": [124, 125], "4201": [124, 125, 127], "580087": [124, 125, 127], "083333": [124, 125, 127], "539": [10, 124, 125], "065657": [124, 125], "5170": [124, 125, 127], "525000": [124, 125, 127], "147": [124, 125, 127], "350198": [124, 125, 127], "616727": [124, 125], "437500": [124, 125, 127], "6504": [124, 125, 127], "081169": [124, 125, 127], "836364": [124, 125, 127], "423": [124, 125], "mimic3_data_fin": [124, 125], "smaple_demo": 124, "est_mt": [124, 125], "w_threshold": [124, 125], "refit": [124, 125], "demo_res_net": [124, 125], "topo_list": [124, 125], "topological_sort": [124, 125], "topolog": [124, 125], "buttom": [124, 125], "administrait": [124, 125], "35384615": [124, 125], "70769231": [124, 125], "06153846": [124, 125], "41538462": [124, 125], "76923077": [124, 125], "12307692": [124, 125], "47692308": [124, 125], "83076923": [124, 125], "18461538": [124, 125], "53846154": [124, 125], "gap": [124, 125], "intak": [124, 125], "death": [124, 125], "administr": [124, 125], "gradientboostingclassifi": [124, 125], "42850795": 124, "04122985": 124, "37054069": 124, "0055272": 124, "10384686": 124, "01457029": 124, "16909439": 124, "28221447": 124, "05764574": 124, "008193": 124, "30211856": 124, "0551675": 124, "01006845": 124, "09689565": 124, "10600407": 124, "18238777": 124, "44978522": 124, "19716563": 124, "289073": 124, "03827421": 124, "22619666": 124, "1875545": 124, "23778146": 124, "20841167": 124, "73958005": 124, "11909299": 124, "09661241": 124, "15624675": 124, "3466977": 124, "42682439": 124, "353852": 124, "12244475": 124, "53581201": 124, "38763738": 124, "00624024": 124, "02708992": 124, "08227609": 124, "09644005": 124, "19550407": 124, "30207966": 124, "03525717": 124, "34339108": 124, "30668368": 124, "11740263": 124, "23538089": 124, "41147115": 124, "46029296": 124, "10346963": 124, "51161134": 124, "04498817": 124, "18302802": 124, "21907476": 124, "54002382": 124, "23518752": 124, "06635588": 124, "83090637": 124, "3999141": 124, "counterintuit": [124, 125], "remind": [124, 125], "20399937380848096": [], "49003107": 124, "50057977": 124, "20914573": 124, "66345884": 124, "23977303": 124, "0794276": 124, "34455499": 124, "36109094": 124, "19848057": 124, "58006391": 124, "11359767": 124, "23537098": 124, "18899855": 124, "64967052": 124, "63723815": 124, "05042186": 124, "26366224": 124, "00872736": 124, "32914701": 124, "51474347": 124, "41667122": 124, "54158338": 124, "71321121": 124, "26489405": 124, "0774718": 124, "52229178": 124, "61766863": 124, "57557176": 124, "94774448": 124, "55186488": 124, "29666119": 124, "35960446": 124, "20136832": 124, "77408578": 124, "19227108": 124, "11463203": 124, "35932623": 124, "29545405": 124, "86337085": 124, "95171379": 124, "61272862": 124, "00475441": 124, "06064992": 124, "64206127": 124, "75432718": 124, "20535944": 124, "37009124": 124, "35431129": 124, "78816905": 124, "76940612": 124, "68175408": 124, "74628053": 124, "10881984": 124, "17531085": 124, "07151351": 124, "82140618": 124, "01038676": 124, "bad": [124, 125], "08642818615808806": [], "086": 124, "sample_demo": 125, "ipykernel_69660": [], "2233535502": [], "692308": 125, "636364": 125, "625000": 125, "45322357": 125, "12551825": 125, "31095315": 125, "06658004": 125, "14936954": 125, "13404695": 125, "32144405": 125, "41540906": 125, "11657287": 125, "0605553": 125, "41204992": 125, "350003": 125, "07587157": 125, "1937542": 125, "29406602": 125, "27231197": 125, "44362365": 125, "08949383": 125, "4349184": 125, "13355717": 125, "16845723": 125, "0938565": 125, "30817118": 125, "06978495": 125, "50736663": 125, "20295236": 125, "17239035": 125, "27745005": 125, "2927717": 125, "31615833": 125, "3621005": 125, "19816815": 125, "29745249": 125, "31014128": 125, "00821821": 125, "19483265": 125, "16912685": 125, "20077837": 125, "37305844": 125, "24538905": 125, "20552501": 125, "38095327": 125, "38948743": 125, "2780394": 125, "11502808": 125, "45806054": 125, "29489358": 125, "18854476": 125, "06531642": 125, "22022294": 125, "22806464": 125, "31916684": 125, "05725299": 125, "37429873": 125, "16776177": 125, "30377136": 125, "44658451": 125, "harm": 125, "21392525739350662": 125, "33471421": 125, "58750923": 125, "69769602": 125, "50468707": 125, "04119141": 125, "08032529": 125, "24677671": 125, "46879497": 125, "14228685": 125, "40913012": 125, "26967209": 125, "10424795": 125, "15469547": 125, "86680554": 125, "01699509": 125, "50534554": 125, "50120394": 125, "0832772": 125, "4053538": 125, "61938348": 125, "63167011": 125, "53840976": 125, "10602297": 125, "04338229": 125, "18159866": 125, "77996324": 125, "7988097": 125, "94550731": 125, "28227784": 125, "9895861": 125, "34582444": 125, "63707457": 125, "67745798": 125, "16396444": 125, "3173255": 125, "41720785": 125, "66927895": 125, "09861153": 125, "9408872": 125, "21402004": 125, "85013445": 125, "61804279": 125, "67352783": 125, "06219661": 125, "78217875": 125, "87809129": 125, "81120382": 125, "61344813": 125, "6384825": 125, "26478542": 125, "95845848": 125, "14744284": 125, "86349984": 125, "74704598": 125, "2168899": 125, "97526792": 125, "68596023": 125, "4460136626503026": 125, "446": [10, 125], "single_data": 127, "single_dataset": 127, "2133": 127, "0030": 127, "2104": 127, "2332": 127, "2276": 127, "0164": 127, "2440": 127, "_valid": 127, "372": 127, "fitfailedwarn": 127, "490": 127, "fail": [127, 132], "debug": 127, "error_scor": 127, "680": [127, 128], "_fit_and_scor": 127, "y_train": 127, "fit_param": 127, "_class": [70, 127], "937": 127, "super": 127, "203": 127, "check_classification_target": 127, "multiclass": 127, "y_type": 127, "some_fits_failed_messag": 127, "_search": 127, "ipykernel_69685": [], "2289951171": [], "palearn": 127, "pie_a": 127, "problearn": [70, 122, 127], "regressor": 127, "decisiontreeclassifi": 127, "183": 127, "best_param": 127, "best_params_": 127, "184": 127, "refit_start_tim": 127, "926": 127, "best_estimator_": 127, "927": 127, "928": 127, "check_input": [70, 127], "x_idx_sort": 127, "935": 127, "936": [], "938": 127, "939": 127, "is_classif": 127, "205": [], "195": 127, "multilabel": 127, "199": [], "23320671819000469": 127, "22762835456807218": 127, "01638548320515956": 127, "24401383777323174": 127, "9999": 127, "7646": 127, "2353": 127, "9999999999999999": 127, "764561656518231": 127, "0004": 127, "5510": 127, "greenland": 127, "exchang": 127, "epidemiolog": [127, 131], "latin": 128, "cleric": 128, "admin": 128, "farmer": 128, "homemak": 128, "lawyer": 128, "programm": 128, "retir": 128, "scientist": 128, "tradesman": 128, "craftsman": 128, "unemploi": 128, "ipykernel_69704": [], "407324603": 128, "parserwarn": 128, "back": 128, "regex": 128, "char": 128, "_decor": 128, "stacklevel": 128, "310": 128, "io": [128, 132], "parser": [10, 128], "filepath_or_buff": 128, "delimit": 128, "index_col": 128, "usecol": 128, "squeez": 128, "mangle_dupe_col": 128, "true_valu": 128, "false_valu": 128, "skipinitialspac": 128, "skiprow": 128, "skipfoot": 128, "nrow": 128, "na_valu": 128, "keep_default_na": 128, "na_filt": 128, "skip_blank_lin": 128, "parse_d": 128, "infer_datetime_format": 128, "keep_date_col": 128, "date_pars": 128, "dayfirst": 128, "cache_d": 128, "chunksiz": 128, "compress": 128, "decim": 128, "linetermin": 128, "quotechar": 128, "quot": 128, "doublequot": 128, "escapechar": 128, "comment": 128, "encoding_error": 128, "dialect": 128, "error_bad_lin": 128, "warn_bad_lin": 128, "on_bad_lin": 128, "delim_whitespac": 128, "low_memori": 128, "memory_map": 128, "float_precis": 128, "storage_opt": 128, "676": 128, "kwds_default": 128, "678": 128, "_read": 128, "573": [], "575": 128, "textfileread": 128, "576": [], "577": [10, 128], "930": 128, "iohandl": 128, "_engin": 128, "_make_engin": 128, "933": 128, "934": 127, "1214": 128, "pathlik": 128, "readcsvbuff": 128, "byte": 128, "1215": 128, "1216": 128, "get_handl": 128, "1217": 128, "path_or_buf": 128, "is_text": 128, "784": 128, "ioarg": 128, "785": 128, "786": 128, "787": 128, "788": 128, "timestamp": 128, "movie_titl": 128, "adventur": 128, "anim": 128, "children": 128, "crime": 128, "documentari": 128, "fantasi": 128, "noir": 128, "horror": 128, "music": 128, "mysteri": 128, "romanc": 128, "war": 128, "western": 128, "temp": [121, 124, 128], "idx_of_genr": 128, "idx": 128, "final_data": 128, "merg": 128, "flew": 128, "cuckoo": 128, "1975": [10, 128], "1000209": 128, "movielens_1m": 128, "popular_genr": 128, "sort_valu": 128, "ascend": 128, "popular_occup": 128, "col": [128, 129], "movielens_1m_popular": 128, "isin": 128, "119103": 128, "96564": 128, "77955": 128, "66745": 128, "54408": 128, "414775": 128, "gender_f": 128, "single_genr": 128, "multi_genr": 128, "nuniqu": 128, "movielens_cleaned_1m": 128, "linalg": [45, 128, 129, 130], "block_diag": [128, 130], "movielens_bandit": 128, "get_sum_r": 128, "denom": 128, "25182431": 128, "52394863": 128, "20922347": 128, "32501066": 128, "20043842": 128, "deepcopi": 128, "movielens_mtts_1m_gaussian": 128, "19933493": 128, "8245542": 128, "39117662": 128, "67363023": 128, "31367902": 128, "6491084": 128, "float": [10, 128], "movielens_mtts_1m_bernoulli": 128, "iteract": 129, "logged_data": 129, "get_logged_dat": [129, 130], "ipykernel_69709": [], "791222544": [], "685706": 129, "2042": 129, "499683": 129, "2424": 129, "694860": 129, "330": 129, "207691": 129, "169": 129, "3671": 129, "425839": 129, "213638": 129, "4140": 129, "242271": 129, "717322": 129, "4411": 129, "910": 129, "345927": 129, "870113": 129, "1226": [128, 129], "406": 129, "data_cel_sampl": 129, "1286": 129, "models_cel": 129, "whitespac": 129, "feature_nam": 129, "underlin": 129, "info": 129, "overhead": 129, "000062": [], "force_row_wis": 129, "And": 129, "force_col_wis": 129, "339901": 129, "inf": 129, "000009": [], "393": 129, "483461": 129, "000039": [], "319149": 129, "000035": [], "319527": 129, "000018": [], "951807": 129, "thev": 129, "age_rang": 129, "itertool": 129, "1224": [128, 129], "0439": 129, "7664": 129, "5822": 129, "6663": 129, "6364": 129, "1312": 129, "result_cel_nonlinear": 129, "122379": 129, "576471": 129, "066448": 129, "583382": 129, "133766": 129, "043862": 129, "205939": 129, "232727": 129, "766441": 129, "910281": 129, "336623": 129, "717603": 129, "160268": 129, "687924": 129, "331463": 129, "345233": 129, "377340": 129, "649888": 129, "039056": 129, "923635": 129, "1307": 129, "297553": 129, "090110": 129, "024221": 129, "658442": 129, "151436": 129, "1308": 129, "612166": 129, "695911": 129, "608458": 129, "740830": 129, "1309": 129, "582210": 129, "165707": 129, "552889": 129, "1310": 129, "666311": 129, "283311": 129, "129195": 129, "1311": 129, "636355": 129, "103647": 129, "115987": 129, "read": [10, 129], "te_femal": 129, "500268": 129, "309777": 129, "562432": 129, "605472": 129, "960134": 129, "te_mal": 129, "365749": 129, "321332": 129, "256846": 129, "447365": 129, "schi": 129, "lowest": 129, "models_cel_linear": 129, "result_cel_linear": 129, "323169": 129, "453650": 129, "692167": 129, "482883": 129, "357668": 129, "325782": 129, "098945": 129, "628177": 129, "145705": 129, "886814": 129, "578237": 129, "666234": 129, "464250": 129, "392727": 129, "691633": 129, "580850": 129, "311529": 129, "400261": 129, "055549": 129, "220779": 129, "530090": 129, "566701": 129, "455929": 129, "741310": 129, "570002": 129, "494923": 129, "259652": 129, "899359": 129, "006980": 129, "469963": 129, "444164": 129, "514824": 129, "955027": 129, "692742": 129, "819186": 129, "446776": 129, "160120": 129, "891038": 129, "355564": 129, "348332": 129, "699231": 129, "727408": 129, "727111": 129, "602585": 129, "153151": 129, "701844": 129, "372704": 129, "663122": 129, "265407": 129, "682297": 129, "te_female_linear": 129, "579924": 129, "402675": 129, "282099": 129, "511989": 129, "082199": 129, "te_male_linear": 129, "445089": 129, "423679": 129, "073189": 129, "236301": 129, "957766": 129, "cel_result": 129, "mean_error": 129, "genere_dat": 129, "genere_error": 129, "ddof": 129, "05i": 129, "sigma1": [129, 130], "cum_reward_inform": 129, "informative_t": 129, "cum_reward_informative_t": 129, "rec_action_informative_t": 129, "cumsum": [129, 130], "1000i": 129, "cum_reward_uninform": 129, "uninformative_t": 129, "cum_reward_uninformative_t": 129, "rec_action_uninformative_t": 129, "sole": 129, "cum_reward_greedi": [129, 130], "cum_reward_greedy_t": [129, 130], "rec_action_greedy_t": 129, "884": 129, "010": [10, 129], "011": 129, "391": 129, "674": 129, "061": 129, "041": 129, "088": 129, "algo": [129, 130], "lineplot": [129, 130], "hue": [129, 130], "n_boot": [129, 130], "linewidth": [129, 130], "marker": [129, 130], "bbox_to_anchor": [129, 130], "borderaxespad": [129, 130], "autoarg": 130, "true_model": 130, "logged_dat": 130, "randint": 130, "user_info": 130, "r_mean": 130, "optimal_action_reward": 130, "rec_genr": 130, "ipykernel_69720": [], "2393233947": [], "true_model_1": 130, "scifi": 130, "inercept": 130, "to_markdown": 130, "338373e": 130, "553173e": 130, "916054e": 130, "419341e": 130, "574240e": 130, "646757e": 130, "578371e": 130, "303934e": 130, "339018e": 130, "560132e": 130, "625256e": 130, "893010e": [], "984154e": [], "818640e": [], "184398e": 130, "816416e": 130, "784788e": 130, "145633e": 130, "053477e": 130, "396107e": 130, "478043e": 130, "337961e": 130, "061687e": 130, "295411e": 130, "821867e": 130, "000000e": 130, "0039255479596445": [], "33837": 130, "0564676": 130, "362526": 130, "81642": 130, "47804": 130, "89155": 130, "0193161": 130, "03163": 130, "85992": 130, "25443": 130, "0739259": 130, "329217": 130, "58364": 130, "58031": 130, "0130774": 130, "23706": 130, "81737": 130, "880949": 130, "0499074": 130, "880965": 130, "87681": 130, "995856": 130, "estimated_gamma": 130, "cum_reward_infolint": 130, "cum_reward_uninfolint": 130, "cum_reward_uninfolinucb": 130, "cum_reward_t": 130, "cum_reward_ucb": 130, "info_lint": 130, "cum_reward_infolints_t": 130, "uninfo_lint": 130, "cum_reward_uninfolints_t": 130, "uninfo_linucb": 130, "cum_reward_uninfolinucb_t": 130, "uninfo_t": 130, "cum_reward_ts_t": 130, "uninfo_ucb": 130, "cum_reward_ucb_t": 130, "tight_layout": 130, "savefig": 130, "movielens_contextu": 130, "432x288": 130, "workflow": 131, "merit": 131, "downsid": 131, "miscellan": 131, "wish": 131, "ccc": 131, "hline": 131, "vdot": 131, "hdashlin": 131, "ct": 131, "bs": 131, "unrel": 131, "correpond": 131, "conjunct": 131, "bowl": 131, "quatil": 131, "otr": 131, "jump": 131, "comb": 131, "practition": 132, "handbook": 132, "complement": 132, "unifi": 132, "desktop": 132, "branch": 132, "visiabl": 132, "_build": 132, "commit": 132, "push": 132, "cd": 132, "password": 132, "gh": [121, 125, 132], "reinstal": 132, "credenti": 132, "token": 132, "cname": 132, "restart": [], "200940": [], "860076": [], "429924": [], "567775": [], "773225": [], "757968": [], "492155": [], "995205": [], "788571": [], "010011": [], "330366": [], "338528": [], "244661": [], "584258": [], "041915": [], "080423": [], "200256": [], "779331": [], "424088": [], "658939": [], "120684": [], "690309": [], "192955": [], "192424": [], "349678": [], "490935": [], "157418": [], "381966": [], "161022": [], "397795": [], "ipykernel_69931": [], "2212": 60, "14466": 60, "848432": [], "094492": [], "461446": [], "408936": [], "551120": [], "381643": [], "506465": [], "111141": [], "951119": [], "692756": [], "029846": [], "850486": [], "475040": [], "545858": [], "278642": [], "374928": [], "025845": [], "272796": [], "530463": [], "881486": [], "874465": [], "311966": [], "739413": [], "225175": [], "103833": [], "696629": [], "292097": [], "497187": [], "677902": [], "992124": [], "ipykernel_69961": [], "usag": 10, "create_new": 10, "invalid": 10, "argumenterror": 10, "argpars": 10, "1857": 10, "argumentpars": 10, "parse_known_arg": 10, "1856": 10, "_parse_known_arg": 10, "arg_str": 10, "2065": 10, "start_index": 10, "consume_opt": 10, "option_str": 10, "action_tupl": 10, "1918": 10, "argument_str": 10, "1917": 10, "seen_act": 10, "argument_valu": 10, "_get_valu": 10, "1920": 10, "1921": 10, "seen": 10, "1922": 10, "realli": 10, "2450": 10, "2449": 10, "_check_valu": 10, "remaind": 10, "2506": 10, "2505": 10, "msg": [10, 128], "systemexit": 10, "interactiveshel": 10, "2727": 10, "safe_execfil": 10, "fname": 10, "exit_ignor": 10, "raise_except": 10, "shell_futur": 10, "2726": 10, "glob": 10, "py3compat": 10, "execfil": 10, "2728": 10, "2729": 10, "2730": 10, "2731": 10, "exit": 10, "sy": 10, "2732": 10, "bother": 10, "2738": 10, "2739": 10, "silenc": 10, "exec": 10, "2_causal_structure_learn": 10, "add_argu": 10, "3e": 10, "parse_arg": 10, "1824": 10, "1823": 10, "argv": 10, "1825": 10, "err": 10, "_sy": 10, "exc_info": 10, "2581": 10, "2580": 10, "prog": 10, "2568": 10, "2567": 10, "_print_messag": 10, "stderr": 10, "assertionerror": 10, "get_ipython": 10, "run_line_mag": 10, "2294": 10, "magic_nam": 10, "_stack_depth": 10, "2292": 10, "local_n": 10, "get_local_scop": 10, "stack_depth": 10, "builtin_trap": 10, "2295": 10, "magic": 10, "829": 10, "executionmag": 10, "parameter_": 10, "runner": 10, "file_find": 10, "826": 10, "_run_with_tim": 10, "nrun": 10, "827": 10, "828": 10, "831": 10, "832": 10, "shell": 10, "user_n": 10, "__name__": 10, "__name__sav": 10, "814": 10, "813": 10, "filenam": [10, 128], "prog_n": 10, "815": 10, "2744": 10, "2742": 10, "2743": 10, "showtraceback": 10, "exception_onli": 10, "2746": 10, "exc_tupl": 10, "tb_offset": 10, "running_compiled_cod": 10, "stb": 10, "interactivetb": 10, "get_exception_onli": 10, "etyp": 10, "1976": 10, "customis": 10, "1977": 10, "1978": 10, "ultratb": 10, "585": 10, "listtb": 10, "structured_traceback": 10, "etb": 10, "chained_exc_id": 10, "chained_exceptions_tb_offset": 10, "out_list": 10, "445": 10, "chained_exception_messag": 10, "449": 10, "autoformattedtb": 10, "number_of_lines_of_context": 10, "1116": 10, "1117": 10, "formattedtb": 10, "1012": 10, "1009": 10, "1010": 10, "verbose_mod": 10, "1011": 10, "verbosetb": 10, "1013": 10, "1014": 10, "1015": 10, "1016": 10, "865": 10, "856": 10, "857": 10, "858": 10, "862": 10, "863": 10, "formatted_except": 10, "format_exception_as_a_whol": 10, "866": 10, "868": 10, "color": 10, "shorthand": 10, "quicker": 10, "lookup": 10, "colorsnorm": 10, "799": 10, "796": [10, 128], "assert": [10, 128], "isinst": [10, 121, 125, 128], "797": [10, 128], "prepare_head": 10, "long_head": 10, "798": [10, 128], "get_record": 10, "802": 10, "803": 10, "848": 10, "formatt": 10, "849": 10, "stack_data": 10, "850": 10, "851": 10, "852": 10, "pygments_formatt": 10, "853": 10, "frameinfo": 10, "546": 10, "cl": 10, "frame_or_tb": 10, "collapse_repeated_fram": 10, "530": 10, "classmethod": 10, "531": 10, "537": 10, "repeatedfram": 10, "538": 10, "stack": 10, "consecut": 10, "collaps": 10, "544": 10, "configur": 10, "545": 10, "iter_stack": 10, "548": 10, "549": 10, "is_fram": 10, "f_back": 10, "frametyp": 10, "tracebacktyp": 10, "assert_": 10, "212": 10, "026": 10, "068": 10, "043": 10, "084": 10, "072": 10, "055": 10, "070": 10, "079": 10, "047": 10, "052": 10, "014": 10, "winerror": [15, 16, 17, 20, 21, 24, 26, 27, 28, 29, 33, 40, 60, 63, 64, 66, 67, 68, 69, 71, 73, 109, 110, 115, 116], "\u7cfb\u7edf\u627e\u4e0d\u5230\u6307\u5b9a\u7684\u8def\u5f84": [15, 16, 17, 20, 21, 24, 26, 27, 28, 29, 33, 40, 60, 109, 110, 115, 116], "14529621186817238": 15, "3556423779577757": 15, "15559049518872164": 15, "010294283320549269": 15, "elapsed_tim": 17, "285": 17, "40207719802856": 17, "2031": 17, "2s": 17, "898u": 17, "964u": 17, "7404845356941223": 17, "7264252305030823": 17, "ipykernel_35787": 21, "226": [22, 23], "s_2": [22, 23], "discrete_model": [45, 76], "multinomialresultswrapp": [45, 76], "0x16caf8463a0": 45, "3997e": 45, "4189e": 45, "7181e": 45, "estimate_v0": [45, 76], "_get_pseudo_i": [45, 76], "tmp_mul": [45, 76], "contrast_model": [45, 76], "diag": [45, 76], "fitted_prop": [45, 76], "new_psi": 45, "inv": 45, "old_psi": 45, "__array_function__": [45, 76, 122, 129, 130], "correspod": [45, 59], "emphasi": 49, "dosag": 49, "insulin": 49, "0x1c79d964c10": 59, "48792828230197": 59, "98578411527006": 59, "169320881224378": 59, "08401669326004": 59, "881528995771149": 59, "163285": 60, "060892": 60, "564377": 60, "311135": 60, "514363": 60, "626760": 60, "427137": 60, "358856": 60, "876148": 60, "244680": 60, "512531": 60, "178680": 60, "693552": 60, "176564": 60, "439753": 60, "025400": 60, "019747": 60, "915541": 60, "021311": 60, "358523": 60, "304276": 60, "201337": 60, "804306": 60, "396420": 60, "136516": 60, "353355": 60, "833605": 60, "143646": 60, "682747": 60, "902863": 60, "\u7cfb\u7edf\u627e\u4e0d\u5230\u6307\u5b9a\u7684\u6587\u4ef6": [63, 64, 66, 67, 68, 69, 71, 73], "gather": 65, "qlearner": [70, 122], "rewardlearn": [70, 122, 127], "est_q1": [70, 122], "est_q2": [70, 122], "sigma_control": [70, 122], "_sigma": [70, 122], "sigma_target": [70, 122], "sigma_g": [70, 122], "er_sam_pi": 70, "_er_sam_pi": 70, "policy_nam": [70, 122], "matmul": [70, 122], "_xi": [70, 122], "301": [70, 122], "303": [70, 122], "ridg": [70, 122], "304": [70, 122], "s_next": [70, 122], "pa_star": [70, 122], "target_pa_next": 70, "a_star": [70, 122], "sample_phi": [70, 122], "mcmc_em_phi": [70, 122], "253": [70, 122], "para_dim": [70, 122], "unique_act": [70, 122], "276": [70, 122], "279": [70, 122], "pm": [70, 122], "pm_i": 70, "tree_model": 70, "468": 70, "basedecisiontre": [70, 127], "466": 70, "check_is_fit": 70, "467": 70, "_validate_x_predict": 70, "proba": 70, "tree_": 70, "469": 70, "n_sampl": 70, "471": 70, "01810020554867914": 70, "006066387156687134": 70, "004866328022066192": 70, "00018158807389352197": 70, "017081734487951722": 70, "dedic": 72, "0x1d95642dee0": 76, "0x1d95646b040": 76, "0x1d95646ba00": 76, "8924": 76, "1455": 76, "5109": 76, "1229": 76, "0503": 76, "9351": 76, "7725": 76, "0474": 76, "4662578531563": 76, "173": 76, "old_contrast": 76, "q0_model": 76, "new_phi": 76, "0x188f6b7fac0": [], "0x188fcdd6d00": [], "0x188fd976670": [], "3004201781755": 78, "2706553051503": [], "491781916721667": [], "vivia": [121, 124, 128], "appdata": [121, 124, 128], "ipykernel_27140": 121, "3514": [121, 125], "getattr": [121, 125], "5782": [121, 125], "5779": [121, 125], "5780": [121, 125], "5784": [121, 125], "5785": [121, 125], "5786": [121, 125], "42790": [121, 125], "preserv": [121, 125], "5845": [121, 125], "5842": [121, 125], "5844": [121, 125], "_u4al": 122, "action1": 122, "state1": 122, "shape_bas": 122, "345": 122, "tup": 122, "343": 122, "_nx": 122, "arr": 122, "344": 122, "8990981941216631": 123, "8246053645689122": 123, "9637185597953717": 123, "ipykernel_36684": 124, "20399937380853927": 124, "08642818615808659": 124, "i_a": 127, "basesearchcv": 127, "899": 127, "902": 127, "903": 127, "904": 127, "941": 127, "n_outputs_": 127, "classes_": 127, "type_of_target": 127, "ipykernel_34172": 128, "deprecate_nonkeyword_argu": 128, "decor": 128, "num_allow_arg": 128, "307": 128, "308": 128, "665": 128, "_refine_defaults_read": 128, "666": 128, "572": 128, "_validate_nam": 128, "has_index_nam": 128, "1213": 128, "1219": 128, "1220": 128, "1221": 128, "1222": 128, "1223": 128, "1227": 128, "1228": 128, "789": 128, "newlin": 128, "790": 128, "791": 128, "792": 128, "793": 128, "794": 128, "795": 128, "001251": 129, "000065": 129, "000119": 129, "000219": 129, "000162": 129, "sampled_beta": [129, 130], "multivariate_norm": [129, 130], "cov": [129, 130], "sampled_r": [129, 130], "mtrand": [129, 130], "pyx": [129, 130], "4120": [129, 130], "randomst": [129, 130], "svd": [129, 130], "1660": [129, 130], "full_matric": [129, 130], "compute_uv": [129, 130], "hermitian": [129, 130], "1657": [129, 130], "gufunc": [129, 130], "_umath_linalg": [129, 130], "svd_n_": [129, 130], "1659": [129, 130], "ddd": [129, 130], "iscomplextyp": [129, 130], "vh": [129, 130], "extobj": [129, 130], "1661": [129, 130], "result_t": [129, 130], "1662": [129, 130], "_realtyp": [129, 130], "333319e": 130, "835612e": 130, "608225e": 130, "003925547959648": 130, "0x2939a7beeb0": 78, "0x293a09f2dc0": 78, "0x293a15b7670": 78, "3666811952648": 78, "7349311391153175": 78}, "objects": {}, "objtypes": {}, "objnames": {}, "titleterms": {"learner": [0, 9, 10, 11, 13, 14, 16, 20, 22, 24, 25, 26, 28, 29, 42, 43, 50, 51, 70, 81, 82, 83, 85, 86, 87, 89, 94, 96, 97, 98, 99, 101, 103, 104, 105], "name": [0, 131], "singl": [0, 19, 27, 61, 62, 108, 121, 127], "multipl": [0, 21, 37, 77, 128], "stage": [0, 19, 27, 37, 61, 77, 121, 123, 127], "infinit": [0, 63, 68, 71, 73, 122], "horizon": [0, 63, 68, 71, 73, 122], "main": [0, 11, 14, 19, 45, 48, 50, 59, 60, 63, 64, 66, 67, 68, 69, 70, 71, 73, 76, 78, 81, 82, 83, 85, 86, 87, 89, 90, 91, 92, 94, 96, 97, 98, 99, 101, 103, 104, 105, 106, 109, 110, 115, 116], "idea": [0, 11, 14, 19, 45, 48, 50, 59, 60, 63, 64, 66, 67, 68, 69, 70, 71, 73, 76, 78, 81, 82, 83, 85, 86, 87, 89, 90, 91, 92, 94, 96, 97, 98, 99, 101, 103, 104, 105, 106, 109, 110, 115, 116], "algorithm": [0, 11, 13, 14, 40, 45, 59, 60, 76, 78, 79, 83, 85, 86, 95, 96, 100, 101, 102, 103, 106, 108, 109, 110, 115, 116], "detail": [0, 9, 11, 13, 14, 45, 50, 59, 76, 78, 83, 85, 86, 96, 101, 103, 106, 109, 110, 115, 116], "kei": [0, 45, 59, 76, 78, 81, 82, 83, 85, 86, 87, 89, 94, 96, 97, 98, 99, 101, 103, 104, 105, 106, 109, 110, 115, 116], "step": [0, 45, 59, 76, 78, 81, 82, 83, 85, 86, 87, 89, 94, 96, 97, 98, 99, 101, 103, 104, 105, 106, 109, 110, 115, 116, 132], "demo": [0, 11, 13, 14, 21, 33, 40, 45, 48, 50, 59, 60, 63, 64, 66, 67, 68, 69, 70, 73, 76, 78, 81, 82, 83, 85, 86, 87, 89, 90, 91, 92, 94, 96, 97, 98, 99, 101, 103, 104, 105, 106, 109, 110, 115, 116, 124, 125], "code": [0, 5, 11, 13, 14, 45, 50, 59, 70, 76, 78, 81, 82, 83, 85, 86, 87, 89, 90, 91, 92, 94, 96, 97, 98, 99, 101, 103, 104, 105, 106, 109, 110, 115, 116], "1": [0, 2, 9, 11, 12, 13, 14, 15, 17, 21, 22, 26, 27, 45, 50, 59, 71, 76, 78, 90, 91, 92, 108, 131, 132], "polici": [0, 2, 7, 45, 50, 56, 59, 60, 63, 64, 65, 68, 70, 71, 72, 73, 74, 75, 76, 78, 90, 91, 92, 93, 118, 119, 123, 127, 130, 131], "learn": [0, 1, 2, 3, 27, 37, 45, 47, 48, 50, 52, 55, 59, 62, 63, 70, 71, 76, 78, 95, 118, 119, 124, 125, 129, 131], "2": [0, 2, 9, 11, 12, 13, 14, 15, 17, 21, 22, 27, 28, 32, 45, 50, 59, 71, 76, 78, 90, 91, 92, 121, 131, 132], "evalu": [0, 7, 45, 50, 59, 60, 63, 64, 65, 66, 68, 71, 73, 74, 75, 76, 78, 90, 91, 92, 93, 118, 123, 127], "refer": [0, 2, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 33, 35, 36, 37, 39, 40, 41, 42, 43, 45, 48, 50, 59, 60, 63, 64, 66, 67, 68, 69, 70, 73, 74, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 115, 116, 117, 118, 119, 122, 123, 127, 131], "causal": [1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 27, 75, 124, 125, 129, 131], "effect": [1, 4, 6, 10, 12, 21, 27, 70, 124, 125, 129, 131], "cel": [1, 27, 122, 123, 127, 131], "clinic": [1, 2], "trial": 1, "advertis": 1, "market": 1, "more": 1, "beyond": 1, "cpl": [2, 123, 127, 131], "scenario": 2, "fix": [2, 131], "independ": [2, 131], "state": [2, 131], "person": [2, 12], "incent": 2, "ad": [2, 5], "target": [2, 17, 70], "bid": 2, "markovian": [2, 118, 119, 131], "transit": [2, 131], "mobil": 2, "health": 2, "3": [2, 9, 11, 12, 13, 14, 15, 21, 22, 29, 38, 90, 91, 92, 121, 123, 131], "non": [2, 11, 119, 131], "healthcar": 2, "trail": 2, "multi": [2, 84, 87, 112], "touch": 2, "attribut": 2, "4": [2, 24, 25, 131], "adapt": [2, 54, 131], "recommend": [2, 81, 82, 83, 85, 86, 87, 89, 94, 96, 97, 98, 99, 101, 103, 104, 105, 107, 108, 117], "system": 2, "onlin": [2, 90, 91, 92, 93, 95, 100, 129, 130], "dynam": [2, 70, 102], "price": 2, "5": [2, 16, 25, 128, 131], "6": [2, 20, 25, 131], "structur": [3, 9, 11, 13, 14, 80, 84, 107, 131], "csl": [3, 131], "spread": 3, "covid": 3, "19": 3, "gene": 3, "express": 3, "trait": 3, "yeast": 3, "infer": [4, 5, 6], "101": [4, 5], "potenti": [4, 6, 75, 132], "outcom": [4, 6, 48, 52, 75, 124, 125], "assumpt": [4, 6, 15, 33], "averag": [4, 6], "regress": 4, "model": [4, 9, 11, 13, 14, 118, 119, 129, 130], "propens": 4, "score": [4, 13], "stratif": 4, "invers": [4, 92], "weight": [4, 48, 92], "doubli": [4, 15, 63, 91], "robust": [4, 15, 21, 63, 91], "estim": [4, 15, 19, 21, 33, 63, 65, 70, 129], "what": [5, 131], "myst": 5, "ar": 5, "role": 5, "direct": [5, 15, 21, 90], "us": [5, 48], "citat": 5, "execut": 5, "your": 5, "markdown": 5, "file": 5, "preliminari": [6, 8, 12, 74, 75], "do": [6, 58], "oper": 6, "treatment": [6, 10, 12, 21, 60], "heterogen": [6, 12], "optim": [7, 60, 71, 72, 74, 75, 100, 102, 118, 123, 127, 130], "discoveri": [9, 10, 11, 13, 14, 124, 125], "gener": [9, 11, 12, 13, 14, 18, 23, 81, 82, 83, 85, 86, 87, 89, 94, 96, 97, 98, 99, 101, 103, 104, 105, 121], "graph": [9, 11, 12, 13, 14], "terminolog": [9, 11, 12, 13, 14], "overview": [9, 13, 50, 79, 81, 82, 83, 85, 86, 87, 89, 91, 94, 96, 97, 98, 99, 101, 103, 104, 105, 131], "popular": 9, "graphic": [9, 11, 13, 14, 80, 84], "linear": [9, 11, 13, 14, 129], "equat": [9, 11, 13, 14], "addit": [9, 11, 13], "nois": [9, 11, 13], "lsem": [9, 13], "method": [9, 15, 108], "To": [9, 58], "Be": 9, "For": 9, "paradigm": [9, 27, 32, 38, 131], "mediat": [10, 12, 21, 70, 121, 122, 123, 127], "analysi": [10, 12, 21, 70, 122, 123, 127, 129], "from": 10, "tabl": 10, "anoc": 10, "cvae": 10, "cai": 10, "et": [10, 13], "al": [10, 13], "2020": 10, "function": [11, 70, 74], "base": [11, 13, 14, 51, 69, 118], "goal": [11, 13, 14], "applic": [11, 13, 14], "gaussian": [11, 14, 108], "gaussain": 11, "synthet": [11, 13, 14, 40, 41, 42, 43], "dataset": [11, 13, 14, 60, 121, 128], "ica": 11, "lingam": 11, "summari": [11, 13, 14], "result": [11, 13, 14, 129], "under": [11, 13, 14, 75, 90, 91, 92, 128], "differ": [11, 13, 14, 19, 33], "exampl": 12, "decis": [12, 32, 71, 74, 75], "make": 12, "real": [12, 27, 60, 61, 77, 80, 84, 88, 95, 100, 102, 107, 108, 117], "case": 12, "sepsi": 12, "intens": 12, "care": 12, "unit": 12, "icu": 12, "toi": 12, "remark": 12, "notear": 13, "zheng": 13, "2018": 13, "test": [14, 62], "pc": 14, "ATE": [15, 30], "identif": [15, 21], "import": [15, 68, 70, 73, 81, 82, 83, 85, 86, 87, 89, 94, 96, 97, 98, 99, 101, 103, 104, 105, 132], "sampl": [15, 68, 73, 87, 89, 108], "dr": [16, 25], "movielen": [16, 17, 18, 20, 24, 26, 28, 29, 129], "data": [16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 38, 54, 57, 60, 61, 70, 77, 80, 84, 88, 95, 100, 102, 107, 108, 117, 121, 128, 131], "8": [17, 23], "dragon": [17, 23], "net": [17, 23], "part": 17, "dragonnet": 17, "regular": 17, "7": [18, 23], "random": [18, 23], "forest": [18, 23], "hte": [19, 31], "approach": [19, 23], "The": 19, "advantag": 19, "lp": [20, 25], "r": [20, 24, 25, 39], "definit": [21, 33], "ipw": 21, "mr": 21, "aurora": 21, "covid19": 21, "meta": [22, 88, 89, 114], "s": [22, 26], "t": [22, 28], "x": [22, 29, 43], "other": 23, "movi": [27, 128], "len": 27, "pre": 27, "process": [27, 32, 60, 74, 75], "final": 27, "select": 27, "mimic3": [27, 124, 125, 126], "markov": [32, 74, 75], "background": [33, 40], "time": [33, 57], "vari": 33, "att": 33, "extens": 34, "h1sl": 35, "h2sl": 35, "matrix": 36, "complet": 36, "mediatedq": 37, "panel": [38, 131], "did": [39, 41], "control": [40, 70], "miscellan": 44, "A": [45, 62, 76, 131], "reduct": 46, "classif": 46, "problem": [46, 61, 77, 80, 84, 88, 95, 100, 102, 107, 108, 117], "entropi": 47, "when": [48, 132], "should": 48, "i": [48, 131], "owl": 48, "spars": 48, "a1": 48, "deriv": 48, "continu": [49, 50], "action": [49, 50, 53], "space": [49, 53], "deep": 50, "jump": 50, "difficulti": 50, "kernel": 51, "discret": 53, "collect": 54, "concord": 55, "assist": 55, "search": 56, "event": 57, "plan": 58, "q": [59, 66, 67, 71, 78], "quantil": 60, "regim": 60, "motiv": 60, "simul": [60, 108, 130], "calcul": 60, "off": [60, 64, 74, 75], "set": [61, 77, 80, 84, 88, 95, 100, 102, 107, 108, 117], "doubl": 63, "reinforc": [63, 70], "stationari": [63, 68], "distribut": [63, 68, 69], "todo": [63, 64, 66, 67, 68, 69, 73], "note": [63, 64, 68, 69, 73], "deepli": 64, "debias": 64, "valu": [65, 74, 118], "fit": [66, 67, 129], "iter": 67, "break": 68, "curs": 68, "confid": [69, 108], "interv": 69, "op": 69, "asymptot": 69, "ci": 69, "drl": 69, "load": 70, "observ": [70, 128], "specifi": [70, 81, 82, 83, 85, 86, 87, 89, 94, 96, 97, 98, 99, 101, 103, 104, 105, 130], "hyperparamet": [70, 81, 82, 83, 85, 86, 87, 89, 94, 96, 97, 98, 99, 101, 103, 104, 105], "defin": 70, "obtain": 70, "each": 70, "compon": 70, "standard": 70, "error": [70, 132], "framework": [75, 90, 91, 92], "identifi": 75, "dtr": [77, 121], "bandit": [79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 95, 100, 102, 107, 108, 128, 131], "contextu": 80, "lint": [81, 110], "environ": [81, 82, 83, 85, 86, 87, 89, 94, 96, 97, 98, 99, 101, 103, 104, 105, 118, 119, 130], "interact": [81, 82, 83, 85, 86, 87, 89, 94, 96, 97, 98, 99, 101, 103, 104, 105], "bernoulli": [81, 82, 83, 85, 86, 87, 89, 108, 128], "linucb": [82, 111], "epsilon": [83, 108], "greedi": [83, 108, 129], "arm": 84, "mab": [84, 130], "ts": [85, 90, 91, 92, 114, 115, 129], "ucb": [86, 90, 91, 92], "task": [87, 112], "thompson": [87, 89, 108], "mtt": [87, 113], "eg": [90, 91, 92], "probabl": [91, 92], "explor": [91, 92], "cascadelint": 94, "rank": 95, "cascad": 95, "support": [95, 100, 102, 108], "mtss_cascad": 96, "ts_cascad": 97, "comblint": 98, "combt": 99, "combinatori": 100, "semi": 100, "mtss_comb": 101, "assort": 102, "multinomi": 102, "logit": 102, "mtss_mnl": 103, "ts_contextual_mnl": 104, "ts_mnl": 105, "ucb_mnl": 106, "slate": [107, 117], "item": 108, "claasic": 108, "upper": 108, "bound": 108, "epsilon_greedi": 109, "ucb1": 116, "oolin": [118, 119], "gradient": 118, "approxim": 118, "dp": 118, "actor": 118, "critic": 118, "mimic": [120, 122, 123, 127], "iii": [120, 122, 123, 127], "mrl": 121, "rl": 121, "creat": 121, "regard": [124, 125], "died_within_48h": [124, 125], "variabl": [124, 125, 128], "sofa": [124, 125], "ver2": 125, "read": 128, "keep": 128, "onli": 128, "top": 128, "occup": 128, "genr": 128, "convert": 128, "gender": 128, "dummi": 128, "subset": 128, "user": 128, "least": 128, "500": 128, "format": 128, "nonlinear": 129, "sigma": 129, "boldsymbol": 129, "gamma": 129, "run": [129, 132], "inform": 129, "uninform": 129, "true": 130, "offlin": 130, "introduct": 131, "author": 131, "expect": 131, "sl": 131, "ml": 131, "case1": 131, "d": 131, "pl": 131, "case2": 131, "case3": 131, "case4": 131, "case5": 131, "case6": 131, "appendix": 131, "singeldtr": 131, "mdp": 131, "b": 131, "multidtr": 131, "c": 131, "content": 132, "everi": 132, "notebook": 132, "how": 132, "contribut": 132, "compil": 132, "new": 132, "version": 132, "option": 132, "publish": 132, "messag": 132, "ghp": 132}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinxcontrib.bibtex": 9, "sphinx": 56}})
>>>>>>> Stashed changes
