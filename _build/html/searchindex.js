Search.setIndex({"docnames": ["0_Learner Template", "0_Motivating_Examples/CEL", "0_Motivating_Examples/CPL", "0_Motivating_Examples/CSL", "1_Preliminary/(old) Causal Inference 101", "1_Preliminary/Causal Inference 101_old", "1_Preliminary/Causal Inference Preliminary", "1_Preliminary/Policy Evaluation and Optimization", "1_Preliminary/Preliminary", "2_Causal_Structure_Learning/Causal Discovery", "2_Causal_Structure_Learning/Causal Mediation Analysis", "2_Causal_Structure_Learning/Functional-based Learner", "2_Causal_Structure_Learning/Preliminaries of Causal Graphs", "2_Causal_Structure_Learning/Score-based Learner", "2_Causal_Structure_Learning/Testing-based Learner", "3_Causal_Effect_Learning/Scenario 1/ATE", "3_Causal_Effect_Learning/Scenario 1/DR-Learner", "3_Causal_Effect_Learning/Scenario 1/Dragonnet", "3_Causal_Effect_Learning/Scenario 1/GRF", "3_Causal_Effect_Learning/Scenario 1/HTE", "3_Causal_Effect_Learning/Scenario 1/Lp-R-Learner", "3_Causal_Effect_Learning/Scenario 1/Mediation Analysis", "3_Causal_Effect_Learning/Scenario 1/Meta Learners", "3_Causal_Effect_Learning/Scenario 1/Other Approaches", "3_Causal_Effect_Learning/Scenario 1/R-Learner", "3_Causal_Effect_Learning/Scenario 1/R-Learner, DR-Learner, Lp-R-Learner", "3_Causal_Effect_Learning/Scenario 1/S-learner", "3_Causal_Effect_Learning/Scenario 1/Single Stage", "3_Causal_Effect_Learning/Scenario 1/T-learner", "3_Causal_Effect_Learning/Scenario 1/X-learner", "3_Causal_Effect_Learning/Scenario 2/ATE", "3_Causal_Effect_Learning/Scenario 2/HTE", "3_Causal_Effect_Learning/Scenario 2/underMDP", "3_Causal_Effect_Learning/Scenario 3/ATE", "3_Causal_Effect_Learning/Scenario 3/DiD", "3_Causal_Effect_Learning/Scenario 3/H1SL_H2SL", "3_Causal_Effect_Learning/Scenario 3/HTE", "3_Causal_Effect_Learning/Scenario 3/Panel Data", "3_Causal_Effect_Learning/Scenario 3/R-DiD", "3_Causal_Effect_Learning/Scenario 3/Synthetic Control", "3_Causal_Effect_Learning/Scenario 3/Synthetic DiD", "3_Causal_Effect_Learning/Scenario 3/Synthetic Learner", "3_Causal_Effect_Learning/Scenario 3/Synthetic X-Learner", "3_Causal_Effect_Learning/Scenario 4/Miscellaneous", "4_Causal_Policy_Learning/Scenario1/A-learning_Single", "4_Causal_Policy_Learning/Scenario1/Classification", "4_Causal_Policy_Learning/Scenario1/Classification/E-learning", "4_Causal_Policy_Learning/Scenario1/Classification/O-Learning", "4_Causal_Policy_Learning/Scenario1/Continuous", "4_Causal_Policy_Learning/Scenario1/Continuous/Deep Jump Learner", "4_Causal_Policy_Learning/Scenario1/Continuous/Kernel-Based Learner", "4_Causal_Policy_Learning/Scenario1/Continuous/Outcome Learning", "4_Causal_Policy_Learning/Scenario1/Discrete", "4_Causal_Policy_Learning/Scenario1/Micellaneous/Adaptively Collected Data", "4_Causal_Policy_Learning/Scenario1/Micellaneous/Concordance", "4_Causal_Policy_Learning/Scenario1/Micellaneous/Policy Search", "4_Causal_Policy_Learning/Scenario1/Micellaneous/Survival", "4_Causal_Policy_Learning/Scenario1/PlanToDo", "4_Causal_Policy_Learning/Scenario1/Q-learning_Single", "4_Causal_Policy_Learning/Scenario1/Quantile/QuantileOTR_test", "4_Causal_Policy_Learning/Scenario1/Single Stage", "4_Causal_Policy_Learning/Scenario1/Test/A_Q test", "4_Causal_Policy_Learning/Scenario2/DR_Infinite", "4_Causal_Policy_Learning/Scenario2/Deeply_Debiased", "4_Causal_Policy_Learning/Scenario2/Evaluation", "4_Causal_Policy_Learning/Scenario2/FQE", "4_Causal_Policy_Learning/Scenario2/FQI", "4_Causal_Policy_Learning/Scenario2/IPW_Infinite", "4_Causal_Policy_Learning/Scenario2/Inference", "4_Causal_Policy_Learning/Scenario2/Model_based_Infinite", "4_Causal_Policy_Learning/Scenario2/Optimization", "4_Causal_Policy_Learning/Scenario2/Spatial_temporal_DR", "4_Causal_Policy_Learning/Scenario2/archive/archive_preliminary_MDP", "4_Causal_Policy_Learning/Scenario2/preliminary_MDP-potential-outcome", "4_Causal_Policy_Learning/Scenario3/A-learning_Multiple", "4_Causal_Policy_Learning/Scenario3/MediatedQ-learning_Multiple", "4_Causal_Policy_Learning/Scenario3/Multi Stage", "4_Causal_Policy_Learning/Scenario3/Q-learning_Multiple", "4_Causal_Policy_Learning/Scenario4/Bandits", "4_Causal_Policy_Learning/Scenario4/Contextual_Bandits/Contextual_Bandits", "4_Causal_Policy_Learning/Scenario4/Contextual_Bandits/LinTS", "4_Causal_Policy_Learning/Scenario4/Contextual_Bandits/LinUCB", "4_Causal_Policy_Learning/Scenario4/MAB/Epsilon_Greedy", "4_Causal_Policy_Learning/Scenario4/MAB/MAB", "4_Causal_Policy_Learning/Scenario4/MAB/TS", "4_Causal_Policy_Learning/Scenario4/MAB/UCB", "4_Causal_Policy_Learning/Scenario4/Meta_Bandits/MTTS", "4_Causal_Policy_Learning/Scenario4/Meta_Bandits/Meta_Bandits", "4_Causal_Policy_Learning/Scenario4/Meta_Bandits/Meta_TS", "4_Causal_Policy_Learning/Scenario4/OnlineEval/Direct Online Policy Evaluator", "4_Causal_Policy_Learning/Scenario4/OnlineEval/Doubly Robust Online Policy Evaluator", "4_Causal_Policy_Learning/Scenario4/OnlineEval/Inverse Probability Weighted Online Policy Evaluator", "4_Causal_Policy_Learning/Scenario4/OnlineEval/Online Policy Evaluation", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/CascadeLinTS", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/Learning to rank", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/MTSS_Cascade", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/TS_Cascade", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/CombLinTS", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/CombTS", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/Combinatorial Optimization", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/MTSS_Comb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/Assortment Optimization", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/MTSS_MNL", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/TS_Contextual_MNL", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/TS_MNL_Beta", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/UCB-MNL", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Structured_Bandit", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single-Item Recommendation", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/Epsilon Greedy", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/LinTS", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/LinUCB", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/Multi-Task", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/MultiTask/MTTS", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/MultiTask/Meta-TS", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/TS", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/UCB1", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Slate Recommendation", "4_Causal_Policy_Learning/Scenario5/OnlineRL_Markov", "4_Causal_Policy_Learning/Scenario6/OnlineRL_non_Markov", "5_Case_Study/MIMIC3/Case_Study_1", "5_Case_Study/MIMIC3/Infinite_Horizon", "5_Case_Study/MIMIC3/Longitudinal", "5_Case_Study/MIMIC3/MIMIC3-Demo", "5_Case_Study/MIMIC3/MIMIC3-Demo-Ver2", "5_Case_Study/MIMIC3/MIMIC3_intro", "5_Case_Study/MIMIC3/Single_Stage", "5_Case_Study/MIMIC3/Single_Stage_V2", "5_Case_Study/MovieLens/MovieLens", "5_Case_Study/MovieLens/MovieLens-Demo", "Overview", "README", "_old files(to delete)/Map"], "filenames": ["0_Learner Template.ipynb", "0_Motivating_Examples/CEL.ipynb", "0_Motivating_Examples/CPL.ipynb", "0_Motivating_Examples/CSL.ipynb", "1_Preliminary/(old) Causal Inference 101.ipynb", "1_Preliminary/Causal Inference 101_old.md", "1_Preliminary/Causal Inference Preliminary.ipynb", "1_Preliminary/Policy Evaluation and Optimization.md", "1_Preliminary/Preliminary.md", "2_Causal_Structure_Learning/Causal Discovery.ipynb", "2_Causal_Structure_Learning/Causal Mediation Analysis.ipynb", "2_Causal_Structure_Learning/Functional-based Learner.ipynb", "2_Causal_Structure_Learning/Preliminaries of Causal Graphs.ipynb", "2_Causal_Structure_Learning/Score-based Learner.ipynb", "2_Causal_Structure_Learning/Testing-based Learner.ipynb", "3_Causal_Effect_Learning/Scenario 1/ATE.ipynb", "3_Causal_Effect_Learning/Scenario 1/DR-Learner.ipynb", "3_Causal_Effect_Learning/Scenario 1/Dragonnet.ipynb", "3_Causal_Effect_Learning/Scenario 1/GRF.ipynb", "3_Causal_Effect_Learning/Scenario 1/HTE.ipynb", "3_Causal_Effect_Learning/Scenario 1/Lp-R-Learner.ipynb", "3_Causal_Effect_Learning/Scenario 1/Mediation Analysis.ipynb", "3_Causal_Effect_Learning/Scenario 1/Meta Learners.ipynb", "3_Causal_Effect_Learning/Scenario 1/Other Approaches.ipynb", "3_Causal_Effect_Learning/Scenario 1/R-Learner.ipynb", "3_Causal_Effect_Learning/Scenario 1/R-Learner, DR-Learner, Lp-R-Learner.ipynb", "3_Causal_Effect_Learning/Scenario 1/S-learner.ipynb", "3_Causal_Effect_Learning/Scenario 1/Single Stage.ipynb", "3_Causal_Effect_Learning/Scenario 1/T-learner.ipynb", "3_Causal_Effect_Learning/Scenario 1/X-learner.ipynb", "3_Causal_Effect_Learning/Scenario 2/ATE.md", "3_Causal_Effect_Learning/Scenario 2/HTE.md", "3_Causal_Effect_Learning/Scenario 2/underMDP.md", "3_Causal_Effect_Learning/Scenario 3/ATE.md", "3_Causal_Effect_Learning/Scenario 3/DiD.ipynb", "3_Causal_Effect_Learning/Scenario 3/H1SL_H2SL.ipynb", "3_Causal_Effect_Learning/Scenario 3/HTE.md", "3_Causal_Effect_Learning/Scenario 3/Panel Data.md", "3_Causal_Effect_Learning/Scenario 3/R-DiD.ipynb", "3_Causal_Effect_Learning/Scenario 3/Synthetic Control.ipynb", "3_Causal_Effect_Learning/Scenario 3/Synthetic DiD.ipynb", "3_Causal_Effect_Learning/Scenario 3/Synthetic Learner.ipynb", "3_Causal_Effect_Learning/Scenario 3/Synthetic X-Learner.ipynb", "3_Causal_Effect_Learning/Scenario 4/Miscellaneous.md", "4_Causal_Policy_Learning/Scenario1/A-learning_Single.ipynb", "4_Causal_Policy_Learning/Scenario1/Classification.md", "4_Causal_Policy_Learning/Scenario1/Classification/E-learning.ipynb", "4_Causal_Policy_Learning/Scenario1/Classification/O-Learning.ipynb", "4_Causal_Policy_Learning/Scenario1/Continuous.md", "4_Causal_Policy_Learning/Scenario1/Continuous/Deep Jump Learner.ipynb", "4_Causal_Policy_Learning/Scenario1/Continuous/Kernel-Based Learner.md", "4_Causal_Policy_Learning/Scenario1/Continuous/Outcome Learning.md", "4_Causal_Policy_Learning/Scenario1/Discrete.md", "4_Causal_Policy_Learning/Scenario1/Micellaneous/Adaptively Collected Data.ipynb", "4_Causal_Policy_Learning/Scenario1/Micellaneous/Concordance.ipynb", "4_Causal_Policy_Learning/Scenario1/Micellaneous/Policy Search.ipynb", "4_Causal_Policy_Learning/Scenario1/Micellaneous/Survival.ipynb", "4_Causal_Policy_Learning/Scenario1/PlanToDo.md", "4_Causal_Policy_Learning/Scenario1/Q-learning_Single.ipynb", "4_Causal_Policy_Learning/Scenario1/Quantile/QuantileOTR_test.ipynb", "4_Causal_Policy_Learning/Scenario1/Single Stage.md", "4_Causal_Policy_Learning/Scenario1/Test/A_Q test.ipynb", "4_Causal_Policy_Learning/Scenario2/DR_Infinite.ipynb", "4_Causal_Policy_Learning/Scenario2/Deeply_Debiased.ipynb", "4_Causal_Policy_Learning/Scenario2/Evaluation.md", "4_Causal_Policy_Learning/Scenario2/FQE.ipynb", "4_Causal_Policy_Learning/Scenario2/FQI.ipynb", "4_Causal_Policy_Learning/Scenario2/IPW_Infinite.ipynb", "4_Causal_Policy_Learning/Scenario2/Inference.ipynb", "4_Causal_Policy_Learning/Scenario2/Model_based_Infinite.ipynb", "4_Causal_Policy_Learning/Scenario2/Optimization.md", "4_Causal_Policy_Learning/Scenario2/Spatial_temporal_DR.ipynb", "4_Causal_Policy_Learning/Scenario2/archive/archive_preliminary_MDP.ipynb", "4_Causal_Policy_Learning/Scenario2/preliminary_MDP-potential-outcome.ipynb", "4_Causal_Policy_Learning/Scenario3/A-learning_Multiple.ipynb", "4_Causal_Policy_Learning/Scenario3/MediatedQ-learning_Multiple.ipynb", "4_Causal_Policy_Learning/Scenario3/Multi Stage.md", "4_Causal_Policy_Learning/Scenario3/Q-learning_Multiple.ipynb", "4_Causal_Policy_Learning/Scenario4/Bandits.md", "4_Causal_Policy_Learning/Scenario4/Contextual_Bandits/Contextual_Bandits.ipynb", "4_Causal_Policy_Learning/Scenario4/Contextual_Bandits/LinTS.ipynb", "4_Causal_Policy_Learning/Scenario4/Contextual_Bandits/LinUCB.ipynb", "4_Causal_Policy_Learning/Scenario4/MAB/Epsilon_Greedy.ipynb", "4_Causal_Policy_Learning/Scenario4/MAB/MAB.ipynb", "4_Causal_Policy_Learning/Scenario4/MAB/TS.ipynb", "4_Causal_Policy_Learning/Scenario4/MAB/UCB.ipynb", "4_Causal_Policy_Learning/Scenario4/Meta_Bandits/MTTS.ipynb", "4_Causal_Policy_Learning/Scenario4/Meta_Bandits/Meta_Bandits.ipynb", "4_Causal_Policy_Learning/Scenario4/Meta_Bandits/Meta_TS.ipynb", "4_Causal_Policy_Learning/Scenario4/OnlineEval/Direct Online Policy Evaluator.ipynb", "4_Causal_Policy_Learning/Scenario4/OnlineEval/Doubly Robust Online Policy Evaluator.ipynb", "4_Causal_Policy_Learning/Scenario4/OnlineEval/Inverse Probability Weighted Online Policy Evaluator.ipynb", "4_Causal_Policy_Learning/Scenario4/OnlineEval/Online Policy Evaluation.md", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/CascadeLinTS.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/Learning to rank.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/MTSS_Cascade.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/TS_Cascade.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/CombLinTS.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/CombTS.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/Combinatorial Optimization.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/MTSS_Comb.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/Assortment Optimization.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/MTSS_MNL.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/TS_Contextual_MNL.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/TS_MNL_Beta.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/UCB-MNL.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Structured_Bandit.ipynb", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single-Item Recommendation.ipynb", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/Epsilon Greedy.ipynb", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/LinTS.ipynb", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/LinUCB.md", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/Multi-Task.md", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/MultiTask/MTTS.md", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/MultiTask/Meta-TS.md", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/TS.ipynb", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/UCB1.ipynb", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Slate Recommendation.ipynb", "4_Causal_Policy_Learning/Scenario5/OnlineRL_Markov.ipynb", "4_Causal_Policy_Learning/Scenario6/OnlineRL_non_Markov.ipynb", "5_Case_Study/MIMIC3/Case_Study_1.md", "5_Case_Study/MIMIC3/Infinite_Horizon.ipynb", "5_Case_Study/MIMIC3/Longitudinal.ipynb", "5_Case_Study/MIMIC3/MIMIC3-Demo.ipynb", "5_Case_Study/MIMIC3/MIMIC3-Demo-Ver2.ipynb", "5_Case_Study/MIMIC3/MIMIC3_intro.ipynb", "5_Case_Study/MIMIC3/Single_Stage.ipynb", "5_Case_Study/MIMIC3/Single_Stage_V2.ipynb", "5_Case_Study/MovieLens/MovieLens.ipynb", "5_Case_Study/MovieLens/MovieLens-Demo.ipynb", "Overview.md", "README.md", "_old files(to delete)/Map.md"], "titles": ["Learner Name (Single/Multiple Stages/Infinite Horizon)", "<em>Causal Effect Learning (CEL)</em>", "<em>Causal Policy Learning (CPL)</em>", "<em>Causal Structure Learning (CSL)</em>", "Causal Inference 101", "Causal Inference 101", "Causal Inference Preliminary", "Policy Evaluation and Optimization", "Preliminary", "Causal Discovery", "Causal Mediation Analysis", "Functional-based Learner", "Preliminaries of Causal Graphs", "Score-based Learner", "Testing-based Learner", "ATE Estimation", "<strong>5. DR-learner</strong>", "<strong>8. Dragon Net</strong>", "<strong>7. Generalized Random Forest</strong>", "HTE Estimation", "<strong>6. Lp-R-learner</strong>", "Mediation Analysis", "<strong>Meta Learners</strong>", "<strong>Other Approaches</strong>", "<strong>4. R learner</strong>", "<strong>R-Learner, DR-Learner, and Lp-R-Learner</strong>", "<strong>1. S-learner</strong>", "<strong>Single Stage</strong>", "<strong>2. T-learner</strong>", "<strong>3. X-learner</strong>", "ATE", "HTE", "Markov Decision Processes", "ATE", "<strong>Difference in Difference</strong>", "<strong>H1SL and H2SL</strong>", "HTE", "Panel Data", "<strong>R-DiD</strong>", "<strong>Synthetic Control</strong>", "<strong>Synthetic DiD</strong>", "<strong>Synthetic Learner</strong>", "<strong>Synthetic X-Learner</strong>", "Miscellaneous", "A-Learning (Single Stage)", "Reduction to Classification Problems", "Entropy learning", "Outcome Weighted Learning", "Continuous Action Space", "Deep Jump Learner for Continuous Actions", "Kernel-Based Learner", "Outcome Learning", "Discrete Action Space", "Adaptively Collected Data", "Concordance-assisted learning", "Policy Search", "Time-to-Event Data", "Plan To Do", "Q-Learning (Single Stage)", "<strong>Quantile Optimal Treatment Regime</strong>", "Single Stage", "Test A-Learning Single", "Doubly Robust Estimator for Policy Evaluation (Infinite Horizon)", "Deeply-Debiased Off-Policy Evaluation", "Policy Evaluation", "Fitted-Q Evaluation", "Fitted-Q Iteration", "Importance Sampling for Policy Evaluation (Infinite Horizon)", "Confidence Interval in OPE", "Q-Learning (Infinite Horizon)", "Policy Optimization", "Infinite Horizon Importance Sampling for Policy Evaluation", "Preliminary: Off-policy Evaluation and Optimization in Markov Decision Processes", "Preliminary: Off-policy Evaluation and Optimization in Markov Decision Processes", "A-Learning (Multiple Stages)", "MediatedQ-Learning (Multiple Stages)", "Multiple Stages (DTR)", "Q-Learning (Multiple Stages)", "Overview: Bandits ALgorithm", "Contextual Bandits", "LinTS", "LinUCB", "<span class=\"math notranslate nohighlight\">\\(\\epsilon\\)</span>-Greedy", "Multi-Armed Bandits (MAB)", "TS", "UCB", "Multi-Task Thompson Sampling (MTTS)", "Meta Bandits", "Meta Thompson Sampling", "Direct Online Policy Evaluator", "Doubly Robust Online Policy Evaluator", "Inverse Probability Weighted Online Policy Evaluator", "Online Policy Evaluation", "CascadeLinTS", "Online Learning to Rank (Cascading Bandit)", "MTSS_Cascade", "TS_Cascade", "CombLinTS", "CombTS", "Online Combinatorial Optimization (Combinatorial Semi-Bandit)", "MTSS_Comb", "Dynamic Assortment Optimization (Multinomial Logit Bandit)", "MTSS_MNL", "TS_Contextual_MNL", "TS_MNL", "UCB_MNL", "Structured Bandit (Slate Recommendation)", "Single-Item Recommendation", "Epsilon_Greedy", "LinTS", "LinUCB", "Multi-Task", "MTTS", "Meta-TS", "TS", "UCB1", "Slate Recommendation", "Ooline Policy Learning and Evaluation in Markovian Environments", "Ooline Policy Learning in Non-Markovian Environments", "MIMIC III", "MIMIC III (Infinite Horizon)", "MIMIC III (3-Stages)", "Mimic3 Demo", "Mimic3 Demo-Ver2", "Mimic3", "MIMIC III (Single-Stage)", "MIMIC III (Single-Stage)", "MovieLens", "Causal Effect Learning", "Overview", "Content of every notebook", "&lt;no title&gt;"], "terms": {"an": [0, 1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 25, 27, 28, 29, 32, 44, 47, 49, 58, 59, 60, 63, 65, 66, 67, 68, 71, 72, 73, 74, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 114, 115, 116, 117, 118, 120, 121, 125, 126, 127, 128, 129, 130], "overview": [0, 10, 11, 12, 14], "includ": [0, 2, 5, 9, 27, 32, 58, 60, 73, 74, 76, 77, 78, 79, 83, 84, 87, 89, 90, 91, 93, 95, 97, 98, 99, 100, 102, 103, 104, 106, 107, 108, 109, 114, 115, 116, 117, 120, 121, 122, 123, 124, 127, 129], "brief": [0, 118, 129], "introduct": [0, 5, 29, 32, 72, 73, 79, 82, 83, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 107, 108, 117, 118], "evolut": 0, "i": [0, 1, 2, 4, 6, 9, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 25, 26, 27, 32, 44, 49, 58, 59, 60, 62, 63, 65, 66, 67, 68, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 109, 114, 115, 116, 117, 118, 121, 125, 126, 127, 128], "e": [0, 1, 2, 4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 44, 47, 49, 58, 59, 60, 62, 63, 65, 66, 67, 71, 72, 73, 74, 77, 78, 79, 80, 81, 82, 84, 86, 87, 88, 89, 90, 91, 93, 95, 96, 97, 98, 100, 101, 102, 103, 104, 107, 109, 114, 115, 117, 118, 125, 126, 129], "when": [0, 2, 4, 5, 6, 10, 12, 13, 14, 15, 17, 19, 21, 22, 27, 28, 32, 49, 59, 62, 63, 65, 67, 71, 72, 73, 80, 84, 86, 88, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 109, 114, 116, 118, 122, 123, 125, 126, 129], "first": [0, 5, 9, 10, 14, 15, 17, 18, 19, 20, 21, 22, 23, 25, 26, 32, 47, 58, 59, 62, 63, 65, 71, 79, 85, 86, 90, 91, 93, 95, 96, 104, 115, 117, 120, 121, 125, 126, 127, 129, 130], "develop": [0, 1, 2, 9, 14, 18, 23, 32, 47, 49, 87, 98, 103, 104], "ani": [0, 4, 5, 6, 9, 11, 13, 15, 19, 21, 22, 23, 26, 28, 29, 32, 49, 59, 62, 63, 67, 71, 72, 73, 74, 76, 77, 78, 79, 85, 87, 93, 94, 95, 96, 106, 116, 117, 118, 121, 122, 123, 125, 126, 129], "altern": [0, 15, 44, 74, 101, 117], "extens": [0, 5, 19, 20, 25, 32, 44, 58, 62, 63, 71, 74, 77, 79, 83, 107, 117, 118, 129], "applic": [0, 1, 2, 3, 9, 10, 12, 20, 32, 47, 49, 62, 65, 67, 72, 73, 75, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 116, 121], "situat": [0, 11, 13, 14, 49, 62, 65, 67, 79, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105], "describ": [0, 6, 27, 106, 122, 123, 124, 130], "data": [0, 2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 19, 22, 23, 25, 32, 44, 47, 49, 58, 61, 62, 63, 67, 71, 72, 73, 74, 77, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91, 105, 117, 120, 121, 122, 123, 124, 125, 126, 127], "structur": [0, 2, 5, 10, 12, 15, 17, 19, 21, 32, 44, 47, 58, 63, 74, 76, 77, 78, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 117, 120, 121, 125, 126], "can": [0, 1, 2, 4, 5, 6, 9, 10, 11, 13, 15, 17, 18, 19, 20, 21, 22, 23, 25, 26, 28, 29, 32, 44, 47, 49, 58, 59, 60, 62, 63, 65, 66, 67, 68, 69, 71, 73, 74, 77, 78, 80, 82, 84, 86, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 114, 115, 116, 117, 120, 122, 123, 127, 129, 130], "analyz": [0, 120, 121, 125, 126], "make": [0, 4, 5, 6, 9, 15, 17, 32, 49, 58, 59, 77, 78, 79, 82, 89, 90, 91, 117, 118, 127, 128, 129, 130], "connect": [0, 12, 73, 117], "between": [0, 1, 2, 4, 6, 14, 15, 19, 22, 29, 32, 44, 49, 58, 61, 67, 71, 73, 74, 81, 84, 86, 90, 91, 95, 96, 102, 103, 104, 107, 129], "real": [0, 2, 3, 9, 12, 17, 18, 19, 20, 23, 25, 32, 44, 49, 58, 74, 77, 78, 89, 90, 91, 93, 98, 105, 127], "mention": [0, 71, 129], "motiv": [0, 2, 4, 15, 58, 62, 63, 65, 66, 71, 72, 77, 79, 83, 87, 93, 94, 99, 101, 117, 122, 123], "exampl": [0, 1, 2, 4, 5, 6, 9, 14, 17, 18, 19, 21, 22, 23, 32, 44, 58, 59, 62, 63, 71, 74, 77, 78, 79, 80, 82, 83, 84, 85, 87, 94, 95, 99, 100, 101, 102, 109, 114, 117, 121, 125, 126, 129], "we": [0, 1, 2, 3, 4, 6, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 32, 44, 47, 49, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 114, 115, 116, 117, 118, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130], "us": [0, 1, 2, 4, 6, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 44, 49, 58, 59, 60, 61, 63, 66, 67, 71, 72, 73, 74, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 100, 102, 103, 104, 105, 106, 107, 108, 109, 114, 115, 116, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130], "advantag": [0, 11, 13, 14, 44, 49, 59, 62, 63, 65, 67, 68, 74, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 107, 127, 129, 130], "descript": [0, 94, 99, 101, 116], "clear": 0, "definit": [0, 10, 27, 44, 59, 63, 65, 72, 73, 74, 94, 122, 123, 124], "concept": [0, 19, 73, 94], "abstract": 0, "pseudo": [0, 16, 25, 59, 74, 77, 130], "In": [0, 1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 32, 44, 47, 49, 58, 59, 62, 63, 67, 68, 71, 72, 73, 74, 77, 78, 79, 80, 81, 83, 84, 87, 88, 89, 90, 91, 93, 94, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 109, 114, 116, 117, 118, 120, 121, 122, 123, 125, 126, 127, 129], "follow": [0, 2, 3, 4, 5, 9, 10, 11, 13, 14, 15, 19, 22, 24, 25, 27, 44, 47, 49, 58, 59, 60, 62, 63, 65, 66, 67, 68, 71, 72, 73, 74, 77, 78, 79, 83, 89, 90, 91, 95, 96, 100, 102, 105, 106, 107, 116, 117, 121, 122, 123, 124, 125, 126, 127, 129], "exhibit": [0, 44, 49, 58, 74, 77, 89, 90, 91, 105], "how": [0, 1, 2, 3, 9, 10, 12, 17, 22, 27, 44, 47, 49, 58, 59, 60, 61, 62, 71, 74, 77, 78, 79, 87, 89, 90, 91, 105, 106, 116, 117], "appli": [0, 10, 11, 16, 17, 19, 20, 25, 44, 49, 58, 59, 62, 63, 67, 71, 74, 77, 83, 86, 88, 89, 90, 91, 105, 107, 117, 118, 121, 125, 126, 129], "do": [0, 5, 10, 12, 15, 21, 24, 25, 32, 44, 47, 49, 58, 59, 74, 77, 81, 85, 96, 98, 104, 115, 117, 121, 125, 126, 129], "respect": [0, 4, 6, 9, 13, 44, 49, 58, 59, 62, 65, 67, 71, 72, 73, 74, 77, 89, 90, 91, 117], "import": [0, 1, 2, 3, 10, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 44, 47, 49, 58, 59, 60, 61, 62, 63, 65, 66, 68, 69, 73, 74, 77, 105, 108, 109, 114, 115, 118, 120, 121, 122, 123, 125, 126, 127, 128], "from": [0, 1, 2, 3, 4, 6, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 44, 47, 49, 58, 59, 60, 61, 62, 63, 67, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 114, 115, 116, 117, 118, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129], "causaldm": [0, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 44, 47, 58, 60, 61, 62, 63, 65, 66, 67, 68, 69, 71, 74, 77, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115, 120, 121, 125, 126, 127, 128, 130], "alearn": [0, 44, 61, 74], "test": [0, 1, 9, 10, 11, 12, 13, 16, 20, 24, 25, 27, 44, 47, 58, 74, 77, 122, 123, 124, 129], "shared_simul": [0, 47, 61, 74, 77], "numpi": [0, 10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 44, 47, 59, 61, 74, 77, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115, 120, 121, 122, 123, 125, 126, 127, 128], "np": [0, 10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 44, 47, 49, 59, 61, 74, 77, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115, 120, 121, 122, 123, 125, 126, 127, 128], "find": [0, 2, 4, 6, 9, 14, 15, 27, 44, 49, 58, 59, 74, 77, 78, 79, 83, 84, 87, 89, 90, 91, 94, 97, 98, 99, 100, 101, 106, 107, 109, 114, 117, 120, 121, 125, 126, 127, 130], "optim": [0, 2, 5, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 25, 27, 44, 47, 49, 58, 61, 62, 63, 65, 66, 67, 71, 74, 77, 78, 79, 83, 84, 87, 89, 90, 91, 94, 95, 97, 98, 100, 102, 104, 105, 106, 107, 108, 109, 114, 115, 116, 118, 120, 127, 128, 129, 130], "regim": [0, 2, 15, 19, 44, 49, 58, 61, 74, 77, 108, 109, 114, 115, 121, 125, 126, 129], "appropri": [0, 11, 59, 62, 65, 67, 71, 86, 95, 98, 102, 120, 121, 125, 130], "interpret": [0, 3, 10, 13, 44, 49, 58, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 108, 109, 114, 115], "A": [0, 1, 2, 3, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 29, 32, 47, 49, 58, 59, 60, 62, 63, 71, 72, 73, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 114, 115, 116, 117, 120, 121, 122, 123, 125, 126, 127], "sentenc": [0, 108, 109, 114, 115], "analysi": [0, 3, 9, 11, 13, 14, 27, 49, 75, 82, 85, 95, 101, 107, 108, 109, 114, 115, 116, 122, 124, 129], "result": [0, 2, 4, 5, 10, 15, 17, 18, 19, 20, 21, 22, 23, 25, 27, 28, 29, 44, 49, 58, 61, 62, 63, 65, 67, 71, 74, 77, 93, 95, 96, 99, 108, 109, 114, 115, 120, 122, 123, 124, 128, 129], "estim": [0, 1, 2, 5, 6, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 32, 44, 47, 49, 58, 59, 61, 63, 65, 66, 67, 68, 71, 72, 73, 74, 77, 81, 82, 85, 89, 90, 91, 95, 96, 98, 105, 107, 108, 109, 114, 115, 117, 118, 120, 121, 122, 123, 125, 126, 128, 129], "fix": [0, 20, 44, 58, 59, 65, 66, 74, 77, 79, 82, 89, 90, 91, 108, 117, 118, 120, 121, 125, 126], "valu": [0, 2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 20, 22, 23, 24, 25, 27, 32, 44, 47, 49, 58, 59, 60, 61, 62, 63, 65, 66, 67, 71, 73, 74, 77, 79, 82, 83, 87, 89, 90, 91, 94, 107, 108, 120, 121, 122, 123, 124, 125, 126, 127, 128], "subfield": 1, "infer": [1, 2, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 25, 26, 27, 32, 58, 59, 63, 73, 75, 89, 90, 91, 101, 104, 117, 118, 121, 129], "aim": [1, 2, 6, 11, 13, 14, 15, 17, 18, 19, 21, 22, 23, 28, 32, 44, 58, 60, 65, 66, 73, 74, 77, 79, 83, 87, 94, 99, 101, 106, 116, 117, 127, 129], "identifi": [1, 3, 9, 10, 11, 13, 14, 15, 17, 18, 21, 22, 23, 26, 125, 126], "conduct": [1, 27, 59, 120, 121, 125, 126, 127], "statist": [1, 2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 16, 18, 19, 20, 21, 23, 25, 34, 35, 38, 39, 40, 41, 42, 44, 47, 49, 59, 62, 63, 67, 68, 71, 74, 79, 80, 81, 87, 89, 90, 91, 93, 94, 96, 98, 107, 109, 117, 118, 120, 125, 126, 129], "specif": [1, 2, 3, 4, 5, 6, 10, 15, 17, 18, 19, 21, 22, 23, 26, 27, 32, 44, 58, 59, 62, 63, 66, 67, 68, 71, 72, 73, 77, 78, 80, 82, 84, 86, 87, 88, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 106, 107, 108, 109, 114, 116, 120, 125, 126, 127, 129], "intervent": [1, 2, 4, 6, 10, 12, 15, 27], "system": [1, 5, 9, 10, 11, 12, 13, 14, 17, 19, 25, 49, 67, 71, 72, 78, 79, 83, 86, 87, 88, 94, 95, 98, 100, 101, 102, 103, 106, 107, 118], "It": [1, 2, 4, 5, 19, 25, 32, 65, 66, 67, 71, 73, 80, 81, 82, 84, 85, 86, 93, 95, 96, 97, 98, 99, 100, 102, 103, 107, 109, 114, 117, 118], "tri": [1, 25], "answer": [1, 2, 17], "question": [1, 2, 17, 62, 71], "what": [1, 2, 32, 74, 77, 78, 101], "have": [1, 2, 3, 4, 6, 10, 12, 15, 27, 32, 47, 59, 60, 62, 67, 71, 72, 73, 76, 78, 79, 86, 87, 88, 93, 103, 106, 107, 116, 117, 122, 123, 124, 127, 129, 130], "done": [1, 117], "someth": [1, 61], "differ": [1, 2, 3, 4, 5, 6, 12, 15, 22, 28, 32, 44, 58, 59, 60, 61, 67, 71, 72, 73, 74, 77, 79, 80, 83, 84, 86, 87, 88, 90, 91, 95, 96, 98, 99, 100, 102, 103, 106, 107, 109, 114, 117, 118, 127, 129], "s": [1, 2, 3, 5, 6, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 23, 24, 25, 27, 28, 29, 32, 44, 58, 60, 62, 63, 65, 66, 67, 71, 72, 73, 74, 76, 77, 79, 80, 81, 82, 86, 87, 88, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 117, 121, 125, 126, 127, 129], "consequ": [1, 4, 15, 49, 62, 71], "excecut": 1, "polici": [1, 5, 15, 17, 19, 21, 22, 23, 25, 32, 47, 61, 65, 66, 68, 79, 82, 120, 127, 130], "quantifi": [1, 2, 3, 10, 85, 90, 91, 94, 122, 123], "etc": [1, 2, 17, 19, 32, 44, 58, 79, 99, 106, 116], "suppos": [1, 9, 10, 11, 12, 13, 14, 19, 44, 60, 74, 76, 79, 80, 81, 82, 83, 84, 85, 94, 99, 101, 108, 109, 114, 115, 117], "you": [1, 5, 10, 44, 47, 58, 59, 77, 96, 121, 125, 126, 130], "ar": [1, 2, 3, 4, 6, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 28, 29, 32, 44, 47, 58, 59, 60, 62, 63, 65, 67, 71, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 106, 107, 108, 109, 114, 115, 116, 117, 120, 121, 122, 123, 125, 126, 127, 129, 130], "medic": [1, 15], "research": [1, 2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 21, 32, 62, 66, 71, 98, 101, 104, 105], "who": [1, 2, 4, 6, 15, 27, 60, 80, 81, 86, 87, 122, 123, 124], "just": [1, 18, 20, 22, 23, 25, 28, 32, 117], "fictiti": 1, "hopefulli": 1, "allevi": 1, "patient": [1, 2, 27, 32, 49, 59, 87, 121, 122, 123, 124, 125, 126], "symptom": 1, "hypertens": 1, "sinc": [1, 4, 10, 15, 21, 32, 60, 63, 67, 78, 79, 83, 89, 90, 91, 101, 107, 114, 117, 118, 129], "thi": [1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 32, 47, 49, 59, 60, 62, 63, 65, 66, 67, 68, 69, 71, 72, 73, 78, 79, 82, 83, 85, 87, 94, 99, 100, 101, 102, 105, 106, 107, 108, 109, 114, 115, 116, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130], "newli": [1, 49], "drug": [1, 3], "must": [1, 2, 5, 20, 128], "go": [1, 130], "through": [1, 2, 5, 9, 10, 11, 12, 14, 15, 17, 21, 73, 79, 83, 86, 87, 94, 101, 104, 106, 107, 116, 117, 122, 123, 127], "preclin": 1, "bitro": 1, "vivo": 1, "three": [1, 6, 9, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 24, 25, 26, 28, 29, 32, 59, 78, 79, 80, 81, 82, 84, 85, 88, 89, 90, 91, 93, 95, 96, 97, 100, 102, 103, 104, 106, 107, 116, 117, 118, 121, 129], "phase": 1, "final": [1, 2, 17, 19, 20, 21, 22, 25, 28, 29, 58, 59, 62, 63, 65, 66, 71, 72, 74, 77, 79, 80, 81, 84, 95, 102, 103, 104, 109, 114, 117, 120, 121, 125, 126, 127, 128, 129], "approv": 1, "confirm": [1, 4, 6, 15], "potenti": [1, 2, 15, 19, 21, 22, 28, 29, 32, 44, 58, 59, 63, 65, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 87, 88, 89, 90, 91, 94, 96, 97, 98, 99, 100, 101, 106, 117, 122, 123, 129], "side": [1, 65, 66, 117], "dure": [1, 2, 3, 16, 20, 60], "procedur": [1, 6, 11, 15, 16, 17, 19, 25, 63, 68], "usual": [1, 2, 15, 59, 67, 71], "evalu": [1, 5, 11, 13, 14, 15, 18, 21, 22, 23, 27, 32, 61, 66, 68, 79, 107, 120, 129], "mesur": 1, "well": [1, 9, 11, 13, 19, 22, 27, 32, 47, 59, 65, 67, 71, 72, 73, 82, 83, 93, 97, 99, 100, 107, 108, 117, 118, 129], "perform": [1, 9, 13, 17, 18, 19, 20, 22, 23, 25, 27, 28, 47, 59, 62, 65, 66, 67, 71, 79, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91, 107, 108, 117, 127, 128], "compar": [1, 3, 15, 16, 18, 20, 22, 23, 25, 62, 71, 82, 88, 117, 120, 121, 125, 126, 127, 129], "placebo": 1, "other": [1, 2, 3, 4, 5, 6, 9, 13, 15, 17, 19, 21, 22, 25, 27, 28, 44, 49, 58, 63, 71, 72, 73, 74, 77, 78, 79, 80, 83, 87, 93, 96, 97, 98, 99, 100, 103, 104, 106, 107, 116, 117, 127, 129], "exist": [1, 2, 4, 5, 6, 9, 10, 11, 12, 13, 17, 19, 21, 32, 44, 49, 58, 62, 73, 94, 101, 106, 116, 117, 129], "treatment": [1, 2, 4, 9, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 44, 47, 49, 58, 60, 63, 73, 74, 77, 78, 87, 107, 117, 120, 121, 122, 123, 125, 126, 129], "method": [1, 2, 5, 10, 12, 13, 17, 19, 20, 21, 22, 26, 28, 29, 32, 44, 49, 58, 59, 62, 63, 65, 66, 67, 68, 71, 74, 77, 88, 89, 90, 91, 117, 118, 120, 125, 126, 129, 130], "experiment": [1, 4, 6, 15, 129], "design": [1, 17, 18, 19, 23, 62, 63, 71, 95, 100, 102, 117], "wide": [1, 2, 9, 15, 19, 32, 62, 67, 71, 78, 79, 82, 83, 87, 93, 95, 99, 100, 102, 106, 107, 108, 127, 129], "known": [1, 2, 3, 9, 12, 15, 21, 22, 26, 32, 44, 67, 71, 72, 73, 74, 78, 83, 84, 86, 87, 88, 89, 90, 91, 94, 95, 99, 100, 101, 102, 107, 109, 114, 117, 118, 129], "b": [1, 2, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 25, 26, 28, 29, 44, 47, 49, 58, 59, 62, 67, 71, 72, 73, 74, 77, 78, 79, 80, 84, 86, 87, 88, 93, 94, 97, 99, 100, 106, 107, 109, 114, 115, 116, 122, 123], "randomli": [1, 2, 4, 6, 16, 17, 18, 20, 24, 26, 28, 29, 82, 108, 128], "assign": [1, 2, 4, 6, 12, 15, 19, 22, 23, 32, 47, 58, 73, 77], "one": [1, 2, 4, 5, 6, 15, 19, 21, 22, 26, 32, 44, 47, 59, 62, 63, 65, 67, 71, 73, 74, 79, 83, 84, 87, 93, 94, 95, 96, 101, 102, 103, 104, 106, 107, 109, 114, 117, 121, 125, 126], "two": [1, 2, 3, 4, 5, 6, 10, 14, 15, 16, 17, 20, 21, 22, 25, 28, 29, 32, 59, 60, 62, 63, 67, 71, 73, 78, 79, 83, 84, 87, 89, 90, 91, 95, 100, 102, 107, 114, 117, 121, 122, 123, 125, 126, 129, 130], "group": [1, 2, 4, 6, 15, 19, 22, 28, 29, 44, 59, 74, 83, 99, 107, 122, 123, 129], "receiv": [1, 2, 4, 6, 15, 32, 58, 60, 72, 73, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 114, 115, 116, 121, 125, 126, 127, 129], "measur": [1, 3, 4, 6, 9, 10, 11, 12, 13, 14, 15, 19, 63, 67, 73, 117, 129], "sbp": 1, "systol": 1, "blood": 1, "pressur": [1, 27, 122, 123, 124], "each": [1, 2, 3, 4, 6, 9, 10, 11, 13, 14, 18, 19, 20, 21, 22, 23, 25, 28, 32, 44, 49, 58, 60, 67, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 108, 109, 114, 115, 116, 120, 121, 122, 123, 125, 126, 127, 128, 129], "both": [1, 4, 5, 6, 11, 13, 14, 15, 17, 22, 27, 28, 49, 59, 62, 63, 67, 71, 73, 82, 86, 88, 95, 100, 102, 108, 114, 117, 121, 125, 126, 127, 128, 129], "befor": [1, 10, 11, 15, 16, 20, 22, 23, 25, 88], "after": [1, 2, 3, 11, 13, 14, 15, 17, 24, 25, 27, 47, 60, 62, 63, 65, 66, 67, 68, 69, 71, 72, 77, 80, 82, 84, 85, 96, 105, 108, 109, 114, 115, 117, 122, 123, 124], "By": [1, 17, 19, 44, 58, 60, 63, 72, 73, 77, 82, 86, 106, 108], "analys": 1, "abl": [1, 4, 6, 15, 17, 19, 84, 86, 122, 123], "determin": [1, 9, 12, 14, 82, 86, 95, 100, 101, 102, 103, 104, 106, 116], "treat": [1, 17, 27, 106, 122, 123, 129], "shop": [1, 19], "websit": [1, 2, 19, 27, 76, 79, 83, 87, 106, 107, 127, 130], "seller": 1, "often": [1, 4, 6, 17, 22, 28, 32, 59, 129], "veri": [1, 3, 5, 19, 22, 26, 28, 59, 129], "cautiou": 1, "about": [1, 2, 4, 5, 6, 15, 17, 18, 20, 22, 23, 25, 29, 32, 60, 79, 84, 87, 88], "custom": [1, 2, 19, 59, 60, 86, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104], "purchas": [1, 2, 60, 101, 102, 103, 104, 105], "experi": [1, 4, 6, 15, 19, 47, 73, 79, 83, 87, 89, 90, 91, 106, 107, 127], "whenev": [1, 2, 79, 83, 94, 101], "consum": 1, "satisfi": [1, 9, 15, 17, 18, 23, 24, 25, 59, 62, 63, 67, 71, 79, 83, 87, 97, 98, 99, 100, 106, 107, 116, 117, 127], "item": [1, 2, 20, 78, 79, 80, 82, 83, 84, 85, 86, 87, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 108, 109, 115, 116, 129], "thei": [1, 2, 4, 5, 6, 32, 67, 71, 73, 79, 83, 87, 106, 107, 127], "bought": 1, "order": [1, 2, 9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 23, 25, 32, 59, 63, 86, 87, 88, 93, 94, 95, 96, 97, 98, 100, 102, 103, 104, 106, 116, 122, 123], "wrong": [1, 61], "size": [1, 22, 23, 25, 44, 49, 58, 59, 61, 97, 98, 99, 100, 120, 127, 129], "cloth": [1, 19], "broken": 1, "miss": [1, 5, 16, 73], "sever": [1, 2, 16, 17, 19, 24, 25, 27, 32, 106, 122, 123, 124, 127, 128, 129], "option": [1, 18, 20, 23, 25, 44, 49, 58, 61, 74, 77, 79, 80, 81, 82, 84, 85, 108, 109, 114, 115], "provid": [1, 2, 12, 14, 15, 19, 27, 28, 29, 32, 44, 58, 61, 63, 71, 73, 74, 77, 82, 86, 89, 90, 91, 103, 108, 117, 118, 120, 121, 125, 126, 129, 130], "address": [1, 2, 17, 19, 32, 49, 82, 86, 117, 129], "problem": [1, 2, 3, 10, 17, 18, 19, 23, 24, 25, 32, 47, 58, 59, 62, 63, 65, 66, 67, 71, 77, 78, 82, 84, 85, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 115, 117, 118, 122, 123, 129, 130], "For": [1, 2, 3, 4, 5, 6, 17, 19, 20, 22, 25, 27, 29, 32, 44, 58, 59, 60, 62, 67, 71, 73, 74, 76, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 114, 115, 117, 122, 123, 124, 127, 128, 129], "mai": [1, 2, 3, 4, 6, 10, 15, 18, 19, 21, 23, 32, 47, 59, 73, 79, 80, 87, 109, 122, 123, 130], "offer": [1, 2, 63, 82, 101, 102, 103, 104, 105, 106, 116], "1": [1, 4, 5, 6, 10, 16, 18, 19, 20, 23, 24, 25, 28, 29, 32, 47, 59, 60, 61, 62, 63, 65, 66, 67, 68, 71, 72, 73, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 114, 115, 116, 117, 118, 120, 121, 122, 123, 125, 126, 127], "fulli": [1, 79, 83, 86, 87, 107, 117, 127], "refund": 1, "without": [1, 22, 24, 72, 73, 91, 129], "return": [1, 2, 20, 21, 22, 23, 24, 25, 44, 49, 58, 59, 61, 74, 77, 117, 120, 122, 123, 125, 126, 128], "2": [1, 10, 16, 18, 19, 20, 23, 24, 25, 26, 29, 32, 34, 35, 38, 39, 40, 41, 42, 47, 59, 60, 61, 62, 63, 65, 66, 67, 68, 71, 72, 75, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 114, 115, 116, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128], "3": [1, 5, 10, 16, 17, 18, 20, 23, 24, 25, 26, 27, 28, 44, 47, 49, 58, 59, 61, 74, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 114, 115, 116, 117, 118, 120, 122, 123, 124, 125, 126, 127, 128], "discount": [1, 63, 71, 72, 73, 117], "next": [1, 10, 15, 19, 22, 29, 59, 67, 71, 72, 73, 90, 91, 122, 123, 130], "compens": 1, "level": [1, 3, 4, 5, 6, 19, 59, 117, 122, 123, 129], "vari": [1, 75, 79, 121], "accord": [1, 2, 4, 6, 12, 17, 27, 32, 63, 65, 67, 73, 84, 86, 104, 107, 109, 114, 122, 123, 129], "primari": [1, 3, 17, 60, 78, 129], "goal": [1, 2, 3, 17, 27, 47, 59, 63, 72, 73, 79, 83, 87, 89, 90, 91, 99, 101, 106, 107, 127, 129, 130], "outcom": [1, 2, 3, 10, 12, 15, 16, 17, 19, 20, 21, 22, 24, 25, 28, 29, 32, 44, 49, 58, 59, 60, 74, 75, 77, 78, 86, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 117, 121, 125, 126, 129], "so": [1, 2, 4, 5, 9, 11, 13, 15, 17, 20, 24, 25, 27, 59, 72, 73, 77, 82, 85, 107, 108, 115, 122, 123], "examin": [1, 94, 121, 125, 126, 129], "which": [1, 2, 3, 4, 5, 6, 10, 12, 15, 17, 18, 19, 21, 22, 23, 24, 25, 27, 28, 29, 32, 44, 47, 49, 58, 59, 62, 66, 67, 71, 72, 73, 74, 77, 78, 79, 80, 83, 84, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 108, 109, 114, 116, 117, 118, 120, 122, 123, 124, 125, 126, 129], "take": [1, 11, 13, 14, 22, 29, 32, 47, 59, 63, 72, 77, 79, 82, 83, 84, 86, 87, 88, 93, 95, 97, 98, 99, 100, 102, 103, 104, 105, 107, 108, 120, 123, 127, 129], "histori": [1, 2, 27, 44, 58, 59, 60, 73, 82, 89, 90, 91, 107, 108, 117, 118, 129], "maxim": [1, 2, 27, 47, 49, 58, 59, 77, 78, 79, 83, 87, 94, 106, 107, 117, 121, 125, 126], "profit": [1, 2, 101, 106, 116], "asid": [1, 19, 59], "abov": [1, 4, 6, 9, 10, 11, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 29, 32, 49, 101, 117, 121, 122, 123, 125, 126, 130], "idea": [1, 17, 20, 22, 24, 25, 26, 117, 130], "fundament": 1, "ha": [1, 2, 3, 5, 9, 10, 13, 18, 19, 21, 23, 24, 44, 47, 49, 58, 59, 62, 63, 67, 68, 71, 76, 80, 83, 84, 85, 86, 87, 95, 98, 99, 101, 102, 106, 107, 109, 114, 115, 117, 120, 125, 126, 129], "broad": 1, "our": [1, 2, 4, 6, 15, 17, 18, 23, 32, 49, 59, 63, 67, 68, 71, 73, 77, 87, 89, 90, 91, 117], "daili": 1, "live": 1, "leverag": [1, 14, 18, 20, 23, 25, 49, 88, 117], "studi": [1, 2, 3, 4, 5, 6, 9, 13, 15, 19, 21, 27, 32, 60, 62, 65, 71, 79, 83, 87, 106, 107, 118, 121, 125, 126, 127, 129], "new": [1, 2, 4, 6, 17, 20, 32, 44, 59, 60, 74, 77, 79, 86, 87, 88, 99, 106, 107, 116, 117, 127, 129], "catalyst": 1, "rate": [1, 2, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 24, 25, 26, 27, 28, 29, 49, 62, 63, 71, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 94, 106, 107, 108, 117, 121, 122, 123, 125, 126, 127, 128], "chemic": 1, "reaction": 1, "smoke": 1, "risk": 1, "lung": 1, "cancer": 1, "ad": [1, 4, 6, 19, 44, 74, 89, 90, 91, 99, 106, 116, 123], "exposur": [1, 2, 3, 10, 19, 75, 121], "convers": [1, 2, 19], "bui": [1, 102, 103, 104], "product": [1, 2, 101, 106, 116, 127, 128], "extracurricular": 1, "remedi": 1, "class": [1, 4, 9, 17, 20, 24, 25, 49, 59, 62, 63, 65, 71, 78, 79, 85, 87, 95, 100, 102, 106, 107, 115, 116, 118, 129], "improv": [1, 2, 5, 16, 17, 18, 19, 20, 24, 26, 28, 29, 59, 93, 117, 118], "student": [1, 15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 79, 80, 81, 86, 87, 107, 127, 128], "grade": 1, "cdot": [1, 4, 6, 9, 10, 11, 12, 13, 14, 15, 18, 20, 21, 23, 24, 25, 44, 49, 60, 62, 63, 65, 66, 67, 71, 72, 73, 74, 76, 77, 78, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 93, 95, 96, 97, 98, 100, 101, 102, 103, 104, 105, 108, 109, 114, 115, 117, 129], "social": [1, 129], "phenomena": 1, "natur": [1, 2, 5, 10, 12, 21, 24, 25, 47, 59, 117, 120, 121, 122, 123, 125, 126], "quantif": 1, "allow": [1, 2, 4, 5, 6, 20, 47, 49, 58, 59, 63, 73, 77, 129], "understand": [1, 10, 19, 58, 77, 82, 117], "relationship": [1, 3, 4, 6, 9, 10, 11, 12, 13, 14, 47, 58, 67, 80, 95, 102, 104, 109, 117, 129], "methodolog": [1, 9, 12, 44, 74, 129], "onli": [1, 2, 4, 5, 6, 12, 15, 17, 59, 60, 62, 63, 67, 68, 71, 72, 73, 78, 88, 93, 94, 95, 96, 101, 102, 103, 104, 117, 129, 130], "scientif": [1, 4, 6], "also": [1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 19, 21, 22, 24, 25, 26, 44, 58, 59, 61, 62, 65, 66, 67, 71, 73, 74, 77, 84, 86, 87, 95, 96, 97, 98, 99, 100, 101, 102, 104, 107, 109, 114, 118, 122, 123, 129], "practic": [1, 2, 49, 58, 63, 77, 79, 80, 82, 83, 84, 86, 89, 90, 91, 93, 95, 96, 97, 98, 100, 102, 103, 104, 107, 108, 109, 114, 117], "where": [1, 2, 4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 44, 47, 49, 58, 59, 60, 62, 63, 65, 67, 68, 71, 72, 73, 74, 77, 78, 79, 80, 82, 83, 84, 86, 87, 88, 89, 90, 91, 94, 95, 97, 99, 100, 101, 102, 106, 107, 108, 116, 117, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130], "seek": 1, "user": [2, 4, 6, 10, 15, 16, 17, 18, 20, 21, 24, 25, 26, 27, 28, 29, 44, 47, 58, 74, 77, 79, 80, 81, 82, 83, 86, 87, 88, 94, 97, 98, 100, 101, 102, 103, 104, 106, 107, 108, 116, 127], "growth": 2, "engag": 2, "critic": [2, 5, 27, 62, 71, 73, 122, 123, 124], "fast": [2, 9, 10, 11, 12, 13, 14, 62, 129], "chang": [2, 20, 22, 27, 32, 49, 67, 74, 97, 121, 122, 123, 125, 126, 129, 130], "market": 2, "campaign": [2, 60], "internet": 2, "compani": [2, 19], "encourag": [2, 47], "The": [2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 34, 35, 38, 39, 40, 41, 42, 44, 47, 49, 58, 59, 60, 62, 63, 65, 66, 67, 71, 72, 73, 74, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 108, 109, 114, 115, 116, 117, 118, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130], "posit": [2, 4, 6, 11, 13, 14, 15, 21, 22, 26, 32, 44, 58, 74, 77, 87, 106, 116], "effect": [2, 3, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 32, 47, 60, 63, 77, 101, 106, 116, 120, 121, 125, 126], "desir": [2, 3, 59], "busi": 2, "lead": [2, 19, 63], "surplu": 2, "oper": [2, 10, 12, 15, 63, 101, 104, 105], "cost": [2, 25, 47, 104], "increas": [2, 49, 63, 78, 82, 89, 90, 91, 107, 121, 122, 123, 125, 126], "impel": 2, "carri": 2, "out": [2, 10, 16, 17, 18, 19, 20, 24, 26, 28, 29, 58, 73], "more": [2, 3, 4, 5, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 21, 22, 23, 25, 26, 28, 29, 32, 44, 47, 49, 59, 60, 62, 63, 65, 66, 67, 68, 69, 71, 73, 74, 79, 81, 82, 88, 97, 98, 100, 103, 104, 105, 107, 108, 109, 114, 115, 117, 130], "refin": 2, "strategi": 2, "acquisit": 2, "retent": 2, "associ": [2, 4, 5, 6, 9, 11, 13, 21, 47, 49, 59, 73, 78, 89, 90, 91, 118, 122, 123, 125, 126, 129], "massiv": [2, 19], "scale": [2, 9, 20, 25, 49, 65, 78, 93, 94, 95, 97, 99, 100, 102, 103, 107, 129], "promot": 2, "balanc": [2, 72, 84, 107], "increment": [2, 117], "sustain": 2, "invest": [2, 44, 58, 74, 77], "roi": [2, 84, 106, 107, 114, 115, 116], "requir": [2, 9, 11, 14, 17, 18, 23, 32, 44, 47, 49, 59, 62, 63, 71, 73, 74, 77, 87, 117, 129], "predict": [2, 5, 15, 18, 22, 23, 26, 28, 29, 49, 58, 77, 117, 122, 123, 127, 128], "caus": [2, 4, 6, 9, 11, 12, 13, 14, 19, 20, 21, 32, 47, 59, 122, 123], "action": [2, 4, 6, 19, 21, 27, 32, 44, 47, 58, 59, 60, 61, 62, 63, 65, 66, 67, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 114, 115, 116, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129], "uplift": [2, 59, 60], "model": [2, 6, 10, 12, 15, 17, 22, 24, 25, 26, 28, 29, 44, 49, 58, 59, 61, 62, 63, 65, 71, 72, 73, 74, 77, 78, 80, 81, 86, 87, 89, 90, 91, 93, 94, 95, 97, 100, 101, 102, 103, 104, 106, 107, 109, 116, 121, 125, 126, 129], "heterogen": [2, 9, 15, 16, 18, 19, 20, 22, 23, 24, 25, 26, 28, 29, 86, 94, 95, 99, 100, 101, 102, 129], "attent": [2, 3, 9, 11, 12, 13, 14, 32, 49, 78, 89, 90, 91, 107, 122, 123, 129], "literatur": [2, 9, 15, 19, 21, 32, 49, 62, 68, 71, 73, 87, 104, 117, 118, 120, 129, 130], "book": [2, 5, 58, 77, 117, 129, 130], "sampl": [2, 4, 6, 16, 17, 18, 20, 22, 23, 25, 32, 44, 47, 49, 58, 59, 62, 63, 68, 72, 79, 80, 82, 83, 84, 87, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 108, 109, 114, 115, 116, 117, 127, 129], "code": [2, 9, 10, 17, 18, 23, 39, 47, 61, 116, 121, 125, 126, 130], "relat": [2, 9, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 44, 67, 72, 73, 74, 78, 79, 87, 107, 117, 122, 123, 124, 127, 129], "under": [2, 3, 4, 5, 6, 9, 10, 15, 16, 17, 19, 20, 21, 22, 25, 26, 28, 29, 32, 44, 47, 49, 58, 62, 63, 65, 67, 71, 79, 86, 88, 95, 100, 101, 102, 103, 104, 107, 121, 122, 123, 125, 126, 127, 128, 129, 130], "set": [2, 3, 5, 9, 10, 11, 12, 13, 14, 18, 23, 24, 27, 32, 49, 61, 63, 67, 71, 72, 73, 77, 82, 88, 89, 90, 91, 93, 95, 96, 97, 98, 100, 102, 103, 104, 108, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129, 130], "point": [2, 15, 16, 17, 18, 20, 23, 24, 26, 28, 29, 32, 47, 49, 58, 60, 65, 66, 67, 68, 72, 73, 74, 77, 83, 87, 117, 118], "interest": [2, 3, 4, 6, 10, 12, 17, 18, 19, 21, 23, 32, 44, 49, 58, 59, 60, 71, 74, 77, 93, 94, 95, 96, 117, 120, 121, 122, 123, 125, 126, 127, 129], "dataset": [2, 3, 15, 19, 25, 27, 44, 49, 58, 60, 72, 73, 76, 77, 79, 83, 87, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 116, 117, 122, 123, 124, 127], "space": [2, 9, 21, 27, 44, 49, 58, 60, 62, 67, 71, 72, 73, 74, 77, 80, 81, 82, 84, 85, 87, 88, 89, 90, 91, 97, 98, 100, 106, 108, 109, 114, 115, 116], "should": [2, 10, 12, 16, 17, 61, 74, 77, 80, 93, 95, 96, 97, 98, 100, 102, 103, 130], "variou": [2, 3, 11, 13, 58, 62, 71, 77, 88, 97, 106, 129], "email": [2, 44, 58, 59], "sent": 2, "total": [2, 10, 12, 19, 21, 49, 59, 60, 74, 79, 82, 83, 85, 86, 93, 95, 96, 97, 98, 100, 102, 103, 104, 106, 107, 108, 115, 116, 120, 127, 128, 129], "amount": [2, 17, 32, 94, 122, 123], "spent": [2, 49, 60], "fetch_hillstrom": [2, 59, 60], "discret": [2, 4, 5, 6, 27, 49, 59, 72, 73, 80, 81, 82, 84, 85, 121, 122, 123, 125, 126, 129], "q": [2, 5, 9, 17, 32, 44, 49, 59, 61, 62, 63, 71, 72, 73, 74, 78, 82, 84, 86, 88, 95, 100, 102, 104, 107, 108, 117, 121, 125, 126, 129], "much": [2, 3, 19], "spend": [2, 44, 58, 59, 60], "averag": [2, 9, 12, 15, 16, 17, 19, 20, 22, 25, 29, 44, 58, 63, 67, 68, 74, 77, 82, 85, 108, 115, 117, 120, 122, 123, 129], "add": [2, 5, 44, 58, 59, 86, 94, 99, 101, 130], "quantil": [2, 68, 129], "continu": [2, 4, 6, 9, 10, 11, 12, 13, 14, 44, 58, 59, 67, 71, 72, 74, 77, 82, 84, 85, 86, 88, 97, 98, 99, 100, 122, 123, 129, 130], "owl": [2, 129], "john": [2, 5, 72, 73, 117], "wanamak": 2, "onc": [2, 5, 86, 88, 94], "phrase": 2, "half": 2, "monei": [2, 60], "advertis": [2, 19, 97, 98, 99, 100], "wast": 2, "troubl": 2, "don": [2, 20, 59, 102, 103, 104], "t": [2, 4, 5, 6, 10, 11, 13, 14, 15, 17, 18, 19, 20, 21, 23, 25, 29, 32, 44, 47, 49, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 114, 115, 116, 117, 120, 121, 122, 123, 125, 126, 127, 128, 129], "know": [2, 19, 59], "indic": [2, 4, 6, 11, 13, 14, 15, 27, 49, 82, 90, 91, 94, 101, 102, 103, 104, 106, 122, 123], "high": [2, 3, 4, 9, 10, 11, 12, 13, 14, 15, 32, 44, 74, 117, 122, 123], "intent": 2, "convert": [2, 4, 6, 11, 13, 14, 59, 74, 77, 122, 123, 127], "todai": 2, "digit": 2, "techniqu": [2, 62, 71, 129], "enabl": [2, 9, 10, 12, 95, 100, 102], "lift": 2, "via": [2, 3, 4, 9, 10, 11, 12, 13, 14, 15, 62, 63, 65, 71, 72, 86, 89, 90, 91, 95, 100, 101, 102, 117, 118], "random": [2, 4, 6, 9, 11, 12, 13, 14, 15, 16, 19, 20, 21, 24, 26, 34, 35, 38, 39, 40, 41, 42, 59, 61, 68, 72, 73, 79, 80, 81, 82, 83, 84, 86, 87, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 107, 108, 109, 120, 122, 123, 125, 126, 128], "control": [2, 3, 4, 5, 6, 9, 12, 15, 16, 19, 20, 21, 22, 24, 25, 27, 28, 29, 32, 44, 74, 117, 120, 121, 122, 123, 125, 126, 129], "select": [2, 10, 47, 49, 60, 72, 78, 79, 80, 81, 82, 83, 84, 85, 87, 93, 95, 96, 97, 98, 100, 101, 102, 104, 105, 107, 108, 109, 114, 115, 117, 118, 122, 123, 124, 127, 128], "form": [2, 11, 15, 62, 66, 71, 72, 80, 84, 86, 88, 95, 102, 117], "interven": [2, 4, 6, 9, 12], "cannot": [2, 4, 6, 11, 14, 15, 63, 73, 118], "base": [2, 4, 5, 9, 10, 12, 15, 16, 17, 18, 19, 21, 22, 23, 24, 26, 27, 32, 44, 47, 49, 58, 62, 63, 65, 66, 67, 71, 73, 74, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 93, 95, 96, 97, 98, 100, 101, 102, 103, 104, 105, 107, 108, 109, 114, 115, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129], "collect": [2, 3, 4, 6, 17, 19, 23, 27, 59, 72, 73, 79, 83, 87, 101, 106, 107, 117, 122, 123, 124, 127, 129], "converion": 2, "even": [2, 15, 32, 118, 129], "win": 2, "impress": [2, 19], "those": [2, 5, 16, 47, 73, 80, 81, 82, 84, 85, 86, 88], "With": [2, 44, 47, 67, 95, 102, 106, 121, 125, 126], "wearabl": 2, "devic": 2, "easili": [2, 22, 28, 80, 84, 89, 95, 96, 98, 102, 103, 109, 114], "keep": [2, 6, 10, 12, 20, 101, 104], "track": [2, 9], "own": [2, 87, 129], "meanwhil": [2, 72], "util": [2, 10, 11, 13, 14, 17, 20, 58, 62, 63, 67, 68, 71, 74, 77, 79, 80, 81, 86, 87, 93, 95, 101, 102, 103, 104, 106, 117, 118, 122, 123, 124, 127], "manag": [2, 130], "increasingli": 2, "hot": 2, "topic": [2, 32, 117], "among": [2, 4, 9, 10, 11, 12, 13, 14, 59, 65, 71, 78, 79, 83, 86, 87, 95, 100, 102, 107, 125, 126, 129], "them": [2, 6, 10, 15, 21, 22, 28, 32, 59, 71, 83, 94, 101, 103, 107], "decid": [2, 18, 23, 93, 95, 96, 97, 98, 99, 100], "biggest": 2, "challeng": [2, 3, 10, 63, 68, 117, 118], "given": [2, 4, 6, 11, 13, 14, 15, 16, 17, 21, 22, 24, 25, 27, 29, 32, 44, 49, 58, 59, 62, 63, 65, 68, 71, 72, 73, 74, 77, 78, 80, 81, 89, 90, 91, 95, 100, 102, 117, 129], "activ": 2, "suggest": [2, 4, 44, 65, 78, 85, 106, 107, 115], "help": [2, 27, 77, 79, 83, 87, 106, 107, 127], "regul": [2, 3, 10, 12], "psycholog": [2, 21], "howev": [2, 4, 6, 9, 12, 15, 18, 19, 21, 22, 23, 25, 28, 32, 44, 62, 63, 67, 68, 71, 74, 77, 84, 107, 109, 114, 117, 118], "send": [2, 44, 58, 97, 98, 100], "written": [2, 5, 9, 14, 15, 19, 20, 21, 25, 32], "intuit": [2, 47, 79, 82, 107, 108], "asleep": 2, "intens": [2, 19], "workout": 2, "rare": [2, 68], "exercis": 2, "would": [2, 4, 19, 21, 22, 26, 32, 44, 47, 58, 59, 60, 72, 73, 76, 77, 78, 79, 80, 81, 82, 83, 84, 87, 88, 89, 90, 91, 94, 99, 101, 106, 107, 109, 114, 116, 117, 118, 121, 125, 126, 129], "decreas": [2, 3, 63, 82, 107, 108, 122, 123], "To": [2, 13, 15, 17, 18, 22, 23, 27, 49, 59, 62, 63, 67, 71, 72, 82, 88, 94, 95, 102, 117, 127, 128, 130], "number": [2, 4, 9, 11, 13, 14, 20, 22, 23, 25, 27, 44, 47, 49, 59, 67, 74, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 108, 115, 116, 122, 123, 128, 129], "formal": [2, 3, 4, 15, 17, 24, 25, 71, 73, 94, 99], "reinforc": [2, 5, 9, 10, 11, 12, 13, 14, 58, 65, 66, 67, 71, 72, 73, 77, 82, 107, 108, 117, 118, 120], "mdp": [2, 32, 62, 67, 71, 72, 73, 117, 118], "seri": [2, 5, 18, 23, 44, 67, 71, 74], "stage": [2, 16, 17, 25, 32, 120, 129], "condit": [2, 4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 25, 32, 44, 49, 59, 62, 63, 73, 74, 86, 89, 90, 91, 95, 100, 102, 106, 117, 118], "affect": [2, 3, 4, 6, 12, 15, 21, 47, 129], "previou": [2, 17, 19, 73, 79, 85, 87, 89, 90, 91, 95, 100, 102, 106, 107, 116, 127, 129], "delai": [2, 20, 77, 120], "current": [2, 3, 20, 59, 72, 73, 78, 89, 90, 91, 117, 129], "decis": [2, 5, 9, 15, 17, 44, 49, 58, 59, 60, 74, 77, 78, 87, 89, 90, 91, 101, 117, 118, 127, 128, 129, 130], "subsequ": [2, 4, 6, 106], "regard": [2, 19, 63, 65, 67, 71, 79, 129], "cumul": [2, 67, 72, 73, 78, 79, 83, 87, 95, 100, 102, 106, 107, 117, 127], "sequenc": [2, 25, 76, 78, 87, 106, 116, 118, 128], "longitudin": [2, 32, 75, 121], "subject": [2, 4, 6, 15, 19, 22, 44, 58, 74, 77], "experienc": 2, "entir": [2, 5, 17, 32, 95, 100, 102, 122, 123, 129], "formul": [2, 9, 13, 73, 100, 129], "illustr": [2, 17, 18, 21, 23, 27, 59, 63, 78, 83, 89, 90, 91, 107, 117, 122, 123, 124, 129], "context": [2, 21, 49, 78, 79, 89, 90, 91, 129], "hiv": 2, "infect": [2, 3], "time": [2, 5, 9, 10, 11, 13, 14, 16, 19, 21, 25, 32, 44, 49, 59, 63, 67, 71, 72, 73, 74, 75, 79, 82, 83, 85, 86, 87, 89, 90, 91, 106, 107, 108, 115, 117, 118, 120, 121, 122, 123, 125, 126, 127, 129], "datamdp": [2, 74, 76, 77], "cd4": 2, "count": [2, 82, 85, 108, 115, 128], "wa": [2, 4, 9, 13, 15, 21, 24, 25, 27, 32, 47, 58, 59, 74, 77, 118], "all": [2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 24, 25, 26, 27, 28, 29, 32, 44, 47, 58, 59, 63, 71, 73, 74, 76, 77, 79, 86, 87, 89, 90, 91, 94, 97, 98, 99, 100, 103, 105, 106, 107, 116, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129], "interact": [2, 20, 25, 87, 106, 116], "same": [2, 4, 5, 6, 15, 18, 19, 21, 22, 23, 28, 29, 44, 47, 58, 63, 73, 74, 77, 88, 97, 98, 101, 102, 103, 104, 106, 117], "possibl": [2, 4, 6, 9, 13, 22, 29, 63, 97, 98, 100, 127, 128, 129], "style": [2, 14, 105], "mani": [2, 3, 5, 9, 10, 12, 47, 65, 71, 72, 73, 89, 90, 91, 95, 100, 102, 106, 116, 117], "channel": [2, 59], "distribut": [2, 4, 6, 9, 14, 17, 21, 22, 23, 25, 47, 59, 60, 63, 71, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 109, 114, 117, 118, 127, 129], "credit": 2, "correspond": [2, 4, 6, 10, 12, 32, 44, 47, 49, 58, 59, 62, 63, 67, 68, 71, 73, 74, 77, 79, 82, 83, 84, 85, 86, 87, 88, 94, 95, 98, 101, 102, 103, 104, 106, 107, 108, 109, 114, 115, 116, 117, 118, 129], "contribut": [2, 3, 10], "recent": [2, 3, 9, 11, 12, 13, 14, 17, 20, 22, 23, 25, 32, 44, 47, 49, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 71, 74, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 107, 108, 109, 114, 115, 118, 120, 121, 122, 123, 125, 126, 127, 128, 130], "becom": [2, 15, 24, 25, 32, 63, 67, 118], "rule": [2, 47, 49, 98], "simpl": [2, 18, 23, 65, 66, 67, 78, 82, 87, 100, 107, 108, 129], "been": [2, 4, 6, 9, 13, 15, 18, 23, 27, 32, 49, 59, 62, 67, 68, 71, 78, 83, 84, 86, 87, 98, 103, 107, 109, 114, 122, 123, 124, 129], "long": [2, 17, 32, 62, 67, 71, 101, 129], "ever": 2, "enhanc": 2, "capabl": 2, "driven": 2, "attempt": 2, "popular": [2, 49, 66, 94, 95, 101, 104, 106, 107, 116, 117], "framework": [2, 4, 6, 15, 17, 79, 80, 86, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 116, 120], "classic": [2, 4, 6, 9, 14, 21, 22, 24, 25, 32, 49, 58, 65, 77, 79, 83, 84, 107, 114, 118, 129, 130], "bandit": [2, 5, 89, 90, 91, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 115, 116, 118, 127], "prefer": [2, 19, 20, 22, 28], "click": [2, 19, 94, 102, 103, 104, 106], "overal": [2, 19, 22, 23, 25, 44, 58, 59, 74, 77, 79, 83, 94, 95, 99, 100, 101, 102, 107, 122, 123, 129], "repres": [2, 4, 6, 9, 11, 12, 13, 14, 15, 27, 49, 117, 122, 123, 124, 129], "movi": [2, 79, 82, 83, 87, 102, 103, 104, 106, 107, 116, 127, 128], "youtub": 2, "netflix": 2, "agent": [2, 59, 72, 73, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 109, 114, 116, 117, 127], "list": [2, 11, 13, 14, 32, 61, 74, 88, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 106, 116, 122, 123, 127, 129], "video": [2, 59], "visit": [2, 32, 49, 63, 67, 79, 83, 87, 94, 101, 106, 107, 117, 127], "site": [2, 10, 11, 16, 17, 18, 20, 22, 23, 24, 25, 44, 58, 61, 74, 77, 120, 121, 122, 123, 125, 128], "either": [2, 4, 6, 15, 27, 44, 58, 60, 62, 65, 66, 71, 74, 77, 79, 82, 84, 85, 86, 88, 90, 93, 95, 96, 97, 98, 100, 101, 102, 103, 104, 106, 107, 108, 115, 117, 118, 129], "leav": [2, 3, 32, 83, 87, 94, 106, 129], "typic": [2, 62, 67, 68, 71, 78, 79, 83, 99, 100, 117, 129], "larg": [2, 17, 19, 27, 47, 61, 62, 63, 65, 67, 71, 73, 78, 82, 84, 85, 86, 87, 88, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 107, 115, 122, 123, 124], "avail": [2, 4, 6, 9, 10, 13, 14, 17, 39, 60, 73, 79, 83, 87, 93, 94, 100, 101, 106, 107, 116, 122, 123, 124, 127], "therefor": [2, 17, 32, 44, 58, 63, 65, 66, 67, 79, 83, 84, 87, 88, 94, 97, 98, 100, 107, 109, 114, 117, 121, 125, 126, 127, 129], "explor": [2, 22, 32, 47, 59, 62, 63, 65, 66, 67, 68, 69, 71, 77, 79, 80, 81, 82, 83, 84, 85, 86, 88, 89, 93, 96, 105, 107, 108, 109, 114, 115, 117, 127], "exploit": [2, 19, 82, 83, 84, 85, 89, 90, 91, 96, 107, 108, 109, 114, 115], "inform": [2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 17, 19, 22, 27, 29, 44, 49, 60, 67, 71, 74, 76, 78, 79, 80, 81, 84, 86, 87, 88, 90, 91, 93, 94, 95, 97, 98, 100, 101, 102, 103, 106, 107, 109, 114, 116, 118, 120, 121, 125, 126, 129, 130], "far": [2, 82, 85, 107, 108], "approach": [2, 3, 4, 6, 15, 16, 17, 18, 21, 22, 25, 32, 44, 47, 58, 62, 63, 65, 66, 67, 68, 71, 74, 77, 78, 79, 101, 103, 104, 105, 107, 117, 118, 129], "As": [2, 15, 20, 22, 25, 26, 28, 29, 32, 62, 63, 65, 71, 72, 73, 78, 80, 81, 85, 86, 88, 93, 95, 96, 107, 109, 115, 117, 120, 121, 122, 123, 125, 126, 129], "chapter": [2, 60, 73, 79, 83, 87, 93, 95, 96, 97, 98, 100, 102, 103, 104, 106, 107, 116, 117, 118, 129], "genr": [2, 79, 83, 87, 106, 107, 127], "five": [2, 102, 103, 104, 106], "whose": [2, 3, 73, 129], "unknown": [2, 9, 12, 13, 67, 71, 78, 79, 83, 84, 86, 88, 89, 90, 91, 95, 100, 102, 107, 109, 114, 129], "over": [2, 3, 15, 22, 49, 62, 63, 67, 71, 88, 89, 90, 91, 104, 107, 117, 122, 129], "satisfact": [2, 27, 79, 83, 87, 106, 107, 127], "movielen": [2, 15, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 101, 102, 103, 104, 106, 107, 116, 128], "arm": [2, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 98, 99, 106, 107, 108, 115, 116, 127, 129], "contextu": [2, 78, 80, 81, 83, 89, 90, 91, 101, 102, 103, 107, 109, 127, 129], "meta": [2, 19, 29, 78, 86, 94, 95, 99, 100, 101, 102, 106, 129], "multipl": [2, 9, 10, 11, 12, 13, 14, 32, 44, 47, 59, 61, 78, 88, 118, 125, 126, 129], "million": [2, 3, 9, 10, 11, 12, 13, 14], "try": [2, 16, 17, 20, 24, 25, 27, 107, 122, 123, 130], "assort": [2, 102, 104, 105, 106, 116, 129], "rank": [2, 93, 95, 96, 106, 116, 129], "top": [2, 9, 10, 11, 12, 13, 14, 17, 73, 79, 83, 87, 93, 94, 95, 96, 104, 106, 107, 117, 122, 123], "restaur": [2, 93, 94, 95, 96], "true": [2, 3, 10, 11, 13, 14, 17, 18, 20, 21, 22, 23, 25, 44, 47, 58, 59, 60, 61, 63, 65, 74, 77, 80, 81, 82, 84, 86, 88, 90, 102, 104, 105, 106, 107, 108, 109, 114, 115, 120, 121, 122, 123, 125, 126], "expect": [2, 15, 16, 17, 18, 20, 22, 23, 24, 25, 26, 28, 29, 32, 44, 47, 49, 58, 62, 67, 71, 72, 73, 74, 77, 79, 80, 81, 84, 86, 87, 88, 90, 91, 96, 98, 107, 121, 122, 123, 125, 126, 127, 128], "yelp": [2, 93, 94, 95, 96], "discuss": [2, 9, 32, 67, 71, 72, 73, 88, 117, 129, 130], "offlin": [2, 27, 32, 49, 59, 90, 117, 118, 129], "prevent": 2, "unnecessari": [2, 122, 123], "essenti": [2, 3, 71, 86, 118], "variant": [2, 3, 67, 82, 107, 108, 117], "frequent": 2, "commerci": 2, "googl": 2, "displai": [2, 5, 17, 21, 93, 94, 95, 96], "twitter": 2, "view": [2, 3, 24, 71, 90, 91, 122, 123], "bipartit": 2, "match": [2, 16, 62, 67, 90, 91, 99, 102, 103, 104, 106, 116], "need": [2, 20, 25, 44, 49, 59, 67, 74, 79, 83, 84, 85, 87, 88, 94, 99, 101, 106, 107, 109, 114, 116, 117, 118, 120, 130], "show": [2, 4, 10, 15, 19, 59, 62, 71, 73, 82, 90, 93, 95, 96, 99, 101, 107, 108, 127], "most": [2, 5, 9, 11, 12, 13, 14, 17, 20, 22, 23, 25, 26, 32, 44, 47, 49, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 71, 72, 73, 74, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 114, 115, 116, 117, 120, 121, 122, 123, 125, 126, 127, 128, 129], "like": [2, 5, 19, 21, 22, 26, 27, 28, 44, 47, 58, 59, 63, 77, 79, 83, 87, 106, 107, 121, 125, 126, 127], "attract": [2, 3, 4, 9, 11, 12, 13, 14, 15, 22, 59, 89, 90, 91, 94, 95, 96, 97, 98, 99, 100, 106], "while": [2, 6, 10, 12, 22, 28, 32, 44, 47, 59, 74, 78, 79, 88, 95, 100, 102, 103, 120, 129], "adher": 2, "budget": 2, "constraint": [2, 5, 9, 10, 13, 20, 65, 97, 98, 99, 100, 106, 116], "feedback": [2, 78, 79, 80, 83, 87, 89, 90, 91, 95, 99, 100, 102, 106, 107, 109, 114, 116], "achiev": [2, 17, 19, 20, 25, 47, 62, 63, 71, 84, 88], "whom": 2, "its": [2, 5, 9, 11, 13, 17, 19, 20, 22, 25, 47, 49, 62, 63, 66, 67, 71, 72, 73, 79, 84, 86, 87, 90, 93, 107, 109, 114, 117, 129, 130], "chanc": 2, "accept": [2, 5], "adult": [2, 97, 98, 99, 100], "combinatori": [2, 95, 97, 98, 100, 102, 105, 106, 116, 129], "world": [2, 78, 79, 83, 87, 93, 98, 107], "across": [2, 86, 87, 97], "retail": 2, "adjust": [2, 10, 21, 88], "period": [2, 11, 32, 120, 121, 122, 123, 125, 129], "rideshar": 2, "servic": [2, 94], "weather": 2, "occur": [2, 20, 73, 117], "outsid": [2, 3, 10, 32], "airlin": 2, "rais": [2, 16, 17, 21, 61, 120, 125, 126, 128], "ticket": 2, "farewel": 2, "date": [2, 86, 88], "rise": [2, 15], "low": [2, 5, 62, 67, 71, 104, 106, 118, 122, 123], "evalut": 2, "section": [2, 4, 6, 15, 17, 19, 20, 21, 22, 25, 32, 67, 68, 71, 73, 117, 120, 122, 123, 125, 126, 127, 129, 130], "harper": 2, "f": [2, 10, 20, 62, 71, 74, 77, 88, 94, 95, 100, 102, 106, 116, 122, 123, 130], "m": [2, 5, 10, 12, 15, 16, 17, 19, 20, 21, 24, 25, 44, 49, 58, 59, 62, 63, 65, 72, 74, 75, 77, 79, 80, 86, 87, 88, 89, 90, 91, 93, 94, 98, 101, 102, 103, 107, 109, 121, 125, 126, 129], "konstan": 2, "j": [2, 9, 11, 13, 14, 15, 16, 17, 19, 20, 21, 22, 25, 26, 28, 29, 44, 59, 63, 71, 73, 74, 78, 79, 86, 87, 88, 89, 90, 91, 95, 101, 102, 103, 104, 105, 107, 114, 115, 117, 120, 125, 126], "acm": [2, 49], "transact": 2, "intellig": [2, 5, 19, 49, 78, 79, 80, 81, 87, 93, 94, 96, 107, 109, 117, 118], "tii": 2, "19": [2, 5, 10, 17, 44, 61, 62, 122, 123, 127, 128], "2015": [2, 5, 47, 58, 67, 71, 77, 78, 94, 97, 99, 107, 117, 128], "asghar": 2, "n": [2, 4, 6, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 44, 47, 49, 58, 59, 60, 61, 62, 63, 65, 66, 67, 71, 72, 73, 74, 76, 77, 79, 80, 82, 83, 84, 85, 86, 87, 88, 93, 94, 95, 97, 99, 100, 101, 102, 103, 105, 106, 107, 108, 109, 115, 116, 117, 121, 122, 123, 125, 126, 127, 128, 129, 130], "review": [2, 9, 12, 17, 19, 44, 49, 67, 68, 71, 74, 83, 95, 100, 102, 106, 107, 130], "arxiv": [2, 5, 9, 10, 11, 12, 13, 14, 16, 19, 20, 25, 49, 62, 65, 79, 83, 84, 89, 90, 91, 93, 94, 95, 99, 100, 101, 102, 103, 106, 107, 116, 117, 118, 120], "preprint": [2, 5, 9, 10, 11, 12, 13, 14, 16, 19, 20, 25, 49, 62, 65, 79, 83, 84, 89, 90, 91, 93, 94, 95, 99, 100, 101, 102, 103, 106, 107, 116, 117, 118, 120], "1605": [2, 128], "05362": 2, "2016": [2, 5, 62, 67, 71, 93, 94, 95, 99, 102, 117], "asuncion": 2, "newman": 2, "d": [2, 5, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 24, 25, 32, 44, 49, 58, 59, 63, 67, 71, 72, 73, 74, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 106, 107, 114, 115, 116, 117, 120, 121, 125, 126, 127, 128], "uci": 2, "machin": [2, 5, 9, 10, 11, 12, 13, 14, 15, 17, 19, 22, 26, 28, 29, 62, 63, 66, 67, 68, 71, 78, 79, 80, 82, 85, 87, 88, 94, 97, 98, 99, 104, 106, 107, 108, 109, 114, 115, 116, 117], "repositori": [2, 9, 10, 11, 13, 130], "2007": [2, 9, 10, 11, 12, 13, 14, 79], "tsiati": [2, 15, 44, 74, 129], "davidian": [2, 15, 44, 74, 129], "hollowai": [2, 129], "laber": [2, 15, 44, 74, 129], "2019": [2, 3, 5, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 22, 23, 25, 26, 28, 29, 34, 35, 38, 39, 40, 41, 42, 62, 65, 79, 83, 94, 96, 101, 102, 103, 104, 105, 107, 129], "precis": [2, 19, 80, 84, 86, 88, 95, 102, 129], "medicin": [2, 19, 47, 89, 90, 91, 129], "chapman": [2, 129], "hall": [2, 129], "crc": [2, 129], "era": [3, 10], "revolut": [3, 10], "area": [3, 10, 32, 47, 83, 89, 90, 91, 107, 117], "gener": [3, 4, 6, 10, 19, 20, 21, 22, 27, 32, 34, 35, 38, 39, 40, 41, 42, 47, 49, 58, 62, 65, 67, 68, 71, 72, 73, 77, 78, 79, 83, 87, 89, 90, 91, 99, 106, 107, 109, 115, 116, 123, 127, 128, 129, 130], "graph": [3, 10, 129], "direct": [3, 9, 10, 11, 12, 13, 14, 59, 63, 65, 66, 71, 78, 101, 104, 117, 120, 121, 125, 126], "indirect": [3, 10, 12, 21, 121, 125, 126], "mediat": [3, 9, 11, 13, 14, 32, 73, 75], "intermedi": 3, "variabl": [3, 4, 6, 9, 10, 11, 12, 13, 14, 16, 19, 20, 21, 22, 23, 25, 27, 32, 47, 58, 59, 68, 73, 76, 77, 79, 83, 87, 94, 107, 117, 118, 127, 128, 129], "instanc": [3, 32, 47, 61, 88, 95, 102], "outbreak": 3, "coronaviru": [3, 10], "diseas": 3, "chines": [3, 10], "govern": 3, "taken": [3, 60, 63, 76, 87, 90, 91, 129], "extrem": [3, 22, 28], "stop": [3, 89, 90, 91, 94, 106], "viru": 3, "lock": 3, "wuhan": 3, "down": 3, "jan": [3, 9, 10, 11, 12, 13, 14], "23rd": 3, "2020": [3, 5, 9, 11, 12, 13, 14, 16, 18, 19, 20, 24, 25, 49, 79, 80, 84, 93, 98, 100, 103, 104, 107, 109, 117, 118], "12": [3, 5, 9, 10, 11, 12, 13, 14, 23, 27, 44, 58, 59, 61, 79, 107, 118, 121, 122, 123, 125, 126, 127, 128], "citi": [3, 10], "hubei": [3, 10], "lockdown": [3, 10], "directli": [3, 5, 12, 17, 27, 44, 47, 58, 59, 62, 63, 65, 66, 67, 68, 69, 71, 72, 73, 74, 96, 100, 104, 105, 108, 109, 114, 115, 117, 118, 120, 125, 126], "block": [3, 5, 121, 125, 126], "peopl": [3, 15, 26, 27, 28, 29], "stimul": [3, 59], "quarantin": 3, "further": [3, 10, 12, 20, 25, 59, 63, 95, 97, 98, 100, 102, 106, 116, 120, 121, 125, 126, 127, 129], "migrat": 3, "countrywid": 3, "china": [3, 10], "thu": [3, 9, 12, 15, 17, 18, 20, 23, 25, 49, 59, 73, 87, 89, 90, 91], "indirectli": 3, "reduc": [3, 10, 12, 20, 21, 59, 63], "great": [3, 19, 94], "crisi": 3, "mechan": [3, 10, 73], "individu": [3, 4, 6, 10, 15, 22, 27, 29, 44, 47, 49, 58, 60, 63, 74, 76, 77, 101, 116, 121, 125, 126, 128], "decad": 3, "discoveri": [3, 12, 49], "disentangl": [3, 9, 11, 12, 13, 14], "complex": [3, 5, 9, 11, 12, 13, 14, 22, 28, 32, 49, 63, 97, 98, 100, 104, 118, 129], "field": [3, 44, 74, 78], "4": [3, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 27, 28, 29, 44, 47, 49, 58, 59, 61, 63, 71, 74, 77, 78, 79, 80, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 94, 95, 99, 100, 101, 102, 105, 106, 107, 108, 109, 114, 115, 116, 117, 120, 121, 122, 123, 125, 126, 127, 128], "5": [3, 9, 10, 11, 12, 13, 14, 15, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 44, 47, 49, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 71, 74, 75, 77, 79, 83, 84, 87, 88, 94, 95, 99, 101, 102, 103, 104, 105, 107, 108, 109, 114, 115, 120, 121, 122, 123, 125, 126, 127, 128], "singl": [3, 22, 26, 28, 32, 49, 62, 71, 74, 77, 108, 109, 114, 115, 122, 123, 124, 129], "nucleotid": 3, "polymorph": 3, "snp": 3, "person": [3, 9, 32, 44, 49, 58, 74, 77, 79, 107, 130], "genom": 3, "fewer": [3, 129], "non": [3, 9, 10, 12, 13, 14, 17, 19, 27, 44, 47, 58, 59, 74, 77, 90, 91], "spuriou": 3, "protein": 3, "systemat": [3, 130], "phenotyp": 3, "focu": [3, 4, 6, 12, 16, 17, 18, 19, 20, 24, 26, 28, 29, 44, 65, 74, 78, 79, 83, 87, 89, 90, 91, 100, 101, 102, 107, 117, 127, 129], "brem": 3, "kruglyak": 3, "2005": [3, 5, 58, 66, 77, 118], "discov": [3, 106], "featur": [3, 4, 6, 12, 15, 16, 24, 27, 47, 49, 60, 79, 80, 81, 86, 87, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 109, 116, 117, 120, 122, 123, 124, 127, 129], "explain": 3, "104": [3, 20, 44, 83, 128], "segreg": 3, "simul": [3, 6, 10, 12, 17, 27, 79, 83, 87, 106, 127], "genet": 3, "divers": [3, 58, 77, 129], "strain": 3, "by4716": 3, "rm11": 3, "1a": [3, 20, 25], "contain": [3, 4, 6, 9, 11, 12, 13, 14, 15, 17, 19, 27, 49, 60, 76, 88, 89, 90, 91, 94, 106, 116, 127, 128, 129, 130], "thousand": [3, 74, 77, 122, 123], "genotyp": 3, "rich": 3, "influenc": [3, 10, 12, 21, 63, 129], "target": [3, 10, 22, 23, 25, 32, 49, 58, 59, 62, 65, 67, 71, 72, 73, 77, 90, 99, 120, 121, 125, 126, 129], "herit": 3, "due": [3, 14, 32, 62, 63, 65, 66, 67, 68, 104, 117, 118, 120, 122, 123, 124, 129], "dimension": [3, 4, 9, 10, 11, 12, 13, 14, 15, 18, 23, 44, 63, 74, 87, 106, 116, 118, 129], "name": [3, 5, 9, 11, 13, 14, 16, 17, 21, 24, 25, 32, 44, 49, 59, 62, 65, 71, 74, 77, 78, 83, 85, 87, 95, 99, 107, 115, 117, 122, 123, 127, 128], "quantit": 3, "loci": 3, "qtl": 3, "involv": [3, 78, 117], "parsimoni": 3, "reveal": 3, "necessari": [3, 4, 6, 80, 95, 96, 97, 98, 102, 103], "depend": [3, 5, 49, 63, 67, 71, 73, 78, 79, 89, 90, 91, 99, 100, 101, 104, 106, 116, 117, 118, 129], "present": [3, 63, 72, 93, 95, 96, 97, 98, 100, 102, 103, 104, 129], "toward": [3, 63, 94, 95, 99, 100, 101, 102, 106], "yer124c": 3, "daughter": 3, "cell": [3, 5, 47, 62, 63, 65, 66, 67, 68, 69, 71, 105, 108, 109, 114, 115], "particip": 3, "pathwai": 3, "wall": 3, "metabol": 3, "delet": [3, 11, 13, 14], "separ": [3, 15, 19, 21, 22, 28, 29, 62, 71, 99], "divis": 3, "sensit": [3, 21, 44, 47, 74, 125, 126], "against": [3, 63], "consid": [4, 6, 9, 11, 12, 13, 14, 19, 32, 44, 58, 59, 60, 62, 63, 65, 66, 67, 71, 72, 73, 74, 77, 79, 80, 83, 84, 86, 87, 88, 93, 94, 95, 97, 98, 100, 101, 102, 103, 106, 109, 114, 116, 120, 121, 125, 126, 129], "popul": [4, 6, 15, 128], "doe": [4, 6, 9, 11, 12, 13, 14, 79, 93, 95, 96, 118, 121, 125, 126, 129], "y": [4, 6, 10, 12, 15, 16, 17, 19, 20, 21, 25, 44, 47, 49, 58, 59, 61, 74, 77, 78, 79, 89, 90, 91, 94, 95, 98, 99, 100, 101, 102, 104, 106, 107, 116, 127, 129], "establish": [4, 6, 14, 58, 63, 77], "respons": [4, 5, 6, 15, 22, 26, 28, 101, 102, 103, 104, 118], "advoc": [4, 6], "neyman": [4, 6], "rubin": [4, 6], "robin": [4, 6, 15, 17, 44, 74, 125, 126], "denot": [4, 6, 9, 11, 13, 19, 20, 21, 22, 25, 27, 28, 32, 49, 59, 62, 63, 65, 66, 67, 71, 72, 73, 78, 79, 83, 86, 87, 89, 90, 91, 94, 99, 101, 106, 107, 116, 117, 122, 123, 129], "vector": [4, 6, 9, 11, 12, 13, 14, 20, 25, 73, 79, 80, 84, 87, 94, 95, 100, 101, 102, 106, 109, 114, 116, 117, 118, 129], "simplic": [4, 6, 22, 67, 97, 98, 100, 129], "simplest": [4, 5, 6, 59], "case": [4, 6, 9, 11, 13, 14, 15, 19, 22, 24, 25, 28, 32, 44, 47, 58, 59, 74, 77, 85, 114, 116, 129, 130], "binari": [4, 6, 10, 21, 27, 44, 47, 58, 60, 74, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 93, 94, 95, 96, 99, 101, 102, 103, 104, 107, 121, 122, 123, 125, 126, 127, 129], "0": [4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 44, 47, 49, 58, 59, 60, 61, 62, 63, 65, 66, 67, 71, 72, 73, 74, 77, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 114, 115, 117, 120, 121, 122, 123, 125, 126, 127, 128, 129], "sai": [4, 6, 9, 11, 13, 14], "versu": [4, 6, 17, 24, 27, 32, 122, 123, 129], "acquir": [4, 6], "app": [4, 6, 120, 121, 125], "download": [4, 6, 17, 23, 59], "baselin": [4, 6, 11, 13, 14, 15, 22, 27, 67, 71, 79, 86, 87, 107, 127], "observ": [4, 5, 6, 9, 11, 13, 15, 17, 19, 20, 21, 22, 23, 25, 26, 32, 47, 49, 58, 60, 62, 63, 65, 67, 71, 72, 73, 74, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 102, 105, 106, 107, 108, 115, 116, 117, 118, 120, 121, 125, 126, 127, 129], "summar": [4, 6, 9, 10, 17, 19, 22, 26, 28, 59, 83, 118, 120, 121, 125, 126, 127, 129], "z_i": [4, 6, 9, 11, 12, 13, 14, 20, 25], "x_i": [4, 15, 47, 49, 59], "t_i": [4, 72, 73], "y_i": [4, 47, 49, 59], "th": [4, 6, 15, 18, 23, 63, 67, 68, 72, 73, 87, 94, 120], "covari": [4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 25, 86, 88, 97, 98, 100, 122, 123], "prior": [4, 6, 11, 78, 79, 80, 84, 86, 87, 88, 95, 96, 97, 98, 100, 102, 103, 104, 107, 109, 114, 120, 127], "assum": [4, 6, 9, 11, 13, 24, 25, 44, 47, 58, 67, 72, 73, 74, 77, 78, 79, 80, 81, 83, 84, 86, 87, 88, 93, 95, 96, 97, 98, 100, 101, 102, 103, 104, 106, 107, 109, 114, 116, 118, 127, 129], "chosen": [4, 6, 16, 17, 18, 19, 20, 24, 26, 28, 29, 65, 73, 79, 90, 91, 94, 95, 99, 101, 102, 103, 104], "henc": [4, 6, 10, 15, 27, 47, 62, 67, 71, 79, 83, 87, 95, 102, 107, 117, 118, 127], "sometim": [4, 6, 117], "refer": [4, 5, 6, 59, 130], "counterfactu": [4, 6, 73, 117, 129], "becaus": [4, 6, 20], "realiti": [4, 6], "hypothet": [4, 6], "contrari": [4, 6], "fact": [4, 6, 62, 63, 65, 66, 71, 72, 79, 117], "actual": [4, 6, 15, 118], "than": [4, 6, 10, 15, 19, 20, 22, 25, 26, 28, 29, 49, 62, 63, 67, 68, 71, 73, 79, 81, 83, 87, 107, 127], "notion": [4, 6], "defin": [4, 5, 6, 10, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 32, 44, 49, 58, 59, 62, 63, 67, 68, 71, 72, 73, 74, 77, 82, 89, 90, 91, 94, 95, 99, 106, 107, 108, 116, 121, 125, 126, 127, 129], "now": [4, 6, 16, 22, 59, 106, 117], "deduc": [4, 6], "x": [4, 6, 15, 17, 18, 19, 20, 21, 23, 24, 25, 44, 47, 49, 58, 59, 61, 78, 80, 81, 86, 88, 89, 90, 91, 96, 97, 107, 109, 116, 127, 128], "sutva": [4, 6, 15, 32, 73], "stabl": [4, 6, 10, 15, 24, 122, 123], "unit": [4, 6, 15, 129], "begin": [4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 32, 44, 47, 49, 58, 59, 62, 63, 65, 66, 67, 68, 71, 72, 73, 74, 77, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91, 93, 94, 95, 97, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 115, 116, 117, 121, 125, 126, 129], "align": [4, 6, 15, 17, 21, 24, 25, 32, 44, 47, 58, 62, 63, 67, 71, 72, 74, 77, 80, 81, 82, 84, 85, 104, 108, 109, 115, 117, 121, 125, 126], "end": [4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 32, 44, 47, 49, 58, 59, 62, 63, 65, 66, 67, 68, 71, 72, 73, 74, 77, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91, 93, 94, 95, 97, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 114, 115, 116, 117, 121, 125, 126, 129], "That": [4, 6, 15, 19, 24, 25, 59], "regardless": [4, 6, 15], "interfer": [4, 6, 15, 32], "No": [4, 6, 9, 11, 13, 14, 15, 21, 44, 47, 49, 58, 59, 62, 63, 65, 66, 67, 68, 69, 71, 74, 77, 80, 81, 82, 84, 85, 86, 87, 88, 93, 95, 96, 97, 98, 100, 101, 102, 103, 104, 105, 108, 109, 114, 115, 120, 121, 122, 123, 125, 126, 128, 129], "unmeasur": [4, 6, 9, 11, 13, 14, 15, 21, 22, 26, 32, 73, 118], "confound": [4, 5, 6, 9, 11, 12, 13, 14, 15, 21, 22, 26, 32, 73, 118, 120, 121, 125, 126, 129], "strong": [4, 6, 14, 15, 18, 23, 32, 67, 71], "ignor": [4, 6, 15, 67, 71, 74, 77, 89, 90, 91, 122, 123, 130], "perp": [4, 6, 15, 21, 73], "refut": [4, 6, 15], "believ": [4, 6, 15, 129], "relev": [4, 6, 15, 67], "reason": [4, 6, 9, 12, 14, 15, 19, 25], "p": [4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 17, 19, 20, 21, 22, 25, 26, 28, 29, 32, 44, 47, 49, 61, 71, 72, 73, 74, 79, 80, 81, 82, 85, 86, 88, 93, 95, 97, 98, 99, 100, 102, 103, 105, 107, 108, 109, 114, 115, 117, 120, 125, 126, 127, 129, 130], "ensur": [4, 6, 15, 73], "similar": [4, 5, 6, 15, 21, 47, 62, 63, 66, 67, 71, 73, 74, 78, 80, 81, 82, 84, 85, 86, 87, 88, 93, 94, 109, 117, 129], "vice": [4, 6, 15], "versa": [4, 6, 15], "text": [4, 5, 6, 12, 15, 16, 17, 19, 21, 22, 25, 26, 28, 29, 32, 47, 58, 60, 62, 65, 66, 72, 77, 85, 86, 88, 95, 100, 102, 103, 117], "ATE": [4, 6, 12, 17, 19, 21, 26, 28, 32, 120], "There": [4, 5, 6, 19, 59, 60, 85, 117], "deriv": [4, 6, 18, 21, 22, 23, 29, 32, 44, 49, 63, 68, 77, 100, 120], "confoun": 4, "come": [4, 97, 98, 129], "consider": 4, "e_x": [4, 15], "quad": [4, 15, 18, 22, 23, 29, 44, 74, 86, 88, 89, 90, 91, 95, 100, 102], "similarli": [4, 10, 15, 44, 62, 63, 71, 72, 73, 74, 86, 88, 99, 100, 106, 120, 122, 123], "mu": [4, 15, 16, 21, 22, 25, 26, 80, 84, 86, 87, 88, 89, 90, 91, 93, 95, 100, 102, 121], "gamma": [4, 15, 17, 20, 25, 32, 44, 62, 63, 65, 66, 67, 71, 72, 73, 74, 80, 81, 86, 88, 93, 95, 97, 100, 102, 103, 109, 117], "paramet": [4, 9, 11, 15, 17, 18, 20, 23, 25, 49, 80, 82, 85, 86, 88, 95, 100, 101, 102, 104, 107, 108, 109, 120], "mle": 4, "least": [4, 15, 20, 22, 25, 79, 83, 87, 101, 106, 107, 127], "squar": [4, 15, 20, 25], "Then": [4, 9, 10, 11, 12, 13, 14, 15, 18, 23, 68, 74, 77, 79, 83, 85, 87, 89, 90, 91, 95, 100, 102, 106, 107, 115, 116, 117, 127, 130], "hat": [4, 15, 16, 17, 18, 20, 22, 23, 24, 25, 26, 28, 29, 44, 58, 59, 62, 65, 67, 71, 72, 73, 74, 77, 81, 82, 86, 93, 97, 105, 117, 127], "sum_": [4, 15, 17, 18, 21, 23, 32, 44, 49, 58, 59, 62, 63, 65, 66, 67, 68, 71, 72, 73, 74, 79, 83, 85, 87, 89, 90, 91, 93, 94, 95, 99, 100, 101, 102, 103, 104, 105, 107, 115, 117], "anoth": [4, 5, 9, 17, 19, 20, 59, 67, 68, 71, 117, 121, 125, 126], "pi": [4, 15, 16, 20, 25, 32, 47, 58, 59, 62, 63, 65, 66, 67, 68, 71, 72, 73, 77, 89, 90, 91, 117], "get": [4, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 44, 58, 59, 60, 61, 74, 77, 80, 81, 82, 83, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 116, 121, 125, 126, 127], "function": [4, 5, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 44, 47, 49, 58, 59, 62, 63, 65, 66, 67, 71, 73, 74, 79, 81, 82, 86, 89, 90, 91, 95, 97, 98, 100, 101, 102, 103, 106, 107, 108, 116, 117, 127, 128, 129], "One": [4, 15, 62, 71, 117, 130], "difficult": [4, 15, 82], "build": [4, 5, 71, 79, 120, 129, 130], "simpli": [4, 59, 87, 97], "stratifi": 4, "choos": [4, 16, 17, 18, 20, 24, 26, 27, 28, 29, 62, 63, 71, 78, 79, 83, 85, 87, 89, 90, 91, 95, 99, 100, 101, 102, 106, 107, 115, 116], "cutoff": 4, "c_0": 4, "c_1": 4, "c_k": 4, "belong": [4, 27, 65, 129], "k": [4, 5, 9, 10, 11, 12, 13, 14, 17, 20, 25, 49, 59, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 114, 115, 116, 117, 127, 128], "c_": [4, 44, 74, 82, 85, 108, 115], "le": [4, 5, 49, 62, 63, 65, 66, 72, 73, 94], "bar": [4, 18, 23, 32, 67, 73, 76, 77, 117], "_": [4, 9, 11, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 28, 29, 32, 44, 47, 49, 58, 59, 60, 62, 63, 65, 66, 67, 68, 71, 72, 73, 74, 76, 77, 80, 84, 86, 87, 88, 89, 90, 91, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 106, 107, 109, 114, 115, 116, 117, 122, 123, 129], "1k": 4, "0k": 4, "n_k": 4, "theoret": [4, 19, 63, 73, 88, 101, 116, 130], "justif": 4, "semiparametr": [4, 16, 19, 20, 21, 24, 25, 62, 63, 71, 125, 126], "theori": [4, 17, 19, 20, 21, 25, 44, 47, 63, 74, 79, 101, 102, 104, 106, 125, 126], "augment": [4, 15, 47, 63], "ipw": [4, 15, 59, 125, 126], "probabl": [4, 15, 21, 47, 49, 59, 62, 63, 67, 71, 72, 82, 83, 88, 101, 106, 107, 108, 125, 126], "everi": [4, 15, 62, 67, 71, 79, 83, 86, 87, 88, 93, 95, 100, 102, 103, 107, 117, 127], "themselv": [4, 15], "did": [4, 15, 74, 77, 129], "frac": [4, 15, 16, 17, 18, 20, 21, 23, 25, 44, 47, 49, 58, 59, 62, 63, 67, 71, 74, 82, 85, 101, 102, 103, 104, 105, 107, 108, 115], "ty": 4, "unbias": [4, 15, 67], "left": [4, 15, 18, 20, 23, 24, 25, 49, 59, 62, 71, 74, 89, 90, 91, 129], "right": [4, 9, 12, 15, 18, 20, 23, 24, 25, 49, 59, 62, 65, 66, 71, 74, 89, 90, 91, 117, 129], "t_iy_i": 4, "combin": [4, 15, 20, 22, 25, 26, 28, 29, 59, 62, 63, 71, 85, 87, 117, 127, 128], "obtain": [4, 9, 11, 13, 15, 17, 18, 20, 21, 22, 23, 24, 25, 28, 29, 32, 59, 63, 67, 77, 98, 99, 117, 127, 129], "call": [4, 5, 9, 10, 11, 12, 13, 14, 15, 17, 20, 21, 22, 23, 25, 28, 44, 47, 49, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 71, 74, 77, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115, 120, 121, 122, 123, 125, 126, 127, 128, 130], "whether": [5, 90, 91, 102, 103, 104, 122, 123], "write": [5, 15, 18, 23], "content": [5, 20, 25, 32, 129], "jupyt": [5, 130], "notebook": [5, 120, 121, 125, 126], "ipynb": [5, 9, 14], "regular": [5, 49, 71, 86], "md": 5, "ll": [5, 27, 127, 128], "flavor": 5, "stand": [5, 44, 74, 101], "markedli": 5, "slight": 5, "variat": [5, 9], "commonmark": 5, "small": [5, 47, 122, 123], "syntax": [5, 21], "sphinx": 5, "ecosystem": 5, "power": [5, 20, 25, 130], "tool": [5, 15, 17], "kind": [5, 20, 32, 68], "markup": 5, "languag": [5, 78], "serv": [5, 15, 17, 27, 73], "purpos": [5, 15, 27, 122, 123, 124], "line": [5, 17, 19, 21, 28, 62, 71, 130], "wherea": [5, 73, 120], "span": 5, "input": [5, 17, 20, 21, 27, 61, 120, 121, 122, 123, 124, 125, 126, 129], "being": [5, 82, 85, 87, 88, 94, 95, 100, 101, 102, 104, 106, 108, 115, 122, 123, 124, 127], "At": [5, 72, 74, 77, 79, 80, 82, 84, 85, 94, 95, 97, 100, 102, 107, 108, 109, 114, 115, 121], "insert": [5, 127, 128], "mydirectivenam": 5, "my": [5, 19], "work": [5, 9, 13, 17, 21, 32, 44, 59, 63, 74, 77], "alreadi": [5, 18, 23, 58, 59, 77], "doesn": [5, 32, 129], "pre": [5, 11, 73, 82, 106, 107, 108], "note": [5, 10, 11, 13, 14, 17, 19, 22, 29, 32, 44, 47, 58, 59, 60, 72, 73, 74, 77, 80, 82, 84, 85, 86, 87, 88, 93, 95, 96, 97, 98, 100, 101, 102, 103, 106, 109, 114, 116, 118], "box": 5, "here": [5, 9, 10, 11, 12, 13, 14, 17, 18, 19, 20, 23, 44, 47, 49, 63, 72, 74, 77, 80, 81, 82, 84, 85, 86, 87, 88, 90, 91, 93, 95, 96, 97, 98, 100, 102, 103, 104, 106, 107, 108, 114, 116, 120, 121, 125, 126, 127], "built": [5, 47, 71], "see": [5, 9, 10, 11, 13, 14, 17, 20, 22, 24, 25, 26, 28, 63, 71, 79, 83, 88, 106, 107, 122, 123, 129], "document": [5, 15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 122, 123, 127, 128, 130], "less": [5, 19, 44, 49, 74, 117], "pattern": [5, 121, 125, 126], "some": [5, 15, 16, 19, 21, 22, 25, 28, 32, 44, 49, 59, 62, 63, 71, 73, 74, 88, 89, 90, 91, 95, 106, 116, 122, 123, 129], "rolenam": 5, "again": [5, 77, 121, 125, 126], "valid": [5, 20, 63, 68, 73, 117], "doc": [5, 10, 24, 122, 123], "page": [5, 16, 19, 20, 24, 25, 67, 78, 99, 106, 107, 116, 118, 130], "rel": [5, 22, 28, 67, 71, 87, 129], "path": [5, 10, 21, 25], "intro": 5, "cite": [5, 71], "store": [5, 90], "bibtex": 5, "holdgraf_evidence_2014": 5, "render": 5, "moreov": [5, 15, 19, 32, 62, 63, 71], "bibliographi": 5, "properli": [5, 9], "bib": 5, "look": [5, 19, 23, 63], "egw05": [5, 66], "damien": [5, 66], "ernst": [5, 66], "pierr": [5, 66], "geurt": [5, 66], "loui": [5, 66], "wehenkel": [5, 66], "tree": [5, 18, 19, 23, 59, 66], "batch": [5, 20, 65, 66, 95, 100, 102, 117], "mode": [5, 25, 66, 74, 77, 95, 100, 102, 122, 123], "learn": [5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 25, 26, 28, 29, 32, 59, 63, 65, 66, 67, 68, 71, 72, 73, 78, 79, 80, 82, 83, 85, 86, 87, 88, 89, 90, 91, 93, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 114, 115, 116, 120, 121, 125, 126, 130], "journal": [5, 9, 10, 11, 12, 13, 14, 16, 19, 20, 21, 24, 25, 44, 47, 59, 66, 73, 74, 75, 79, 89, 90, 91, 101, 118, 121], "hzal18": [5, 117], "tuoma": [5, 117], "haarnoja": [5, 117], "aurick": [5, 117], "zhou": [5, 49, 59, 62, 67, 78, 104, 107, 117], "pieter": [5, 117], "abbeel": [5, 117], "sergei": [5, 117], "levin": [5, 117], "soft": [5, 117], "actor": 5, "off": [5, 49, 62, 65, 67, 68, 71, 83, 89, 90, 91, 96, 107, 117, 118, 130], "maximum": [5, 59, 74, 77, 81, 82, 85, 86, 99, 106, 108, 115, 116, 117], "entropi": [5, 15, 117], "deep": [5, 17, 19, 44, 74, 117, 118, 120, 129], "stochast": [5, 62, 71, 72, 73, 78, 79, 83, 87, 89, 90, 91, 106, 107, 116, 117], "intern": [5, 9, 10, 11, 12, 13, 14, 16, 19, 20, 25, 49, 62, 63, 67, 68, 71, 78, 79, 80, 81, 87, 88, 93, 94, 96, 97, 98, 99, 104, 106, 107, 109, 116, 117, 118, 130], "confer": [5, 9, 10, 11, 12, 13, 14, 17, 19, 49, 62, 63, 67, 68, 71, 78, 79, 80, 81, 87, 88, 93, 94, 96, 97, 98, 99, 101, 102, 104, 106, 107, 109, 116, 117, 118], "1861": [5, 117], "1870": [5, 117], "pmlr": [5, 19, 49, 62, 63, 67, 68, 71, 78, 79, 80, 87, 88, 93, 94, 96, 97, 98, 99, 101, 102, 104, 106, 107, 109, 116, 117], "2018": [5, 9, 10, 11, 12, 14, 15, 17, 44, 47, 49, 59, 67, 71, 72, 73, 74, 78, 82, 99, 101, 103, 107, 108, 114, 115, 117], "hk20": [5, 118], "yichun": [5, 10, 118], "hu": [5, 118], "nathan": [5, 62, 118], "kallu": [5, 49, 62, 118], "dtr": [5, 58, 77, 118, 129], "adapt": [5, 17, 18, 19, 20, 23, 25, 47, 49, 58, 73, 77, 78, 82, 95, 96, 98, 100, 102, 103, 105, 107, 108, 117, 118], "regret": [5, 44, 72, 73, 74, 78, 83, 86, 87, 88, 95, 97, 100, 102, 107, 118], "02791": [5, 118], "jl16": [5, 62, 67], "nan": [5, 10, 20, 62, 65, 67], "jiang": [5, 62, 65, 67, 71, 78, 107], "lihong": [5, 62, 67], "li": [5, 15, 49, 62, 67, 71, 79, 80, 81, 89, 90, 91, 93, 101, 103, 104, 107, 109, 117, 118], "doubli": [5, 6, 16, 19, 20, 25, 44, 49, 59, 63, 67, 71, 74, 89, 91], "robust": [5, 16, 19, 20, 25, 32, 44, 49, 59, 63, 67, 71, 74, 86, 89, 91, 94, 95, 99, 100, 101, 102, 106, 120, 125, 126, 129], "652": [5, 62, 67, 71, 128], "661": [5, 62, 67, 71, 79, 107], "ku19": [5, 62], "masatoshi": [5, 62], "uehara": [5, 62], "effici": [5, 15, 16, 19, 21, 22, 25, 29, 47, 62, 63, 65, 66, 67, 68, 69, 71, 81, 86, 87, 88, 93, 95, 97, 98, 99, 100, 101, 102, 104, 105, 108, 109, 114, 115, 117, 125, 126, 127], "break": [5, 62, 71], "curs": [5, 18, 23, 62, 63, 71], "horizon": [5, 32, 63, 72, 73, 97, 98, 100, 117, 118, 129], "doubl": [5, 15, 17, 20, 25, 32, 71, 90, 117], "1909": [5, 62], "05850": [5, 62], "lvy19": [5, 65], "hoang": [5, 62, 65], "cameron": [5, 62, 65], "voloshin": [5, 62, 65], "yisong": [5, 62, 65], "yue": [5, 9, 10, 11, 12, 13, 14, 62, 65], "1903": [5, 65], "08738": [5, 65], "lltz18": [5, 67], "qiang": [5, 62, 67], "liu": [5, 47, 62, 67, 71], "ziyang": [5, 62, 67], "tang": [5, 62, 67, 71], "dengyong": [5, 62, 67], "infinit": [5, 32, 63, 72, 73, 79, 117, 118, 129], "advanc": [5, 9, 10, 11, 12, 13, 14, 19, 22, 49, 67, 71, 86, 87, 88, 98, 101, 102, 103, 130], "neural": [5, 9, 10, 11, 12, 13, 14, 17, 19, 49, 67, 71, 78, 86, 87, 88, 98, 101, 102, 103, 107], "process": [5, 9, 10, 11, 12, 13, 14, 17, 19, 20, 49, 62, 67, 71, 78, 86, 87, 88, 97, 98, 100, 101, 102, 103, 106, 107, 117, 118, 120, 129], "5356": [5, 67], "5366": [5, 67], "mgkulic21": [5, 118], "lingheng": [5, 118], "meng": [5, 118], "rob": [5, 118], "gorbet": [5, 118], "dana": [5, 118], "kuli": [5, 118], "\u0107": [5, 118], "memori": [5, 20, 118], "pomdp": [5, 32, 118, 129], "2021": [5, 9, 13, 16, 19, 20, 24, 25, 49, 59, 63, 68, 86, 87, 88, 89, 90, 91, 118, 120, 121, 125], "ieee": [5, 118], "rsj": [5, 118], "robot": [5, 118], "iro": [5, 118], "5619": [5, 118], "5626": [5, 22, 118], "mbm": [5, 117], "16": [5, 10, 17, 18, 20, 59, 61, 117, 122, 123, 127, 128], "volodymyr": [5, 117], "mnih": [5, 117], "adria": [5, 117], "puigdomenech": [5, 117], "badia": [5, 117], "mehdi": [5, 117], "mirza": [5, 117], "alex": [5, 117], "grave": [5, 117], "timothi": [5, 117], "lillicrap": [5, 117], "tim": [5, 117], "harlei": [5, 117], "david": [5, 9, 10, 11, 12, 13, 14, 17, 19, 117], "silver": [5, 117], "korai": [5, 117], "kavukcuoglu": [5, 117], "asynchron": [5, 117], "1928": [5, 117], "1937": [5, 117], "mk": [5, 117], "15": [5, 10, 17, 20, 21, 23, 27, 58, 59, 61, 117, 122, 123, 127, 128], "andrei": [5, 117], "rusu": [5, 117], "joel": [5, 117], "veness": [5, 117], "marc": [5, 117], "g": [5, 9, 10, 11, 12, 13, 14, 17, 20, 22, 27, 29, 44, 59, 62, 63, 65, 67, 71, 72, 73, 78, 82, 86, 88, 95, 100, 101, 102, 103, 107, 108, 117, 118, 125, 126, 127, 128, 129], "bellemar": [5, 117], "martin": [5, 73, 117], "riedmil": [5, 117], "andrea": [5, 117], "fidjeland": [5, 117], "georg": [5, 117], "ostrovski": [5, 117], "human": [5, 117], "518": [5, 117, 128], "7540": [5, 117], "529": [5, 117], "533": [5, 89, 90, 91, 117], "pre00": [5, 67], "doina": [5, 67], "precup": [5, 67, 71], "elig": [5, 67, 71, 117], "trace": [5, 67, 71, 117], "comput": [5, 9, 13, 19, 67, 71, 79, 86, 95, 101, 102, 103, 104, 117], "scienc": [5, 9, 10, 11, 12, 13, 14, 15, 19, 22, 26, 28, 29, 44, 67, 71, 74, 95, 102, 129], "depart": [5, 67, 71], "faculti": [5, 67, 71], "public": [5, 23, 67, 71], "80": [5, 44, 59, 61, 67, 71, 74], "2000": [5, 9, 10, 11, 12, 13, 14, 58, 67, 71, 77, 100, 108, 109, 114, 115], "put14": [5, 73], "l": [5, 20, 24, 25, 49, 62, 71, 72, 73, 78, 79, 80, 81, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 109, 120], "puterman": [5, 72, 73], "markov": [5, 9, 11, 13, 14, 67, 94, 117, 118, 129], "dynam": [5, 15, 44, 47, 49, 58, 72, 73, 74, 77, 102, 104, 105, 106, 116, 117, 118, 120, 129], "program": [5, 72, 73, 95, 101, 102, 104], "wilei": [5, 72, 73], "son": [5, 72, 73], "2014": [5, 9, 10, 11, 12, 13, 14, 44, 59, 72, 73, 74], "sla": [5, 117], "schulman": [5, 117], "michael": [5, 117], "jordan": [5, 117], "philipp": [5, 117], "moritz": [5, 117], "trust": [5, 117], "region": [5, 117], "1889": [5, 117], "1897": [5, 117, 128], "swd": [5, 117], "17": [5, 10, 17, 59, 61, 117, 122, 123, 127, 128], "filip": [5, 117], "wolski": [5, 117], "prafulla": [5, 117], "dhariw": [5, 117], "alec": [5, 117], "radford": [5, 117], "oleg": [5, 117], "klimov": [5, 117], "proxim": [5, 117], "algorithm": [5, 9, 10, 12, 19, 20, 22, 25, 26, 28, 29, 47, 62, 66, 72, 73, 79, 80, 83, 86, 87, 88, 89, 90, 91, 93, 96, 97, 98, 103, 104, 117, 121, 125, 126, 127, 129, 130], "1707": [5, 84, 106, 107, 116, 117], "06347": [5, 117], "2017": [5, 9, 10, 11, 12, 13, 14, 16, 19, 20, 23, 25, 59, 75, 78, 84, 101, 102, 104, 106, 107, 116, 117, 118, 121], "swcs21": [5, 63], "chengchun": [5, 63, 117, 118], "shi": [5, 17, 19, 44, 49, 63, 68, 73, 74, 117, 118, 120], "runzh": [5, 63], "wan": [5, 63, 68, 86, 87, 94, 95, 99, 100, 101, 102, 106], "victor": [5, 17, 19, 63], "chernozhukov": [5, 15, 17, 63, 68], "rui": [5, 9, 10, 11, 12, 13, 14, 47, 59, 63, 117, 118], "song": [5, 9, 10, 11, 12, 13, 14, 44, 47, 49, 58, 59, 63, 74, 77, 86, 87, 89, 90, 91, 94, 95, 99, 100, 101, 102, 106, 117, 118, 120], "deepli": [5, 68], "debias": [5, 15, 17, 68], "interv": [5, 18, 23, 49, 58, 59, 63, 72, 73, 89, 90, 91, 117, 118], "9580": [5, 63, 68], "9591": [5, 63, 68], "swl": [5, 73], "20": [5, 9, 10, 14, 17, 18, 23, 44, 49, 58, 59, 61, 73, 100, 102, 103, 122, 123, 127, 128], "shi2020reinforc": [5, 73], "szls20": [5, 117], "sheng": [5, 117], "zhang": [5, 15, 78, 104, 107, 117], "wenbin": [5, 9, 10, 11, 12, 13, 14, 117], "lu": [5, 9, 10, 11, 12, 13, 14, 44, 49, 74, 89, 90, 91, 107, 117], "2001": [5, 27, 117, 122, 123, 124], "04515": [5, 117], "szy": [5, 118], "22": [5, 10, 17, 18, 23, 44, 58, 61, 117, 118, 127, 128], "jin": [5, 101, 103, 118], "zhu": [5, 9, 10, 11, 12, 13, 14, 49, 101, 103, 118], "shen": [5, 78, 89, 90, 91, 107, 118], "ye": [5, 9, 118, 129], "shikai": [5, 118], "luo": [5, 118], "hongtu": [5, 118], "confid": [5, 16, 19, 20, 25, 58, 81, 83, 85, 89, 90, 91, 105, 115, 117, 118], "american": [5, 21, 47, 59, 89, 90, 91, 118, 125, 126], "2022": [5, 18, 21, 23, 87, 94, 95, 99, 100, 101, 102, 106, 118], "ss96": [5, 117], "satind": [5, 117], "singh": [5, 117], "richard": [5, 9, 10, 11, 12, 13, 14, 73, 117], "sutton": [5, 72, 73, 82, 107, 108, 117], "replac": [5, 10, 12, 44, 49, 59, 63, 67, 71, 117], "123": [5, 10, 20, 117, 122], "158": [5, 77, 117], "1996": [5, 117], "spa12": [5, 118], "matthij": [5, 118], "tj": [5, 74, 118], "spaan": [5, 118], "partial": [5, 10, 12, 24, 25, 27, 32, 44, 74, 97, 98, 100, 118, 122, 123, 124, 129], "state": [5, 6, 11, 13, 14, 19, 21, 22, 27, 28, 32, 59, 62, 63, 65, 66, 67, 71, 72, 73, 117, 118, 120, 121, 125, 126, 127, 128], "art": [5, 11, 13, 14, 19, 62, 71, 118, 129], "387": [5, 118, 128], "414": [5, 118], "2012": [5, 21, 27, 47, 78, 101, 116, 118, 122, 123, 124, 125, 126, 128], "sut88": [5, 117], "tempor": [5, 9, 10, 67, 71, 117], "9": [5, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 44, 58, 59, 61, 71, 74, 77, 107, 109, 114, 117, 120, 121, 122, 123, 125, 127, 128], "44": [5, 17, 59, 61, 117, 122, 123, 127, 128], "1988": [5, 16, 19, 20, 24, 25, 95, 117, 128], "sb18": [5, 73, 117], "andrew": [5, 73, 117], "barto": [5, 72, 73, 82, 107, 108, 117], "mit": [5, 72, 73, 82, 107, 108, 117], "press": [5, 72, 73, 82, 84, 107, 108, 117], "tfl": [5, 62], "yihao": [5, 62], "feng": [5, 62], "bia": [5, 15, 21, 22, 23, 25, 32, 47, 49, 59, 62, 63, 65, 67, 71, 118, 122, 123, 129], "reduct": [5, 62, 118], "represent": [5, 9, 10, 11, 12, 13, 14, 47, 62], "tb16": [5, 62], "philip": [5, 62, 67], "thoma": [5, 62, 67, 71], "emma": [5, 62], "brunskil": [5, 62], "2139": [5, 62], "2148": [5, 62], "tho15": [5, 67], "safe": [5, 20, 67, 71], "doctor": [5, 12, 32, 67], "dissert": [5, 67], "univers": [5, 67, 84, 107], "massachusett": [5, 67], "amherst": [5, 67], "uhj19": [5, 62], "jiawei": [5, 62], "huang": [5, 62], "minimax": [5, 62, 63], "weight": [5, 9, 10, 11, 12, 13, 14, 15, 17, 18, 20, 21, 22, 23, 25, 29, 62, 63, 67, 71, 99, 106, 116, 125, 126, 129], "1910": [5, 62], "12809": [5, 62], "vhgs16": [5, 117], "hado": [5, 117], "van": [5, 16, 19, 20, 25, 75, 84, 100, 106, 107, 114, 115, 116, 117, 121], "hasselt": [5, 117], "arthur": [5, 117], "guez": [5, 117], "proceed": [5, 19, 21, 22, 26, 28, 29, 44, 49, 74, 79, 81, 107, 117, 125, 126], "aaai": [5, 117], "artifici": [5, 19, 49, 78, 79, 80, 81, 87, 93, 94, 96, 107, 109, 117], "volum": [5, 25, 117], "30": [5, 10, 17, 27, 61, 117, 127, 128], "vljy19": [5, 62, 65], "empir": [5, 62, 65, 67, 73, 79, 83, 107], "1911": [5, 62, 65], "06854": [5, 62, 65], "zlpm17": [5, 118], "pengfei": [5, 118], "xin": [5, 118], "pascal": [5, 118], "poupart": [5, 118], "guanghui": [5, 118], "miao": [5, 118], "On": [5, 47, 49, 118], "1704": [5, 118], "07978": [5, 118], "If": [5, 15, 58, 74, 77, 86, 87, 93, 97, 100, 106, 116, 130], "insid": 5, "jupytext": 5, "metadata": [5, 23, 86, 87], "run": [5, 10, 14, 20, 117], "command": [5, 130], "init": [5, 17], "print": [5, 11, 13, 14, 16, 17, 18, 20, 22, 23, 24, 25, 26, 28, 29, 44, 58, 61, 74, 77, 121, 122, 123, 125, 126, 127, 128], "default": [5, 9, 11, 20, 27, 58, 59, 86, 88, 93, 117, 127, 128, 130], "kernel": [5, 18, 19, 20, 23, 25, 32, 47, 49, 62, 71, 72, 73, 117, 129], "output": [5, 11, 17, 20, 49, 127], "rest": [5, 6, 10, 12, 17, 79, 87, 89, 90, 91, 122, 123, 127], "nb": 5, "r": [6, 10, 12, 15, 16, 17, 18, 19, 21, 22, 23, 26, 28, 29, 32, 44, 49, 58, 59, 60, 62, 67, 68, 71, 72, 73, 74, 76, 77, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 114, 115, 116, 117, 120, 121, 122, 123, 125, 126, 127, 129], "s_i": [6, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 29, 129], "a_i": [6, 15, 17, 18, 19, 20, 21, 23, 24, 25, 47, 49, 59, 60, 89, 90, 91, 129], "r_i": [6, 15, 17, 18, 19, 20, 21, 22, 23, 24, 25, 29, 44, 60, 74, 76, 89, 90, 91, 129], "equival": [6, 9, 10, 11, 12, 13, 14, 47, 63, 78, 83, 107], "pearl": [6, 9, 10, 11, 12, 13, 14, 21], "spirt": [6, 9, 10, 11, 12, 13, 14], "mathemat": [6, 10, 12, 44, 74, 99, 106, 116], "physic": [6, 10, 12, 129], "hold": [6, 10, 12, 21, 32, 67, 71, 72, 73], "constant": [6, 10, 12, 22, 28, 47], "unchang": [6, 10, 12], "regress": [6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 22, 24, 25, 26, 28, 29, 44, 58, 59, 65, 67, 71, 74, 77, 95, 121, 125, 126], "propens": [6, 12, 15, 16, 17, 20, 22, 24, 25, 29, 44, 49, 59, 67, 71, 74], "score": [6, 9, 12, 15, 16, 17, 20, 22, 24, 25, 27, 29, 44, 49, 59, 67, 71, 74, 122, 123, 124, 129], "roust": 6, "introduc": [6, 15, 17, 18, 19, 20, 21, 22, 23, 25, 26, 29, 44, 62, 63, 67, 68, 71, 72, 73, 74, 77, 78, 79, 85, 86, 88, 89, 90, 91, 94, 101, 104, 107, 115, 117, 118, 129, 130], "cel": [6, 17, 21, 32], "detail": [6, 10, 12, 15, 16, 17, 19, 20, 22, 25, 29, 32, 60, 63, 83, 107, 129, 130], "hte": [6, 15, 16, 17, 18, 20, 22, 23, 24, 25, 26, 28, 29, 32, 122, 123], "captur": [6, 17, 18, 22, 23, 49, 90, 91], "heterogenieti": 6, "quit": [6, 17, 19, 22, 67, 71, 129], "few": [6, 19, 62, 71, 73, 79, 83, 87, 99, 107, 129], "deal": [6, 32, 95, 96, 100, 102, 105, 129], "reli": [9, 12, 13, 62, 71], "locat": [9, 12], "reward": [9, 12, 15, 19, 21, 22, 23, 25, 27, 32, 47, 58, 59, 60, 67, 72, 73, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 114, 115, 116, 117, 120, 121, 125, 126, 127, 128, 129], "conveni": [9, 12], "violat": [9, 12, 32, 63], "emerg": [9, 12], "basic": [9, 15, 16, 22, 25, 26, 29, 44, 97, 98, 100, 129], "wai": [9, 22, 24, 25, 29, 47, 59, 62, 63, 65, 66, 67, 68, 69, 71, 77, 105, 108, 109, 114, 115, 117], "mathcal": [9, 10, 11, 12, 13, 14, 21, 32, 44, 49, 62, 63, 67, 71, 72, 73, 74, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 114, 115, 116, 117, 127, 129], "mathbf": [9, 10, 11, 12, 13, 14], "z": [9, 10, 11, 12, 13, 14, 16, 17, 19, 20, 25, 71, 84, 93, 94, 96, 97, 99, 106, 107, 114, 115, 116, 120], "node": [9, 11, 12, 13, 14, 17, 129], "edg": [9, 10, 11, 12, 13, 14], "said": [9, 11, 12, 13, 14], "parent": [9, 11, 12, 13, 14, 17, 130], "z_j": [9, 11, 12, 13, 14], "let": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 24, 25, 26, 28, 29, 49, 58, 62, 63, 67, 71, 72, 73, 76, 79, 83, 87, 94, 99, 101, 106, 107, 116, 117], "pa_": [9, 11, 12, 13, 14], "cycl": [9, 11, 12, 13, 14], "acycl": [9, 10, 11, 12, 13, 14], "dag": [9, 10, 11, 12, 13, 14, 122, 123], "character": [9, 10, 11, 12, 13, 14, 66, 72, 90, 91, 93, 95, 101, 106, 116], "z_1": [9, 11, 12, 13, 14], "z_2": [9, 11, 12, 13, 14], "z_d": [9, 11, 12, 13, 14], "rightarrow": [9, 11, 12, 13, 14, 20, 21, 25, 32], "mean": [9, 11, 12, 13, 14, 19, 32, 49, 58, 59, 61, 62, 67, 71, 73, 74, 77, 80, 82, 84, 85, 86, 88, 89, 90, 91, 95, 97, 98, 99, 100, 102, 103, 107, 108, 109, 114, 115, 117, 122, 123, 127, 129], "propos": [9, 10, 13, 14, 17, 21, 32, 47, 49, 62, 63, 67, 68, 71, 74, 89, 90, 91, 93, 120, 121, 125, 126, 129], "plusibl": 9, "up": [9, 13, 18, 20, 23, 25, 73, 78, 86, 88, 117, 129], "markovian": 9, "unless": [9, 14], "certain": [9, 17, 59, 73, 118], "assumpt": [9, 11, 13, 14, 16, 17, 19, 21, 22, 25, 26, 32, 47, 63, 67, 71, 73, 78, 79, 90, 94, 95, 100, 102, 117, 118, 129], "specifi": [9, 10, 11, 15, 18, 23, 24, 25, 44, 47, 58, 60, 63, 73, 74, 77, 90, 107, 108, 109, 114, 121, 125, 126], "type": [9, 15, 17, 20, 32, 60, 61, 62, 63, 65, 66, 67, 68, 71, 74, 77, 79, 83, 84, 87, 89, 90, 101, 102, 103, 104, 105, 107, 122, 123, 129, 130], "focus": [9, 19, 32, 59, 67, 83, 94, 106, 107, 116, 117, 129], "local": [9, 14, 18, 19, 20, 22, 23, 25, 59, 130], "independ": [9, 10, 11, 12, 13, 14, 15, 20, 21, 25, 32, 59, 60, 73, 97, 117], "skeleton": [9, 129], "orient": [9, 10, 14], "pc": [9, 10, 11, 12, 13, 129], "et": [9, 11, 12, 14, 15, 16, 21, 25, 47, 59, 62, 63, 67, 68, 71, 73, 82, 85, 89, 90, 91, 93, 97, 107, 108, 115, 117], "al": [9, 11, 12, 14, 15, 16, 21, 25, 47, 59, 62, 63, 67, 68, 71, 73, 82, 85, 89, 90, 91, 93, 97, 107, 108, 115, 117], "kalisch": [9, 10, 11, 12, 13, 14], "b\u00fchlmann": [9, 10, 11, 12, 13, 14], "easi": [9, 14, 19, 22, 24, 25, 26, 58, 65, 67, 77, 82, 101], "shah": [9, 10, 11, 12, 13, 14], "peter": [9, 10, 11, 12, 13, 14, 16, 19, 20, 24, 25], "second": [9, 15, 21, 22, 28, 44, 49, 63, 74, 93, 95, 96, 117, 129], "ica": [9, 13, 14], "lingam": [9, 13, 14, 129], "shimizu": [9, 10, 11, 12, 13, 14], "2006": [9, 10, 11, 12, 13, 14, 16, 19, 20, 25, 96], "cam": [9, 10, 11, 12, 13, 14], "last": [9, 10, 11, 13, 14, 15, 17, 20, 21, 22, 23, 25, 27, 44, 47, 49, 58, 59, 60, 61, 62, 63, 65, 66, 67, 68, 69, 71, 72, 74, 77, 80, 81, 82, 84, 85, 86, 88, 90, 91, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115, 120, 121, 122, 123, 125, 126, 127, 128, 129], "greedi": [9, 10, 11, 12, 13, 14, 83, 89, 90, 91, 108, 117, 129], "search": [9, 10, 11, 12, 13, 14, 94, 117], "ge": [9, 32, 62, 63, 67, 71, 72, 73, 86, 87, 94, 95, 99, 100, 101, 102, 106, 117, 120], "chicker": [9, 10, 11, 12, 13, 14], "2002": [9, 10, 11, 12, 13, 14, 79, 82, 85, 107, 108, 115], "fge": 9, "ramsei": [9, 10, 11, 12, 13, 14], "bayesian": [9, 10, 11, 12, 13, 14, 86, 87, 95, 96, 98, 100, 102], "zheng": [9, 10, 11, 12, 14, 75, 121], "open": [9, 10, 27, 74, 77, 120, 121, 122, 123, 124, 128, 130], "construct": [9, 10, 11, 12, 13, 14, 16, 20, 21, 22, 25, 26, 62, 63, 65, 67, 68, 71, 86, 117], "notear": [9, 11, 14, 122, 123, 129], "vae": [9, 13], "parameter": [9, 13, 86, 88, 95, 100, 102, 117], "network": [9, 10, 11, 12, 13, 14, 17, 19, 49, 59], "yu": [9, 10, 11, 12, 13, 14, 19, 22, 26, 28, 29, 47, 59], "friendli": [9, 13], "gnn": [9, 10, 11, 12, 13, 14], "chen": [9, 10, 11, 12, 13, 14, 89, 90, 91, 98, 99, 106, 116], "cai": [9, 11, 12, 13, 14, 49, 89, 90, 91], "cut": [9, 13], "support": [9, 20, 25, 73, 79, 84, 85, 88, 117, 129], "train": [9, 10, 16, 17, 18, 19, 20, 23, 24, 25, 44, 47, 58, 61, 74, 77, 80, 81, 93, 121, 125, 126, 129], "free": [9, 65, 129], "gaussian": [9, 10, 12, 13, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 97, 98, 100, 109, 114, 129], "o": [9, 10, 11, 12, 13, 14, 15, 17, 129], "max": [9, 49, 58, 59, 62, 71, 77, 127, 128, 129], "adjac": [9, 10, 11, 13, 14, 129], "b_": [9, 11, 13, 14], "leq": [9, 11, 13, 14, 32, 89, 90, 91, 99, 101, 129], "matrix": [9, 10, 11, 13, 14, 21, 80, 84, 86, 95, 97, 98, 100, 102, 103, 106, 120, 122, 123, 125, 126], "otherwis": [9, 11, 13, 14, 58, 60, 77, 82, 88, 94, 108, 130], "nest": [9, 11, 13, 14, 44, 74], "faith": [9, 11, 13, 14], "suffici": [9, 11, 13, 14, 17, 62, 67], "pair": [9, 11, 13, 14, 62, 63, 67, 71, 73, 80, 84, 95, 96, 98, 102, 103, 104, 109, 114], "epsilon": [9, 11, 13, 14, 17, 24, 25, 59, 83, 89, 90, 91, 108, 117, 129], "label": [9, 10, 11, 13, 14, 47, 49, 62, 63, 65, 67, 68, 71, 72, 73, 86, 89, 90, 91, 94, 95, 100, 101, 102, 106, 116, 117], "lsem_x": [9, 11, 13, 14], "jointli": [9, 11, 13, 14, 44, 74], "error": [9, 11, 13, 14, 16, 19, 44, 58, 74, 77, 121, 122, 123], "plu": [9, 11, 13], "n_i": [9, 11, 13], "anm": [9, 11, 13], "f_i": [9, 11, 13], "special": [9, 11, 13, 32, 129], "handl": [9, 11, 13, 14, 19, 20, 22, 25, 49, 67, 71, 74, 77, 107, 122, 123, 129], "version": [9, 11, 13, 16, 17, 18, 23, 62, 63, 67, 71, 79, 82, 83, 101, 107, 108, 118, 120, 121, 125], "f_2": [9, 13], "f_1": [9, 13], "nonlinear": [9, 13, 22, 28], "transform": [9, 13, 44], "fisher": [9, 14], "implement": [9, 11, 13, 14, 15, 18, 19, 22, 23, 26, 27, 47, 49, 58, 59, 65, 67, 77, 86, 88, 89, 90, 91, 127, 128, 129, 130], "py": [9, 10, 11, 13, 14, 16, 17, 20, 21, 22, 23, 24, 25, 28, 44, 47, 49, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 71, 74, 77, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115, 120, 121, 122, 123, 125, 126, 127, 128], "packag": [9, 10, 11, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 44, 47, 58, 59, 60, 61, 74, 77, 95, 102, 120, 121, 122, 123, 125, 128, 130], "http": [9, 10, 11, 13, 14, 17, 23, 24, 27, 60, 122, 123, 130], "github": [9, 10, 11, 13, 14, 17, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 120, 121, 125, 126, 127, 130], "com": [9, 10, 11, 13, 14, 17, 27, 60, 130], "bd2kccd": [9, 14], "highli": [9, 14], "java": [9, 14], "blob": [9, 14], "20pc": [9, 14], "20in": [9, 14], "20action": [9, 14], "recov": [9, 11], "hyper": [9, 11, 85, 120], "cdt15": [9, 11], "xunzheng": [9, 13], "incorpor": [9, 10, 19, 82, 84, 107, 108], "auto": 9, "encod": [9, 74, 77, 122, 123], "modifi": [9, 12, 17, 80, 84, 95, 96, 97, 98, 100, 102, 103, 109, 114, 120], "smooth": [9, 49], "evid": [9, 127], "lower": [9, 11, 13, 14, 15, 59, 62, 67, 71, 90, 97, 121, 125, 126], "bound": [9, 19, 20, 21, 25, 62, 63, 71, 72, 73, 81, 83, 85, 88, 89, 90, 91, 97, 105, 115, 125, 126], "loss": [9, 10, 17, 19, 20, 72, 73, 129], "fishmoon1234": 9, "pytorch": [9, 10], "paszk": 9, "anoc": [9, 11, 12, 13, 14], "cvae": 9, "constrain": [9, 10, 11, 12, 13, 14], "novel": [9, 10, 17, 71], "identif": [9, 10, 11, 12, 13, 14, 129, 130], "publicli": [9, 10, 122, 123, 124], "anonym": [9, 10, 27, 122, 123, 124], "judea": [9, 10, 11, 12, 13, 14, 21], "survei": [9, 10, 11, 12, 13, 14, 79, 83, 99, 101, 107, 130], "96": [9, 10, 11, 12, 13, 14, 20, 44, 58, 61, 114, 115, 122, 123, 128], "146": [9, 10, 11, 12, 13, 14, 83], "2009": [9, 10, 11, 12, 13, 14], "pater": [9, 10, 11, 12, 13, 14], "clark": [9, 10, 11, 12, 13, 14], "glymour": [9, 10, 11, 12, 13, 14], "schein": [9, 10, 11, 12, 13, 14], "stuart": [9, 10, 11, 12, 13, 14], "kauffman": [9, 10, 11, 12, 13, 14], "valerio": [9, 10, 11, 12, 13, 14], "aimal": [9, 10, 11, 12, 13, 14], "frank": [9, 10, 11, 12, 13, 14], "wimberli": [9, 10, 11, 12, 13, 14], "gene": [9, 10, 11, 12, 13, 14], "express": [9, 10, 11, 12, 13, 14, 18, 22, 23, 26, 62, 71, 78, 84], "microarrai": [9, 10, 11, 12, 13, 14], "marku": [9, 10, 11, 12, 13, 14], "8": [9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 24, 25, 26, 28, 29, 58, 59, 61, 63, 67, 68, 71, 77, 79, 107, 109, 114, 122, 123, 127, 128], "mar": [9, 10, 11, 12, 13, 14], "613": [9, 10, 11, 12, 13, 14, 128], "636": [9, 10, 11, 12, 13, 14], "rajen": [9, 10, 11, 12, 13, 14], "jona": [9, 10, 11, 12, 13, 14], "hard": [9, 10, 11, 12, 13, 14], "generalis": [9, 10, 11, 12, 13, 14], "1804": [9, 10, 11, 12, 13, 14], "07203": [9, 10, 11, 12, 13, 14], "shohei": [9, 10, 11, 12, 13, 14], "patrik": [9, 10, 11, 12, 13, 14], "hoyer": [9, 10, 11, 12, 13, 14], "aapo": [9, 10, 11, 12, 13, 14], "hyv\u00e4rinen": [9, 10, 11, 12, 13, 14], "antti": [9, 10, 11, 12, 13, 14], "kerminen": [9, 10, 11, 12, 13, 14], "7": [9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 24, 25, 26, 27, 28, 29, 47, 49, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 71, 79, 94, 101, 105, 107, 108, 109, 114, 115, 120, 121, 122, 123, 125, 127, 128], "oct": [9, 10, 11, 12, 13, 14], "2003": [9, 10, 11, 12, 13, 14, 44, 74], "2030": [9, 10, 11, 12, 13, 14], "6": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 24, 26, 27, 28, 29, 44, 47, 49, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 71, 77, 79, 101, 105, 106, 107, 108, 109, 114, 115, 120, 122, 123, 125, 126, 127, 128], "ernest": [9, 10, 11, 12, 13, 14], "penal": [9, 10, 11, 12, 13, 14, 19, 47, 58, 77], "annal": [9, 10, 11, 12, 13, 14, 18, 19, 21, 23, 34, 35, 38, 39, 40, 41, 42, 44, 74, 125, 126], "42": [9, 10, 11, 12, 13, 14, 59, 61, 80, 81, 82, 84, 85, 86, 88, 108, 109, 114, 115, 127, 128], "2526": [9, 10, 11, 12, 13, 14], "2556": [9, 10, 11, 12, 13, 14], "maxwel": [9, 10, 11, 12, 13, 14], "nov": [9, 10, 11, 12, 13, 14], "507": [9, 10, 11, 12, 13, 14, 96], "554": [9, 10, 11, 12, 13, 14, 128], "joseph": [9, 10, 11, 12, 13, 14], "madelyn": [9, 10, 11, 12, 13, 14], "ruben": [9, 10, 11, 12, 13, 14], "sanchez": [9, 10, 11, 12, 13, 14], "romero": [9, 10, 11, 12, 13, 14], "magnet": [9, 10, 11, 12, 13, 14], "reson": [9, 10, 11, 12, 13, 14], "imag": [9, 10, 11, 12, 13, 14, 17, 21], "analyt": [9, 10, 11, 12, 13, 14, 60], "121": [9, 10, 11, 12, 13, 14, 20, 27], "129": [9, 10, 11, 12, 13, 14, 122, 123, 128], "xun": [9, 10, 11, 12, 13, 14], "bryon": [9, 10, 11, 12, 13, 14], "aragam": [9, 10, 11, 12, 13, 14], "pradeep": [9, 10, 11, 12, 13, 14], "ravikumar": [9, 10, 11, 12, 13, 14], "eric": [9, 10, 11, 12, 13, 14, 21], "xing": [9, 10, 11, 12, 13, 14], "tear": [9, 10, 11, 12, 13, 14], "pp": [9, 10, 11, 12, 13, 14, 21, 44, 49, 74, 78, 79, 80, 81, 87, 88, 93, 94, 96, 97, 98, 99, 101, 102, 104, 106, 109, 125, 126], "9472": [9, 10, 11, 12, 13, 14], "9483": [9, 10, 11, 12, 13, 14], "10": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 44, 47, 49, 58, 59, 61, 81, 95, 97, 98, 100, 102, 107, 120, 121, 122, 123, 125, 126, 127, 128], "jie": [9, 10, 11, 12, 13, 14], "tian": [9, 10, 11, 12, 13, 14], "gao": [9, 10, 11, 12, 13, 14], "mo": [9, 10, 11, 12, 13, 14], "1904": [9, 10, 11, 12, 13, 14, 79, 83, 107], "10098": [9, 10, 11, 12, 13, 14], "11": [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 44, 58, 59, 61, 71, 107, 114, 115, 120, 121, 122, 123, 125, 126, 127, 128], "shengyu": [9, 10, 11, 12, 13, 14], "zhitang": [9, 10, 11, 12, 13, 14], "1906": [9, 10, 11, 12, 13, 14], "04477": [9, 10, 11, 12, 13, 14], "hengrui": [9, 10, 11, 12, 13, 14], "demand": 10, "kei": [10, 17, 27, 47, 49, 67, 94, 127, 128, 129, 130], "factor": [10, 67, 72, 73, 94, 95, 96, 97, 98, 100, 101, 106], "guid": [10, 81, 84, 86, 88, 107, 109, 114, 117], "downstream": 10, "task": [10, 20, 63, 65, 67, 71, 73, 78, 83, 87, 88, 107], "m_1": [10, 12], "m_2": [10, 12], "m_p": [10, 12], "dimens": [10, 12, 118], "give": [10, 15, 18, 23, 26, 28, 29, 72, 79, 83, 87, 107, 121, 125, 126, 127], "te": [10, 12, 21, 120, 121, 125, 126], "de": [10, 12, 21, 63, 78, 107], "ie": [10, 12, 21], "equat": [10, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 32, 49, 59, 62, 63, 65, 66, 67, 68, 71, 72, 74, 85, 86, 88, 89, 90, 91, 93, 94, 95, 97, 99, 100, 101, 102, 103, 104, 105, 106, 107, 115, 116, 117], "split": [10, 12, 15, 18, 23, 62, 63, 71, 93, 94, 95, 99, 100, 102, 106, 116, 117, 122, 123], "remov": [10, 11, 12, 27, 47, 120, 121, 125, 127, 128], "citet": [10, 68, 71], "pearl2009caus": 10, "dm": [10, 15, 21, 62, 65, 71], "dm_i": 10, "big": [10, 15, 16, 17, 18, 20, 21, 23, 25, 32, 44, 47, 49, 62, 63, 65, 66, 67, 71, 72, 74, 86, 90, 93, 102, 117], "m_i": [10, 21], "_i": [10, 22, 29, 44, 59, 60, 80, 89, 90, 91, 95, 100, 102, 106, 109, 116, 127], "omega_i": 10, "setminu": 10, "except": [10, 17, 20, 74], "im": [10, 120], "def_im": 10, "im_i": 10, "firstli": [10, 85, 107, 115], "sourc": [10, 130], "degre": [10, 11, 13, 14, 19, 20, 25, 93], "freedom": 10, "smaller": [10, 22, 25, 122, 123], "decompos": [10, 63, 95, 100, 102, 120], "compon": [10, 11, 58, 62, 71, 72, 120, 121, 125, 126, 129], "row": [10, 15, 16, 17, 18, 20, 21, 22, 24, 26, 27, 28, 29, 59, 78, 122, 123, 127, 128], "compos": 10, "investig": [10, 79], "spread": 10, "major": [10, 58, 79, 84, 95, 100, 102, 107, 109, 114, 117, 120], "panda": [10, 11, 15, 16, 17, 18, 20, 21, 23, 24, 26, 27, 28, 29, 59, 61, 74, 77, 120, 121, 122, 123, 125, 126, 127, 128], "pd": [10, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 44, 58, 59, 61, 74, 77, 120, 121, 122, 123, 125, 126, 127, 128], "os": [10, 11, 13, 14, 17, 25, 47, 62, 63, 65, 66, 67, 68, 69, 71, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115, 120, 121, 122, 123, 125, 126, 127], "pickl": [10, 27, 49, 120, 121, 122, 123, 128], "data_typ": 10, "realdata": 10, "real_data_fil": 10, "covid19": 10, "pkl": 10, "epoch": [10, 101, 102, 103, 104, 105], "100": [10, 15, 25, 44, 49, 59, 61, 74, 86, 102, 103, 107, 122, 123, 128], "node_numb": 10, "32": [10, 16, 17, 19, 20, 25, 61, 79, 101, 102, 103, 122, 123, 127, 128], "sample_s": 10, "38": [10, 17, 18, 23, 44, 59, 61, 127, 128], "batch_siz": [10, 17], "rep_numb": 10, "namespac": 10, "simu_g_fil": 10, "s1_trueg": 10, "graph_degre": 10, "a_typ": [10, 11, 13, 14], "seed": [10, 11, 13, 14, 15, 16, 20, 21, 22, 23, 24, 25, 26, 47, 49, 59, 61, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 107, 108, 109, 114, 115, 120, 122, 123, 125, 126, 127], "2333": [10, 49], "k_max_it": 10, "original_lr": 10, "003": [10, 44, 127], "alinaxu": [10, 15, 16, 17, 18, 20, 21, 24, 25, 26, 27, 28, 29, 127, 128], "opt": [10, 11, 16, 17, 18, 20, 22, 23, 24, 25, 44, 58, 61, 74, 77, 121, 122, 123, 125, 126, 128], "anaconda3": [10, 11, 16, 17, 18, 20, 22, 23, 24, 25, 44, 58, 61, 74, 77, 122, 123, 128], "lib": [10, 11, 16, 17, 18, 20, 22, 23, 24, 25, 44, 58, 59, 61, 74, 77, 120, 121, 122, 123, 125, 128], "python3": [10, 11, 16, 17, 18, 20, 22, 23, 24, 25, 44, 58, 59, 61, 74, 77, 120, 121, 122, 123, 125, 128], "torch": 10, "lr_schedul": 10, "138": [10, 20, 122, 123, 127, 128], "userwarn": [10, 17, 24], "detect": [10, 27, 49, 127, 128], "step": [10, 16, 17, 20, 22, 24, 25, 26, 28, 29, 47, 59, 61, 62, 63, 67, 71, 76, 89, 90, 91, 117, 127], "later": [10, 15, 27, 32, 44, 47, 62, 63, 65, 66, 67, 68, 69, 71, 74, 105, 108, 109, 114, 115], "opposit": [10, 47], "failur": [10, 27, 122, 123, 124], "skip": 10, "schedul": [10, 20, 86, 88, 102, 105], "org": [10, 23, 24, 122, 123], "html": [10, 24, 60, 122, 123, 130], "warn": [10, 16, 24, 27, 44, 58, 59, 61, 74, 77, 127, 128], "best": [10, 17, 21, 49, 58, 77, 79, 106, 120, 125, 126], "elbo": 10, "2604245517164468": 10, "nll": 10, "001169236510424758": 10, "mse": 10, "307728190154737e": 10, "05": [10, 18, 23, 59, 121, 127], "seaborn": [10, 127], "sn": [10, 127], "matplotlib": [10, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 59, 122, 123], "pyplot": [10, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 122, 123], "plt": [10, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 59, 122, 123], "load": [10, 25, 27, 120, 121, 128], "join": [10, 59], "anoce_result": 10, "rb": [10, 120, 121, 128], "calcul": [10, 17, 19, 59, 62, 65, 71, 74, 77, 80, 81, 82, 85, 86, 88, 102, 104, 107, 108, 109, 115, 120, 121, 125, 126, 127, 128], "calculate_effect": 10, "plot": [10, 11, 13, 14, 122, 123], "covid": 10, "matshow": 10, "cmap": 10, "bwr": 10, "vmin": 10, "vmax": 10, "fig1": 10, "gcf": 10, "colorbar": 10, "df": [10, 11, 13, 14, 20], "datafram": [10, 14, 22, 23, 24, 44, 58, 59, 61, 74, 77, 121, 122, 123, 125, 126, 127, 128], "arrai": [10, 15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 44, 47, 49, 59, 61, 74, 93, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115, 120, 121, 122, 123, 125, 126, 127, 128, 129], "read_csv": [10, 15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 74, 77, 120, 121, 122, 123, 125, 126, 127, 128], "csv": [10, 15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 120, 121, 122, 123, 125, 126, 127, 128], "column": [10, 14, 15, 16, 17, 18, 20, 21, 22, 24, 26, 27, 28, 29, 44, 59, 61, 93, 95, 97, 100, 102, 103, 121, 122, 123, 125, 126, 127, 128], "31": [10, 11, 13, 17, 58, 61, 71, 127, 128], "round": [10, 11, 13, 14, 16, 17, 18, 20, 24, 26, 28, 29, 44, 58, 74, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 108, 109, 114, 115, 116], "reshap": [10, 11, 13, 14, 17, 21, 22, 26, 49, 120, 125, 126], "shenzhen": 10, "198": [10, 27, 74, 128], "027": 10, "guangzhou": 10, "099": 10, "059": 10, "beij": 10, "036": [10, 16], "039": [10, 16], "chengdu": 10, "081": [10, 83], "019": [10, 24], "shanghai": 10, "016": 10, "063": 10, "dongguan": 10, "066": 10, "023": 10, "suzhou": 10, "064": 10, "xian": 10, "051": 10, "042": 10, "hangzhou": 10, "097": 10, "083": 10, "zhengzhou": 10, "069": 10, "062": 10, "chongq": 10, "021": 10, "changsha": 10, "073": 10, "034": [10, 127], "nanj": 10, "094": 10, "044": 10, "13": [10, 11, 13, 14, 17, 18, 23, 27, 61, 107, 121, 122, 123, 127, 128], "kunm": 10, "006": [10, 61], "040": 10, "14": [10, 11, 13, 14, 17, 18, 20, 23, 27, 61, 122, 123, 127, 128], "tianjin": 10, "075": 10, "049": 10, "hefei": 10, "020": [10, 24], "007": 10, "046": 10, "wenzhou": 10, "302": [10, 128], "030": [10, 24, 127], "18": [10, 17, 59, 61, 79, 87, 107, 127, 128], "nanchang": 10, "050": 10, "004": [10, 61], "zhoukou": 10, "008": 10, "013": 10, "fuyang": 10, "21": [10, 17, 18, 23, 44, 58, 59, 61, 95, 123, 127, 128], "shangqiu": 10, "yueyang": 10, "002": [10, 102], "012": 10, "23": [10, 17, 23, 44, 58, 59, 61, 121, 127, 128], "zhumadian": 10, "024": [10, 24], "24": [10, 17, 58, 59, 61, 123, 127, 128], "changd": 10, "001": [10, 127], "25": [10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 23, 24, 26, 27, 28, 29, 58, 59, 61, 77, 80, 81, 86, 122, 123, 127, 128], "nanyang": 10, "029": [10, 24], "26": [10, 17, 47, 59, 61, 127, 128], "022": 10, "27": [10, 17, 61, 127, 128], "xinyang": 10, "031": [10, 24], "28": [10, 59, 61, 98, 127, 128], "anq": 10, "009": [10, 127], "29": [10, 44, 59, 61, 74, 127, 128], "jiujiang": 10, "017": [10, 24], "mt_data": 10, "zero": [10, 11, 13, 14, 15, 22, 26, 27, 44, 49, 59, 62, 71, 74, 80, 86, 93, 95, 96, 97, 98, 100, 105, 108, 109, 114, 115, 127, 128], "fig": [10, 129], "figur": [10, 17, 129], "figsiz": 10, "ax": 10, "add_subplot": 10, "cax": 10, "shrink": 10, "horizont": 10, "cities_nam": 10, "set_xtick": 10, "arang": [10, 20], "len": [10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 24, 25, 26, 28, 29, 44, 47, 49, 58, 59, 61, 74, 77, 79, 83, 87, 88, 106, 107, 120, 121, 122, 123, 125, 126, 127, 128], "set_ytick": 10, "set_xticklabel": 10, "rotat": 10, "90": [10, 59, 61], "set_yticklabel": 10, "linear": [10, 12, 19, 24, 25, 47, 79, 80, 81, 89, 90, 91, 93, 97, 100, 101, 102, 103, 104, 107, 109, 121, 125, 126], "addit": [10, 12, 14, 22, 62, 63, 67, 68, 71, 72, 73, 88], "graphic": [10, 12], "uniqu": [11, 13, 14, 49, 65, 66, 72, 73, 117, 128], "invari": [11, 13, 14, 129], "trasform": [11, 13, 14], "disadvantag": [11, 13, 14, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104], "knowledg": [11, 49, 79, 80, 84, 87, 88, 109, 114], "realiz": [11, 13, 14, 67, 84, 127], "underli": [11, 13, 14, 17, 19, 72, 73, 89, 118], "lsem": [11, 14, 122, 123], "g_j": [11, 13], "differenti": [11, 13], "argument": [11, 13, 17, 20, 63], "corollari": [11, 13], "threshold": 11, "synthetic_dataset": [11, 13, 14], "1234": [11, 13, 14], "300": [11, 13, 14, 18, 20, 49, 83, 128], "ground_truth_g": [11, 13, 14], "simulate_random_dag": [11, 13, 14], "graph_typ": [11, 13, 14], "erdo": [11, 13, 14], "renyi": [11, 13, 14], "w_rang": [11, 13, 14], "c": [11, 13, 14, 15, 17, 18, 23, 27, 44, 47, 49, 58, 59, 68, 71, 74, 77, 78, 79, 80, 82, 84, 85, 86, 87, 88, 93, 94, 95, 96, 102, 103, 104, 105, 106, 107, 108, 109, 115, 116, 120, 127, 128], "ones": [11, 13, 14, 15, 21, 22, 26, 44, 47, 59, 61, 74, 84, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 114, 120, 125, 126, 127], "simulate_lsem": [11, 13, 14], "plot_net": [11, 13, 14, 122, 123], "nx": [11, 13, 14, 59, 122, 123], "to_numpy_arrai": [11, 13, 14], "labels_nam": [11, 13, 14, 122, 123], "rang": [11, 13, 14, 21, 49, 58, 61, 74, 99, 120, 125, 126, 127, 129], "modulenotfounderror": [11, 13, 14, 49], "traceback": [11, 13, 14, 17, 20, 22, 23, 25, 44, 47, 49, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 71, 74, 77, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115, 120, 121, 122, 123, 125, 126, 127, 128], "var": [11, 13, 14, 17, 20, 21, 22, 23, 25, 28, 44, 47, 49, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 71, 74, 77, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115, 120, 121, 122, 123, 125, 126, 127, 128], "folder": [11, 13, 14, 17, 20, 21, 22, 23, 25, 28, 44, 47, 49, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 71, 74, 77, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115, 120, 121, 122, 123, 125, 126, 127, 128, 130], "9j": [11, 13, 14, 17, 20, 21, 22, 23, 25, 28, 44, 47, 49, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 71, 74, 77, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115, 120, 121, 122, 123, 125, 126, 127, 128], "vb5nb4rd5bx0gr1q5ytx9q600000gn": [11, 13, 14, 17, 20, 21, 22, 23, 25, 28, 44, 47, 49, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 71, 74, 77, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115, 120, 121, 122, 123, 125, 126, 127, 128], "ipykernel_34803": 11, "2370726509": [11, 13, 14], "modul": [11, 13, 14, 17, 20, 22, 23, 25, 44, 47, 49, 58, 59, 61, 62, 63, 65, 66, 67, 68, 69, 71, 74, 77, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115, 120, 121, 122, 123, 125, 126, 127, 128], "pip": [11, 14, 18, 23, 59, 130], "instal": [11, 14, 18, 23, 59, 130], "igraph": 11, "factor_analyz": 11, "directlingam": 11, "fit": [11, 15, 16, 17, 18, 20, 22, 23, 24, 25, 26, 28, 29, 32, 44, 58, 59, 61, 74, 77, 121, 122, 123, 125, 126], "adjacency_matrix_": 11, "ica_r": 11, "ab": [11, 13, 14], "fdr": [11, 13, 14], "tpr": [11, 13, 14], "shd": [11, 13, 14], "count_accuraci": [11, 13, 14], "digraph": [11, 13, 14, 122, 123], "statsmodel": [11, 18, 23, 58, 120, 121, 125], "tsa": [11, 120, 121, 125], "tsa_model": [11, 120, 121, 125], "futurewarn": [11, 16, 120, 121, 125], "int64index": [11, 120, 121, 125], "deprec": [11, 17, 120, 121, 125], "futur": [11, 32, 72, 73, 120, 121, 125], "index": [11, 14, 17, 18, 20, 23, 24, 49, 58, 67, 77, 87, 94, 120, 121, 122, 123, 125, 126, 130], "dtype": [11, 20, 24, 44, 58, 59, 61, 74, 77, 120, 121, 122, 123, 125, 126, 128], "instead": [11, 16, 17, 18, 20, 22, 23, 24, 26, 28, 29, 32, 58, 62, 67, 71, 74, 77, 79, 86, 95, 100, 102, 117, 120, 121, 122, 123, 125, 130], "to_datetim": [11, 120, 121, 125], "datetimeindex": [11, 120, 121, 125], "float64index": [11, 120, 121, 125], "67": [11, 13, 14, 20, 58, 61, 78, 101, 104, 105, 107, 128], "prune": [11, 13, 14], "metric": [11, 13, 14, 17, 47], "fals": [11, 13, 14, 18, 20, 21, 23, 44, 58, 80, 81, 86, 88, 102, 103, 104, 105, 108, 120, 121, 122, 123, 125, 126, 127], "ham": [11, 13, 14], "distanc": [11, 13, 14], "smallest": [11, 13, 14, 22, 49], "revers": [11, 13, 14, 122, 123], "account": [11, 13, 14, 21, 77, 84, 86, 94, 95, 99, 100, 101, 102, 120, 129], "neg": [11, 13, 14, 20, 21, 44, 47, 58, 74, 77, 120, 122, 123, 125, 126], "better": [11, 13, 14, 17, 18, 22, 23, 28, 29, 44, 58, 60, 62, 74, 77, 82, 85, 121, 122, 123, 125, 126, 127], "00": [11, 13, 14, 23, 44, 58, 59, 61, 74, 121, 125, 126], "50": [11, 13, 14, 17, 21, 27, 49, 58, 61, 120, 125, 126, 127, 128], "62": [11, 13, 14, 27, 61, 74], "daggnn": [11, 13, 14], "equal": [11, 13, 14, 49, 62, 63, 67, 71, 72, 94, 97, 98, 100, 101], "varianc": [11, 13, 14, 22, 23, 25, 49, 62, 63, 67, 68, 71, 80, 84, 109, 114, 117], "biometrika": [11, 13, 14, 15, 16, 19, 20, 24, 25], "101": [11, 13, 14, 20, 25, 59, 128], "219": [11, 13, 14, 127], "228": [11, 13, 14, 22, 23, 128], "2013": [11, 13, 14, 15, 22, 79, 80, 98, 99, 106, 107, 109, 116], "mooij": [11, 13, 14], "janz": [11, 13, 14], "sch\u00f6lkopf": [11, 13, 14], "cma": 12, "dissect": 12, "transmit": 12, "comprehens": [12, 27, 122, 123, 124], "cate": [12, 19], "moder": 13, "sem": 13, "good": [13, 22, 65, 66, 73, 84, 107, 117, 129], "analysis": 13, "contrain": 13, "ipykernel_34814": 13, "notears_linear": [13, 122, 123], "lambda1": [13, 122, 123], "loss_typ": [13, 122, 123], "l2": [13, 122, 123], "notears_r": 13, "author": [14, 17], "nois": [14, 86, 97, 98, 129], "normal": [14, 17, 59, 61, 62, 67, 68, 71, 86, 90, 98, 99], "sparsiti": [14, 47, 79], "teat": 14, "ipykernel_34822": 14, "pydot": 14, "git": [14, 130], "pycaus": 14, "start_vm": 14, "tetrad": 14, "tetradrunn": 14, "new_df": 14, "map": [14, 65, 66, 73, 78, 89, 90, 91, 117, 129, 130], "02": [14, 44, 58, 61, 74, 121, 125, 126], "format": [14, 74, 127], "algoid": 14, "testid": 14, "gettetradgraph": 14, "getnod": 14, "dot_str": 14, "tetradgraphtodot": 14, "graph_from_dot_data": 14, "node_a": 14, "fill": 14, "fillcolor": 14, "red": 14, "add_nod": 14, "nx_pydot": 14, "from_pydot": 14, "pc_re": 14, "trial": [15, 32, 78, 107], "ve": [15, 19, 129], "preliminari": 15, "notat": [15, 73, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 130], "rl": [15, 63, 72, 73, 117, 118, 129], "main": [15, 20, 24, 25, 117, 129, 130], "common": [15, 19, 22, 26, 74, 77, 97, 99, 122, 123, 129], "causal": [15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26, 28, 32, 75, 117, 118, 120, 121, 125, 126, 130], "consist": [15, 16, 17, 19, 20, 21, 22, 24, 25, 26, 27, 32, 47, 59, 62, 65, 67, 68, 71, 72, 73, 90, 99, 106, 116, 122, 123, 124], "These": [15, 19, 22, 62, 63, 71, 73], "nuc": [15, 21, 22, 26, 32], "remark": [15, 82, 86, 88, 108], "commonli": [15, 19, 21, 65, 66, 67, 68, 71, 72, 79, 80, 89, 90, 91, 109], "impos": [15, 65, 73], "automat": [15, 67, 71, 73, 88], "behavior": [15, 22, 23, 25, 59, 67, 72, 73, 90, 94, 101, 116], "strictli": [15, 67, 71], "re": [15, 87], "shown": [15, 17, 84, 86, 94, 107, 109, 114], "below": [15, 16, 17, 21, 22, 24, 25, 26, 28, 74, 77, 79, 83, 87, 107, 118, 120, 121, 122, 123, 125, 126, 127, 129], "rh": [15, 117], "rid": 15, "pure": [15, 117], "categori": [15, 62, 65, 71, 107, 129], "IS": [15, 62, 67, 71], "dr": [15, 19, 20, 49, 62, 67, 71], "widehat": [15, 16, 17, 21, 25, 49, 62, 63, 65, 66, 68, 71, 89, 90, 91, 117], "learner": [15, 17, 18, 19, 21, 23, 27, 44, 47, 58, 59, 61, 74, 77, 105, 108, 109, 114, 115, 120, 121, 122, 123, 125, 126, 127, 128, 129], "elabor": [15, 32], "sklearn": [15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 47, 122, 123, 127, 128], "ensembl": [15, 16, 17, 18, 20, 21, 24, 26, 28, 29, 122, 123], "gradientboostingregressor": [15, 16, 17, 18, 20, 21, 24, 26, 28, 29], "linear_model": [15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 58, 122, 123, 127, 128], "linearregress": [15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 122, 123, 127, 128], "movielens_cel": [15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29], "cdm": [15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 127, 128], "pop": [15, 16, 17, 18, 20, 21, 24, 26, 28, 29], "user_id": [15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 127, 128], "movie_id": [15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 127, 128], "ag": [15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 62, 63, 65, 66, 67, 68, 69, 71, 79, 87, 105, 107, 108, 109, 114, 115, 127, 128], "drama": [15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 79, 83, 87, 88, 106, 107, 127, 128], "gender_m": [15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 127, 128], "occupation_academ": [15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 127, 128], "educ": [15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 79, 87, 107, 127, 128], "occupation_colleg": [15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 127, 128], "grad": [15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 79, 80, 81, 86, 87, 107, 127, 128], "occupation_execut": [15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 127, 128], "manageri": [15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 79, 87, 107, 127, 128], "occupation_oth": [15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 127, 128], "occupation_technician": [15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 127, 128], "engin": [15, 16, 17, 18, 20, 21, 24, 25, 26, 27, 28, 29, 74, 77, 79, 87, 107, 122, 123, 127, 128], "48": [15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 61, 79, 122, 123, 124, 127, 128], "1193": [15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 128], "919": [15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 128], "527": [15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 128], "1721": [15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 128], "150": [15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 61, 128], "65637": [15, 16, 17, 18, 20, 21, 24, 26, 28, 29], "5878": [15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 127, 128], "3300": [15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29], "65638": [15, 16, 17, 18, 20, 21, 24, 26, 28, 29], "1391": [15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29], "65639": [15, 16, 17, 18, 20, 21, 24, 26, 28, 29], "185": [15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29], "65640": [15, 16, 17, 18, 20, 21, 24, 26, 28, 29], "2232": [15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29], "65641": [15, 16, 17, 18, 20, 21, 24, 26, 28, 29], "426": [15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 128], "65642": [15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29], "userinfo_index": [15, 16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 122, 123, 127, 128], "sanda": [15, 16, 17, 18, 20, 21, 22, 24, 26, 27, 28, 29], "iloc": [15, 16, 17, 18, 20, 21, 22, 23, 24, 26, 27, 28, 29, 49, 120, 121, 122, 123, 125, 126, 127, 128], "s_learner": [15, 22, 26], "max_depth": [15, 16, 18, 20, 21, 22, 23, 24, 25, 26, 28, 29, 120, 122, 123, 125, 126, 127, 128], "sanda_all1": [15, 26], "copi": [15, 20, 21, 24, 26, 59, 120, 122, 123, 125, 126, 127], "sanda_all0": [15, 26], "ate_dm": 15, "sum": [15, 16, 17, 18, 20, 22, 23, 24, 25, 26, 28, 29, 59, 61, 63, 85, 106, 107, 115, 122, 123, 127, 128], "14529621186817238": 15, "inclin": [15, 26, 28, 29, 122, 123], "higher": [15, 19, 26, 28, 29, 63, 79, 83, 87, 107, 122, 123], "fiction": [15, 26, 28, 29], "145": [15, 17, 122, 123], "invers": [15, 21, 59, 67, 71], "aipw": [15, 59], "proce": [15, 73], "bigg": [15, 17, 21], "flip": 15, "role": [15, 89, 90, 91], "a_ir_i": 15, "logisticregress": [15, 16, 18, 20, 22, 23, 24, 25, 29, 122, 123], "ps_model": [15, 16, 24, 25], "pi_": [15, 77, 117], "predict_proba": [15, 22, 29, 122, 123], "ate_i": 15, "3556423779577757": 15, "watch": [15, 27, 59, 82], "356": [15, 128], "sci": [15, 16, 17, 18, 20, 24, 26, 27, 28, 29, 79, 80, 81, 83, 84, 87, 107, 127, 128], "fi": [15, 16, 17, 18, 20, 24, 26, 27, 28, 29, 79, 80, 81, 83, 84, 87, 107, 127, 128], "third": [15, 62, 71, 93, 95, 96], "misspecif": [15, 44, 63, 74, 80, 93, 97, 103], "term": [15, 20, 25, 62, 63, 67, 71, 77, 79, 86, 90, 91], "correct": [15, 32], "correctli": [15, 63, 90], "prove": [15, 16, 20, 21, 25, 47, 62, 63, 68], "mild": [15, 16, 19, 25, 62], "semi": [15, 97, 98, 100, 105, 106, 116], "parametr": [15, 17, 71], "converg": [15, 17, 19, 20, 25, 49, 62, 63, 65, 66, 71, 129], "found": [15, 44, 60, 74, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 129, 130], "15559049518872164": 15, "ate_dr": 15, "010294283320549269": 15, "slightli": [15, 22, 32, 71, 73, 118], "sequenti": [15, 17, 32, 44, 59, 73, 74, 78, 83, 86, 88, 89, 90, 91, 99, 107], "681": [15, 128], "694": 15, "v": [15, 16, 17, 18, 19, 20, 23, 24, 25, 32, 47, 49, 58, 62, 68, 71, 72, 73, 81, 89, 90, 91, 94, 95, 96, 98, 101, 102, 103, 104, 105, 106, 117], "chetverikov": [15, 17], "demir": [15, 17], "duflo": [15, 17], "hansen": [15, 17], "w": [15, 17, 20, 22, 44, 49, 58, 73, 74, 75, 76, 77, 78, 79, 81, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 106, 107, 116, 117, 121], "newei": [15, 17], "kennedi": [16, 19, 20, 25], "extend": [16, 25, 47, 67, 71], "oracl": [16, 19, 20, 24, 25], "theorem": [16, 17, 25, 71, 100, 117], "nuisanc": [16, 18, 20, 23, 25, 62, 63, 67, 71], "i_": [16, 20, 25, 63], "mu_a": [16, 25], "mathbb": [16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 32, 44, 47, 49, 59, 62, 63, 65, 66, 67, 71, 72, 73, 74, 89, 90, 91, 117, 129], "phi": [16, 25, 44, 74, 80, 84, 86, 88, 93, 95, 97, 100, 102, 103, 109, 128], "_a": [16, 20, 25, 81], "_1": [16, 25, 59, 63, 121], "_0": [16, 25, 59], "i_2": [16, 20, 25, 63], "yield": [16, 17, 22, 25, 28, 32, 49, 59, 62, 63, 67, 71], "tau": [16, 18, 19, 20, 22, 23, 24, 25, 26, 28, 29, 59, 63, 117], "_n": [16, 20, 24, 25, 59], "causal_effect_learn": [16, 17, 18, 20, 21, 24, 25, 120, 121, 125, 126], "single_stag": [16, 17, 18, 20, 24, 25], "drlearner": [16, 25], "n_fold": [16, 20, 24, 25], "y_model": [16, 20, 24, 25], "rlearner_model": [16, 24, 25], "hte_dr_learn": [16, 25], "to_numpi": [16, 17, 22, 23, 24, 25, 26, 127], "493": [16, 128], "were": 16, "pass": [16, 20], "start": [16, 17, 24, 25, 32, 72, 77, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 108, 109, 114, 115, 122, 123], "unseen": 16, "t_1": [16, 63, 72, 73, 129], "seen": 16, "yet": [16, 49, 118], "messag": [16, 59], "t_0": [16, 129], "fold": [16, 20, 24, 25, 59], "r2": [16, 24, 25], "baselearn": [16, 25], "pslearner": [16, 25], "735": 16, "038": 16, "037": 16, "734": [16, 24], "1000": [16, 17, 20, 22, 24, 26, 28, 29, 47, 59, 61, 95, 102, 103, 105, 106, 127, 128], "5000": [16, 17, 24, 26, 27, 28, 29, 127], "05672212": 16, "73726057": 16, "09360586": 16, "ate_dr_learn": 16, "3541": 16, "conclus": [16, 17, 18, 20, 22, 24, 25, 26, 28, 29, 122, 123], "xinkun": [16, 19, 20, 24, 25], "nie": [16, 19, 20, 24, 25, 121, 125, 126], "stefan": [16, 18, 19, 20, 23, 24, 25, 34, 35, 38, 39, 40, 41, 42], "wager": [16, 18, 19, 20, 23, 24, 25, 34, 35, 38, 39, 40, 41, 42], "quasi": [16, 19, 20, 24, 25], "108": [16, 17, 19, 20, 24, 25, 27, 128], "299": [16, 19, 20, 24, 25, 128], "319": [16, 19, 20, 24, 25], "robinson": [16, 19, 20, 24, 25], "root": [16, 19, 20, 24, 25], "econometrica": [16, 19, 20, 24, 25], "econometr": [16, 19, 20, 24, 25], "societi": [16, 19, 20, 24, 25, 44, 74], "931": [16, 19, 20, 24, 25, 74, 77, 122, 123, 128], "954": [16, 19, 20, 24, 25, 127], "edward": [16, 19, 20, 25], "h": [16, 19, 20, 25, 44, 49, 77, 78, 86, 87, 88, 89, 90, 91, 93, 94, 95, 97, 100, 101, 102, 103, 106, 107, 115, 116], "2004": [16, 19, 20, 25, 44, 74], "14497": [16, 19, 20, 25], "der": [16, 19, 20, 25, 75, 121], "laan": [16, 19, 20, 25, 75, 121], "biostatist": [16, 19, 20, 25, 44, 74], "lee": [16, 19, 20, 25], "okui": [16, 19, 20, 25], "whang": [16, 19, 20, 25], "uniform": [16, 19, 20, 25, 59], "band": [16, 19, 20, 25], "1207": [16, 19, 20, 25, 128], "1225": [16, 19, 20, 25, 128], "foster": [16, 19, 20, 25], "syrgkani": [16, 19, 20, 25], "orthogon": [16, 19, 20, 25, 78, 107], "1901": [16, 19, 20, 25], "09036": [16, 19, 20, 25], "guarante": [17, 19, 73, 129, 130], "asymptot": [17, 47, 62, 63, 71, 90, 117], "dml": [17, 18, 23], "plug": [17, 21, 22, 26, 49, 62, 63, 65, 71], "att": 17, "despit": [17, 49, 122, 123], "versatil": 17, "choic": [17, 21, 78, 94, 95, 101, 107, 116, 120, 125, 126], "ml": 17, "seem": [17, 122, 123], "criteria": [17, 27, 122, 123, 124], "qualiti": [17, 19], "angl": 17, "innov": 17, "discard": 17, "irrelev": 17, "minimum": 17, "tmle": 17, "imporv": 17, "finit": [17, 47, 58, 63, 67, 71, 77, 82, 85, 88, 107, 108, 115], "stabil": [17, 129], "amd": 17, "word": [17, 44, 58, 72, 73, 74, 77, 79, 83, 87, 106, 107, 116, 127], "head": [17, 27, 61, 74, 121, 122, 123, 125, 126], "archetectur": 17, "ipython": [17, 21, 122], "singlestag": 17, "png": [17, 21], "width": 17, "500": [17, 59, 83, 87, 97, 98, 100, 105, 121], "layer": 17, "resourc": 17, "core": [17, 20], "object": [17, 20, 24, 44, 47, 58, 59, 79, 83, 84, 94, 106, 107, 109, 114, 117, 122, 123, 128], "theta": [17, 20, 25, 80, 82, 84, 86, 93, 94, 95, 96, 97, 98, 100, 102, 103, 104, 106, 108, 109, 114, 116, 117, 121], "arg": [17, 20, 24, 25, 44, 47, 58, 59, 62, 65, 66, 72, 73, 74, 77, 80, 81, 84, 85, 93, 95, 96, 97, 98, 100, 101, 102, 103, 104, 115, 117, 122, 123], "min_": [17, 20, 24, 25, 59, 62, 65, 66, 117], "nn": [17, 118], "alpha": [17, 18, 20, 23, 59, 63, 68, 72, 73, 80, 81, 86, 88, 93, 96, 104, 109, 117], "crossentropi": 17, "hyperparamet": 17, "tild": [17, 22, 29, 63, 74, 77, 80, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 109, 114], "minim": [17, 19, 20, 62, 63, 71, 72, 73, 78, 83, 95, 100, 102, 107], "extra": 17, "beta": [17, 18, 23, 24, 25, 44, 58, 59, 77, 80, 84, 86, 88, 95, 96, 102, 104, 114, 120, 121, 125, 126, 129], "solut": [17, 18, 23, 47, 49, 65, 66, 72, 117, 130], "claudiashi57": 17, "check": [17, 32], "keyboardinterrupt": [17, 20], "ipykernel_34837": 17, "244113421": 17, "demo": [17, 18, 23, 61, 128, 130], "dragonnet_model": 17, "glob": 17, "tensorflow": 17, "tf": 17, "kera": 17, "backend": 17, "topolog": [17, 122, 123], "binary_accuraci": 17, "__init__": [17, 20, 25, 74, 77, 122, 123], "35": [17, 18, 59, 61, 127, 128], "_type": [17, 25], "36": [17, 61, 97, 127, 128], "37": [17, 44, 47, 58, 59, 61, 122, 123, 127, 128], "python": [17, 18, 23, 27, 59, 95, 102, 127, 128, 130], "module_util": 17, "_module_util": 17, "lazy_load": 17, "lazyload": 17, "_lazyload": 17, "39": [17, 18, 23, 44, 59, 61, 123, 127, 128], "43": [17, 61, 127, 128], "45": [17, 18, 23, 59, 61, 127, 128], "feature_column": 17, "feature_column_lib": 17, "46": [17, 44, 61, 74, 100, 127, 128], "47": [17, 18, 19, 23, 27, 34, 35, 38, 39, 40, 41, 42, 61, 82, 85, 107, 108, 115, 122, 123, 124, 127, 128], "pylint": 17, "disabl": 17, "unus": 17, "too": 17, "wildcard": 17, "bad": [17, 122, 123], "feature_column_v2": 17, "sequence_feature_column": 17, "141": [17, 128], "sparse_tensor": 17, "sparse_tensor_lib": 17, "142": [17, 59, 122, 123, 128], "tensor_shap": 17, "143": [17, 27, 83, 125, 126, 127, 128], "144": [17, 27], "op": [17, 20, 62, 65, 67, 71, 72, 73, 129], "array_op": 17, "check_op": 17, "inherit": [17, 19], "legacy_tf_lay": 17, "inputspec": 17, "110718070": 17, "comment18": 17, "input_lay": 17, "metrics_modul": 17, "optimizer_v1": 17, "input_spec": 17, "node_modul": 17, "training_lib": 17, "33": [17, 27, 61, 98, 127, 128], "training_util": 17, "34": [17, 49, 59, 61, 86, 87, 88, 127, 128], "save": [17, 27, 67, 86, 130], "saved_model": 17, "network_seri": 17, "mixed_precis": 17, "loss_scale_optim": 17, "lso": 17, "51": [17, 61, 125, 127, 128], "52": [17, 61, 122, 127, 128], "hdf5_format": 17, "53": [17, 58, 59, 61, 127, 128], "54": [17, 59, 61, 127, 128], "saving_util": 17, "h5py": 17, "hdf5_object_header_limit": 17, "64512": 17, "importerror": 17, "hdf5_version_tupl": 17, "hdf5_built_version_tupl": 17, "namedtupl": 17, "h5": 17, "_h5": 17, "sy": 17, "pyx": 17, "importlib": [17, 23], "_bootstrap": 17, "self": [17, 20, 25, 44, 58, 61, 62, 67, 71, 74, 77, 122, 123, 128], "test_output": 17, "train_output": 17, "train_and_predict_dragon": 17, "targeted_regular": 17, "output_dir": 17, "master": 17, "knob_loss": 17, "dragonnet_loss_binarycross": 17, "ratio": [17, 21, 27, 62, 63, 67, 71, 122, 123, 124, 125, 126], "val_split": 17, "64": [17, 18, 23, 58, 61, 128], "am": 17, "optimizer_v2": 17, "adam": 17, "110": [17, 25, 27, 122, 123, 128], "lr": 17, "learning_r": 17, "super": 17, "kwarg": [17, 20, 74, 77, 122, 123], "gradient_desc": 17, "sgd": 17, "elapsed_tim": 17, "63": [17, 18, 59, 61, 128], "41897392272949": 17, "2052": 17, "1s": 17, "596u": 17, "9176047444343567": 17, "untreat": 17, "9125609993934631": 17, "dict_kei": [17, 27, 127, 128], "q_t0": 17, "q_t1": 17, "ep": [17, 20], "hte_dragonnet": 17, "32294464": 17, "43536925": 17, "33986402": 17, "aaverag": 17, "ate_dragonnet": 17, "3225": 17, "claudia": [17, 19], "blei": [17, 19], "veitch": [17, 19], "33rd": 17, "neurip": 17, "pa": [17, 21, 120, 125, 126], "ramet": 17, "susan": [18, 19, 23, 34, 35, 38, 39, 40, 41, 42], "athei": [18, 19, 23, 34, 35, 38, 39, 40, 41, 42], "juli": [18, 19, 23, 34, 35, 38, 39, 40, 41, 42, 87, 88, 99], "tibshirani": [18, 19, 23, 34, 35, 38, 39, 40, 41, 42], "moment": [18, 23], "psi_": [18, 23, 44, 62, 63, 68, 71, 74], "nu": [18, 23], "o_i": [18, 23, 49], "care": [18, 23, 27, 122, 123, 124], "xi": [18, 23, 62, 71], "induc": [18, 20, 23], "solv": [18, 23, 24, 25, 44, 47, 49, 58, 62, 63, 65, 66, 67, 71, 72, 73, 74, 84, 98, 101, 106, 107, 109, 114, 116, 117], "alpha_i": [18, 23], "otim": [18, 23], "vv": [18, 23], "notic": [18, 23, 80, 96, 97, 104, 109], "formula": [18, 23, 58, 130], "ordinari": [18, 23], "prone": [18, 23], "grf": [18, 19, 23], "quantiti": [18, 23], "grow": [18, 23, 71, 118], "dot": [18, 20, 23, 44, 59, 62, 67, 71, 74, 79, 83, 87, 94, 101, 106, 107, 116, 129], "l_b": [18, 23], "fall": [18, 23, 32], "leaf": [18, 23], "frequenc": [18, 23, 80, 81, 93, 95, 100, 102, 103], "alpha_": [18, 23, 88], "bi": [18, 23], "boldsymbol": [18, 23, 44, 58, 60, 74, 76, 77, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 106, 108, 109, 115, 116, 121, 125, 126], "x_0": [18, 23], "flexibl": [18, 23, 49, 63, 89, 90, 91, 129], "lprlearner": [18, 20, 25], "_util_causaldm": [18, 22, 23, 25, 44, 58, 60], "econml": [18, 23], "spars": [18, 23], "scikit": [18, 23, 59, 60], "lightgbm": [18, 23, 25, 122, 123, 127, 128], "joblib": [18, 20, 23, 59], "scipi": [18, 20, 23, 59], "shap": [18, 23], "41": [18, 23, 58, 61, 127, 128], "40": [18, 21, 23, 59, 61, 122, 125, 126, 127, 128], "threadpoolctl": [18, 23, 59], "tqdm": [18, 23, 59, 122, 123], "slicer": [18, 23], "numba": [18, 23], "55": [18, 61, 95, 102, 122, 127, 128], "cloudpickl": [18, 23], "patsi": [18, 23], "dateutil": [18, 23, 59], "pytz": [18, 23, 59], "wheel": [18, 23], "setuptool": [18, 23], "llvmlite": [18, 23], "0rc1": 18, "pypars": [18, 59], "six": [18, 23, 59, 129], "causalforest": [18, 23], "causalivforest": [18, 23], "regressionforest": [18, 23], "causalforestdml": [18, 23], "est": [18, 23], "criterion": [18, 23], "het": [18, 23], "n_estim": [18, 23], "400": [18, 23, 61], "min_samples_leaf": [18, 23], "none": [18, 20, 21, 23, 25, 27, 58, 59, 61, 74, 77, 82, 86, 94, 108, 114, 120, 122, 123, 125, 126, 127, 128], "min_var_fraction_leaf": [18, 23], "min_var_leaf_on_v": [18, 23], "min_impurity_decreas": [18, 23], "max_sampl": [18, 23], "min_balancedness_tol": [18, 23], "warm_start": [18, 23], "fit_intercept": [18, 20, 23, 47], "subforest_s": [18, 23], "honest": [18, 23], "verbos": [18, 20, 23, 74, 77, 122, 123], "n_job": [18, 20, 23, 47], "random_st": [18, 20, 23], "1235": [18, 23], "hte_grf": [18, 23], "flatten": [18, 21, 23, 120, 125, 126], "900": [18, 20, 128], "3605": 18, "3783": 18, "3646": 18, "ate_grf": 18, "358": [18, 20, 128], "1148": [18, 19, 23, 34, 35, 38, 39, 40, 41, 42], "1178": [18, 19, 23, 34, 35, 38, 39, 40, 41, 42], "execut": [19, 27, 32, 79, 87, 107, 127, 128], "setup": [19, 24, 25, 47, 61, 62, 63, 101, 117, 118, 129], "triplet": [19, 72, 73, 129], "trajectori": [19, 67, 71, 72, 73, 117, 129], "imagin": 19, "terminolog": 19, "lot": [19, 59, 72], "recommend": [19, 27, 44, 47, 49, 58, 61, 74, 77, 78, 79, 83, 87, 94, 99, 101, 121, 125, 126, 127], "adversit": 19, "impact": [19, 122, 123, 125, 126], "annual": 19, "incom": [19, 101, 102, 103, 104, 127], "expos": 19, "statu": [19, 21, 27, 32, 59, 90, 91, 122, 123, 124], "pictur": [19, 59], "dress": 19, "femal": [19, 79, 127, 128], "male": [19, 79, 80, 81, 86, 87, 107, 127], "clearli": [19, 129], "granular": 19, "averg": 19, "characsterist": 19, "subsect": [19, 27, 71], "briefli": [19, 78, 107], "lp": 19, "forest": [19, 34, 35, 38, 39, 40, 41, 42], "dragonnet": 19, "paper": [19, 20, 25, 117], "pleas": [19, 20, 22, 25, 29], "easiest": [19, 22, 24, 25, 59], "apporach": 19, "enough": [19, 63, 130], "complic": [19, 22, 28, 63], "worth": [19, 32, 100], "sensibl": 19, "trend": [19, 22, 79, 114, 115, 129], "cancel": 19, "tend": [19, 22], "particularli": [19, 44, 58, 74, 77], "larger": [19, 28, 44, 58, 60, 63, 71, 74, 77], "part": [19, 59, 63, 117, 120, 129, 130], "properti": [19, 104, 114], "boost": [19, 59], "acheiv": 19, "alwai": [19, 44, 58, 63, 79, 83, 84, 87, 96, 98, 104, 107, 109, 114, 125, 126], "faster": [19, 49, 63, 71], "might": [19, 61, 62, 122, 123], "computation": [19, 68, 95, 100, 102, 104, 118], "polynomi": [19, 20, 25], "tradeoff": [19, 63], "nonparametr": [19, 71], "dragon": 19, "net": 19, "outperform": [19, 80, 93, 96, 97, 98, 103, 104], "kunzel": [19, 22, 26, 28, 29], "sekhon": [19, 22, 26, 28, 29], "bickel": [19, 22, 26, 28, 29], "metalearn": [19, 22, 26, 28, 29], "nation": [19, 22, 26, 28, 29], "academi": [19, 22, 26, 28, 29], "116": [19, 22, 26, 28, 29, 44, 58, 89, 90, 91, 127], "4156": [19, 22, 26, 28, 29, 128], "4165": [19, 22, 26, 28, 29], "alicia": 19, "curth": 19, "mihaela": 19, "schaar": 19, "1810": 19, "1818": 19, "residu": [20, 24, 25], "cross": [20, 25, 59], "relax": [20, 25, 32, 63, 129], "breviti": [20, 25], "1b": [20, 25], "basi": [20, 25, 62, 71, 86, 120], "k_": [20, 25], "hs": [20, 25], "bandwidth": [20, 25, 49], "eta": [20, 21, 23, 24, 25, 59, 62, 63, 65, 67, 68, 71, 72, 73, 95, 100, 101, 102, 106, 116], "mu_1": [20, 22, 25, 28, 29], "mu_0": [20, 22, 25, 28, 29], "estimt": [20, 25], "_b": [20, 25], "_r": [20, 25], "tb": [20, 25], "s_0": [20, 25, 32, 63, 72, 73, 117], "repeat": [20, 25, 77, 107, 117], "twice": [20, 25], "n_": [20, 25], "samplem": [20, 25], "tradit": [20, 25, 67], "milder": [20, 25, 63], "sample_index": 20, "tolist": [20, 122, 123, 127], "ps_model_a": [20, 25], "ps_model_b": [20, 25], "lprlearner_model": [20, 25], "hte_lp_r_learn": [20, 25], "typeerror": [20, 61, 128], "numerictyp": 20, "issubclass_": 20, "arg1": 20, "arg2": 20, "320": [20, 128], "321": [20, 98, 128], "issubclass": 20, "322": [20, 128], "ipykernel_34939": 20, "3692478981": 20, "93": [20, 61], "94": [20, 58, 59, 61], "y_learner": [20, 24, 25], "fold1b": 20, "95": [20, 61, 102, 127], "ps_learner_b": 20, "97": [20, 44, 61, 103, 122, 123, 128], "_logist": 20, "sample_weight": 20, "1587": [20, 98], "els": [20, 21, 25, 44, 58, 120, 121, 125, 126], "1588": 20, "1589": 20, "fold_coefs_": 20, "parallel": 20, "1590": 20, "1591": [20, 128], "__call__": 20, "iter": [20, 59, 63, 65, 74, 77, 86, 95, 100, 102, 117, 122, 123], "1041": 20, "remain": 20, "job": 20, "1042": 20, "_iter": 20, "1043": 20, "dispatch_one_batch": 20, "1044": 20, "_original_iter": 20, "1045": 20, "859": 20, "860": 20, "861": 20, "_dispatch": 20, "862": 20, "863": 20, "777": [20, 128], "_lock": 20, "778": [20, 128], "job_idx": 20, "_job": 20, "779": [20, 128], "_backend": 20, "apply_async": 20, "callback": [20, 25], "cb": 20, "780": [20, 128], "complet": [20, 27, 44, 74, 86, 88, 128], "quickli": [20, 118], "781": [20, 128], "_parallel_backend": 20, "func": [20, 74, 77, 122, 123], "206": [20, 27, 122, 123, 128], "def": [20, 21, 25, 49, 59, 61, 74, 77, 120, 122, 123, 125, 126, 128], "207": [20, 58, 128], "208": [20, 79, 81], "immediateresult": 20, "209": 20, "210": [20, 59], "570": 20, "avoid": [20, 62, 63, 67, 71], "571": [20, 23], "572": 20, "573": [20, 74, 77, 122, 123], "574": [20, 27, 74, 77, 122, 123, 128], "260": [20, 128], "261": [20, 128], "parallel_backend": 20, "_n_job": 20, "262": [20, 128], "263": [20, 127, 128], "264": [20, 59, 128], "listcomp": 20, "214": [20, 22, 74, 79, 81], "215": [20, 59], "config_context": 20, "config": 20, "216": 20, "217": [20, 59], "218": 20, "_logistic_regression_path": 20, "pos_class": 20, "cs": [20, 47, 95, 102], "max_it": 20, "tol": 20, "solver": 20, "coef": 20, "class_weight": 20, "dual": 20, "penalti": [20, 120], "intercept_sc": 20, "multi_class": 20, "check_input": 20, "max_squared_sum": 20, "l1_ratio": 20, "804": [20, 128], "searchsort": 20, "805": [20, 128], "806": [20, 128], "opt_r": 20, "807": [20, 128], "808": [20, 128], "w0": 20, "_minim": 20, "fun": [20, 59], "x0": 20, "jac": 20, "hess": 20, "hessp": 20, "621": [20, 128], "622": [20, 128], "elif": 20, "meth": 20, "bfg": 20, "623": [20, 128], "_minimize_lbfgsb": 20, "624": 20, "625": [20, 122, 123], "tnc": 20, "lbfgsb": 20, "disp": 20, "maxcor": 20, "ftol": 20, "gtol": 20, "maxfun": 20, "maxit": 20, "iprint": 20, "maxl": 20, "finite_diff_rel_step": 20, "unknown_opt": 20, "until": [20, 65, 66, 67, 86, 88, 101, 102, 103, 104, 105, 117], "359": [20, 128], "overwrit": 20, "360": [20, 27, 128], "func_and_grad": 20, "361": [20, 128], "task_str": 20, "startswith": 20, "new_x": 20, "362": [20, 128], "_differentiable_funct": 20, "fun_and_grad": 20, "265": [20, 59, 128], "array_equ": 20, "266": [20, 128], "_update_x_impl": 20, "267": [20, 59, 128], "_update_fun": 20, "268": [20, 128], "_update_grad": 20, "269": [20, 27, 128], "231": [20, 128], "232": [20, 61, 128], "f_updat": 20, "233": [20, 128], "_update_fun_impl": 20, "234": [20, 128], "235": [20, 82, 85, 107, 108, 115, 128], "update_fun": 20, "135": [20, 79, 80, 83, 107, 109, 127, 128], "136": [20, 27, 122, 123, 128], "137": [20, 122, 123, 128], "fun_wrap": 20, "139": [20, 128], "132": [20, 44, 58, 128], "undefin": 20, "behaviour": [20, 47, 67, 71, 101], "133": [20, 49, 122, 123, 128], "longer": [20, 118], "link": [20, 89, 90, 91, 130], "134": [20, 128], "72": [20, 61, 128], "73": [20, 61, 122, 128], "74": [20, 47, 61, 128], "_compute_if_need": 20, "75": [20, 59, 61, 122, 123, 128], "_valu": 20, "76": [20, 61, 101, 102, 104, 106, 122, 123, 128], "66": [20, 58, 59, 61, 122, 123, 128], "asarrai": 20, "68": [20, 24, 47, 58, 61, 128], "fg": 20, "69": [20, 61, 122, 123, 128], "70": [20, 59, 61, 128], "_logistic_loss_and_grad": 20, "120": [20, 74, 122, 123, 127], "logist": [20, 44, 59, 67, 71, 80, 81, 86, 93, 95, 102, 103, 109], "log": [20, 85, 115, 117, 127], "122": [20, 27], "log_logist": 20, "yz": 20, "124": 20, "expit": 20, "extmath": 20, "783": [20, 128], "is_1d": 20, "ndim": 20, "784": [20, 74, 77, 122, 123], "atleast_2d": 20, "785": [20, 74, 77, 122, 123], "check_arrai": 20, "float64": [20, 58, 77, 121], "786": [20, 74, 77, 122, 123], "787": [20, 74, 77, 122, 123], "n_sampl": 20, "n_featur": 20, "shape": [20, 21, 59, 61, 74, 120, 125, 126], "accept_spars": 20, "accept_large_spars": 20, "force_all_finit": 20, "ensure_2d": 20, "allow_nd": 20, "ensure_min_sampl": 20, "ensure_min_featur": 20, "798": 20, "799": 20, "800": [20, 128], "_assert_all_finit": 20, "allow_nan": 20, "801": [20, 128], "802": [20, 128], "msg_dtype": 20, "overflow": 20, "102": [20, 25, 128], "is_float": 20, "fc": 20, "103": [20, 25, 44, 122, 128], "isfinit": 20, "_safe_accumulator_op": 20, "105": [20, 44, 59, 122, 123, 128], "890": 20, "accumul": 20, "891": [20, 127], "892": [20, 27, 128], "issubdtyp": 20, "float": 20, "items": 20, "893": 20, "894": 20, "415": 20, "416": [20, 128], "417": [20, 128], "418": [20, 128], "419": [20, 128], "323": [20, 128], "42383282": 20, "61112563": 20, "12977467": 20, "ate_lp_r_learn": 20, "3884": [20, 128], "hick": 21, "raymond": 21, "dustin": 21, "tinglei": 21, "2011": [21, 79, 81, 89, 90, 91, 103], "stata": 21, "605": 21, "619": [21, 128], "hong": [21, 87, 125, 126], "guanglei": 21, "2010": [21, 79, 107, 125, 126, 128], "biometr": [21, 47, 125, 126], "alexandria": 21, "va": 21, "usa": 21, "2401": [21, 125, 126], "2415": [21, 125, 126], "imai": 21, "kosuk": 21, "luke": 21, "keel": 21, "309": [21, 74, 77, 83, 101, 122, 123], "probabilist": [21, 94, 95, 102], "373": 21, "392": [21, 128], "tchetgen": [21, 125, 126], "ilya": 21, "shpitser": [21, 125, 126], "1816": [21, 98, 125, 126], "foundament": [22, 26], "esitm": [22, 26], "supervis": [22, 26, 28, 29], "n0": [22, 23, 25, 59], "mc": [22, 23, 25, 59, 117], "223": [22, 23, 25, 59], "data_behavior": [22, 23, 25], "get_data_simul": [22, 23, 25], "data_target": [22, 23, 25], "hte_tru": [22, 23, 25], "unboundlocalerror": [22, 23], "ipykernel_34961": 22, "2180662469": [22, 23], "227": [22, 23, 128], "229": [22, 23, 128], "referenc": [22, 23, 25], "s1": [22, 25, 61, 125, 126], "s2": [22, 25, 61, 125, 126], "034775": [22, 59], "453145": [22, 59], "167637": 22, "084880": [22, 59], "234459": [22, 59], "553798": 22, "144626": [22, 59], "040543": [22, 59], "956732": 22, "148426": [22, 59], "021139": [22, 59], "095578": 22, "120852": [22, 59], "377594": [22, 59], "323133": 22, "995": [22, 59, 128], "022440": [22, 59], "887551": [22, 59], "797542": 22, "996": [22, 59, 128], "411179": [22, 59], "655833": [22, 59], "722846": 22, "997": [22, 59, 128], "155706": [22, 59], "992197": [22, 59], "140100": 22, "998": [22, 59, 128], "510241": [22, 59], "828438": [22, 59], "167118": 22, "999": [22, 59, 102, 104, 128], "744187": [22, 59], "857147": [22, 59], "458481": 22, "lgbmregressor": [22, 25, 122, 123, 127, 128], "hstack": [22, 26, 44, 59, 61, 74], "hte_s_learn": [22, 26, 28], "1492": 22, "1687": 22, "589": [22, 128], "0319": 22, "8354": 22, "5843": 22, "4577": 22, "0791": [22, 98], "2961": [22, 23, 25], "4475": [22, 23, 25], "731": [22, 23, 25], "2863": [22, 23, 25], "4471": [22, 23, 25], "1839": [22, 23, 25], "3869": [22, 23, 25, 127], "238": [22, 23, 25, 128], "bias_s_learn": 22, "variance_s_learn": 22, "2857192464627009": 22, "079505077680185": 22, "toi": 22, "although": [22, 32, 63, 68, 122, 123], "cover": [22, 32], "mu0": [22, 28, 29, 122, 123], "mu1": [22, 28, 29, 61, 122, 123], "hte_t_learn": [22, 28, 122, 123], "glanc": 22, "869": [22, 128], "8733": 22, "6596": 22, "3087": 22, "2298": 22, "5598": 22, "2745": 22, "8211": 22, "bias_t_learn": 22, "variance_t_learn": 22, "29138198450323705": 22, "810391408711312": 22, "overfit": [22, 28], "provabl": [22, 29, 107], "imput": [22, 29], "delta": [22, 29, 86, 88], "tau_1": [22, 29], "tau_0": [22, 29], "s_t0": [22, 29], "s_t1": [22, 29], "r_t0": [22, 29], "r_t1": [22, 29], "unobserv": [22, 29, 118, 129], "origin": [22, 27, 29, 44, 58, 59, 60, 88, 117, 122, 123, 124], "n_t0": [22, 29], "n_t1": [22, 29], "delta0": [22, 29], "delta1": [22, 29], "tau0": [22, 29], "tau1": [22, 29], "hte_x_learn": [22, 29], "9341": 22, "9235": 22, "2944": 22, "4147": 22, "5443": 22, "roughli": [22, 62, 63, 129], "catch": 22, "synthet": [22, 129], "bias_x_learn": 22, "variance_x_learn": 22, "2827518068171628": 22, "7686646616779012": 22, "worst": 22, "ipykernel_34966": 23, "pypi": 23, "pkg": 23, "dev": 23, "colab": 23, "cp38": 23, "manylinux_2_17_x86_64": 23, "manylinux2014_x86_64": 23, "whl": [23, 59], "mb": 23, "2k": 23, "90m": 23, "0m": 23, "32m3": 23, "31m96": 23, "36m0": 23, "25hrequir": 23, "usr": [23, 25, 59], "dist": [23, 59], "py2": 23, "py3": [23, 59], "77": [23, 59, 61, 79, 128], "kb": [23, 59], "32m77": 23, "31m12": 23, "manylinux2010_x86_64": 23, "32m571": 23, "31m58": 23, "56": [23, 49, 61, 79, 87, 107, 126, 127, 128], "0dev0": 23, "57": [23, 59, 61], "zipp": 23, "successfulli": [23, 59], "2344": 23, "612": [23, 128], "7801": 23, "6886": 23, "6297": 23, "2293": 23, "4417": 23, "819": 23, "okai": 23, "bias_grf": 23, "variance_grf": 23, "706857912147952": 23, "198946462195667": 23, "came": [24, 25], "g_0": [24, 25], "u": [24, 25, 63, 85, 115, 127, 130], "m_0": [21, 24, 25], "manipul": [24, 25], "l_0": [24, 25], "rlearner": [24, 25], "hte_r_learn": [24, 25], "ps_learner": [24, 25], "015": 24, "739": [24, 128], "740": [24, 128], "736": [24, 128], "018": 24, "725": [24, 27], "settingwithcopywarn": [24, 122, 123], "slice": [24, 122, 123], "loc": [24, 59, 122, 123], "row_index": [24, 122, 123], "col_index": [24, 122, 123], "caveat": [24, 122, 123], "pydata": [24, 122, 123], "user_guid": [24, 122, 123], "x_residu": 24, "intercept": [24, 44, 58, 59, 61, 77, 93, 95, 97, 100, 102, 103, 127], "443": 24, "028": 24, "05127254": 24, "08881288": 24, "10304225": 24, "ate_r_learn": 24, "0755": 24, "oserror": 25, "ipykernel_34977": 25, "1454775972": 25, "pathlib": 25, "booster": 25, "register_logg": 25, "early_stop": 25, "log_evalu": 25, "print_evalu": 25, "record_evalu": 25, "reset_paramet": 25, "cvbooster": 25, "cv": 25, "109": [25, 105, 128], "_lib": 25, "_load_lib": 25, "111": [25, 128], "112": 25, "99": [25, 44, 59, 61, 128], "lib_path": 25, "ctype": 25, "cdll": 25, "loadlibrari": 25, "lgbm_getlasterror": 25, "restyp": 25, "c_char_p": 25, "cfunctyp": 25, "458": [25, 128], "459": [25, 59, 128], "460": [25, 128], "_dlltype": 25, "461": [25, 128], "462": [25, 128], "__class_getitem__": 25, "classmethod": 25, "genericalia": 25, "use_errno": 25, "use_last_error": 25, "winmod": 25, "380": 25, "381": 25, "382": 25, "_handl": 25, "_dlopen": 25, "_name": 25, "383": 25, "384": [25, 128], "dlopen": 25, "lib_lightgbm": 25, "0x0006": 25, "librari": 25, "libomp": 25, "dylib": 25, "d21a7969": 25, "4567": 25, "3bc7": 25, "94ed": 25, "6a9e83ae9d78": 25, "file": [21, 25, 28, 47, 62, 63, 65, 66, 67, 68, 69, 71, 74, 77, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115, 120, 121, 122, 123, 125, 126, 127, 128, 130], "preboot": 25, "cryptex": 25, "dyld": 25, "cach": 25, "942": [25, 128], "943": [25, 98, 128], "958": 25, "966": [25, 128], "951": 25, "948": 25, "957": 25, "932": [25, 74, 77, 122, 123, 128], "950": 25, "944": 25, "683": [25, 128], "584": [25, 128], "659": 25, "705": [25, 128], "677": [25, 74, 77, 122, 123, 128], "536": [25, 59], "667": 25, "642": [25, 27, 128], "669": 25, "551": [25, 128], "4971": 25, "0231": 25, "0514": 25, "0037": 25, "0943": 25, "4128": 25, "1436": 25, "4714": 25, "bias_r_learn": 25, "variance_r_learn": 25, "010664510462813687": 25, "3201771635462656": 25, "amaz": 25, "significantli": [25, 120, 127], "980": [25, 59], "978": 25, "947": 25, "975": [25, 128], "946": 25, "940": [25, 128], "2566": 25, "0408": 25, "8131": 25, "0906": 25, "5665": 25, "7341": 25, "6459": 25, "272": 25, "bias_dr_learn": 25, "variance_dr_learn": 25, "29436318987432813": 25, "011818461500106": 25, "lp_r": 25, "0353": [25, 128], "2368": 25, "0444": 25, "0884": 25, "6845": 25, "6876": 25, "6223": 25, "85": [25, 61], "bias_lp_r_learn": 25, "variance_lp_r_learn": 25, "2909913487561472": 25, "1822936738050482": 25, "incred": 25, "13686218": 26, "52931381": 26, "10841595": 26, "ate_s_learn": [26, 28], "1453": [26, 101, 104, 105], "dislik": 27, "scope": [27, 32], "onlin": [27, 73, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 106, 107, 108, 109, 114, 115, 116, 117, 118, 128, 129, 130], "cmab": [27, 80, 81, 127, 128], "_env_realcmab": [27, 80, 81, 127, 128], "env": [27, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115, 127, 128], "get_movielen": [27, 128], "theano": [27, 127, 128], "configdefault": [27, 127, 128], "unabl": [27, 127, 128], "cpu": [27, 127, 128], "gpu": [27, 127, 128], "degrad": [27, 127, 128], "flag": [27, 127, 128], "cxx": [27, 127, 128], "empti": [27, 127, 128], "string": [27, 28, 127, 128], "tensor": [27, 127, 128], "bla": [27, 127, 128], "api": [27, 127, 128, 130], "xs": [27, 86, 95, 100, 102, 103, 128], "mean_ri": [27, 128], "standardized_x": [27, 128], "data_ml": [27, 128], "users_index": [27, 128], "movie_gener": [27, 127, 128], "comedi": [27, 79, 80, 82, 83, 85, 86, 87, 106, 107, 127, 128], "thriller": [27, 79, 81, 82, 83, 84, 86, 87, 88, 106, 107, 127, 128], "data_cel": [27, 128], "initi": [27, 44, 47, 49, 58, 59, 61, 63, 65, 66, 67, 71, 72, 73, 77, 81, 82, 85, 105, 108, 115, 117, 121, 125, 126, 127, 128], "concat": [27, 59, 127, 128], "4220": [27, 128], "2355": [27, 128], "14400": [27, 128], "2918": [27, 128], "16752": [27, 128], "2791": [27, 128], "20195": [27, 128], "2797": [27, 128], "21689": [27, 128], "2321": [27, 128], "393463": [27, 128], "3299": [27, 128], "395410": [27, 128], "396058": [27, 128], "397794": [27, 128], "1812": [27, 128], "400719": [27, 128], "3830": [27, 128], "49563": [27, 128], "data_cel_al": [27, 128], "drop": [27, 59, 77, 127, 128], "to_csv": [27, 122, 123, 127, 128], "11057": [27, 128], "25871": [27, 128], "31166": [27, 128], "40383": [27, 128], "303406": 27, "320275": 27, "332011": 27, "382221": 27, "397209": 27, "65": [27, 44, 49, 58, 59, 61, 74, 128], "175": [27, 83, 87, 122, 123, 128], "www": 27, "kaggl": [27, 122, 123, 124], "asjad99": 27, "mimiciii": 27, "access": [27, 122, 123, 124, 130], "center": [27, 122, 123, 124], "databas": [27, 122, 123, 124], "clinic": [27, 32, 78, 107, 122, 123, 124], "61": [27, 58, 59, 61, 122, 123, 124], "532": [27, 122, 123, 124], "admiss": [27, 122, 123, 124], "boston": [27, 122, 123, 124], "teach": [27, 122, 123, 124], "hospit": [27, 122, 123, 124], "demograph": [27, 122, 123, 124], "vital": [27, 89, 90, 91, 122, 123, 124], "lab": [27, 122, 123, 124], "cohort": [27, 122, 123, 124], "sepsi": [27, 122, 123, 124], "meet": [27, 122, 123, 124], "ventil": 27, "particular": [27, 59, 62, 71, 117, 129], "characterist": [27, 129], "physiolog": 27, "whole": [27, 59], "mimic3_sepsis_data": 27, "mimic3_data": [27, 122, 123], "bloc": 27, "icustayid": [27, 120, 122, 123], "charttim": 27, "gender": [27, 79, 87, 107, 127, 128], "elixhaus": 27, "re_admiss": 27, "died_in_hosp": 27, "died_within_48h_of_out_tim": [27, 122, 123, 124], "mortality_90d": 27, "input_tot": 27, "input_4hourli": 27, "output_tot": 27, "output_4hourli": 27, "cumulated_bal": 27, "sofa": [21, 27, 120, 121, 124, 125, 126], "sir": 27, "vaso_input": 27, "iv_input": [27, 120, 121, 122, 123, 125, 126], "7245486000": 27, "17639": 27, "826435": 27, "6527": 27, "0000": 27, "13617": 27, "520": [27, 128], "7090": 27, "884898": 27, "6898241400": 27, "30766": 27, "069028": 27, "383136": 27, "5805732000": 27, "12049": 27, "217303": 27, "976040": 27, "4264269300": 27, "30946": 27, "970000": 27, "1300": 27, "340": 27, "160": [27, 83, 128], "960": [27, 105, 128], "125000": [27, 122, 123], "5707825200": 27, "19793": 27, "588912": 27, "9552": 27, "6830": 27, "540": 27, "2722": 27, "457625": 27, "7214122800": 27, "24524": 27, "747419": 27, "10661": 27, "0483": 27, "5746": 27, "4915": 27, "049099": 27, "glucos": [27, 120, 121, 122, 123, 124, 125, 126], "pao2": [27, 122, 123, 124], "pao2_fio2": [27, 120, 121, 122, 123, 124, 125, 126], "mimic3_data_select": 27, "84": [27, 58, 59, 61], "000000": [27, 122, 123], "168": [27, 122, 123, 128], "59": [27, 47, 61, 122, 123], "444444": 27, "148148": 27, "125": 27, "192": [27, 128], "690": 27, "647482": 27, "727273": 27, "179": 27, "447": [27, 94, 96], "499993": 27, "187": [27, 128], "347": 27, "222222": 27, "4995": 27, "375000": 27, "787683": 27, "005547": 27, "965110": 27, "4996": 27, "333333": 27, "846153": 27, "025000": 27, "4997": 27, "106": [27, 44, 122, 123, 128], "258": [27, 128], "500000": [27, 122], "923": 27, "214286": 27, "402531": 27, "4998": 27, "376": [27, 44], "752": [27, 122, 123], "172130": 27, "4999": 27, "113": [27, 59, 122, 127], "999996": 27, "record": [27, 60, 127, 128], "data_cel_select": [27, 122, 123], "oxygen": [27, 122, 123, 124], "fraction": [27, 122, 123, 124], "deliv": [27, 122, 123, 124], "fio2": [27, 122, 123, 124], "organ": [27, 122, 123, 124], "assess": [27, 60, 122, 123, 124], "dysfunct": [27, 122, 123, 124], "iv": [27, 120, 121, 122, 123, 124, 125, 126], "volumn": [27, 122, 123, 124], "fluid": [27, 122, 123, 124], "administ": [27, 122, 123, 124], "addition": 27, "creat": [27, 74, 77, 122, 123], "aspect": 27, "hte_tlet": 28, "_learner": 28, "ipykernel_35015": 28, "1153805520": 28, "syntaxerror": [21, 28], "eol": 28, "scan": 28, "liter": 28, "3598282": 28, "34648075": 28, "35533324": 28, "ate_t_learn": 28, "3571": 28, "estiamt": 28, "33630057": 29, "31723622": 29, "37261498": 29, "ate_x_learn": 29, "3566": 29, "contrast": [44, 61, 67, 74, 90, 91, 106, 129], "incent": [44, 58, 74, 77], "comparison": [44, 67, 74, 118], "mainli": [44, 58, 65, 66, 74, 77, 79, 83, 87, 95, 100, 102, 107, 118, 127, 129], "convent": [44, 73, 74, 101], "soon": [44, 67, 74], "multinomi": [44, 58, 60, 74, 77, 102, 103, 104, 106, 116], "constrast": [44, 74], "furthermor": [44, 74, 79, 83, 86, 87, 95, 100, 102, 107, 127], "omega": [44, 62, 63, 67, 71, 74], "c_j": 44, "blip": [44, 74], "max_": [44, 59, 66, 72, 73, 74, 77, 80, 81, 84, 85, 93, 95, 96, 97, 98, 100, 101, 102, 103, 104, 115, 117], "psi": [44, 49, 74, 86], "hand": [44, 49, 58, 65, 66, 77, 117], "substitut": [44, 101, 106, 116], "euqat": 44, "appendix": 44, "bootstrap": [44, 58, 61, 68, 74, 77, 121], "utilz": [44, 74], "boostrap": [44, 58, 74], "resampl": [44, 58, 74, 77], "standard": [44, 58, 61, 62, 63, 67, 68, 71, 74, 77, 80, 84, 86, 88, 90, 96, 97, 98, 101, 103, 104, 105, 109, 121, 129], "get_data": [44, 58, 60], "target_col": [44, 58, 59, 60], "binary_trt": [44, 58, 60], "2d": 44, "newaxi": [44, 61], "model_info": [44, 58, 61, 74, 77, 121, 125, 126], "x_prop": [44, 61, 74], "recenc": [44, 58, 59, 60], "x_q0": [44, 61, 74], "x_c": [44, 61, 74], "action_spac": [44, 58, 61, 74, 77, 121, 125, 126], "phi_": 44, "01": [44, 58, 59, 61, 74, 121, 125, 126], "exp": [44, 61, 86], "gamma_": 44, "j0": 44, "j1": 44, "j2": 44, "attributeerror": [44, 58], "ipykernel_35063": 44, "15241541": 44, "true_prop": [44, 61], "n_b": [44, 58, 61, 74, 77, 121], "boots_fit": 44, "98": [44, 61, 128], "_fit": 44, "fitted_model": [44, 58, 61, 74, 77, 121, 125, 126], "_fit_model": 44, "pseudo_y_prev": 44, "get_pseudo_i": 44, "107": [44, 47, 128], "attribut": [44, 58, 120], "opt_d": [44, 58, 61, 74, 77, 121, 125, 126], "recommend_act": [44, 47, 58, 74, 77, 121, 125, 126], "value_count": [44, 58, 77, 121, 125, 126], "v_hat": [44, 58, 61, 74, 77, 121, 125, 126], "predict_valu": [44, 58, 74, 77, 121, 125, 126], "3389e": 44, "0295e": 44, "3272e": 44, "03": [44, 60, 74, 121], "1025e": 44, "7135e": 44, "7582e": 44, "202": [44, 128], "int64": [44, 58, 59, 61, 77, 121, 125, 126], "126": [44, 58, 61, 128], "18615811062617": 44, "005": [44, 127], "71": [44, 61, 122, 128], "mail": [44, 58, 59, 60], "women": [44, 58, 59, 60], "men": [44, 58, 59, 60], "deviaiton": [44, 58, 61, 74, 77], "amai": [44, 58, 61, 74, 77], "reliabl": [21, 44, 58, 61, 74, 77], "fitted_param": [44, 58, 61, 74, 77], "fitted_valu": [44, 58, 61, 74, 77], "value_avg": [44, 58, 61, 74, 77], "value_std": [44, 58, 61, 74, 77], "param": [44, 58, 61, 74, 77], "predict_value_boot": [44, 58, 74, 77], "value_hat": [44, 58, 61, 74, 77], "3843662825924": 44, "989242109807423": 44, "200": [44, 58, 59, 61, 74, 77, 128], "replic": [44, 58, 127], "37488160184647": 44, "std": [44, 58, 61, 74, 77, 127], "37127842161804": 44, "2024261616976": 44, "placehold": [44, 74, 77], "schult": [44, 74], "institut": [44, 74], "640": [44, 74, 128], "seattl": [44, 74], "symposium": [44, 74], "189": [44, 74], "326": [44, 74, 128], "springer": [44, 74, 78, 79, 107], "york": [44, 74], "ny": [44, 59, 74], "murphi": [44, 58, 74, 77], "royal": [44, 74], "331": [44, 74, 78, 128], "355": [44, 74, 128], "liang": [44, 74, 78, 107], "88": [44, 59, 61, 74, 122], "fan": [44, 74], "925": [44, 74], "a_": [32, 44, 60, 62, 63, 65, 66, 67, 71, 72, 73, 74, 76, 77, 82, 85, 86, 87, 88, 93, 95, 97, 98, 100, 101, 106, 107, 108, 115, 116, 117, 129], "publish": [47, 62, 63, 65, 66, 67, 68, 69, 71, 105, 108, 109, 114, 115], "todo": [47, 58, 61, 69, 77, 105, 108, 109, 114, 115, 116, 129], "hide": [47, 62, 63, 65, 66, 67, 68, 69, 71, 105, 108, 109, 114, 115], "getcwd": [47, 62, 63, 65, 66, 67, 68, 69, 71, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115, 127], "chdir": [47, 62, 63, 65, 66, 67, 68, 69, 71, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115, 120, 121, 125, 126, 127], "filenotfounderror": [47, 62, 63, 65, 66, 67, 68, 69, 71, 74, 77, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115, 120, 121, 122, 123, 125, 126, 128], "ipykernel_35073": 47, "2987427551": 47, "errno": [47, 62, 63, 65, 66, 67, 68, 69, 71, 74, 77, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115, 120, 121, 122, 123, 125, 126, 128], "directori": [47, 62, 63, 65, 66, 67, 68, 69, 71, 74, 77, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115, 120, 121, 122, 123, 125, 126, 128], "stai": 47, "close": [47, 62, 67, 71, 74, 77, 84, 117, 122, 123], "share": [47, 63, 67, 71, 86, 87, 95, 100, 102, 117, 130], "foundat": [47, 72, 79, 114, 115], "min": [47, 49, 59, 82, 127, 128], "neq": 47, "classif": [47, 65, 67, 71], "classifi": [47, 60], "impli": [47, 62, 72, 73, 121, 125, 126], "why": 47, "w_i": 47, "shift": [21, 47, 117, 129], "though": 47, "instabl": 47, "svm": 47, "tbd": 47, "owl_simu": 47, "generate_test_cas": [47, 61], "case1": 47, "sigma": [47, 62, 63, 68, 71, 80, 84, 86, 88, 95, 97, 98, 100, 102, 109, 114, 115], "xai": [47, 61], "outcomeweightedlearn": 47, "linearsvc": 47, "svc": 47, "model_select": 47, "gridsearchcv": 47, "cross_val_scor": 47, "clf": 47, "logspac": 47, "param_grid": 47, "dict": [47, 74, 128], "assignment_prob": 47, "your": [47, 59, 130], "notabl": [47, 79], "meantim": [47, 90], "zhao": 47, "yingqi": 47, "499": [47, 79], "1106": 47, "1118": 47, "ying": 47, "regimen": [47, 58, 77], "3776": 47, "3788": 47, "lou": 47, "zhilan": 47, "jun": 47, "shao": 47, "menggang": 47, "506": 47, "516": [47, 128], "stat": 47, "sim": [47, 62, 63, 65, 67, 71, 72, 73, 80, 84, 86, 88, 89, 90, 91, 93, 94, 95, 97, 99, 100, 101, 102, 103, 104, 106, 116, 117, 127], "const": 47, "paid": [49, 129], "domain": [49, 106, 116], "dose": 49, "price": [49, 101, 102, 103, 104], "contin": 49, "discontinu": 49, "i2dr": 49, "unlik": [49, 118], "idr": 49, "ingredi": 49, "multi": [49, 60, 74, 78, 79, 87, 88, 98, 99, 106, 107, 116, 129], "overcom": 49, "limit": [32, 49, 59, 63, 67, 71, 85, 115, 117], "bullet": [49, 63], "densiti": [49, 59, 62, 63, 67, 71, 72], "eqnarrai": [49, 62, 63, 65, 66, 71, 72, 73, 117], "eqn": [49, 62, 63, 65, 67, 68, 71, 72, 73, 86, 94, 95, 100, 102, 106, 116, 117], "almost": [49, 73], "sure": [49, 73], "naiv": 49, "concern": [49, 122, 123, 124], "psi_h": 49, "trade": [49, 67, 73, 83, 89, 90, 91, 96, 107], "decai": [49, 63], "union": [49, 74, 77, 122, 123], "q_": [49, 59, 74, 77], "dnn": 49, "argmin_": [49, 71], "substack": [49, 65, 66], "gamma_n": 49, "argmax_": [49, 86, 88, 89, 90, 91, 101, 102, 103, 104, 105, 107, 109, 114, 115], "foral": [49, 72, 73, 89, 90, 91, 94, 95, 99, 100, 101, 102, 104], "argmax": 49, "value_djq": 49, "warfarin": 49, "djl_opt": 49, "data_gen": 49, "data_gener": 49, "realdatagener": 49, "file_nam": [49, 122, 123], "real_envir": 49, "djl_partit": 49, "djl_agent": 49, "djlearn_opt": 49, "mlp_max_it": 49, "ipykernel_35081": 49, "2744164990": 49, "partit": 49, "033": [49, 104], "067": 49, "167": [49, 77, 128], "333": [49, 128], "minut": 49, "opt_polici": 49, "train_data": 49, "xt": 49, "3333333333333333": 49, "0th": 49, "djl_eval": 49, "pi_evalu": 49, "act_list": 49, "linspac": [49, 127, 128], "x_max": 49, "org_data": 49, "x_min": 49, "val": 49, "act": 49, "append": [49, 58, 61, 127], "regr_mean": 49, "djlearn_ev": 49, "10022123966200729": 49, "4833333333333334": 49, "calibr": 49, "2111": 49, "08885": 49, "kosorok": [49, 58, 77], "august": 49, "assist": 49, "26th": 49, "sigkdd": 49, "mine": 49, "march": 49, "1243": [49, 59], "1251": [49, 128], "earli": [58, 77, 89, 90, 91], "kept": [58, 77], "evolv": [58, 77], "hope": [58, 77], "straightforward": [58, 63, 65, 77, 84, 114, 117], "ol": [21, 58, 120, 125, 126], "r_": [21, 32, 58, 60, 62, 63, 65, 66, 67, 71, 72, 73, 74, 79, 81, 83, 85, 86, 87, 88, 93, 95, 97, 100, 106, 107, 115, 116, 129], "qlearn": [58, 61, 77, 121, 125, 126], "want": [21, 58, 59, 74, 77, 96, 130], "beta_": [58, 88, 121, 125, 126], "regressionresultswrapp": 58, "0x7fb1c84fbbe0": 58, "202956": 58, "239801": 58, "611375": 58, "526133": 58, "152892": 58, "843148": 58, "000549": 58, "007584": 58, "000416": 58, "371": 58, "48792828230138": 58, "0005": [58, 121], "0076": 58, "0004histori": 58, "49": [58, 59, 61, 127, 128], "ipykernel_35107": 58, "3664914869": 58, "regime_sampl": 58, "x_sampl": 58, "a_sampl": 58, "y_sampl": 58, "boot": 58, "v1": 58, "reward_nam": 58, "shold": 58, "set_index": [58, 77, 121, 125, 126], "40675465960642": 58, "115": [58, 94], "95548975939548": 58, "502988081748748": 58, "wang": [58, 59, 77, 78, 98, 99, 106, 107, 116, 120], "zeng": [58, 77], "statistica": [58, 77, 95], "sinica": [58, 77], "901": [58, 77, 128], "sandwich": 58, "project": 58, "ci": [58, 63, 72, 73, 127], "extendour": 59, "satisfactori": 59, "prolong": 59, "platform": 59, "tail": 59, "preval": 59, "heavi": [59, 117, 130], "unstabl": [59, 67], "skew": 59, "surviv": [59, 75, 121, 123, 125, 126], "median": 59, "moodi": 59, "invert": 59, "cummul": 59, "qunatil": 59, "year": [59, 60, 80, 81, 86, 118], "feasibl": [59, 61, 63, 77, 99, 103, 117, 118], "misspecifi": 59, "pretain": 59, "c_i": 59, "rho_": 59, "beta_1": 59, "fine": 59, "grid": 59, "beta_0": 59, "u_": [59, 85, 107, 115], "1n": 59, "0n": 59, "1i": [59, 74, 76, 77], "0i": 59, "proper": 59, "nelder": 59, "mead": 59, "x1": 59, "x2": 59, "x_1": 59, "x_2": 59, "nameerror": [59, 95, 127], "ipykernel_35112": 59, "478063769": 59, "quantile_otr": 59, "quantileotr": 59, "mocondquant_0": 59, "mocondquant_1": 59, "coeffici": [59, 80], "coef_original_scal": 59, "q_est": [59, 61], "dr_qopt": 59, "mopropen": 59, "notbinaryrandom": 59, "termin": [59, 89, 90, 91, 130], "129150": 59, "gradient": [59, 62, 71, 89, 90, 91], "final_simplex": 59, "0401e": 59, "04": [59, 121], "0062e": 59, "3241e": 59, "9385e": 59, "9699e": 59, "9649e": 59, "9516e": 59, "0098e": 59, "7645e": 59, "9178e": 59, "9988e": 59, "6791e": 59, "1197": [59, 128], "119701027689532": 59, "nfev": 59, "nit": 59, "success": 59, "0000e": 59, "3468e": 59, "7854e": 59, "06": [59, 98, 121], "scikit_uplift": 59, "request": 59, "cycler": 59, "kiwisolv": 59, "chardet": 59, "idna": 59, "certifi": 59, "urllib3": 59, "sklift": 59, "return_x_y_t": 59, "history_seg": 59, "zip_cod": [59, 60], "newbi": [59, 60], "surburban": 59, "phone": [59, 60], "350": [59, 83], "329": [59, 128], "08": [59, 121], "rural": [59, 60], "web": [59, 60, 79, 94, 106, 107, 116], "180": 59, "750": [59, 122, 123, 128], "675": [59, 128], "83": [59, 61], "urban": [59, 60], "63995": 59, "63996": 59, "91": [59, 61, 122, 123], "63997": 59, "63998": 59, "552": [59, 128], "multichannel": [59, 60], "63999": 59, "472": 59, "82": [59, 61, 78, 107, 128], "64000": 59, "578": [59, 60, 128], "inplac": [59, 121, 125, 126], "332": [59, 128], "451": [59, 83, 128], "63466": 59, "63552": 59, "63743": 59, "63876": 59, "63883": 59, "segment": 59, "length": [59, 72, 73, 94, 97, 98, 100, 101], "get_dummi": 59, "prefix": [59, 74, 77, 122, 123], "axi": [59, 61, 127, 128, 129], "countri": 59, "anymor": 59, "zip_code_rur": 59, "channel_multichannel": 59, "categor": [59, 88, 129], "integ": [59, 87, 106, 116], "subset": [59, 73, 94, 97, 98, 99, 100, 101, 106, 116, 117, 122, 123, 124], "ntreatment": 59, "na": [59, 105, 108, 109, 114, 115, 120, 121, 125], "zip_code_surburban": [59, 60], "zip_code_urban": [59, 60], "channel_phon": [59, 60], "channel_web": [59, 60], "297": [59, 128], "149": [59, 128], "117": 59, "239": [59, 128], "154": 59, "exceed": 59, "502953": 59, "1895e": 59, "7227e": 59, "4110e": 59, "8883e": 59, "3248e": 59, "6189e": 59, "4630e": 59, "8951e": 59, "8789e": 59, "1688e": 59, "1876e": 59, "7185e": 59, "4111e": 59, "9113e": 59, "3260e": 59, "6160e": 59, "5493e": 59, "8964e": 59, "8975e": 59, "1777e": 59, "1816e": 59, "7171e": 59, "4095e": 59, "8872e": 59, "3259e": 59, "6174e": 59, "7327e": 59, "8731e": 59, "9187e": 59, "1762e": 59, "1882e": 59, "7222e": 59, "4113e": 59, "8993e": 59, "3252e": 59, "6171e": 59, "6759e": 59, "9012e": 59, "9038e": 59, "1803e": 59, "1924e": 59, "7234e": 59, "4088e": 59, "8863e": 59, "3250e": 59, "6158e": 59, "4646e": 59, "9095e": 59, "8690e": 59, "2013e": 59, "1900e": 59, "7211e": 59, "4096e": 59, "8999e": 59, "3246e": 59, "6178e": 59, "3607e": 59, "9148e": 59, "9045e": 59, "1516e": 59, "1880e": 59, "9149e": 59, "6187e": 59, "4407e": 59, "9451e": 59, "8686e": 59, "1759e": 59, "1875e": 59, "7196e": 59, "4083e": 59, "9025e": 59, "6157e": 59, "5918e": 59, "9206e": 59, "8949e": 59, "1680e": 59, "1872e": 59, "7252e": 59, "4081e": 59, "8846e": 59, "3243e": 59, "6168e": 59, "4315e": 59, "8960e": 59, "8996e": 59, "1701e": 59, "1925e": 59, "7192e": 59, "4085e": 59, "8711e": 59, "3264e": 59, "6172e": 59, "5903e": 59, "9406e": 59, "8946e": 59, "1745e": 59, "1889e": 59, "7195e": 59, "4101e": 59, "8838e": 59, "3258e": 59, "6177e": 59, "4543e": 59, "9190e": 59, "8917e": 59, "181": 59, "5661e": 59, "6834e": 59, "bin": 59, "patch": [59, 122], "hist": [59, 122, 123], "facecolor": 59, "blue": 59, "xlabel": [59, 127], "r1": 59, "ylabel": [59, 127], "titl": 59, "histogram": [59, 122, 123], "xlim": 59, "ylim": 59, "face": 59, "_c": 59, "rho": [21, 59, 62, 67, 71], "_j": [59, 63, 86, 87, 88], "qdr_qope": 59, "mixtur": 59, "mdn": 59, "gbdt": 59, "futher": 59, "quanatil": 59, "025941": 59, "121537": 59, "806875": 59, "637488": 59, "363393": 59, "641093": 59, "525509": 59, "381373": 59, "342528": 59, "780761": 59, "quantileop": 59, "qope_est": 59, "927600463556344": 59, "5961404868027": 59, "lan": 59, "ben": 59, "sherwood": 59, "523": [59, 128], "1254": [59, 128], "week": 60, "merchandis": 60, "compris": [60, 129], "nine": 60, "month": 60, "dollar": 60, "past": [60, 73, 82], "suburban": 60, "ident": [60, 80, 84, 86, 95, 97, 100, 102, 103, 105, 108, 109, 114, 115, 120, 127], "flase": 60, "blog": 60, "minethatdata": 60, "2008": [60, 101], "phi1": 61, "phi2": 61, "psi1": 61, "psi2": 61, "random_binari": 61, "450": [61, 77, 128], "a1": [61, 74, 77, 121], "binomi": [61, 95], "60": 61, "a2": [61, 74, 77, 121], "astyp": [61, 127, 128], "int": [21, 61, 127, 128], "mu2": 61, "y_opt": 61, "opt_tru": 61, "optimal_a": 61, "optimal_v": 61, "250": 61, "720": 61, "1108": 61, "575955081366": 61, "estimate_value_boot": 61, "estimated_contrast": [61, 74], "estimated_prop": 61, "prop": 61, "estimate_valu": 61, "ipykernel_35117": 61, "1171830641": 61, "assert": 61, "isinst": [61, 128], "ndarrai": 61, "invalid": [21, 61], "153": [61, 83, 127], "a0": 61, "8969": 61, "9788": 61, "s1a1": 61, "del": 61, "1102": [61, 128], "524126394967": 61, "554474056899934": 61, "379": 61, "334892": 61, "318229": 61, "628596": 61, "027810": 61, "313279": 61, "716134": 61, "729627": 61, "050612": 61, "335": [61, 127, 128], "294202": 61, "253088": 61, "460437": 61, "091607": 61, "664498": 61, "409741": 61, "410791": 61, "090007": 61, "200070": 61, "071281": 61, "474": 61, "508450": 61, "375403": 61, "517774": 61, "092061": 61, "114": [61, 83], "a_est": 61, "c0": 61, "c1": 61, "vhat": 61, "q0": [61, 77, 121, 125, 126], "q1": [61, 77, 121, 125, 126], "opt_v": 61, "rep": [61, 127], "58": 61, "78": [61, 101, 102, 104, 106, 128], "79": [61, 122, 128], "81": 61, "86": 61, "87": 61, "89": 61, "92": 61, "248": 61, "2674": 61, "9966": 61, "718": [61, 128], "432": [61, 128], "9964": 61, "1119": 61, "7158350462053": 61, "366": [61, 105, 127, 128], "5116": 61, "157": 61, "1218": [61, 74, 77, 122, 123, 128], "7812": 61, "0755e": 61, "4913e": 61, "3333e": 61, "8864e": 61, "1197e": 61, "0288e": 61, "5741e": 61, "1112": [61, 77], "2353635304949": 61, "1120": [61, 128], "4987706735005": 61, "10000": [61, 84], "decent": 62, "short": [62, 67, 118], "signific": [32, 62, 120, 122, 123], "fqe": [62, 65, 66, 71], "integr": [62, 71], "bellman": [62, 65, 66, 71, 72, 117], "bellman_q": [62, 65, 71, 72, 117], "r_t": [32, 62, 65, 66, 71, 72, 78, 79, 80, 82, 83, 84, 85, 87, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 115, 116, 117, 127, 129], "s_": [32, 62, 63, 65, 66, 67, 71, 72, 73, 105, 117, 129], "a_t": [32, 62, 63, 65, 66, 71, 72, 73, 74, 78, 79, 80, 81, 82, 83, 84, 85, 87, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 104, 106, 107, 108, 109, 114, 115, 116, 117, 127, 129], "s_t": [32, 62, 63, 65, 66, 67, 71, 72, 73, 117, 129], "wise": [62, 67, 71], "stepi": [62, 67, 71], "stepdr": [62, 71], "i_t": [62, 67, 71, 94], "besid": [62, 65, 66, 67, 71, 117], "recurs": [62, 71, 72], "debia": [62, 63, 71], "reflect": [62, 67, 71, 73, 79, 83, 87, 107, 127], "mi": [62, 63, 71], "sens": [21, 62, 63, 71], "per": [62, 71, 80, 81, 86], "suffer": [62, 71, 122, 123], "huge": [62, 71, 117], "widetild": [62, 67, 71], "equiv": [32, 62, 63, 71, 86, 89, 90, 91, 94], "drl": [62, 63, 71], "margin": [62, 63, 67, 71], "infti": [62, 63, 65, 66, 67, 71, 72], "p_t": [62, 63, 67, 71], "p_b": [62, 67, 71], "recal": [62, 63, 67, 68, 71, 117, 118], "manner": [62, 71], "tini": [62, 63, 71], "textrm": [62, 63, 68, 71, 121, 125, 126], "nt": [21, 62, 63, 68, 71, 120, 125, 126], "sqrt": [62, 71, 81, 85, 105, 115], "weakli": [62, 67, 71], "lower_bound": [62, 68, 71], "tupl": [32, 62, 63, 71, 72, 78, 87, 106, 116, 117, 118, 128], "proven": [62, 71], "speak": [62, 63, 71], "pack": [62, 63, 65, 66, 67, 68, 69, 71, 105, 108, 109, 114, 115], "ipykernel_35122": 62, "2982377520": [62, 65, 66, 69], "eqn_omega": [62, 71], "mini": [62, 71], "solvel": [62, 71], "sup_": [62, 71], "simplifi": [62, 71, 72, 89, 90, 91], "reproduc": [62, 71], "hilbert": [62, 71], "rkh": [62, 71], "outer": [62, 71], "descent": [62, 71, 89, 90, 91, 117], "approxim": [62, 67, 71, 86, 88, 93, 95, 97, 102, 103, 129], "still": [63, 67, 71, 86, 118], "stationari": [63, 71, 72, 73, 78], "slow": 63, "wald": [63, 68, 89, 90], "nomin": 63, "coverag": 63, "weaker": 63, "deeper": 63, "new_drl_term": 63, "a_0": [21, 63, 73, 117], "dirac": 63, "p_": [63, 71, 89, 90, 91], "event": 63, "numer": [63, 65, 66, 79, 83, 87, 106, 107, 116, 127], "debiasterm": 63, "protect": [63, 90], "tr": 63, "tripli": 63, "ci_tr": 63, "z_": [63, 68], "nuisans": 63, "i_1": 63, "t_": 63, "disjoint": 63, "t_2": 63, "counterpart": [63, 67], "arbitrari": 63, "ipykernel_35127": 63, "3779975037": [63, 67, 68, 71], "breakthrough": 63, "spirit": 63, "uncorrel": 63, "hoeffd": 63, "decomposit": 63, "degener": 63, "environ": [65, 78, 79, 83, 87, 89, 90, 91, 106, 107, 116, 122, 123], "conceptu": [65, 67], "contract": [65, 66, 117], "ell": [65, 66, 117], "ipykernel_35132": 65, "fqi": [66, 117], "ipykernel_35141": 66, "vanilla": 67, "reweight": 67, "prod_": 67, "transit": [32, 67, 72, 73, 117, 118], "immedi": [67, 72, 73, 120], "_t": [32, 67, 73, 74, 76, 77, 79, 89, 90, 91, 94, 95, 100, 101, 102, 106, 116, 117], "bias": 67, "exponenti": 67, "issu": [67, 82, 117], "made": [32, 67, 78], "forward": 67, "stationar": [67, 72], "sa": [67, 71], "rather": [67, 73], "understood": 67, "trick": [67, 74], "omit": 67, "ipykernel_35146": 67, "principl": [67, 71], "truncat": [21, 67, 71, 120, 125, 126], "estimand": [67, 71], "neglig": [67, 71, 120], "harri": [67, 71], "ergod": [67, 71], "chain": [67, 71], "eventu": [67, 71], "mix": [67, 71, 100], "ref": [68, 71], "sec": [68, 71], "adopt": [68, 95], "tighter": 68, "concentr": [68, 99], "inequ": 68, "curse_horizon": [68, 71], "explicitli": [68, 90, 91, 95, 100, 102], "kallus2019effici": [68, 71], "eqref": [68, 71], "ci_drl": 68, "upper": [68, 81, 83, 85, 89, 90, 91, 105, 115], "ipykernel_35151": 68, "ipykernel_35156": 69, "ipykernel_35161": 71, "textit": 71, "citep": 71, "jiang2016doubl": 71, "farajtabar2018mor": 71, "uehara2019minimax": 71, "rotnitzky1995semiparametr": 71, "carefulli": [71, 85, 117], "thomas2016data": 71, "our_method": 71, "superior": [71, 86], "gain": 71, "tang2019doubl": 71, "upon": [71, 79, 129], "vspace": 71, "1cm": 71, "worthi": 71, "denomin": 71, "modif": 71, "throw": 71, "awai": [71, 91], "geometr": [71, 95, 101, 102, 104], "2cm": 71, "mean_": 71, "proof": 71, "cramer": 71, "rao": 71, "bickel1993effici": 71, "van2000asymptot": 71, "liu2018break": 71, "ineffici": [71, 84, 85, 88], "mass": 72, "enter": 72, "throughout": [72, 122, 123], "report": 72, "move": [32, 72], "readi": 72, "t_n": [72, 73], "uniformli": [72, 73], "def_valu": [72, 73], "benefit": [72, 73], "_l": [72, 73], "_u": [72, 73], "opo": [72, 73], "repeatedli": [73, 87], "perspectii": 73, "implicitli": 73, "writ": 73, "ground": [73, 117], "literautr": 73, "a_1": [21, 73, 117, 121, 125, 126], "y_t": [32, 73, 117], "had": [73, 117], "w_t": [32, 73, 76, 93, 95, 96, 117], "y_0": [73, 117], "s_1": [73, 117], "cup_": [73, 117], "determinist": [73, 86, 89, 90, 91, 95, 100, 101, 102, 106, 116], "homogen": 73, "central": [73, 78, 83, 107], "ma": [32, 73, 117, 118], "subseteq": [32, 73, 99, 101, 117], "cmia": [32, 73, 117, 118], "w_": [32, 73, 94, 95, 117], "statioanri": 73, "ii": [73, 107, 118], "shall": 73, "wors": 73, "ca": 73, "sra": 73, "s_j": 73, "a_j": 73, "y_j": 73, "markovobserv": 73, "robserv": 73, "interchang": 73, "m_t": 74, "h_": [74, 76, 77, 129], "ti": [74, 76, 77], "till": [74, 76, 77], "q_t": [74, 117], "h_t": 74, "v_": [74, 101, 102, 105], "t0": 74, "omega_": 74, "d_t": 74, "backward": [74, 77], "previous": [74, 80, 81, 82, 84, 85, 86, 88], "eqaut": 74, "accordingli": [74, 80, 84, 85, 96, 98, 104, 109, 114, 115], "m_k": 74, "h_ti": 74, "datamdp_feas": [74, 77], "txt": [74, 77, 128], "sep": [74, 77, 122, 123], "cd4_0": [74, 77], "cd4_6": [74, 77], "cd4_12": [74, 77], "a3": [74, 77, 121], "ipykernel_35176": 74, "3951783812": 74, "_decor": [74, 77, 122, 123], "wrapper": [74, 77, 122, 123], "stacklevel": [74, 77, 122, 123], "310": [74, 77, 122, 123], "311": [74, 77, 83, 122, 123], "312": [74, 77, 83, 122, 123], "313": [74, 77, 83, 122, 123], "io": [74, 77, 122, 123, 130], "parser": [74, 77, 122, 123], "reader": [74, 77, 117, 122, 123], "filepath_or_buff": [74, 77, 122, 123], "delimit": [74, 77, 122, 123], "header": [74, 77, 122, 123], "index_col": [74, 77, 122, 123], "usecol": [74, 77, 122, 123], "squeez": [74, 77, 122, 123], "mangle_dupe_col": [74, 77, 122, 123], "true_valu": [74, 77, 122, 123], "false_valu": [74, 77, 122, 123], "skipinitialspac": [74, 77, 122, 123], "skiprow": [74, 77, 122, 123], "skipfoot": [74, 77, 122, 123], "nrow": [74, 77, 122, 123], "na_valu": [74, 77, 122, 123], "keep_default_na": [74, 77, 122, 123], "na_filt": [74, 77, 122, 123], "skip_blank_lin": [74, 77, 122, 123], "parse_d": [74, 77, 122, 123], "infer_datetime_format": [74, 77, 122, 123], "keep_date_col": [74, 77, 122, 123], "date_pars": [74, 77, 122, 123], "dayfirst": [74, 77, 122, 123], "cache_d": [74, 77, 122, 123], "chunksiz": [74, 77, 122, 123], "compress": [74, 77, 122, 123], "decim": [74, 77, 122, 123], "linetermin": [74, 77, 122, 123], "quotechar": [74, 77, 122, 123], "quot": [74, 77, 122, 123], "doublequot": [74, 77, 122, 123], "escapechar": [74, 77, 122, 123], "comment": [74, 77, 122, 123], "encoding_error": [74, 77, 122, 123], "dialect": [74, 77, 122, 123], "error_bad_lin": [74, 77, 122, 123], "warn_bad_lin": [74, 77, 122, 123], "on_bad_lin": [74, 77, 122, 123], "delim_whitespac": [74, 77, 122, 123], "low_memori": [74, 77, 122, 123], "memory_map": [74, 77, 122, 123], "float_precis": [74, 77, 122, 123], "storage_opt": [74, 77, 122, 123], "676": [74, 77, 122, 123, 128], "kwd": [74, 77, 122, 123], "updat": [74, 77, 80, 81, 82, 84, 85, 86, 88, 90, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115, 117, 122, 123, 129, 130], "kwds_default": [74, 77, 122, 123], "678": [74, 77, 122, 123, 128], "_read": [74, 77, 122, 123], "679": [74, 77, 122, 123, 128], "680": [74, 77, 122, 123, 128], "575": [74, 77, 122, 123], "textfileread": [74, 77, 122, 123], "576": [74, 77, 122, 123, 128], "577": [74, 77, 122, 123, 128], "930": [74, 77, 122, 123, 128], "iohandl": [74, 77, 122, 123], "_engin": [74, 77, 122, 123], "_make_engin": [74, 77, 122, 123], "933": [74, 77, 122, 123, 128], "934": [74, 77, 122, 123, 128], "1214": [74, 77, 122, 123], "str": [74, 77, 122, 123], "pathlik": [74, 77, 122, 123], "readcsvbuff": [74, 77, 122, 123], "byte": [74, 77, 122, 123], "1215": [74, 77, 122, 123], "bool": [74, 77, 122, 123], "1216": [74, 77, 122, 123, 128], "get_handl": [74, 77, 122, 123], "overload": [74, 77, 122, 123], "1217": [74, 77, 122, 123, 128], "path_or_buf": [74, 77, 122, 123], "is_text": [74, 77, 122, 123], "ioarg": [74, 77, 122, 123], "788": [74, 77, 122, 123], "5872e": 74, "0493e": 74, "9347e": 74, "2010e": 74, "568": 74, "1057": [74, 128], "8412e": 74, "2479e": 74, "1162": [74, 128], "4662578531918": 74, "3156513295758": 74, "559003921896037": 74, "245571": 74, "595014": 74, "143433": 74, "440232": 74, "3966192806022": 74, "626837283714682": 74, "omega_t": 74, "w_1": 76, "w_2": 76, "multistag": 77, "d_": 77, "prepar": [77, 106], "reset": 77, "reset_index": [77, 122, 123], "ipykernel_35194": 77, "1696292620": 77, "q2": 77, "898024": 77, "102009": 77, "116478": 77, "002859": 77, "171": [77, 128], "676661": 77, "454044": 77, "288382": 77, "921595": 77, "015938": 77, "553900": 77, "477566": 77, "551396": 77, "334465": 77, "182": [77, 122, 123], "312429": 77, "703112": 77, "550": [77, 128], "1113": [77, 97, 99], "3004201781748": 77, "9663576650953": 77, "6050454629164577": 77, "BE": 77, "THE": 77, "AS": 77, "THAT": 77, "OF": 77, "979": 77, "4518636939481": 77, "0772776227565": 77, "2034780374001155": 77, "accuraci": 77, "financ": [78, 83, 107, 129], "slot": 78, "casino": 78, "gambler": 78, "plai": [78, 79, 83, 85, 87, 89, 90, 91, 99], "earn": 78, "payout": 78, "element": [78, 94], "produc": 78, "divid": [78, 129], "adversari": 78, "pacakg": 78, "four": [78, 79, 86, 87, 95, 98, 100, 102, 120, 127], "distinct": 78, "along": [78, 129], "laern": 78, "durand": [78, 107], "achilleo": [78, 107], "iacovid": [78, 107], "strati": [78, 107], "mitsi": [78, 107], "pineau": [78, 107], "mous": [78, 107], "novo": [78, 107], "carcinogenesi": [78, 107], "healthcar": [78, 83, 87, 107], "zha": [78, 107], "portfolio": [78, 107], "twenti": [78, 107], "fourth": [78, 107], "joint": [78, 107], "xu": [78, 107], "811": [78, 107, 128], "821": [78, 107], "bouneffouf": [78, 79, 83, 107], "bouzeghoub": 78, "gan\u00e7arski": 78, "novemb": [78, 104], "mobil": 78, "awar": 78, "324": [78, 128], "berlin": [78, 79], "heidelberg": [78, 79], "primarili": 79, "profil": 79, "occup": [79, 87, 107, 127], "season": 79, "temperatur": 79, "aid": 79, "mab": [79, 82, 84, 85, 87, 107], "tast": 79, "film": 79, "ultim": [79, 83, 87, 94, 99, 101, 106, 107, 127], "lipschitz": 79, "linucb": [79, 107, 129], "lint": [79, 107, 127, 129], "static": [79, 86, 95, 100, 130], "nonstationari": 79, "1m": [79, 83, 87, 106, 107, 127], "highest": [79, 82, 83, 84, 85, 87, 94, 95, 96, 97, 98, 100, 106, 107, 108, 109, 114, 115, 127], "colleg": [79, 80, 81, 86, 87, 107, 127], "academ": [79, 87, 107, 127], "technician": [79, 87, 107, 127], "writer": 107, "bernoulli": [79, 83, 87, 94, 95, 96, 99, 100, 109, 114], "chu": [79, 81, 107], "reyzin": [79, 81], "schapir": [79, 81, 107], "june": [79, 80, 81, 93, 94, 97, 99, 101, 102, 104, 106, 109], "payoff": [79, 80, 81, 107, 109], "fourteenth": [79, 81], "jmlr": [79, 81], "workshop": [79, 81], "agraw": [79, 80, 101, 102, 103, 104, 105, 106, 107, 109], "goyal": [79, 80, 101, 102, 104, 105, 106, 107, 109], "thompson": [79, 80, 83, 84, 87, 89, 90, 91, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 106, 109, 114, 115, 116, 129], "127": [79, 80, 107, 109, 122, 127], "kveton": [79, 80, 86, 87, 88, 93, 94, 97, 99, 106, 107, 109, 116], "zaheer": [79, 80, 86, 87, 88, 93, 107, 109], "szepesvari": [79, 80, 87, 88, 93, 94, 106, 107, 109, 116], "ghavamzadeh": [79, 80, 87, 93, 107, 109], "boutili": [79, 80, 87, 88, 93, 107, 109], "2066": [79, 80, 93, 107, 109], "2076": [79, 80, 93, 107, 109], "rish": [79, 83, 107], "10040": [79, 83, 107], "slivkin": [79, 83, 107], "286": 79, "hazan": 79, "megiddo": 79, "513": [79, 128], "langford": [79, 89, 90, 91, 107], "april": [79, 94, 96], "articl": [79, 107], "19th": [79, 107], "670": [79, 107], "auer": [79, 82, 85, 107, 108, 115], "cesa": [79, 82, 85, 107, 108, 115], "bianchi": [79, 82, 85, 107, 108, 115], "freund": 79, "nonstochast": 79, "multiarm": [79, 82, 85, 107, 108, 115], "siam": 79, "scalabl": [80, 81, 86, 88, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 106, 129], "ucb": [80, 81, 83, 93, 96, 97, 98, 103, 104, 105, 107, 115], "suscept": [80, 93, 97, 103], "avial": [80, 106, 109, 116], "consdier": [80, 109], "ts": [80, 81, 83, 86, 87, 88, 95, 96, 98, 100, 102, 103, 104, 107, 109, 129], "domian": [80, 84, 109, 114], "thecorrespond": [80, 109], "posterior": [80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 107, 109, 114, 127], "greatest": [80, 84, 96, 109, 114], "distirbut": [80, 84, 96, 98, 104, 109, 114], "rewad": [80, 84, 96, 98, 104, 109, 114], "ipykernel_35207": 80, "836241344": [80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104], "imit": [80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104], "_env": [80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 127], "single_contextual_env": [80, 81, 127], "deviat": [80, 84, 86, 88, 97, 98], "prior_theta_u": [80, 109, 127], "prior_theta_cov": [80, 109, 127], "covarainc": [80, 84], "lints_gaussian_ag": [80, 88, 109], "lints_gaussian": [80, 109, 127], "get_phi": [80, 81, 86, 127], "take_act": [80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115, 127], "get_reward": [80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115, 127], "receive_reward": [80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115, 127], "feature_info": [80, 81, 86, 127], "encount": [32, 80, 81], "old": [80, 81, 86], "retrain_freq": [80, 81, 93, 109], "glm": [80, 81, 107, 129], "lints_glm_ag": 80, "lints_glm": 80, "specifci": 81, "gaussain": 81, "theta_a": [81, 82, 84, 108], "u_a": [81, 85, 115], "theta_": [81, 82, 84, 93, 94, 95, 96, 97, 99, 101, 104, 108, 109, 114, 121], "ipykernel_35212": 81, "exploration_t": 81, "linucb_gaussian_ag": 81, "linucb_gaussian": 81, "linucb_glm_ag": 81, "linucb_glm": 81, "ideal": [32, 82, 117], "domin": [82, 125, 126], "eploit": 82, "epsilon_t": [82, 108], "epsilon_": [82, 86, 88, 107, 108], "pull": [82, 85, 86, 108, 115], "c_a": [82, 85, 108, 115], "decrease_ep": [82, 108], "specfi": [82, 108], "ipykernel_35217": 82, "epsilon_greedi": 82, "_env_realmab": [82, 84, 85], "single_gaussian_env": [82, 84, 85, 108, 109, 114, 115], "emploi": [32, 82, 101, 106], "greedy_ag": [82, 108], "single_bernoulli_env": [82, 84, 85, 109, 114], "fischer": [82, 85, 107, 108, 115], "256": [82, 85, 107, 108, 115, 128], "satisf": [83, 94], "tackl": [83, 107], "preprocess": [83, 87], "tabl": [83, 120, 121, 125, 126], "045": 83, "288": [83, 128], "204": [83, 128], "096": 83, "170": [83, 128], "287": 83, "076": 83, "305": 83, "176": 83, "278": 83, "455": [83, 128], "553": [83, 128], "421": [83, 102, 103, 128], "420": [83, 128], "07272": [83, 107], "Be": 84, "especi": [32, 84, 86, 101, 106, 116, 129], "uncertainti": [84, 85], "dilemma": [84, 107, 109, 114], "greedili": [84, 85, 95, 100, 102, 107, 109, 114, 115, 127], "nearli": [84, 107, 109, 114], "manual": [84, 114, 130], "r_0": 84, "ipykernel_35227": 84, "reward_typ": [84, 114], "u_prior_mean": [84, 98, 114], "u_prior_cov": [84, 114], "ts_gaussian_ag": [84, 114], "prior_phi_beta": [84, 114], "ts_bernoulli_ag": [84, 114], "russo": [84, 106, 107, 114, 115, 116], "kazerouni": [84, 106, 107, 114, 115, 116], "osband": [84, 106, 107, 114, 115, 116], "wen": [84, 93, 94, 97, 99, 106, 107, 114, 115, 116], "tutori": [84, 94, 99, 100, 101, 102, 106, 107, 114, 115, 116, 127, 130], "0203": [84, 107], "lattimor": [84, 107], "szepesv": [84, 107], "ari": [84, 107], "cambridg": [84, 107], "radiu": [85, 107, 115], "2log": 85, "ucb1": [85, 107, 129], "ipykernel_35232": 85, "ucb_ag": [85, 105, 115], "hierarch": [86, 87, 95, 100, 102], "alignedat": [86, 88, 95, 100, 102], "inter": [86, 94, 95, 99, 100, 101, 102, 129], "intra": 86, "y_": [86, 88, 94, 95, 98, 99, 100, 101, 102, 104], "mu_": [86, 87, 88, 121], "hierachical_model": 86, "explicit": [86, 88, 95, 102], "pymc3": [86, 88, 95, 102, 103], "mathmet": 86, "simultan": [86, 95, 100, 102], "ipykernel_35237": 86, "meta_bandit": [86, 88], "mtts_gaussian": 86, "_env_realmultitask": [86, 88], "multitask_env": [86, 88], "episod": [86, 88], "preced": [86, 88], "concurr": 86, "theta_prior_mean": 86, "theta_prior_cov": 86, "delta_cov": 86, "approximate_solut": 86, "finish": [86, 88], "update_freq": [86, 88, 95, 100, 102, 103, 105], "mtts_gaussian_ag": 86, "mtts_agent": 86, "posterior_u": [86, 88, 114], "posterior_cov_diag": [86, 88], "mtts_binari": 86, "phi_beta": [86, 88, 95, 102, 105, 108, 109, 114], "mtts_binary_ag": 86, "posterior_alpha": [86, 88, 114], "posterior_beta": [86, 88, 114], "29655": [86, 87], "29668": [86, 87], "basu": [86, 87, 88], "szepesv\u00e1ri": [86, 87, 88], "28029": [86, 87, 88], "28041": [86, 87, 88], "acceler": 87, "perspect": [87, 96, 98, 117], "arbitrati": 87, "decsion": 87, "lack": [87, 129], "a_k": 87, "r_k": 87, "konobeev": [87, 88], "hsu": [87, 88], "mladenov": [87, 88], "5884": [87, 88], "5893": [87, 88], "7724": 87, "7741": 87, "maintain": [88, 117], "demonstr": 88, "accommod": [88, 97], "ipykernel_35247": 88, "meta_ts_gaussian": 88, "sigma_0": 88, "sigma_q": 88, "meta_ts_gaussian_ag": 88, "meta_ts_ag": 88, "episode_finish": 88, "meta_post": 88, "candid": [88, 93, 95, 96, 97, 98, 100, 102, 103, 104], "candi_mean": 88, "entri": [88, 94], "meta_ts_binari": 88, "meta_ts_binary_ag": 88, "ongo": [89, 90, 91], "econom": [89, 90, 91, 129], "crucial": [89, 90, 91], "instruct": [89, 90, 91], "exposit": [89, 90, 91], "dud\u00edk": [89, 90, 91], "suvta": [89, 90, 91], "dr_est": [89, 90, 91], "2110": [89, 90, 91], "15501": [89, 90, 91], "240": [89, 90, 91, 128], "255": [89, 90, 91], "534": [89, 90, 91], "708": [89, 90, 91, 128], "719": [89, 90, 91, 128], "1103": [89, 90, 91, 128], "4601": [89, 90, 91], "dream": 90, "architectur": [90, 118], "tripl": 90, "x_t": 90, "buffer": [90, 117], "pi_b": 90, "pi_t": 90, "histor": [90, 91, 118], "kappa_t": [90, 91], "pr": [90, 91], "kappa": [90, 91], "overlap": 91, "zong": [93, 94], "laplac": 93, "mid": [93, 95, 96, 97, 98, 100, 101, 102, 103, 104, 107, 115], "inroduct": [93, 95, 96, 97, 98, 100, 102, 103, 104], "cascad": [93, 95, 96, 106, 116, 129], "ipykernel_35267": 93, "structured_bandit": [93, 95, 96, 97, 98, 100, 102, 103, 104], "_env_realcascad": [93, 95, 96], "cascading_env": [93, 95, 96], "itm": [93, 95, 96, 97, 98, 100, 102, 103, 104], "considerd": [93, 97, 100], "lints_ag": [93, 97, 103], "fisrt": [93, 97, 100], "restatur": [93, 95, 96, 97, 98, 100, 102, 103, 104], "1301": 93, "2087": 93, "1123": [93, 128], "unfortun": [93, 95, 96], "ni": [93, 94], "sung": [93, 94], "ke": [93, 94], "1603": [93, 94, 127], "05359": [93, 94], "sort": [94, 128], "slate": [94, 99, 101, 104, 105], "f_r": [94, 95, 100, 102, 106, 116], "bottom": [94, 106], "she": 94, "latent": 94, "e_": [94, 95], "visibl": 94, "theta_i": [94, 95, 96, 98, 99, 100, 101, 102, 103, 104], "mathmat": 94, "model_cascad": [94, 95], "permut": 94, "ts_cascad": 94, "cascadelint": [94, 129], "mtss_cascad": 94, "chuklin": 94, "rijk": 94, "synthesi": 94, "lectur": 94, "retriev": [94, 106, 127], "2202": [94, 95, 99, 100, 101, 102, 106], "13227": [94, 95, 99, 100, 101, 102, 106], "ashkan": [94, 97, 99, 106, 116], "767": [94, 106, 116], "776": [94, 104, 106, 116, 128], "cheung": [94, 96], "tan": [94, 96], "zhong": [94, 96], "22nd": [94, 96], "438": [94, 96], "mtss": [95, 100, 102, 129], "general_hierach": [95, 100, 102], "mtt": [95, 100, 102], "subsum": [95, 100, 102, 106, 116], "full": [95, 100, 129], "enjoi": [95, 102], "conjug": [95, 96, 102, 104, 114], "facilit": [95, 100, 102], "deploy": [95, 100, 102], "ipykernel_35280": 95, "gamma_prior_mean": [95, 100, 102, 103], "gamma_prior_cov": [95, 100, 102, 103], "coverainc": [95, 102, 103], "n_init": [95, 102, 103, 105], "draw": [95, 102, 103], "mtss_agent": [95, 100, 102], "tmp": 95, "ipykernel_540529": 95, "4210367235": 95, "2189": 95, "1610": 95, "1206": 95, "forcina": 95, "franconi": 95, "rivista": 95, "di": [95, 120, 122, 123, 125, 126], "applicata": 95, "salvati": [95, 102], "wiecki": [95, 102], "fonnesbeck": [95, 102], "peerj": [95, 102], "e55": [95, 102], "doi": [95, 102], "7717": [95, 102], "ipykernel_35285": 96, "u_prior_alpha": [96, 104], "u_prior_beta": [96, 104], "ts_agent": [96, 98, 104], "2690": 96, "reach": 97, "kalman": 97, "filter": 97, "exact": 97, "Of": [97, 98, 100], "cours": [97, 98, 100], "welcom": [97, 98, 100], "ipykernel_35290": 97, "combinatorial_semi": [97, 98, 100], "_env_realcomb": [97, 98, 100], "combsemi_env": [97, 98, 100], "prior_gamma_mu": 97, "prior_gamma_cov": [97, 100], "lints_semi": 97, "tot_r": [97, 98, 100], "480": [97, 128], "1895": 97, "1700": 97, "2219": 97, "2807": 97, "1593": 97, "2784": 97, "172": [97, 122, 123, 128], "2831": 97, "1523": [97, 100], "8214": 97, "2055": 97, "408": 97, "0487": 97, "8551": 97, "1778": [97, 128], "595": 97, "9068": 97, "6194": 97, "9444": [97, 100], "3574891974648375": 97, "1122": [97, 99, 128], "began": 98, "famili": 98, "sub": [98, 117], "bay": [98, 100], "ipykernel_35295": 98, "u_prior_cov_diag": 98, "diagon": 98, "ts_semi": 98, "1054": 98, "2060": 98, "494": [98, 128], "1488": 98, "1351": 98, "898": [98, 128], "1114": [98, 100], "8094": 98, "8462": 98, "8306": 98, "6929": 98, "6706": 98, "6444": 98, "5902": 98, "5764": [98, 100], "0607550383245": 98, "yuan": [98, 99, 106, 116], "februari": 98, "151": [98, 99, 106, 116, 127], "159": [98, 99, 106, 116, 127], "perrault": 98, "boursier": 98, "valko": 98, "perchet": 98, "5429": 98, "5440": 98, "alloc": [99, 106, 116], "scenario": [32, 99, 129], "pali": 99, "sigma_2": [99, 100], "combt": [99, 129], "comblint": [99, 129], "mtss_comb": 99, "sankararaman": 99, "5114": 99, "5122": 99, "lmm": 100, "sigma_1": 100, "ipykernel_35305": 100, "prior_gamma_mean": 100, "mtss_semi": 100, "686": [100, 128], "2132": 100, "689": 100, "1645": 100, "1733": 100, "2671": 100, "1611": 100, "2099": 100, "1668": 100, "9462": 100, "4307": 100, "9867": 100, "846": [100, 128], "504": 100, "3613": 100, "6928": 100, "45535406270607": 100, "pari": 100, "golrezaei": 100, "ssrn": 100, "3651397": 100, "mnl": [101, 102, 103, 104, 105, 106, 129], "arguabl": 101, "eta_0": 101, "eta_1": 101, "eta_": [101, 102, 103, 104, 105], "eta_k": 101, "revenu": [101, 102, 103, 104], "convention": 101, "v_i": 101, "mnldist": 101, "cup": 101, "v_0": 101, "intract": [101, 104], "appear": [101, 102, 103, 104, 105], "matter": 101, "ts_mnl": 101, "ts_contextual_mnl": 101, "mtss_mnl": 101, "pentico": 101, "european": 101, "190": [101, 122, 123], "295": [101, 128], "luce": [101, 116], "courier": [101, 116], "corpor": [101, 116], "avadhanula": [101, 102, 103, 104, 105, 106], "zeevi": [101, 102, 104, 105, 106], "oh": [101, 102, 103], "iyengar": [101, 102, 103], "1485": [101, 104, 105], "ou": [101, 103], "1805": [101, 103], "02971": [101, 103], "concret": 102, "eqn1": 102, "logit": [102, 103, 104, 106, 116], "ipykernel_35315": 102, "_env_realmnl": [102, 103, 104], "mnl_env": [102, 103, 104, 105], "same_reward": [102, 103, 104, 105], "clip": [102, 104], "275": 102, "448": [102, 103, 128], "836": [102, 103, 128], "9493188224156814": 102, "id": [102, 103, 104], "framwork": 103, "realtionship": 103, "ipykernel_35320": 103, "mnl_ts_contextu": 103, "298": [103, 128], "9729194890231303": 103, "tulabandhula": 103, "tractabl": [103, 104], "14033": 103, "multinomila": 104, "nice": [104, 114], "ipykernel_35325": 104, "ts_mnl_beta": 104, "mnl_t": 104, "864": [104, 128], "394": [104, 122, 123, 128], "911": [104, 128], "430": [104, 122, 123, 128], "03330462654669619": 104, "dong": 104, "switch": [104, 130], "2607": 104, "2615": 104, "48log": 105, "longleaf": [105, 108, 109, 114, 115, 120, 121, 125], "home": [105, 108, 109, 114, 115], "lge": [105, 108, 109, 114, 115], "ipykernel_35330": 105, "3636065689": [105, 108, 109, 114, 115], "_env_mnl": 105, "20000": 105, "update_freq_linear": 105, "with_intercept": [105, 108, 109, 114, 115], "x_mu": [105, 108, 109, 114, 115], "x_sigma": [105, 108, 109, 114, 115], "sigma_gamma": [105, 108, 109, 114, 115], "mu_gamma": 105, "exp_r": 105, "519": [105, 128], "906": [105, 128], "main_raw_model": [106, 116], "cardin": [106, 116], "exclud": [106, 116], "appeal": 106, "brows": 106, "02038": [106, 116], "2015a": [106, 116], "strike": 107, "unfamiliar": 107, "iii": 107, "guaasian": [107, 129], "glmt": 107, "guassian": [107, 129], "2071": 107, "2080": 107, "ipykernel_35348": 108, "sigma_theta": [108, 109, 114, 115], "mu_theta": [108, 109, 114, 115], "specifii": 108, "cnt": [108, 109], "rewrit": 109, "ipykernel_35353": 109, "lints_bernoulli_ag": 109, "lints_bernoulli": 109, "breward": 114, "ipykernel_35358": 114, "4375": 114, "ipykernel_35363": 115, "rs": 115, "1249": [115, 128], "cook": 116, "vast": 117, "disucss": 117, "hear": 117, "materi": 117, "recap": 117, "appraoch": 117, "mont": 117, "carlo": 117, "td": 117, "wait": 117, "paradigm": [32, 117, 118], "trasit": 117, "schema": 117, "trpo": 117, "ppo": 117, "simplist": 117, "descient": 117, "around": [117, 122, 123], "fortun": [117, 118], "bigtriangledown_": 117, "abil": 117, "dqn": 117, "replai": 117, "scratch": 117, "Such": 117, "q_0": 117, "effiic": 117, "a2c": 117, "sac": 117, "a3c": 117, "pomdp_comparison": 118, "valuabl": 118, "lag": [118, 122, 123], "infeas": 118, "horiozn": 118, "belief": 118, "within": [120, 122, 123, 125, 126, 130], "48h": [120, 122, 123, 125, 126], "multipli": 120, "dierct": 120, "dde": 120, "dme": 120, "1137": 128, "0273": [], "0187": [], "0067": [], "0247": [], "0153": [], "0182": [], "0119": [], "1390": [], "0297": [], "dive": 120, "insignific": 120, "conclud": 120, "mrl": [], "evaluator_linear": [], "problearn": [], "pmlearner": [], "rewardlearn": [], "palearn": [], "ratiolearn": [], "ratiolinearlearn": [], "qlearner_linear": [], "qlearner": [], "mrl_df": 120, "mimic3_mrl_df_v2": 120, "1006": [120, 122, 123, 128], "ipykernel_35383": [], "1809877625": [], "mimic3_mrl_data_dict_v2": 120, "mimic3_mrl": 120, "control_polici": [21, 120, 125, 126], "dim_stat": [21, 120, 121, 125, 126], "get_a": [21, 120, 125, 126], "action_valu": [21, 120, 125, 126], "target_polici": [21, 120, 125, 126], "prob_arr": [21, 120, 125, 126], "valueerror": [21, 120, 125, 126], "expectation_mcmc_it": [21, 120, 125, 126], "expectation_mcmc_iter_q3": 120, "expectation_mcmc_iter_q_diff": 120, "problearner_paramet": [21, 120, 125, 126], "splitter": [21, 120, 125, 126], "dim_medi": [21, 120, 121, 125, 126], "ratio_ndim": 120, "t_depend_target": [], "t_dependent_q": 120, "scaler": 120, "est_obj1": [], "l2penalti": 120, "q_set": 120, "product_tensor": 120, "include_intercept": 120, "min_l": 120, "estimate_de_me_s": [], "est_value1": [], "est_demes": [], "se_value1": [], "se_demes": [], "spline": 120, "dimems": 120, "ide_mr": [], "ime_mr": [], "dde_mr": [], "dme_mr": [], "se": [], "se_ide_mr": [], "se_ime_mr": [], "se_dde_mr": [], "se_dme_mr": [], "se_at": [], "11369785727090427": [], "018734623459877756": [], "02474802766411448": [], "018187656614314426": [], "13899285178058207": [], "02730353979464337": [], "006745477470886179": [], "015252674867721994": [], "011899325617065859": [], "029707778327035382": [], "164216732557529": [], "7773606154252737": [], "6225368913151579": [], "528461124572465": [], "6786686722410495": [], "wu": 120, "2023": 120, "2301": 120, "13348": 120, "mimic3_mdtr_data_dict_3stage_v2": 121, "mimic3_mdtr": 121, "mdtr_data": 121, "mimic3_mdtr_3stage_v2": 121, "dtr_data": [], "mimic3_dtr_3stage_v2": [], "icustayid_1": [], "glucose_1": 121, "pao2_fio2_1": 121, "iv_input_1": 121, "sofa_1": 121, "glucose_2": 121, "pao2_fio2_2": 121, "iv_input_2": 121, "sofa_2": 121, "glucose_3": 121, "pao2_fio2_3": 121, "iv_input_3": 121, "sofa_3": 121, "died_within_48h": [120, 121, 125, 126], "31005": [], "833333": [], "666667": [122, 123], "364": 128, "200000": [122, 123], "439": [], "310339": [], "10989": [], "163": 128, "714286": [], "164": 128, "174": [122, 123, 128], "4132": [122, 123], "400000": 123, "600000": [122, 123], "388889": [], "37528": [], "277": [], "777778": [], "257": 128, "857143": [], "191": [], "935482": [], "86428": [], "nde": [121, 125, 126], "274": [], "390": 128, "220": [], "054": [], "567": [], "mediated_qlearn": 121, "mediatedqlearn": 121, "regime_control": 121, "regime_target": 121, "est_nde_ni": 121, "ipykernel_35388": [], "2533832358": [], "v_target": [], "v_control": [], "647057": [], "761217": [], "boots_result": [], "mean_effect": [], "se_effect": [], "_predict_value_boot": 121, "2201": [], "2744": [], "0543": [], "2949": [], "3891": [], "q_1": 121, "q_2": 121, "a_2": 121, "_2": 121, "q_3": 121, "a_3": 121, "07": 121, "_3": 121, "polic": [121, 125, 126], "treatement": [121, 125, 126], "policy1": [121, 125, 126], "7982": [], "policy2": [121, 125, 126], "6492": [], "1490": [], "mortal": [121, 122, 123, 124, 125, 126], "renam": [121, 125, 126], "s1_1": 121, "s1_2": 121, "s1_3": 121, "s3_1": 121, "s3_2": 121, "s3_3": 121, "s4_1": 121, "s4_2": 121, "s4_3": 121, "mimic3_clip": [121, 125, 126], "7981963882433065": [], "649210729138117": [], "0002": [120, 121], "0012": [121, 125], "1101": 128, "00002": [], "0141": [], "1442": [], "0009": [], "0016": [], "0228": [], "4136": [], "appl": [121, 125, 126], "9274": [], "summari": [121, 125, 126, 129], "9274371195908725": [], "privaci": [122, 123, 124], "he": [122, 123, 124], "hour": [122, 123, 124], "diagram": [122, 123], "load_ext": [122, 123], "autoreload": [122, 123], "randn": [122, 123], "rseed": [122, 123], "npseed": [122, 123], "math": [122, 123], "datetim": [122, 123], "multiprocess": [122, 123], "pool": [122, 123], "functool": [122, 123], "omp_num_thread": [122, 123], "subset_rl_data_final_cont": [122, 123], "ipykernel_35394": 122, "2950252550": [122, 123], "mimic3_bas": [122, 123], "8e9c55e7e19c": 122, "000": [122, 123], "173913": [122, 123], "428571": 122, "148": [122, 123, 128], "758782": [122, 123], "140": [122, 123, 128], "mimic_fin": [122, 123], "mimic3_multi_stag": [122, 123], "wb": [122, 123], "dump": [122, 123], "748": [122, 123, 128], "98685": [122, 123], "142857": [122, 123], "749": [122, 123, 128], "751": [122, 123, 128], "545455": [122, 123], "818182": [122, 123], "030303": [122, 123], "118": 122, "196": [122, 123, 128], "692": [122, 123, 128], "lag_k": [122, 123], "new_sofa": [122, 123], "mimic3_sampl": [122, 123], "groupbi": [122, 123], "6e125fd2096c": 122, "mimic3_single_stag": [122, 123, 125, 126], "152": [122, 123, 128], "081590": [122, 123], "800000": [122, 123], "1204": [122, 123], "794872": [122, 123], "782051": 122, "668956": [122, 123], "153846": [122, 123], "364286": [122, 123], "956461": 122, "252": [122, 123], "883864": [122, 123], "4201": [122, 123], "580087": [122, 123], "083333": 122, "539": [122, 123], "065657": [122, 123], "363636": [122, 123], "5170": [122, 123], "525000": [122, 123], "147": 122, "350198": 122, "616727": [122, 123], "437500": [122, 123], "6504": [122, 123], "081169": [122, 123], "836364": 122, "423": [122, 123, 128], "090909": [122, 123], "mimic3_data_fin": [122, 123], "smaple_demo": [122, 123], "est_mt": [122, 123], "w_threshold": [122, 123], "refit": [122, 123], "demo_res_net": [122, 123], "topo_list": [122, 123], "topological_sort": [122, 123], "buttom": [122, 123], "administrait": [122, 123], "35384615": [122, 123], "70769231": [122, 123], "06153846": [122, 123], "41538462": [122, 123], "76923077": [122, 123], "12307692": [122, 123], "47692308": [122, 123], "83076923": [122, 123], "18461538": [122, 123], "53846154": [122, 123], "gap": [122, 123], "intak": [122, 123], "death": [122, 123], "administr": [122, 123], "gradientboostingclassifi": [122, 123], "42850795": 122, "04122985": 122, "37054069": 122, "0055272": 122, "10384686": 122, "01457029": 122, "16909439": 122, "28221447": 122, "05764574": 122, "008193": 122, "30211856": 122, "0551675": 122, "01006845": 122, "09689565": 122, "10600407": 122, "18238777": 122, "44978522": 122, "19716563": 122, "289073": 122, "03827421": 122, "22619666": 122, "1875545": 122, "23778146": 122, "20841167": 122, "73958005": 122, "11909299": 122, "09661241": 122, "15624675": 122, "3466977": 122, "42682439": 122, "353852": 122, "12244475": 122, "53581201": 122, "38763738": 122, "00624024": 122, "02708992": 122, "08227609": 122, "09644005": 122, "19550407": 122, "30207966": 122, "03525717": 122, "34339108": 122, "30668368": 122, "11740263": 122, "23538089": 122, "41147115": 122, "46029296": 122, "10346963": 122, "51161134": 122, "04498817": 122, "18302802": 122, "21907476": 122, "54002382": 122, "23518752": 122, "06635588": 122, "83090637": 122, "3999141": 122, "health": [32, 122, 123], "counterintuit": [122, 123], "remind": [122, 123], "pai": [32, 122, 123], "20399937380851768": 122, "49003107": 122, "50057977": 122, "20914573": 122, "66345884": 122, "23977303": 122, "0794276": 122, "34455499": 122, "36109094": 122, "19848057": 122, "58006391": 122, "11359767": 122, "23537098": 122, "18899855": 122, "64967052": 122, "63723815": 122, "05042186": 122, "26366224": 122, "00872736": 122, "32914701": 122, "51474347": 122, "41667122": 122, "54158338": 122, "71321121": 122, "26489405": 122, "0774718": 122, "52229178": 122, "61766863": 122, "57557176": 122, "94774448": 122, "55186488": 122, "29666119": 122, "35960446": 122, "20136832": 122, "77408578": 122, "19227108": 122, "11463203": 122, "35932623": 122, "29545405": 122, "86337085": 122, "95171379": 122, "61272862": 122, "00475441": 122, "06064992": 122, "64206127": 122, "75432718": 122, "20535944": 122, "37009124": 122, "35431129": 122, "78816905": 122, "76940612": 122, "68175408": 122, "74628053": 122, "10881984": 122, "17531085": 122, "07151351": 122, "82140618": 122, "01038676": 122, "086428186158087": 122, "086": 122, "ipykernel_35403": 123, "ipykernel_26090": 123, "541810081": 123, "barcontain": 123, "artist": 123, "post": 123, "2077792220": 123, "692308": 123, "636364": 123, "625000": 123, "45322357": 123, "12551825": 123, "31095315": 123, "06658004": 123, "14936954": 123, "13404695": 123, "32144405": 123, "41540906": 123, "11657287": 123, "0605553": 123, "41204992": 123, "350003": 123, "07587157": 123, "1937542": 123, "29406602": 123, "27231197": 123, "44362365": 123, "08949383": 123, "4349184": 123, "13355717": 123, "16845723": 123, "0938565": 123, "30817118": 123, "06978495": 123, "50736663": 123, "20295236": 123, "17239035": 123, "27745005": 123, "2927717": 123, "31615833": 123, "3621005": 123, "19816815": 123, "29745249": 123, "31014128": 123, "00821821": 123, "19483265": 123, "16912685": 123, "20077837": 123, "37305844": 123, "24538905": 123, "20552501": 123, "38095327": 123, "38948743": 123, "2780394": 123, "11502808": 123, "45806054": 123, "29489358": 123, "18854476": 123, "06531642": 123, "22022294": 123, "22806464": 123, "31916684": 123, "05725299": 123, "37429873": 123, "16776177": 123, "30377136": 123, "44658451": 123, "harm": 123, "21392525739350676": 123, "33471421": 123, "58750923": 123, "69769602": 123, "50468707": 123, "04119141": 123, "08032529": 123, "24677671": 123, "46879497": 123, "14228685": 123, "40913012": 123, "26967209": 123, "10424795": 123, "15469547": 123, "86680554": 123, "01699509": 123, "50534554": 123, "50120394": 123, "0832772": 123, "4053538": 123, "61938348": 123, "63167011": 123, "53840976": 123, "10602297": 123, "04338229": 123, "18159866": 123, "77996324": 123, "7988097": 123, "94550731": 123, "28227784": 123, "9895861": 123, "34582444": 123, "63707457": 123, "67745798": 123, "16396444": 123, "3173255": 123, "41720785": 123, "66927895": 123, "09861153": 123, "9408872": 123, "21402004": 123, "85013445": 123, "61804279": 123, "67352783": 123, "06219661": 123, "78217875": 123, "87809129": 123, "81120382": 123, "61344813": 123, "6384825": 123, "26478542": 123, "95845848": 123, "14744284": 123, "86349984": 123, "74704598": 123, "2168899": 123, "97526792": 123, "68596023": 123, "4460136626503029": 123, "446": 123, "single_data": [21, 125, 126], "single_dataset": [21, 125, 126], "3465": [], "0097": [], "3368": [], "4585": [], "4584": [], "3643": [], "0482": [], "4126": [], "evaluator_baselin": [], "ipykernel_35415": [], "1751400768": [], "9050": [], "5085": [], "3965": [], "9050002023104254": [], "5085214515408744": [], "0014": [], "0015": [], "greenland": [125, 126], "exchang": [125, 126], "epidemiolog": [125, 126, 129], "155": [125, 126, 128], "1992": [125, 126, 128], "workflow": 129, "depict": 129, "merit": 129, "downsid": 129, "miscellan": 129, "subtract": 129, "wish": 129, "ccc": 129, "hline": 129, "vdot": 129, "hdashlin": 129, "ct": 129, "bs": 129, "unrel": 129, "sc": 129, "correpond": 129, "conjunct": 129, "bowl": 129, "quatil": 129, "otr": 129, "jump": 129, "comb": 129, "practition": 130, "handbook": 130, "complement": 130, "unifi": 130, "desktop": 130, "branch": 130, "visiabl": 130, "_build": 130, "commit": 130, "push": 130, "cd": 130, "password": 130, "gh": 130, "reinstal": 130, "fail": 130, "credenti": 130, "token": 130, "cname": 130, "substanti": 32, "easier": 32, "TO": [], "cpl": 32, "paradigm2": [], "talk": 32, "influnc": 21, "treamtent": 21, "borrow": 21, "necess": 21, "birth": 21, "pill": 21, "incid": 21, "thrombosi": 21, "pregnanc": 21, "marit": 21, "iid": 21, "treament": 21, "m_a": 21, "m_": 21, "suffic": 21, "p_a": 21, "movielens_cel_md": 21, "ipykernel_87950": [], "3397862122": 21, "mediation_analysi": [21, 120, 121, 125, 126], "me_singl": [21, 125, 126], "direct_est": [21, 125, 126], "r_model": [21, 120, 125, 126], "nature_decomp": [21, 120, 125, 126], "estimate_de_m": [21, 120, 125, 126], "est_d": [21, 125, 126], "est_m": [21, 125, 126], "est_t": [21, 125, 126], "ipw_est": [21, 125, 126], "robust_est": [21, 120, 125, 126], "mimic3": [120, 121, 125, 126], "ipykernel_87965": [], "3787818056": [], "ind": 120, "inm": 120, "dnde": 120, "nddnme": 120, "nide": [], "nime": [], "ndde": [], "ndme": [], "0341": [], "0046": [], "0018": [], "0040": [], "0060": [], "1441": [], "0339": [], "dnme": 120, "me_mdp": 120, "rhel8": [120, 121, 125], "anaconda": [120, 121, 125], "ood": [120, 121, 125], "est_id": 120, "1452771259348552": [], "004637499340581467": [], "003993095022944491": [], "0005317328373979431": [], "14410098877982028": [], "ide_s": 120, "ime_s": 120, "dde_s": 120, "dme_s": 120, "te_s": [120, 121], "03413229284322258": [], "0018118276672658687": [], "0059963999590195915": [], "0017995551161793478": [], "03387985782346984": [], "ipykernel_87970": [], "2696480475": [], "0181": 120, "0059": 120, "0061": 120, "0021": 120, "0049": 120, "0028": 120, "0011": 120, "0171": 120, "0058": 120, "018100205548084617": 120, "006066387157097036": 120, "00486632802292234": 120, "0001815880750934009": 120, "017081734489003318": 120, "00586890111356167": 120, "002110278954333155": 120, "002770561709397491": 120, "0010678186846428818": 120, "005821662648170317": 120, "ipykernel_87975": [], "2395763461": [], "parenthesi": 121, "311516": [], "425676": [], "114161": [], "nie_s": 121, "nde_s": 121, "ipykernel_87980": [], "3056442794": [], "213": 121, "695": 121, "156": 121, "647": [121, 128], "057": 121, "284": 121, "155758": 121, "212838": 121, "05708": 121, "6474": [121, 128], "6946": 121, "2835": 121, "8991": 121, "8246": 121, "0745": 121, "899098194121663": 121, "824605364568914": 121, "0001": 121, "0551": 121, "00001": 121, "0070": 121, "0721": 121, "0008": [121, 126], "0114": 121, "2068": 121, "9637": 121, "9637185597953722": 121, "ipykernel_87985": [], "2964169404": [], "3425": [], "0057": [], "3652": [], "0474": [], "34252946570098064": [], "005711302763402198": [], "33681816293757844": [], "45848128672516364": [], "36522141159831284": [], "0473586513222677": [], "4125800629205805": [], "ipykernel_87990": [], "3676611072": 126, "1713": 126, "0029": 126, "1684": 126, "2380": 126, "1826": 126, "0237": 126, "2063": [126, 128], "1712647328504904": 126, "002855651381701156": 126, "16840908146878925": 126, "23801345046785374": 126, "1826107057991566": 126, "02367932566113366": 126, "20629003146029024": 126, "9525": 126, "7543": 126, "1982": 126, "9525001011551312": 126, "7542607257704607": 126, "0007": 126, "5530": [126, 128], "ipykernel_88047": [], "ipykernel_88083": [], "restrict": 32, "cima": 32, "effort": 32, "instrument": 32, "proxi": 32, "trim": 32, "strict": 32, "greater": 32, "depth": 32, "ipykernel_90659": 126, "ipykernel_91590": 21, "ipykernel_31946": 120, "1205981465": 120, "ipykernel_31951": 121, "1615765813": 121, "ipykernel_31957": 125, "1747230348": 125, "2133": 125, "0030": 125, "2104": 125, "2332": 125, "2276": 125, "0164": 125, "2440": 125, "21336626681098006": 125, "0029629796887433255": 125, "21040328712223674": 125, "23320671819000469": 125, "227628354568072": 125, "016385483205159614": 125, "24401383777323163": 125, "9999": 125, "7646": 125, "2353": 125, "9999999999999996": 125, "7645616565182293": 125, "0004": 125, "5510": 125, "iteract": 127, "logged_data": 127, "get_logged_dat": 127, "685706": 127, "2042": 127, "499683": 127, "2424": 127, "694860": 127, "330": [127, 128], "207691": 127, "169": [127, 128], "3671": 127, "425839": 127, "213638": 127, "4140": [127, 128], "242271": 127, "435": [127, 128], "717322": 127, "4411": [127, 128], "910": [127, 128], "345927": 127, "870113": 127, "1226": [127, 128], "406": 127, "data_cel_sampl": [127, 128], "1286": [127, 128], "models_cel": [127, 128], "thev": [127, 128], "age_rang": [127, 128], "itertool": [127, 128], "1307": [127, 128], "1308": [127, 128], "1309": [127, 128], "1310": [127, 128], "1311": [127, 128], "1312": [127, 128], "1224": [127, 128], "0439": 127, "7664": 127, "5822": 127, "6663": 127, "6364": 127, "5765": 127, "2059": 127, "9103": 127, "1657": 127, "2833": 127, "1036": [127, 128], "0664": 127, "2327": 127, "3366": 127, "5529": 127, "1292": [127, 128], "5834": 127, "7176": 127, "7408": 127, "1338": 127, "1514": 127, "result_cel": [127, 128], "ipykernel_31962": 127, "1546985469": 127, "122379": 127, "576471": 127, "066448": 127, "583382": 127, "133766": 127, "043862": 127, "205939": 127, "232727": 127, "766441": 127, "910281": 127, "336623": 127, "717603": 127, "160268": 127, "687924": 127, "331463": 127, "345233": 127, "377340": 127, "649888": 127, "039056": 127, "923635": 127, "297553": 127, "090110": 127, "024221": 127, "658442": 127, "151436": 127, "612166": 127, "695911": 127, "608458": 127, "740830": 127, "582210": 127, "165707": 127, "552889": 127, "666311": 127, "283311": 127, "129195": 127, "636355": 127, "103647": 127, "115987": 127, "5_case_studi": [127, 128], "result_cel_nonlinear": [127, 128], "read": [127, 128], "1291": [127, 128], "332436": 127, "872823": 127, "384179": 127, "570366": 127, "581828": 127, "681775": 127, "981202": 127, "683080": 127, "1293": [127, 128], "542217": 127, "151571": 127, "925634": 127, "1294": [127, 128], "679223": 127, "269175": 127, "536997": 127, "1295": [127, 128], "639611": 127, "089511": 127, "523789": 127, "656": [127, 128], "te_femal": [127, 128], "500268": 127, "309777": 127, "562432": 127, "605472": 127, "960134": 127, "te_mal": [127, 128], "365749": 127, "321332": 127, "256846": 127, "447365": 127, "models_cel_linear": [127, 128], "3232": 127, "3258": 127, "5782": 127, "4468": 127, "6992": 127, "7018": 127, "4536": 127, "0989": 127, "6662": 127, "1601": 127, "7274": 127, "3727": 127, "6922": 127, "6282": 127, "4642": 127, "7271": 127, "6631": 127, "4829": 127, "1457": 127, "3927": 127, "3556": 127, "6026": 127, "2654": 127, "3577": 127, "8868": 127, "6916": 127, "3483": [127, 128], "1532": 127, "6823": 127, "result_cel_linear": [127, 128], "323169": 127, "453650": 127, "692167": 127, "482883": 127, "357668": 127, "325782": 127, "098945": 127, "628177": 127, "145705": 127, "886814": 127, "578237": 127, "666234": 127, "464250": 127, "392727": 127, "691633": 127, "580850": 127, "311529": 127, "400261": 127, "055549": 127, "220779": 127, "530090": 127, "566701": 127, "455929": 127, "741310": 127, "570002": 127, "494923": 127, "259652": 127, "899359": 127, "006980": 127, "469963": 127, "444164": 127, "514824": 127, "955027": 127, "692742": 127, "819186": 127, "446776": 127, "160120": 127, "891038": 127, "355564": 127, "348332": 127, "699231": 127, "727408": 127, "727111": 127, "602585": 127, "153151": 127, "701844": 127, "372704": 127, "663122": 127, "265407": 127, "682297": 127, "629759": 127, "238649": 127, "108269": 127, "282668": 127, "594396": 127, "578999": 127, "493821": 127, "163938": 127, "968430": 127, "943619": 127, "581612": 127, "139116": 127, "099948": 127, "631252": 127, "472765": 127, "834067": 127, "706405": 127, "936021": 127, "878273": 127, "277584": 127, "836679": 127, "351700": 127, "872032": 127, "541095": 127, "806730": 127, "te_female_linear": [127, 128], "579924": 127, "402675": 127, "282099": 127, "511989": 127, "082199": 127, "te_male_linear": [127, 128], "445089": 127, "423679": 127, "073189": 127, "236301": 127, "957766": 127, "cel_result": 127, "mean_error": 127, "genere_dat": 127, "genere_error": 127, "ddof": 127, "intercept_": 127, "coef_": 127, "05i": 127, "ran": 127, "sigma1": 127, "cum_reward_inform": 127, "informative_t": 127, "cum_reward_informative_t": 127, "rec_action_informative_t": 127, "cumsum": 127, "ipykernel_31684": 127, "3828886315": 127, "1000i": 127, "cum_reward_uninform": 127, "uninformative_t": 127, "cum_reward_uninformative_t": 127, "rec_action_uninformative_t": 127, "173": [127, 128], "080": 127, "872": [127, 128], "082": 127, "047": 127, "084": 127, "409": 127, "976": 127, "477": 127, "398": [127, 128], "468": 127, "165": [127, 128], "concaten": 127, "algo": 127, "lineplot": 127, "hue": 127, "n_boot": 127, "linewidth": 127, "marker": 127, "axessubplot": 127, "ipykernel_31970": 128, "3560118741": 128, "movielens_mtts_1m": 128, "fp": 128, "352": 128, "411": 128, "424": 128, "524": 128, "699": 128, "770": 128, "839": 128, "1010": 128, "1019": 128, "1051": 128, "1068": 128, "1181": 128, "1203": 128, "1242": 128, "1244": 128, "1246": 128, "1264": 128, "1266": 128, "1274": 128, "1285": 128, "1317": 128, "1340": 128, "1383": 128, "1422": 128, "1447": 128, "1470": 128, "1579": 128, "1639": 128, "1671": 128, "1676": 128, "1741": 128, "1748": 128, "1780": 128, "1880": 128, "1912": 128, "1920": 128, "1926": 128, "1941": 128, "1943": 128, "1980": 128, "2073": 128, "2092": 128, "2105": 128, "2181": 128, "2453": 128, "2507": 128, "2544": 128, "2793": 128, "2820": 128, "2857": 128, "2909": 128, "3029": 128, "3067": 128, "3272": 128, "3280": 128, "3285": 128, "3336": 128, "3389": 128, "3391": 128, "3410": 128, "3462": 128, "3507": 128, "3539": 128, "3589": 128, "3618": 128, "3626": 128, "3648": 128, "3650": 128, "3681": 128, "3705": 128, "3778": 128, "3808": 128, "3824": 128, "3934": 128, "3942": 128, "3999": 128, "4016": 128, "4048": 128, "4064": 128, "4089": 128, "4169": 128, "4186": 128, "4305": 128, "4344": 128, "4425": 128, "4482": 128, "4510": 128, "4578": 128, "4682": 128, "4802": 128, "5074": 128, "5107": 128, "5220": 128, "5317": 128, "5367": 128, "5387": 128, "5394": 128, "5433": 128, "5504": 128, "5511": 128, "5614": 128, "5627": 128, "5636": 128, "5643": 128, "5682": 128, "5759": 128, "5763": 128, "5795": 128, "5812": 128, "5831": 128, "5880": 128, "6016": 128, "528": 128, "970": 128, "1050": 128, "1125": 128, "1194": 128, "1958": 128, "2077": 128, "2116": 128, "2419": 128, "2777": 128, "2986": 128, "3312": 128, "3471": 128, "3768": 128, "3829": 128, "4579": 128, "5026": 128, "5306": 128, "5312": 128, "5333": 128, "5837": 128, "5996": 128, "877": 128, "1635": 128, "2124": 128, "3018": 128, "3032": 128, "3311": 128, "3401": 128, "3675": 128, "4028": 128, "4387": 128, "4808": 128, "5788": 128, "1764": 128, "3823": 128, "355916": 128, "361546": 128, "2926": 128, "379684": 128, "3477": 128, "380838": 128, "380966": 128, "377598": 128, "3404": 128, "378510": 128, "379685": 128, "380598": 128, "280": 128, "380967": 128, "48235": 128, "32375": 128, "25583": 128, "17407": 128, "173163": 128, "32285": 128, "32286": 128, "32287": 128, "32288": 128, "32289": 128, "32290": 128, "32291": 128, "32292": 128, "32293": 128, "32294": 128, "32295": 128, "32296": 128, "32297": 128, "32298": 128, "32299": 128, "32300": 128, "32301": 128, "32302": 128, "32303": 128, "32304": 128, "32305": 128, "32306": 128, "32307": 128, "32308": 128, "32309": 128, "32310": 128, "32311": 128, "32312": 128, "32313": 128, "32314": 128, "32315": 128, "32316": 128, "32317": 128, "32318": 128, "32319": 128, "32320": 128, "32321": 128, "32322": 128, "32323": 128, "32324": 128, "32325": 128, "32326": 128, "32327": 128, "32328": 128, "32329": 128, "32330": 128, "32331": 128, "32332": 128, "32333": 128, "32334": 128, "32335": 128, "32336": 128, "32337": 128, "32338": 128, "32339": 128, "32340": 128, "32341": 128, "32342": 128, "32343": 128, "32344": 128, "32345": 128, "32346": 128, "32347": 128, "32348": 128, "32349": 128, "32350": 128, "32351": 128, "32352": 128, "32353": 128, "32354": 128, "32355": 128, "32356": 128, "32357": 128, "32358": 128, "32359": 128, "32360": 128, "32361": 128, "32362": 128, "32363": 128, "32364": 128, "32365": 128, "32366": 128, "32367": 128, "32368": 128, "32369": 128, "32370": 128, "32371": 128, "32372": 128, "32373": 128, "32374": 128, "ceil": 128, "ipykernel_29676": 128, "1759006568": 128, "431": 128, "_sequenc": 128, "433": 128, "434": 128, "1974279358": 128, "5565": 128, "6671": 128, "3669": 128, "7403": 128, "1545": 128, "7169": 128, "7921": 128, "8884": 128, "617": 128, "1462": 128, "6609": 128, "7536": 128, "8367": 128, "9265": 128, "7139": 128, "8914": 128, "8843": 128, "428": 128, "5516": 128, "5793": 128, "4066": 128, "0967": 128, "1025": 128, "9624": 128, "667108": 128, "159101": 128, "621042": 128, "891404": 128, "579256": 128, "366861": 128, "888376": 128, "660929": 128, "884298": 128, "406647": 128, "740314": 128, "323008": 128, "753576": 128, "930968": 128, "621002": 128, "432508": 128, "036827": 128, "793464": 128, "923861": 128, "460696": 128, "654633": 128, "138223": 128, "807868": 128, "984900": 128, "545622": 128, "783766": 128, "636899": 128, "261385": 128, "142084": 128, "852911": 128, "108480": 128, "215949": 128, "049312": 128, "523752": 128, "236776": 128, "154513": 128, "617045": 128, "836742": 128, "647366": 128, "096732": 128, "716872": 128, "146200": 128, "926512": 128, "428002": 128, "102457": 128, "792068": 128, "623021": 128, "713942": 128, "551617": 128, "962412": 128, "128": 128, "130": 128, "131": 128, "161": 128, "162": 128, "166": 128, "193": 128, "194": 128, "195": 128, "197": 128, "199": 128, "201": 128, "203": 128, "205": 128, "224": 128, "225": 128, "226": 128, "230": 128, "236": 128, "237": 128, "259": 128, "270": 128, "271": 128, "289": 128, "290": 128, "291": 128, "292": 128, "293": 128, "294": 128, "296": 128, "301": 128, "303": 128, "325": 128, "327": 128, "328": 128, "334": 128, "353": 128, "354": 128, "357": 128, "363": 128, "365": 128, "367": 128, "385": 128, "386": 128, "388": 128, "389": 128, "391": 128, "393": 128, "395": 128, "396": 128, "397": 128, "399": 128, "422": 128, "425": 128, "427": 128, "429": 128, "449": 128, "452": 128, "453": 128, "454": 128, "456": 128, "457": 128, "463": 128, "481": 128, "482": 128, "483": 128, "484": 128, "485": 128, "486": 128, "487": 128, "488": 128, "489": 128, "490": 128, "491": 128, "492": 128, "495": 128, "512": 128, "514": 128, "515": 128, "517": 128, "521": 128, "522": 128, "525": 128, "526": 128, "544": 128, "545": 128, "546": 128, "547": 128, "548": 128, "549": 128, "555": 128, "556": 128, "557": 128, "558": 128, "559": 128, "579": 128, "580": 128, "581": 128, "582": 128, "583": 128, "585": 128, "586": 128, "587": 128, "588": 128, "590": 128, "591": 128, "608": 128, "609": 128, "610": 128, "611": 128, "614": 128, "615": 128, "616": 128, "618": 128, "620": 128, "641": 128, "643": 128, "644": 128, "645": 128, "646": 128, "648": 128, "649": 128, "650": 128, "651": 128, "653": 128, "654": 128, "655": 128, "672": 128, "673": 128, "674": 128, "682": 128, "684": 128, "685": 128, "687": 128, "704": 128, "706": 128, "707": 128, "709": 128, "710": 128, "711": 128, "712": 128, "713": 128, "714": 128, "715": 128, "716": 128, "717": 128, "737": 128, "738": 128, "741": 128, "742": 128, "743": 128, "744": 128, "745": 128, "746": 128, "747": 128, "768": 128, "769": 128, "771": 128, "772": 128, "773": 128, "774": 128, "775": 128, "782": 128, "803": 128, "809": 128, "810": 128, "812": 128, "813": 128, "814": 128, "815": 128, "832": 128, "833": 128, "834": 128, "835": 128, "837": 128, "838": 128, "840": 128, "841": 128, "842": 128, "843": 128, "844": 128, "845": 128, "847": 128, "865": 128, "866": 128, "867": 128, "868": 128, "870": 128, "871": 128, "873": 128, "874": 128, "875": 128, "876": 128, "878": 128, "879": 128, "896": 128, "897": 128, "899": 128, "902": 128, "903": 128, "904": 128, "905": 128, "907": 128, "908": 128, "909": 128, "928": 128, "929": 128, "935": 128, "936": 128, "937": 128, "938": 128, "939": 128, "941": 128, "961": 128, "962": 128, "963": 128, "964": 128, "965": 128, "967": 128, "968": 128, "969": 128, "971": 128, "972": 128, "973": 128, "974": 128, "992": 128, "993": 128, "994": 128, "1001": 128, "1002": 128, "1003": 128, "1004": 128, "1005": 128, "1007": 128, "1024": 128, "1026": 128, "1027": 128, "1028": 128, "1029": 128, "1030": 128, "1031": 128, "1032": 128, "1033": 128, "1034": 128, "1035": 128, "1037": 128, "1038": 128, "1039": 128, "1056": 128, "1058": 128, "1059": 128, "1060": 128, "1061": 128, "1062": 128, "1063": 128, "1064": 128, "1065": 128, "1066": 128, "1067": 128, "1069": 128, "1070": 128, "1071": 128, "1088": 128, "1089": 128, "1090": 128, "1091": 128, "1092": 128, "1093": 128, "1094": 128, "1095": 128, "1096": 128, "1097": 128, "1098": 128, "1099": 128, "1100": 128, "1121": 128, "1124": 128, "1126": 128, "1127": 128, "1128": 128, "1129": 128, "1130": 128, "1131": 128, "1132": 128, "1133": 128, "1134": 128, "1135": 128, "1152": 128, "1153": 128, "1154": 128, "1155": 128, "1156": 128, "1157": 128, "1158": 128, "1159": 128, "1160": 128, "1161": 128, "1163": 128, "1164": 128, "1165": 128, "1166": 128, "1167": 128, "1184": 128, "1185": 128, "1186": 128, "1187": 128, "1188": 128, "1189": 128, "1190": 128, "1191": 128, "1192": 128, "1195": 128, "1196": 128, "1198": 128, "1199": 128, "1219": 128, "1220": 128, "1221": 128, "1222": 128, "1223": 128, "1227": 128, "1228": 128, "1229": 128, "1230": 128, "1231": 128, "1248": 128, "1250": 128, "1252": 128, "1253": 128, "1255": 128, "1256": 128, "1257": 128, "1258": 128, "1259": 128, "1260": 128, "1261": 128, "1262": 128, "1263": 128, "1280": 128, "1281": 128, "1282": 128, "1283": 128, "1284": 128, "1287": 128, "1288": 128, "1289": 128, "1290": 128, "794232": 128, "697612": 128, "391132": 128, "328777": 128, "938607": 128, "212522": 128, "417237": 128, "849207": 128, "435471": 128, "563120": 128, "317231": 128, "961143": 128, "636637": 128, "194262": 128, "491331": 128, "722974": 128, "234974": 128, "241653": 128, "736452": 128, "258903": 128, "856846": 128, "854605": 128, "029084": 128, "495243": 128, "199417": 128, "474339": 128, "830191": 128, "666765": 128, "599922": 128, "379801": 128, "337232": 128, "707185": 128, "387759": 128, "441026": 128, "325087": 128, "243": 128, "4266": 128, "4122": 128, "2197": 128, "2311": 128, "0386": 128, "6734": 128, "5095": 128, "703": 128, "2655": 128, "2951": 128, "2971": 128, "2555": 128, "2409": 128, "4948": 128, "4161": 128, "4481": 128, "1083": 128, "2862": 128, "2593": 128, "9672": 128, "0982": 128, "9404": 128, "412203": 128, "673359": 128, "297117": 128, "494783": 128, "286167": 128, "219698": 128, "509493": 128, "255487": 128, "416131": 128, "128323": 128, "415576": 128, "703012": 128, "306670": 128, "448094": 128, "259327": 128, "223072": 128, "539146": 128, "265040": 128, "369442": 128, "101483": 128, "359126": 128, "665731": 128, "404304": 128, "538511": 128, "253674": 128, "091722": 128, "302749": 128, "092034": 128, "064599": 128, "972893": 128, "227776": 128, "429334": 128, "231298": 128, "233668": 128, "125085": 128, "035271": 128, "265468": 128, "189667": 128, "155016": 128, "967241": 128, "231149": 128, "458987": 128, "240851": 128, "186979": 128, "098245": 128, "038645": 128, "295121": 128, "199220": 128, "108327": 128, "940401": 128, "drive": 128, "mydriv": 128, "205060": 128, "347510": 128, "158682": 128, "172299": 128, "983469": 128, "341114": 128, "474094": 128, "297946": 128, "341368": 128, "135660": 128, "148609": 128, "310228": 128, "256316": 128, "262715": 128, "977817": 128, "344487": 128, "503747": 128, "307499": 128, "294679": 128, "108820": 128, "151983": 128, "339881": 128, "265868": 128, "216027": 128, "950977": 128, "282093": 128, "506620": 128, "281493": 128, "355405": 128, "118572": 128, "168755": 128, "461860": 128, "214845": 128, "247705": 128, "107996": 128}, "objects": {}, "objtypes": {}, "objnames": {}, "titleterms": {"learner": [0, 9, 10, 11, 13, 14, 16, 20, 22, 24, 25, 26, 28, 29, 41, 42, 49, 50, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104], "name": [0, 129], "singl": [0, 19, 27, 44, 58, 59, 60, 61, 107, 125, 126], "multipl": [0, 21, 74, 75, 76, 77], "stage": [0, 19, 27, 44, 58, 59, 60, 74, 75, 76, 77, 121, 125, 126], "infinit": [0, 62, 67, 69, 71, 120], "horizon": [0, 62, 67, 69, 71, 120], "main": [0, 11, 14, 19, 44, 47, 49, 58, 59, 62, 63, 65, 66, 67, 68, 69, 71, 74, 77, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115], "idea": [0, 11, 14, 19, 44, 47, 49, 58, 59, 62, 63, 65, 66, 67, 68, 69, 71, 74, 77, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115], "algorithm": [0, 11, 13, 14, 44, 58, 59, 74, 77, 78, 82, 84, 85, 94, 95, 99, 100, 101, 102, 105, 107, 108, 109, 114, 115], "detail": [0, 9, 11, 13, 14, 44, 49, 58, 74, 77, 82, 84, 85, 95, 100, 102, 105, 108, 109, 114, 115], "kei": [0, 44, 58, 74, 77, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115], "step": [0, 44, 58, 74, 77, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115, 130], "demo": [0, 11, 13, 14, 21, 44, 47, 49, 58, 59, 62, 63, 65, 66, 67, 68, 71, 74, 77, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115, 122, 123], "code": [0, 5, 11, 13, 14, 44, 49, 58, 74, 77, 80, 81, 82, 84, 85, 86, 88, 89, 90, 91, 93, 95, 96, 97, 98, 100, 102, 103, 104, 105, 108, 109, 114, 115], "1": [0, 2, 9, 11, 12, 13, 14, 15, 17, 21, 22, 26, 27, 44, 49, 58, 69, 74, 77, 89, 90, 91, 107, 128, 129, 130], "polici": [0, 2, 7, 44, 49, 55, 58, 59, 62, 63, 64, 67, 69, 70, 71, 72, 73, 74, 77, 89, 90, 91, 92, 117, 118, 121, 125, 126, 129], "learn": [0, 1, 2, 3, 27, 44, 46, 47, 49, 51, 54, 58, 61, 62, 69, 74, 75, 77, 94, 117, 118, 122, 123, 127, 128, 129], "2": [0, 2, 9, 11, 12, 13, 14, 15, 17, 21, 22, 27, 28, 44, 49, 58, 69, 74, 77, 89, 90, 91, 129, 130], "evalu": [0, 7, 44, 49, 58, 59, 62, 63, 64, 65, 67, 69, 71, 72, 73, 74, 77, 89, 90, 91, 92, 117, 121, 125, 126], "refer": [0, 2, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 28, 29, 34, 35, 38, 39, 40, 41, 42, 44, 47, 49, 58, 62, 63, 65, 66, 67, 68, 71, 72, 73, 74, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 114, 115, 116, 117, 118, 120, 121, 125, 126, 129], "causal": [1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 27, 73, 122, 123, 127, 128, 129], "effect": [1, 4, 6, 10, 12, 27, 122, 123, 127, 128, 129], "cel": [1, 27, 120, 121, 125, 126, 129], "clinic": [1, 2], "trial": 1, "advertis": 1, "market": 1, "more": 1, "beyond": 1, "cpl": [2, 121, 125, 126, 129], "scenario": 2, "fix": [2, 129], "independ": [2, 129], "state": [2, 129], "person": [2, 12], "incent": 2, "ad": [2, 5], "target": [2, 17], "bid": 2, "markovian": [2, 117, 118, 129], "transit": [2, 129], "mobil": 2, "health": 2, "3": [2, 9, 11, 12, 13, 14, 15, 21, 22, 29, 89, 90, 91, 121, 129], "non": [2, 11, 118, 129], "healthcar": 2, "trail": 2, "multi": [2, 83, 86, 111], "touch": 2, "attribut": 2, "4": [2, 24, 25, 129], "adapt": [2, 53, 129], "recommend": [2, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 106, 107, 116], "system": 2, "onlin": [2, 89, 90, 91, 92, 94, 99, 127], "dynam": [2, 101], "price": 2, "5": [2, 16, 25, 129], "6": [2, 20, 25, 129], "structur": [3, 9, 11, 13, 14, 79, 83, 106, 129], "csl": [3, 129], "spread": 3, "covid": 3, "19": 3, "gene": 3, "express": 3, "trait": 3, "yeast": 3, "infer": [4, 5, 6], "101": [4, 5], "potenti": [4, 6, 73, 130], "outcom": [4, 6, 47, 51, 73, 122, 123], "assumpt": [4, 6, 15], "averag": [4, 6], "regress": 4, "model": [4, 9, 11, 13, 14, 117, 118, 127, 128], "propens": 4, "score": [4, 13], "stratif": 4, "invers": [4, 91], "weight": [4, 47, 91], "doubli": [4, 15, 62, 90], "robust": [4, 15, 21, 62, 90], "estim": [4, 15, 19, 21, 62, 127], "what": [5, 129], "myst": 5, "ar": 5, "role": 5, "direct": [5, 15, 21, 89], "us": [5, 47], "citat": 5, "execut": 5, "your": 5, "markdown": 5, "file": 5, "preliminari": [6, 8, 12, 72, 73], "do": [6, 57], "oper": 6, "treatment": [6, 10, 12, 59], "heterogen": [6, 12], "optim": [7, 59, 69, 70, 72, 73, 99, 101, 117, 121, 125, 126], "discoveri": [9, 10, 11, 13, 14, 122, 123], "gener": [9, 11, 12, 13, 14, 18, 23, 59, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104], "graph": [9, 11, 12, 13, 14], "terminolog": [9, 11, 12, 13, 14], "overview": [9, 13, 49, 78, 80, 81, 82, 84, 85, 86, 88, 90, 93, 95, 96, 97, 98, 100, 102, 103, 104, 129], "popular": 9, "graphic": [9, 11, 13, 14, 79, 83], "linear": [9, 11, 13, 14, 127, 128], "equat": [9, 11, 13, 14], "addit": [9, 11, 13], "nois": [9, 11, 13], "lsem": [9, 13], "method": [9, 15, 107], "To": [9, 57], "Be": 9, "mediat": [10, 12, 21, 120, 121, 123, 125, 126], "analysi": [10, 12, 21, 120, 121, 123, 125, 126, 127, 128], "from": 10, "tabl": 10, "anoc": 10, "cvae": 10, "cai": 10, "et": [10, 13], "al": [10, 13], "2020": 10, "function": [11, 72], "base": [11, 13, 14, 50, 68, 117], "goal": [11, 13, 14], "applic": [11, 13, 14], "gaussian": [11, 14, 107], "gaussain": 11, "synthet": [11, 13, 14, 39, 40, 41, 42], "dataset": [11, 13, 14, 59, 128], "ica": 11, "lingam": 11, "summari": [11, 13, 14], "result": [11, 13, 14, 127], "under": [11, 13, 14, 73, 89, 90, 91], "differ": [11, 13, 14, 19, 34], "toi": 12, "exampl": 12, "decis": [12, 32, 69, 72, 73], "make": 12, "remark": 12, "notear": 13, "zheng": 13, "2018": 13, "test": [14, 61], "pc": 14, "ATE": [15, 30, 33], "identif": [15, 21], "import": [15, 67, 71, 80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 130], "sampl": [15, 67, 71, 86, 88, 107, 128], "dr": [16, 25], "movielen": [16, 17, 18, 20, 24, 26, 28, 29, 127], "data": [16, 17, 18, 20, 21, 24, 26, 27, 28, 29, 37, 53, 56, 59, 60, 76, 79, 83, 87, 94, 99, 101, 106, 107, 116, 128, 129], "8": [17, 23], "dragon": [17, 23], "net": [17, 23], "part": 17, "dragonnet": 17, "regular": 17, "7": [18, 23], "random": [18, 23], "forest": [18, 23], "hte": [19, 31, 36], "approach": [19, 23], "The": 19, "advantag": 19, "lp": [20, 25], "r": [20, 24, 25, 38], "meta": [22, 87, 88, 113], "s": [22, 26], "t": [22, 28], "x": [22, 29, 42], "other": 23, "real": [27, 59, 60, 76, 79, 83, 87, 94, 99, 101, 106, 107, 116], "movi": 27, "len": 27, "pre": [27, 59], "process": [27, 32, 59, 72, 73], "final": 27, "select": 27, "mimic3": [27, 122, 123, 124], "markov": [32, 72, 73], "h1sl": 35, "h2sl": 35, "panel": [37, 129], "did": [38, 40], "control": 39, "miscellan": 43, "A": [44, 61, 74, 129], "reduct": 45, "classif": 45, "problem": [45, 60, 76, 79, 83, 87, 94, 99, 101, 106, 107, 116], "entropi": 46, "when": [47, 130], "should": 47, "i": [47, 129], "owl": 47, "spars": 47, "a1": 47, "deriv": 47, "continu": [48, 49], "action": [48, 49, 52], "space": [48, 52], "deep": 49, "jump": 49, "difficulti": 49, "kernel": 50, "discret": 52, "collect": 53, "concord": 54, "assist": 54, "search": 55, "time": 56, "event": 56, "plan": 57, "q": [58, 65, 66, 69, 77], "quantil": 59, "regim": 59, "motiv": 59, "set": [59, 60, 76, 79, 83, 87, 94, 99, 101, 106, 107, 116], "simul": [59, 107], "off": [59, 63, 72, 73], "qope": 59, "doubl": 62, "reinforc": 62, "stationari": [62, 67], "distribut": [62, 67, 68], "todo": [62, 63, 65, 66, 67, 68, 71], "note": [62, 63, 67, 68, 71], "deepli": 63, "debias": 63, "fit": [65, 66, 127, 128], "iter": 66, "break": 67, "curs": 67, "confid": [68, 107], "interv": 68, "op": 68, "asymptot": 68, "ci": 68, "drl": 68, "valu": [72, 117], "framework": [73, 89, 90, 91], "identifi": 73, "mediatedq": 75, "dtr": 76, "bandit": [78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 94, 99, 101, 106, 107, 129], "contextu": 79, "lint": [80, 109], "environ": [80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104, 117, 118], "specifi": [80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104], "hyperparamet": [80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104], "interact": [80, 81, 82, 84, 85, 86, 88, 93, 95, 96, 97, 98, 100, 102, 103, 104], "bernoulli": [80, 81, 82, 84, 85, 86, 88, 107], "linucb": [81, 110], "epsilon": [82, 107], "greedi": [82, 107], "arm": 83, "mab": 83, "ts": [84, 89, 90, 91, 113, 114, 127], "ucb": [85, 89, 90, 91], "task": [86, 111], "thompson": [86, 88, 107], "mtt": [86, 112], "eg": [89, 90, 91], "probabl": [90, 91], "explor": [90, 91], "cascadelint": 93, "rank": 94, "cascad": 94, "support": [94, 99, 101, 107], "mtss_cascad": 95, "ts_cascad": 96, "comblint": 97, "combt": 98, "combinatori": 99, "semi": 99, "mtss_comb": 100, "assort": 101, "multinomi": 101, "logit": 101, "mtss_mnl": 102, "ts_contextual_mnl": 103, "ts_mnl": 104, "ucb_mnl": 105, "slate": [106, 116], "item": 107, "claasic": 107, "upper": 107, "bound": 107, "epsilon_greedi": 108, "ucb1": 115, "oolin": [117, 118], "gradient": 117, "approxim": 117, "dp": 117, "actor": 117, "critic": 117, "mimic": [119, 120, 121, 125, 126], "iii": [119, 120, 121, 125, 126], "regard": [122, 123], "died_within_48h": [122, 123], "variabl": [122, 123], "sofa": [122, 123], "ver2": 123, "introduct": 129, "expect": 129, "sl": 129, "ml": 129, "case1": 129, "paradigm": 129, "d": 129, "pl": 129, "case2": 129, "case3": 129, "case4": 129, "case5": 129, "case6": 129, "appendix": 129, "singeldtr": 129, "mdp": 129, "b": 129, "multidtr": 129, "c": 129, "content": 130, "everi": 130, "notebook": 130, "how": 130, "contribut": 130, "compil": 130, "new": 130, "version": 130, "option": 130, "publish": 130, "error": 130, "messag": 130, "run": [127, 130], "ghp": 130, "definit": 21, "ipw": 21, "mr": 21, "revis": 21, "nonlinear": [127, 128], "sigma": 127, "boldsymbol": 127, "gamma": 127, "inform": 127, "uninform": 127, "entir": 128, "interst": 128, "user": 128}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinxcontrib.bibtex": 9, "sphinx": 56}})