

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>TS &#8212; Causal Decision Making</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=365ca57ee442770a23c6" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=365ca57ee442770a23c6" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=365ca57ee442770a23c6" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=365ca57ee442770a23c6" />
  <script src="../../../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=365ca57ee442770a23c6"></script>

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '4_Causal_Policy_Learning/Scenario4/MAB/TS';</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Contextual Bandits" href="../Contextual_Bandits/Contextual_Bandits.html" />
    <link rel="prev" title="UCB" href="UCB.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../../Overview.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../_static/logo.png" class="logo__image only-light" alt="Causal Decision Making - Home"/>
    <script>document.write(`<img src="../../../_static/logo.png" class="logo__image only-dark" alt="Causal Decision Making - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../../Overview.html">
                    Overview
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Motivating Examples</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../0_Motivating_Examples/CSL.html">Causal Structure Learning (CSL)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../0_Motivating_Examples/CEL.html">Causal Effect Learning (CEL)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../0_Motivating_Examples/CPL.html">Causal Policy Learning (CPL)</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Preliminary</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../1_Preliminary/Causal%20Inference%20Preliminary.html">Causal Inference Preliminary</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Causal Structure Learning (CSL)</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../2_Causal_Structure_Learning/Preliminaries%20of%20Causal%20Graphs.html">Preliminaries of Causal Graphs</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../2_Causal_Structure_Learning/Causal%20Discovery.html">Causal Discovery</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../2_Causal_Structure_Learning/Testing-based%20Learner.html">Testing-based Learner</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../2_Causal_Structure_Learning/Functional-based%20Learner.html">Functional-based Learner</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../2_Causal_Structure_Learning/Score-based%20Learner.html">Score-based Learner</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../2_Causal_Structure_Learning/Causal%20Mediation%20Analysis.html">Causal Mediation Analysis</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Causal Effect Learning (CEL)</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../3_Causal_Effect_Learning/Scenario%201/Single%20Stage.html"><strong>Single Stage – Paradigm 1</strong></a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../3_Causal_Effect_Learning/Scenario%201/ATE.html">ATE Estimation</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../3_Causal_Effect_Learning/Scenario%201/HTE.html">HTE Estimation</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../3_Causal_Effect_Learning/Scenario%201/S-learner.html"><strong>1. S-learner</strong></a></li>


<li class="toctree-l3"><a class="reference internal" href="../../../3_Causal_Effect_Learning/Scenario%201/T-learner.html"><strong>2. T-learner</strong></a></li>


<li class="toctree-l3"><a class="reference internal" href="../../../3_Causal_Effect_Learning/Scenario%201/X-learner.html"><strong>3. X-learner</strong></a></li>


<li class="toctree-l3"><a class="reference internal" href="../../../3_Causal_Effect_Learning/Scenario%201/R-Learner.html"><strong>4. R learner</strong></a></li>


<li class="toctree-l3"><a class="reference internal" href="../../../3_Causal_Effect_Learning/Scenario%201/DR-Learner.html"><strong>5. DR-learner</strong></a></li>


<li class="toctree-l3"><a class="reference internal" href="../../../3_Causal_Effect_Learning/Scenario%201/Lp-R-Learner.html"><strong>6. Lp-R-learner</strong></a></li>


<li class="toctree-l3"><a class="reference internal" href="../../../3_Causal_Effect_Learning/Scenario%201/GRF.html"><strong>7. Generalized Random Forest</strong></a></li>


<li class="toctree-l3"><a class="reference internal" href="../../../3_Causal_Effect_Learning/Scenario%201/Dragonnet.html"><strong>8. Dragon Net</strong></a></li>


</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../3_Causal_Effect_Learning/Scenario%201/Mediation%20Analysis.html">Mediation Analysis</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../3_Causal_Effect_Learning/Scenario%202/underMDP.html">Markov Decision Processes – Paradigm 2</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../3_Causal_Effect_Learning/Scenario%203/Panel%20Data.html">Panel Data  – Paradigm 3</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../3_Causal_Effect_Learning/Scenario%203/DiD.html"><strong>Difference in Difference</strong></a></li>

<li class="toctree-l2"><a class="reference internal" href="../../../3_Causal_Effect_Learning/Scenario%203/Synthetic%20Control.html"><strong>Synthetic Control</strong></a></li>




<li class="toctree-l2 has-children"><a class="reference internal" href="../../../3_Causal_Effect_Learning/Scenario%203/Extensions.html">Extensions</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../3_Causal_Effect_Learning/Scenario%203/Matrix%20Completion.html"><strong>Matrix Completion</strong></a></li>

<li class="toctree-l3"><a class="reference internal" href="../../../3_Causal_Effect_Learning/Scenario%203/Synthetic%20DiD.html"><strong>Synthetic DiD</strong></a></li>

<li class="toctree-l3"><a class="reference internal" href="../../../3_Causal_Effect_Learning/Scenario%203/H1SL_H2SL.html"><strong>H1SL and H2SL</strong></a></li>

</ul>
</li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Causal Policy Learning (CPL)--Paradigm 1</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Scenario1/Single%20Stage.html">Single Stage</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../Scenario1/Discrete.html">Discrete Action Space</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../Scenario1/Q-learning_Single.html">Q-Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Scenario1/A-learning_Single.html">A-Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Scenario1/Classification/O-Learning.html">Outcome Weighted Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Scenario1/Quantile/QuantileOTR_test.html">Quantile Optimal Treatment Regime</a></li>

</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../Scenario1/Continuous.html">Continuous Action Space</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../Scenario1/Continuous/Deep%20Jump%20Learner.html">Deep Jump Learner for Continuous Actions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Scenario1/Continuous/Kernel-Based%20Learner.html">Kernel-Based Learner</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Scenario1/Continuous/Outcome%20Learning.html">Outcome Learning</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../Scenario1/PlanToDo.html">Plan To Do</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../Scenario1/Classification/E-learning.html">Entropy learning</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Causal Policy Learning (CPL)--Paradigm 2</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Scenario2/preliminary_MDP-potential-outcome.html">Preliminary: Off-policy Evaluation and Optimization in Markov Decision Processes</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../Scenario2/Evaluation.html">Policy Evaluation–Value Estimation</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../Scenario2/FQE.html">Fitted-Q Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Scenario2/IPW_Infinite.html">Importance Sampling for Policy Evaluation (Infinite Horizon)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Scenario2/DR_Infinite.html">Doubly Robust Estimator for Policy Evaluation (Infinite Horizon)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../Scenario2/Deeply_Debiased.html">Deeply-Debiased Off-Policy Evaluation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../Scenario2/MediationRL.html">Policy Evaluation--Mediation Analysis</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../Scenario2/Optimization.html">Policy Optimization</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../Scenario2/FQI.html">Fitted-Q Iteration</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Causal Policy Learning (CPL)--Paradigm 3</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Scenario3/Multi%20Stage.html">Multiple Stages (DTR)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Scenario3/Q-learning_Multiple.html">Q-Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../Scenario3/A-learning_Multiple.html">A-Learning</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Causal Policy Learning (CPL)--Paradigm 4</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Bandits.html">Overview: Bandits ALgorithm</a></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="MAB.html">Multi-Armed Bandits (MAB)</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="Epsilon_Greedy.html"><span class="math notranslate nohighlight">\(\epsilon\)</span>-Greedy</a></li>
<li class="toctree-l2"><a class="reference internal" href="UCB.html">UCB</a></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">TS</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Contextual_Bandits/Contextual_Bandits.html">Contextual Bandits</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../Contextual_Bandits/LinUCB.html">LinUCB</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Contextual_Bandits/LinTS.html">LinTS</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Meta_Bandits/Meta_Bandits.html">Meta Bandits</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../Meta_Bandits/Meta_TS.html">Meta Thompson Sampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../Meta_Bandits/MTTS.html">Multi-Task Thompson Sampling (MTTS)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Structured_Bandits/Structured_Bandit.html">Structured Bandit (Slate Recommendation)</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../Structured_Bandits/Cascade/Learning%20to%20rank.html">Online Learning to Rank (Cascading Bandit)</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../Structured_Bandits/Cascade/TS_Cascade.html">TS_Cascade</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Structured_Bandits/Cascade/CascadeLinTS.html">CascadeLinTS</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Structured_Bandits/Cascade/MTSS_Cascade.html">MTSS_Cascade</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../Structured_Bandits/Combinatorial-Semi/Combinatorial%20Optimization.html">Online Combinatorial Optimization (Combinatorial Semi-Bandit)</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../Structured_Bandits/Combinatorial-Semi/CombTS.html">CombTS</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Structured_Bandits/Combinatorial-Semi/CombLinTS.html">CombLinTS</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Structured_Bandits/Combinatorial-Semi/MTSS_Comb.html">MTSS_Comb</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../Structured_Bandits/MNL/Assortment%20Optimization.html">Dynamic Assortment Optimization (Multinomial Logit Bandit)</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../Structured_Bandits/MNL/TS_MNL_Beta.html">TS_MNL</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Structured_Bandits/MNL/TS_Contextual_MNL.html">TS_Contextual_MNL</a></li>
<li class="toctree-l3"><a class="reference internal" href="../Structured_Bandits/MNL/MTSS_MNL.html">MTSS_MNL</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../OnlineEval/Online%20Policy%20Evaluation.html">Online Policy Evaluation</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-18"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../OnlineEval/Direct%20Online%20Policy%20Evaluator.html">Direct Online Policy Evaluator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../OnlineEval/Inverse%20Probability%20Weighted%20Online%20Policy%20Evaluator.html">Inverse Probability Weighted Online Policy Evaluator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../OnlineEval/Doubly%20Robust%20Online%20Policy%20Evaluator.html">Doubly Robust Online Policy Evaluator</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Causal Policy Learning (CPL)--Paradigm 5</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Scenario5/OnlineRL_Markov.html">Ooline Policy Learning and Evaluation in Markovian Environments</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Causal Policy Learning (CPL)--Paradigm 6</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../Scenario6/OnlineRL_non_Markov.html">Ooline Policy Learning in Non-Markovian Environments</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Case Studies</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../5_Case_Study/MIMIC3/MIMIC3_intro.html">Mimic3</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-19"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../5_Case_Study/MIMIC3/MIMIC3-Demo-Ver2.html">Mimic3 Demo-Ver2</a></li>


<li class="toctree-l2"><a class="reference internal" href="../../../5_Case_Study/MIMIC3/Single_Stage.html">MIMIC III (Single-Stage)</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../../5_Case_Study/MIMIC3/Longitudinal.html">MIMIC III (3-Stages)</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../../5_Case_Study/MIMIC3/Infinite_Horizon.html">MIMIC III (Infinite Horizon)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../5_Case_Study/MovieLens/MovieLens.html">MovieLens</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2F4_Causal_Policy_Learning/Scenario4/MAB/TS.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../../_sources/4_Causal_Policy_Learning/Scenario4/MAB/TS.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>TS</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">Overview</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#main-idea">Main Idea</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#algorithms-details">Algorithms Details</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-steps">Key Steps</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#demo-code">Demo Code</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#import-the-learner">Import the learner.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generate-the-environment">Generate the Environment</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#specify-hyperparameters">Specify Hyperparameters</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#recommendation-and-interaction">Recommendation and Interaction</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#demo-code-for-bernoulli-bandit">Demo Code for Bernoulli Bandit</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="ts">
<h1>TS<a class="headerlink" href="#ts" title="Permalink to this heading">#</a></h1>
<section id="overview">
<h2>Overview<a class="headerlink" href="#overview" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p><strong>Advantage</strong>: Be able to incorporate prior knowledge about reward distribution, which is especially useful when the prior knowledge is informative. Taking uncertainty into account by updating the posterior distribution of the expectation of potential reward to achieve a good balance between exploration and exploitation.</p></li>
<li><p><strong>Disadvantage</strong>: Inefficient if there is a large number of action items.</p></li>
<li><p><strong>Application Situation</strong>: discrete action space, binary/Gaussian reward space</p></li>
</ul>
</section>
<section id="main-idea">
<h2>Main Idea<a class="headerlink" href="#main-idea" title="Permalink to this heading">#</a></h2>
<p>Thompson Sampling (TS), also known as posterior sampling, solves the exploration-exploitation dilemma by selecting an action according to its posterior distribution [1].  At each round <span class="math notranslate nohighlight">\(t\)</span>, the agent sample the rewards from the corresponding posterior distributions of the expectation of the potential reward (i.e., <span class="math notranslate nohighlight">\(E[R_t(a)]\)</span>) and then select the action with the highest sampled reward greedily. It has been shown that, when the true reward distribution is known, a TS algorithm with the true reward distribution as the prior is nearly optimal [2]. However, such a distribution is always unknown in practice. Therefore, one of the major objectives of TS-based algorithms is to find an informative prior to guide the exploration. Note that the algorithm here supports bandit problem with either binary reward or continuous reward.</p>
</section>
<section id="algorithms-details">
<h2>Algorithms Details<a class="headerlink" href="#algorithms-details" title="Permalink to this heading">#</a></h2>
<p>Supposed there are <span class="math notranslate nohighlight">\(K\)</span> options, and the action space is <span class="math notranslate nohighlight">\(\mathcal{A} = \{0,1,\cdots, K-1\}\)</span>. The TS algorithm starts with specifying a prior distribution of the potential reward, based on the domian knowledge. At each round <span class="math notranslate nohighlight">\(t\)</span>, the agent will samples a vector of <span class="math notranslate nohighlight">\(\boldsymbol{\theta}^{t}\)</span> from the posterior distribution of the potential rewards. The action <span class="math notranslate nohighlight">\(a\)</span> with the greatest <span class="math notranslate nohighlight">\(\theta_{a}^{t}\)</span> is then selected. Finally, the posterior distribution would be updated after receiving the realized reward at the end of each round. Note that the posterior updating step differs for different pairs of prior distribution of the mean reward and reward distribution. Here, we consider two classical examples of the TS algorithm, including</p>
<ul class="simple">
<li><p>Gaussian Bandits</p></li>
</ul>
<div class="amsmath math notranslate nohighlight" id="equation-a75fce00-5e9f-4434-a24f-f3d45f2ec77c">
<span class="eqno">(122)<a class="headerlink" href="#equation-a75fce00-5e9f-4434-a24f-f3d45f2ec77c" title="Permalink to this equation">#</a></span>\[\begin{align}
\boldsymbol{\theta} &amp;\sim Q(\boldsymbol{\theta}),\\
R_t(a) &amp;\sim \mathcal{N}(\theta_a,\sigma^2),
\end{align}\]</div>
<ul class="simple">
<li><p>Bernoulli Bandits</p></li>
</ul>
<div class="amsmath math notranslate nohighlight" id="equation-758330c3-6874-4799-b903-eb346f269f10">
<span class="eqno">(123)<a class="headerlink" href="#equation-758330c3-6874-4799-b903-eb346f269f10" title="Permalink to this equation">#</a></span>\[\begin{align}
\boldsymbol{\theta} &amp;\sim Q(\boldsymbol{\theta}),\\
R_t(a) &amp;\sim Bernoulli(\theta_a).
\end{align}\]</div>
<p>Assuming a Gaussian prior for the Gaussian bandits and a Beta prior for the Bernoulli bandits, the posterior updating is straightforward with closed-form expression. In the Gaussian bandits, the variance of reward <span class="math notranslate nohighlight">\(\sigma^2\)</span> is assumed to be known, and need to be specified manually. Note that code can be easily modified to different specifications of the prior/potential reward distribution.</p>
</section>
<section id="key-steps">
<h2>Key Steps<a class="headerlink" href="#key-steps" title="Permalink to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Specifying a prior distirbution of <span class="math notranslate nohighlight">\(E[R_0(a)]\)</span>, <span class="math notranslate nohighlight">\(a \in \mathcal{A}\)</span>, and the variance of the reward distribution.</p></li>
<li><p>For t = <span class="math notranslate nohighlight">\(0, 1,\cdots, T\)</span>:</p>
<ul class="simple">
<li><p>sample a <span class="math notranslate nohighlight">\(\boldsymbol{\theta}^{t}\)</span> from the posterior distribution of <span class="math notranslate nohighlight">\(E[R_t(a)]\)</span> or prior distribution if in round <span class="math notranslate nohighlight">\(0\)</span></p></li>
<li><p>select action <span class="math notranslate nohighlight">\(A_t\)</span> which has the greatest <span class="math notranslate nohighlight">\(\theta^{t}_{a}\)</span>, i.e. <span class="math notranslate nohighlight">\(A_t = \arg\max_{a \in \mathcal{A}} \theta_{a}^{t}\)</span></p></li>
<li><p>receive the rewad <span class="math notranslate nohighlight">\(R_t\)</span>, and update the posterior distirbution accordingly.</p></li>
</ul>
</li>
</ol>
</section>
<section id="demo-code">
<h2>Demo Code<a class="headerlink" href="#demo-code" title="Permalink to this heading">#</a></h2>
<section id="import-the-learner">
<h3>Import the learner.<a class="headerlink" href="#import-the-learner" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">causaldm.learners.CPL4.MAB</span> <span class="kn">import</span> <span class="n">TS</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>WARNING (theano.tensor.blas): Using NumPy C-API based implementation for BLAS functions.
</pre></div>
</div>
</div>
</div>
</section>
<section id="generate-the-environment">
<h3>Generate the Environment<a class="headerlink" href="#generate-the-environment" title="Permalink to this heading">#</a></h3>
<p>Here, we imitate an environment based on the MovieLens data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">causaldm.learners.CPL4.MAB</span> <span class="kn">import</span> <span class="n">_env_realMAB</span> <span class="k">as</span> <span class="n">_env</span>
<span class="n">env</span> <span class="o">=</span> <span class="n">_env</span><span class="o">.</span><span class="n">Single_Gaussian_Env</span><span class="p">(</span><span class="n">seed</span> <span class="o">=</span> <span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="specify-hyperparameters">
<h3>Specify Hyperparameters<a class="headerlink" href="#specify-hyperparameters" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Reward_Type: the type of the MAB, i.e., “Gaussian”/”Bernoulli”</p></li>
<li><p>sigma: the standard deviation of the reward distributions</p></li>
<li><p>u_prior_mean: mean of the prior distribution of the mean reward</p></li>
<li><p>u_prior_cov: Covaraince matrix of the prior distribution of the mean reward</p></li>
<li><p>seed: random seed</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Reward_Type</span> <span class="o">=</span> <span class="s2">&quot;Gaussian&quot;</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">K</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">K</span>
<span class="n">u_prior_mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">K</span><span class="p">)</span>
<span class="n">u_prior_cov</span> <span class="o">=</span> <span class="mi">10000</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">K</span><span class="p">)</span>
<span class="n">seed</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">TS_Gaussian_agent</span> <span class="o">=</span> <span class="n">TS</span><span class="o">.</span><span class="n">TS</span><span class="p">(</span><span class="n">Reward_Type</span> <span class="o">=</span> <span class="n">Reward_Type</span><span class="p">,</span> <span class="n">sigma</span> <span class="o">=</span> <span class="n">sigma</span><span class="p">,</span> 
                          <span class="n">u_prior_mean</span> <span class="o">=</span> <span class="n">u_prior_mean</span><span class="p">,</span> <span class="n">u_prior_cov</span> <span class="o">=</span> <span class="n">u_prior_cov</span><span class="p">,</span> 
                          <span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="recommendation-and-interaction">
<h3>Recommendation and Interaction<a class="headerlink" href="#recommendation-and-interaction" title="Permalink to this heading">#</a></h3>
<p>Starting from t = 0, for each step t, there are three steps:</p>
<ol class="arabic simple">
<li><p>Recommend an action
<code> A = TS_Gaussian_agent.take_action() </code></p></li>
<li><p>Get the reward from the environment
<code> R = env.get_reward(t,A) </code></p></li>
<li><p>Update the posterior distribution
<code> TS_Gaussian_agent.receive_reward(t,A,R) </code></p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">t</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">TS_Gaussian_agent</span><span class="o">.</span><span class="n">take_action</span><span class="p">()</span>
<span class="n">R</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">get_reward</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="n">TS_Gaussian_agent</span><span class="o">.</span><span class="n">receive_reward</span><span class="p">(</span><span class="n">t</span><span class="p">,</span><span class="n">A</span><span class="p">,</span><span class="n">R</span><span class="p">)</span>
<span class="n">t</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">R</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(0, 3, 2)
</pre></div>
</div>
</div>
</div>
<p><strong>Interpretation</strong>: For step 0, the TS agent recommend a Thriller (arm 3), and received a rate of 2 from the environment.</p>
</section>
<section id="demo-code-for-bernoulli-bandit">
<h3>Demo Code for Bernoulli Bandit<a class="headerlink" href="#demo-code-for-bernoulli-bandit" title="Permalink to this heading">#</a></h3>
<p>The steps are similar to those previously performed with a Gaussian Bandit. Note that, when specifying the prior distribution of the expected reward, the mean-precision form of the Beta distribution is used here, i.e., Beta(<span class="math notranslate nohighlight">\(\mu\)</span>, <span class="math notranslate nohighlight">\(\phi\)</span>), where <span class="math notranslate nohighlight">\(\mu\)</span> is the mean reward of each arm and <span class="math notranslate nohighlight">\(\phi\)</span> is the precision of the Beta distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">env</span> <span class="o">=</span> <span class="n">_env</span><span class="o">.</span><span class="n">Single_Bernoulli_Env</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="n">K</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">K</span>
<span class="n">Reward_Type</span> <span class="o">=</span> <span class="s2">&quot;Bernoulli&quot;</span>
<span class="c1">## specify the mean of the prior beta distribution</span>
<span class="n">u_prior_mean</span> <span class="o">=</span> <span class="mf">.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">K</span><span class="p">)</span>
<span class="c1">## specify the precision of the prior beta distribution</span>
<span class="n">prior_phi_beta</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">TS_Bernoulli_agent</span> <span class="o">=</span> <span class="n">TS</span><span class="o">.</span><span class="n">TS</span><span class="p">(</span><span class="n">Reward_Type</span> <span class="o">=</span> <span class="n">Reward_Type</span><span class="p">,</span>
                           <span class="n">u_prior_mean</span> <span class="o">=</span> <span class="n">u_prior_mean</span><span class="p">,</span>
                           <span class="n">prior_phi_beta</span> <span class="o">=</span> <span class="n">prior_phi_beta</span><span class="p">,</span>
                           <span class="n">seed</span> <span class="o">=</span> <span class="n">seed</span><span class="p">)</span>
<span class="n">t</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">A</span> <span class="o">=</span> <span class="n">TS_Bernoulli_agent</span><span class="o">.</span><span class="n">take_action</span><span class="p">()</span>
<span class="n">R</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">get_reward</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>
<span class="n">TS_Bernoulli_agent</span><span class="o">.</span><span class="n">receive_reward</span><span class="p">(</span><span class="n">t</span><span class="p">,</span><span class="n">A</span><span class="p">,</span><span class="n">R</span><span class="p">)</span>
<span class="n">t</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">R</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(0, 4, 0)
</pre></div>
</div>
</div>
</div>
<p><strong>Interpretation</strong>: For step 0, the TS agent recommend a Sci-Fi (arm 4), and received a reward of 0 from the environment.</p>
</section>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this heading">#</a></h2>
<p>[1] Russo, D., Van Roy, B., Kazerouni, A., Osband, I., and Wen, Z. (2017). A tutorial on thompson sampling. arXiv preprint arXiv:1707.0203</p>
<p>[2] Lattimore, T. and Szepesv´ari, C. (2020). Bandit algorithms. Cambridge University Press.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./4_Causal_Policy_Learning\Scenario4\MAB"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="UCB.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">UCB</p>
      </div>
    </a>
    <a class="right-next"
       href="../Contextual_Bandits/Contextual_Bandits.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Contextual Bandits</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">Overview</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#main-idea">Main Idea</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#algorithms-details">Algorithms Details</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-steps">Key Steps</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#demo-code">Demo Code</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#import-the-learner">Import the learner.</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#generate-the-environment">Generate the Environment</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#specify-hyperparameters">Specify Hyperparameters</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#recommendation-and-interaction">Recommendation and Interaction</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#demo-code-for-bernoulli-bandit">Demo Code for Bernoulli Bandit</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Causal Decision Making Team
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=365ca57ee442770a23c6"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=365ca57ee442770a23c6"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>