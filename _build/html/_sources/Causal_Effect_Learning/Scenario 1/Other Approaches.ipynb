{"cells":[{"cell_type":"markdown","source":["### **7. Generalized Random Forest**\n","\n","Developed by Susan Athey, Julie Tibshirani and Stefan Wager, Generalized Random Forest [8] aims to give the solution to a set of local moment equations:\n","\\begin{equation}\n","  \\mathbb{E}\\big[\\psi_{\\tau(s),\\nu(s)}(O_i)\\big| S_i=s\\big]=0,\n","\\end{equation}\n","where $\\tau(s)$ is the parameter we care about and $\\nu(s)$ is an optional nuisance parameter. In the problem of Heterogeneous Treatment Effect Evaluation, our parameter of interest $\\tau(s)=\\xi\\cdot \\beta(s)$ is identified by \n","\\begin{equation}\n","  \\psi_{\\beta(s),\\nu(s)}(R_i,A_i)=(R_i-\\beta(s)\\cdot A_i-c(s))(1 \\quad A_i^T)^T.\n","\\end{equation}\n","The induced estimator $\\hat{\\tau}(s)$ for $\\tau(s)$ can thus be solved by\n","\\begin{equation}\n","  \\hat{\\tau}(s)=\\xi^T\\left(\\sum_{i=1}^n \\alpha_i(s)\\big(A_i-\\bar{A}_\\alpha\\big)^{\\otimes 2}\\right)^{-1}\\sum_{i=1}^n \\alpha_i(s)\\big(A_i-\\bar{A}_\\alpha\\big)\\big(R_i-\\bar{R}_\\alpha\\big),\n","\\end{equation}\n","where $\\bar{A}_\\alpha=\\sum \\alpha_i(s)A_i$ and $\\bar{R}_\\alpha=\\sum \\alpha_i(s)R_i$, and we write $v^{\\otimes 2}=vv^T$.\n","\n","Notice that this formula is just a weighted version of R-learner introduced above. However, instead of using ordinary kernel weighting functions that are prone to a strong curse of dimensionality, GRF uses an adaptive weighting function $\\alpha_i(s)$ derived from a forest designed to express heterogeneity in the specified quantity of interest. \n","    \n","To be more specific, in order to obtain $\\alpha_i(s)$, GRF first grows a set of $B$ trees indexed by $1,\\dots,B$. Then for each such tree, define $L_b(s)$ as the set of training samples falling in the same ``leaf\" as x. The weights $\\alpha_i(s)$ then capture the frequency with which the $i$-th training example falls into the same leaf as $s$:\n","\\begin{equation}\n","  \\alpha_{bi}(s)=\\frac{\\boldsymbol{1}\\big(\\{S_i\\in L_b(s)\\}\\big)}{\\big|L_b(s)\\big|},\\quad \\alpha_i(s)=\\frac{1}{B}\\sum_{b=1}^B \\alpha_{bi}(s).\n","\\end{equation}\n","\n","To sum up, GRF aims to leverage the splitting result of a series of trees to decide the ``localized” weight for HTE estimation at each point $x_0$. Compared with kernel functions, we may expect tree-based weights to be more flexible and better performed in real settings.\n","\n"],"metadata":{"id":"SgWh47pKR1XR"},"id":"SgWh47pKR1XR"},{"cell_type":"code","source":["import sys\n","!{sys.executable} -m pip install scikit-uplift"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oJd6A5hgXmGZ","executionInfo":{"status":"ok","timestamp":1675479965923,"user_tz":300,"elapsed":4826,"user":{"displayName":"Yang Xu","userId":"12270366590264264299"}},"outputId":"7f2cb5c6-26e0-4d5a-9033-608d15f576e7"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting scikit-uplift\n","  Downloading scikit_uplift-0.5.1-py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 KB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from scikit-uplift) (3.2.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from scikit-uplift) (2.25.1)\n","Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.8/dist-packages (from scikit-uplift) (1.21.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from scikit-uplift) (4.64.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from scikit-uplift) (1.3.5)\n","Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.8/dist-packages (from scikit-uplift) (1.0.2)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.0->scikit-uplift) (1.7.3)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.0->scikit-uplift) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.0->scikit-uplift) (1.2.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->scikit-uplift) (1.4.4)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->scikit-uplift) (3.0.9)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->scikit-uplift) (0.11.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->scikit-uplift) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->scikit-uplift) (2022.7.1)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->scikit-uplift) (1.24.3)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->scikit-uplift) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->scikit-uplift) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->scikit-uplift) (2.10)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib->scikit-uplift) (1.15.0)\n","Installing collected packages: scikit-uplift\n","Successfully installed scikit-uplift-0.5.1\n"]}],"id":"oJd6A5hgXmGZ"},{"cell_type":"code","source":["# import related packages\n","from matplotlib import pyplot as plt\n","from lightgbm import LGBMRegressor\n","from sklearn.linear_model import LinearRegression\n","from sklearn.linear_model import LogisticRegression \n","from drive.MyDrive.CausalDM.causaldm._util_causaldm import *"],"metadata":{"id":"eRpP5k9MBtzO","executionInfo":{"status":"ok","timestamp":1675480045393,"user_tz":300,"elapsed":3512,"user":{"displayName":"Yang Xu","userId":"12270366590264264299"}}},"execution_count":3,"outputs":[],"id":"eRpP5k9MBtzO"},{"cell_type":"code","source":["n = 10**3  # sample size in observed data\n","n0 = 10**5 # the number of samples used to estimate the true reward distribution by MC\n","seed=223"],"metadata":{"id":"lovM_twTxuOj","executionInfo":{"status":"ok","timestamp":1675480045393,"user_tz":300,"elapsed":5,"user":{"displayName":"Yang Xu","userId":"12270366590264264299"}}},"execution_count":4,"outputs":[],"id":"lovM_twTxuOj"},{"cell_type":"code","source":["# Get data\n","data_behavior = get_data_simulation(n, seed, policy=\"behavior\")\n","#data_target = get_data_simulation(n0, seed, policy=\"target\")\n","\n","# The true expected heterogeneous treatment effect\n","HTE_true = get_data_simulation(n, seed, policy=\"1\")['R']-get_data_simulation(n, seed, policy=\"0\")['R']\n","\n"],"metadata":{"id":"AnRQO0viX3D1","executionInfo":{"status":"ok","timestamp":1675480045394,"user_tz":300,"elapsed":5,"user":{"displayName":"Yang Xu","userId":"12270366590264264299"}}},"execution_count":5,"outputs":[],"id":"AnRQO0viX3D1"},{"cell_type":"code","source":["# import the package for Causal Random Forest\n","! pip install econml"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fZT7U8YnNLGo","executionInfo":{"status":"ok","timestamp":1675480054329,"user_tz":300,"elapsed":4180,"user":{"displayName":"Yang Xu","userId":"12270366590264264299"}},"outputId":"b3d4a3ec-3680-4f86-906e-deeafd162109"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting econml\n","  Downloading econml-0.14.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m96.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: scikit-learn<1.2,>0.22.0 in /usr/local/lib/python3.8/dist-packages (from econml) (1.0.2)\n","Collecting sparse\n","  Downloading sparse-0.13.0-py2.py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 KB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: statsmodels>=0.10 in /usr/local/lib/python3.8/dist-packages (from econml) (0.12.2)\n","Requirement already satisfied: lightgbm in /usr/local/lib/python3.8/dist-packages (from econml) (2.2.3)\n","Requirement already satisfied: joblib>=0.13.0 in /usr/local/lib/python3.8/dist-packages (from econml) (1.2.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from econml) (1.21.6)\n","Collecting shap<0.41.0,>=0.38.1\n","  Downloading shap-0.40.0-cp38-cp38-manylinux2010_x86_64.whl (571 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.1/571.1 KB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from econml) (1.3.5)\n","Requirement already satisfied: scipy>1.4.0 in /usr/local/lib/python3.8/dist-packages (from econml) (1.7.3)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn<1.2,>0.22.0->econml) (3.1.0)\n","Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.8/dist-packages (from shap<0.41.0,>=0.38.1->econml) (23.0)\n","Requirement already satisfied: numba in /usr/local/lib/python3.8/dist-packages (from shap<0.41.0,>=0.38.1->econml) (0.56.4)\n","Requirement already satisfied: tqdm>4.25.0 in /usr/local/lib/python3.8/dist-packages (from shap<0.41.0,>=0.38.1->econml) (4.64.1)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.8/dist-packages (from shap<0.41.0,>=0.38.1->econml) (2.2.1)\n","Collecting slicer==0.0.7\n","  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n","Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.8/dist-packages (from statsmodels>=0.10->econml) (0.5.3)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->econml) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->econml) (2022.7.1)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.8/dist-packages (from numba->shap<0.41.0,>=0.38.1->econml) (6.0.0)\n","Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba->shap<0.41.0,>=0.38.1->econml) (0.39.1)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba->shap<0.41.0,>=0.38.1->econml) (57.4.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from patsy>=0.5->statsmodels>=0.10->econml) (1.15.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata->numba->shap<0.41.0,>=0.38.1->econml) (3.12.0)\n","Installing collected packages: slicer, sparse, shap, econml\n","Successfully installed econml-0.14.0 shap-0.40.0 slicer-0.0.7 sparse-0.13.0\n"]}],"id":"fZT7U8YnNLGo"},{"cell_type":"code","source":["# A demo code of Causal Random Forest\n","from econml.grf import CausalForest, CausalIVForest, RegressionForest\n","from econml.dml import CausalForestDML\n","est = CausalForest(criterion='het', n_estimators=400, min_samples_leaf=5, max_depth=None,\n","                    min_var_fraction_leaf=None, min_var_leaf_on_val=True,\n","                    min_impurity_decrease = 0.0, max_samples=0.45, min_balancedness_tol=.45,\n","                    warm_start=False, inference=True, fit_intercept=True, subforest_size=4,\n","                    honest=True, verbose=0, n_jobs=-1, random_state=1235)\n","\n","\n","est.fit(data_behavior.iloc[:,0:2], data_behavior['A'], data_behavior['R'])\n","\n","HTE_GRF = est.predict(data_behavior.iloc[:,0:2], interval=False, alpha=0.05)\n","HTE_GRF = HTE_GRF.flatten()\n"],"metadata":{"id":"gk0nYH559XIL","executionInfo":{"status":"ok","timestamp":1675480056533,"user_tz":300,"elapsed":2210,"user":{"displayName":"Yang Xu","userId":"12270366590264264299"}}},"execution_count":7,"outputs":[],"id":"gk0nYH559XIL"},{"cell_type":"code","source":["print(\"Generalized Random Forest:  \",HTE_GRF[0:8])\n","print(\"true value:                 \",HTE_true[0:8].to_numpy())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675480056535,"user_tz":300,"elapsed":27,"user":{"displayName":"Yang Xu","userId":"12270366590264264299"}},"outputId":"8ec90bcb-06a2-41f2-fda2-c9d5b0c110f6","id":"cNcRW6yBOQJy"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Generalized Random Forest:   [-1.2344  1.612  -0.7801  0.6886 -0.6297  0.2293  0.4417 -0.819 ]\n","true value:                  [ 1.2961 -0.4475  0.731   0.2863  0.4471 -0.1839 -3.3869 -1.238 ]\n"]}],"id":"cNcRW6yBOQJy"},{"cell_type":"markdown","source":["Causal Forest performs just okay in this example."],"metadata":{"id":"_djs10pxOQJ1"},"id":"_djs10pxOQJ1"},{"cell_type":"code","source":["Bias_GRF = np.sum(HTE_GRF-HTE_true)/n\n","Variance_GRF = np.sum((HTE_GRF-HTE_true)**2)/n\n","print(\"The overall estimation bias of Generalized Random Forest is :     \", Bias_GRF, \", \\n\", \"The overall estimation variance of Generalized Random Forest is :\",Variance_GRF ,\". \\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1675480056538,"user_tz":300,"elapsed":22,"user":{"displayName":"Yang Xu","userId":"12270366590264264299"}},"outputId":"f0409488-3aab-4d84-84d0-40587cab54c6","id":"0p9XqW8DOQJ2"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["The overall estimation bias of Generalized Random Forest is :      0.706857912147952 , \n"," The overall estimation variance of Generalized Random Forest is : 5.198946462195667 . \n","\n"]}],"id":"0p9XqW8DOQJ2"},{"cell_type":"code","source":[],"metadata":{"id":"ZotDk-EKZMGY"},"id":"ZotDk-EKZMGY","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **8. Dragon Net**\n","\n","\n","\n"],"metadata":{"id":"XUdcqLkabYny"},"id":"XUdcqLkabYny"},{"cell_type":"code","source":[],"metadata":{"id":"LAtbTkgLbcZU"},"id":"LAtbTkgLbcZU","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1098b550"},"source":["## References\n","\n","8. Susan Athey, Julie Tibshirani, and Stefan Wager. Generalized random forests. The Annals of Statistics, 47(2):1148–1178, 2019."],"id":"1098b550"}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[],"collapsed_sections":["1098b550"]}},"nbformat":4,"nbformat_minor":5}