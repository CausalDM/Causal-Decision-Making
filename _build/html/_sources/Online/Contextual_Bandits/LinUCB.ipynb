{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3ca32e0",
   "metadata": {},
   "source": [
    "# Epsilon_Greedy\n",
    "\n",
    "## Main Idea\n",
    "An overview of the learner include:\n",
    "1. a brief introduction of the learner \n",
    "2. evolution of the learner (i.e. when it is first developed, any alternative extensions?)\n",
    "3. Application situations: Describe the data structure that can be analyzed, and make a connection between the real application situations (mentioned in the Motivating Examples) and the learner (i.e., when can we use the learner) \n",
    "4. the advantage of the learner\n",
    "\n",
    "## Algorithm Details\n",
    "a detailed description of the learner with clear definitions of key concepts.\n",
    "\n",
    "## Key Steps\n",
    "an abstract pseudo-code for policy learning and policy evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea1be59",
   "metadata": {},
   "source": [
    "## Demo Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3b02f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After we publish the pack age, we can directly import it\n",
    "# TODO: explore more efficient way\n",
    "# we can hide this cell later\n",
    "import os\n",
    "os.getcwd()\n",
    "os.chdir('/nas/longleaf/home/lge/CausalDM')\n",
    "# code used to import the learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "291f88a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from causaldm.learners.Online.Single import LinUCB\n",
    "from causaldm.learners.Online.Single import Env\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9c17056",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 2000\n",
    "K = 5\n",
    "with_intercept = True\n",
    "p=3\n",
    "X_mu = np.zeros(p-1)\n",
    "X_sigma = np.identity(p-1)\n",
    "Sigma_theta = sigma_gamma = np.identity(p)\n",
    "mu_theta = np.zeros(p)\n",
    "seed = 0\n",
    "sigma = 1\n",
    "\n",
    "env = Env.Single_Gaussian_Env(T, K, p, sigma\n",
    "                         , mu_theta, Sigma_theta\n",
    "                        , seed = 42, with_intercept = True\n",
    "                         , X_mu = X_mu, X_Sigma = X_sigma)\n",
    "LinUCB_Gaussian_agent = LinUCB.LinUCB_Gaussian(alpha = .5, K = K, p = p)\n",
    "A = LinUCB_Gaussian_agent.take_action(env.Phi)\n",
    "t = 0\n",
    "R = env.get_reward(t,A)\n",
    "LinUCB_Gaussian_agent.receive_reward(t,A,R, env.Phi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc79fede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LinUCB_Gaussian_agent.cnts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ee7a2a",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Agrawal, S., & Goyal, N. (2013, May). Thompson sampling for contextual bandits with linear payoffs. In International conference on machine learning (pp. 127-135). PMLR.\n",
    "\n",
    "[2] Kveton, B., Zaheer, M., Szepesvari, C., Li, L., Ghavamzadeh, M., & Boutilier, C. (2020, June). Randomized exploration in generalized linear bandits. In International Conference on Artificial Intelligence and Statistics (pp. 2066-2076). PMLR."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
