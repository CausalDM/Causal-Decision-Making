Search.setIndex({"docnames": ["0_Learner Template", "0_Motivating_Examples/CEL", "0_Motivating_Examples/CPL", "0_Motivating_Examples/CSL", "1_Preliminary/(old) Causal Inference 101", "1_Preliminary/Causal Inference 101_old", "1_Preliminary/Causal Inference Preliminary", "1_Preliminary/Policy Evaluation and Optimization", "1_Preliminary/Preliminary", "2_Causal_Structure_Learning/Causal Discovery", "2_Causal_Structure_Learning/Causal Mediation Analysis with Causal Discovery", "2_Causal_Structure_Learning/Functional-based Learner", "2_Causal_Structure_Learning/Preliminaries of Causal Graphs", "2_Causal_Structure_Learning/Score-based Learner", "2_Causal_Structure_Learning/Testing-based Learner", "3_Causal_Effect_Learning/Scenario 1/ATE", "3_Causal_Effect_Learning/Scenario 1/DR-Learner", "3_Causal_Effect_Learning/Scenario 1/Dragonnet", "3_Causal_Effect_Learning/Scenario 1/GRF", "3_Causal_Effect_Learning/Scenario 1/HTE", "3_Causal_Effect_Learning/Scenario 1/Lp-R-Learner", "3_Causal_Effect_Learning/Scenario 1/Meta Learners", "3_Causal_Effect_Learning/Scenario 1/Other Approaches", "3_Causal_Effect_Learning/Scenario 1/R-Learner", "3_Causal_Effect_Learning/Scenario 1/R-Learner, DR-Learner, Lp-R-Learner", "3_Causal_Effect_Learning/Scenario 1/S-learner", "3_Causal_Effect_Learning/Scenario 1/Single Stage", "3_Causal_Effect_Learning/Scenario 1/T-learner", "3_Causal_Effect_Learning/Scenario 1/X-learner", "3_Causal_Effect_Learning/Scenario 2/ATE", "3_Causal_Effect_Learning/Scenario 2/HTE", "3_Causal_Effect_Learning/Scenario 2/underMDP", "3_Causal_Effect_Learning/Scenario 3/Multiple Stage", "3_Causal_Effect_Learning/Scenario 4/Miscellaneous", "4_Causal_Policy_Learning/Scenario1/A-learning_Single", "4_Causal_Policy_Learning/Scenario1/Classification", "4_Causal_Policy_Learning/Scenario1/Classification/E-learning", "4_Causal_Policy_Learning/Scenario1/Classification/O-Learning", "4_Causal_Policy_Learning/Scenario1/Continuous", "4_Causal_Policy_Learning/Scenario1/Continuous/Deep Jump Learner", "4_Causal_Policy_Learning/Scenario1/Continuous/Kernel-Based Learner", "4_Causal_Policy_Learning/Scenario1/Continuous/Outcome Learning", "4_Causal_Policy_Learning/Scenario1/Discrete", "4_Causal_Policy_Learning/Scenario1/Micellaneous/Adaptively Collected Data", "4_Causal_Policy_Learning/Scenario1/Micellaneous/Concordance", "4_Causal_Policy_Learning/Scenario1/Micellaneous/Policy Search", "4_Causal_Policy_Learning/Scenario1/Micellaneous/Survival", "4_Causal_Policy_Learning/Scenario1/PlanToDo", "4_Causal_Policy_Learning/Scenario1/Q-learning_Single", "4_Causal_Policy_Learning/Scenario1/Quantile/QuantileOTR_test", "4_Causal_Policy_Learning/Scenario1/Single Stage", "4_Causal_Policy_Learning/Scenario1/Test/A_Q test", "4_Causal_Policy_Learning/Scenario2/DR_Infinite", "4_Causal_Policy_Learning/Scenario2/Deeply_Debiased", "4_Causal_Policy_Learning/Scenario2/Evaluation", "4_Causal_Policy_Learning/Scenario2/FQE", "4_Causal_Policy_Learning/Scenario2/FQI", "4_Causal_Policy_Learning/Scenario2/IPW_Infinite", "4_Causal_Policy_Learning/Scenario2/Inference", "4_Causal_Policy_Learning/Scenario2/Model_based_Infinite", "4_Causal_Policy_Learning/Scenario2/Optimization", "4_Causal_Policy_Learning/Scenario2/Spatial_temporal_DR", "4_Causal_Policy_Learning/Scenario2/preliminary_MDP", "4_Causal_Policy_Learning/Scenario2/preliminary_MDP-potential-outcome", "4_Causal_Policy_Learning/Scenario3/A-learning_Multiple", "4_Causal_Policy_Learning/Scenario3/Multi Stage", "4_Causal_Policy_Learning/Scenario3/Q-learning_Multiple", "4_Causal_Policy_Learning/Scenario4/Bandits", "4_Causal_Policy_Learning/Scenario4/Contextual_Bandits/Contextual_Bandits", "4_Causal_Policy_Learning/Scenario4/Contextual_Bandits/LinTS", "4_Causal_Policy_Learning/Scenario4/Contextual_Bandits/LinUCB", "4_Causal_Policy_Learning/Scenario4/MAB/Epsilon_Greedy", "4_Causal_Policy_Learning/Scenario4/MAB/MAB", "4_Causal_Policy_Learning/Scenario4/MAB/TS", "4_Causal_Policy_Learning/Scenario4/MAB/UCB", "4_Causal_Policy_Learning/Scenario4/Meta_Bandits/MTTS", "4_Causal_Policy_Learning/Scenario4/Meta_Bandits/Meta_Bandits", "4_Causal_Policy_Learning/Scenario4/Meta_Bandits/Meta_TS", "4_Causal_Policy_Learning/Scenario4/OnlineEval/Direct Online Policy Evaluator", "4_Causal_Policy_Learning/Scenario4/OnlineEval/Doubly Robust Online Policy Evaluator", "4_Causal_Policy_Learning/Scenario4/OnlineEval/Inverse Probability Weighted Online Policy Evaluator", "4_Causal_Policy_Learning/Scenario4/OnlineEval/Online Policy Evaluation", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/CascadeLinTS", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/Learning to rank", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/MTSS_Cascade", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/TS_Cascade", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/CombLinTS", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/CombTS", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/Combinatorial Optimization", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/MTSS_Comb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/Assortment Optimization", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/MTSS_MNL", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/TS_Contextual_MNL", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/TS_MNL_Beta", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/UCB-MNL", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Structured_Bandit", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single-Item Recommendation", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/Epsilon Greedy", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/LinTS", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/LinUCB", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/Multi-Task", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/MultiTask/MTTS", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/MultiTask/Meta-TS", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/TS", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/UCB1", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Slate Recommendation", "4_Causal_Policy_Learning/Scenario5/OnlineRL", "4_Causal_Policy_Learning/Scenario6/OnlineRL_non_Markov", "5_Case_Study/MIMIC3/Case_Study_1", "5_Case_Study/MIMIC3/MIMIC3-Demo", "5_Case_Study/MovieLens/Case_Study_2", "Overview", "README", "_old files(to delete)/Map"], "filenames": ["0_Learner Template.ipynb", "0_Motivating_Examples/CEL.ipynb", "0_Motivating_Examples/CPL.ipynb", "0_Motivating_Examples/CSL.ipynb", "1_Preliminary/(old) Causal Inference 101.ipynb", "1_Preliminary/Causal Inference 101_old.md", "1_Preliminary/Causal Inference Preliminary.ipynb", "1_Preliminary/Policy Evaluation and Optimization.md", "1_Preliminary/Preliminary.md", "2_Causal_Structure_Learning/Causal Discovery.ipynb", "2_Causal_Structure_Learning/Causal Mediation Analysis with Causal Discovery.ipynb", "2_Causal_Structure_Learning/Functional-based Learner.ipynb", "2_Causal_Structure_Learning/Preliminaries of Causal Graphs.ipynb", "2_Causal_Structure_Learning/Score-based Learner.ipynb", "2_Causal_Structure_Learning/Testing-based Learner.ipynb", "3_Causal_Effect_Learning/Scenario 1/ATE.ipynb", "3_Causal_Effect_Learning/Scenario 1/DR-Learner.ipynb", "3_Causal_Effect_Learning/Scenario 1/Dragonnet.ipynb", "3_Causal_Effect_Learning/Scenario 1/GRF.ipynb", "3_Causal_Effect_Learning/Scenario 1/HTE.ipynb", "3_Causal_Effect_Learning/Scenario 1/Lp-R-Learner.ipynb", "3_Causal_Effect_Learning/Scenario 1/Meta Learners.ipynb", "3_Causal_Effect_Learning/Scenario 1/Other Approaches.ipynb", "3_Causal_Effect_Learning/Scenario 1/R-Learner.ipynb", "3_Causal_Effect_Learning/Scenario 1/R-Learner, DR-Learner, Lp-R-Learner.ipynb", "3_Causal_Effect_Learning/Scenario 1/S-learner.ipynb", "3_Causal_Effect_Learning/Scenario 1/Single Stage.ipynb", "3_Causal_Effect_Learning/Scenario 1/T-learner.ipynb", "3_Causal_Effect_Learning/Scenario 1/X-learner.ipynb", "3_Causal_Effect_Learning/Scenario 2/ATE.md", "3_Causal_Effect_Learning/Scenario 2/HTE.md", "3_Causal_Effect_Learning/Scenario 2/underMDP.md", "3_Causal_Effect_Learning/Scenario 3/Multiple Stage.md", "3_Causal_Effect_Learning/Scenario 4/Miscellaneous.md", "4_Causal_Policy_Learning/Scenario1/A-learning_Single.ipynb", "4_Causal_Policy_Learning/Scenario1/Classification.md", "4_Causal_Policy_Learning/Scenario1/Classification/E-learning.ipynb", "4_Causal_Policy_Learning/Scenario1/Classification/O-Learning.ipynb", "4_Causal_Policy_Learning/Scenario1/Continuous.md", "4_Causal_Policy_Learning/Scenario1/Continuous/Deep Jump Learner.ipynb", "4_Causal_Policy_Learning/Scenario1/Continuous/Kernel-Based Learner.md", "4_Causal_Policy_Learning/Scenario1/Continuous/Outcome Learning.md", "4_Causal_Policy_Learning/Scenario1/Discrete.md", "4_Causal_Policy_Learning/Scenario1/Micellaneous/Adaptively Collected Data.ipynb", "4_Causal_Policy_Learning/Scenario1/Micellaneous/Concordance.ipynb", "4_Causal_Policy_Learning/Scenario1/Micellaneous/Policy Search.ipynb", "4_Causal_Policy_Learning/Scenario1/Micellaneous/Survival.ipynb", "4_Causal_Policy_Learning/Scenario1/PlanToDo.md", "4_Causal_Policy_Learning/Scenario1/Q-learning_Single.ipynb", "4_Causal_Policy_Learning/Scenario1/Quantile/QuantileOTR_test.ipynb", "4_Causal_Policy_Learning/Scenario1/Single Stage.md", "4_Causal_Policy_Learning/Scenario1/Test/A_Q test.ipynb", "4_Causal_Policy_Learning/Scenario2/DR_Infinite.ipynb", "4_Causal_Policy_Learning/Scenario2/Deeply_Debiased.ipynb", "4_Causal_Policy_Learning/Scenario2/Evaluation.md", "4_Causal_Policy_Learning/Scenario2/FQE.ipynb", "4_Causal_Policy_Learning/Scenario2/FQI.ipynb", "4_Causal_Policy_Learning/Scenario2/IPW_Infinite.ipynb", "4_Causal_Policy_Learning/Scenario2/Inference.ipynb", "4_Causal_Policy_Learning/Scenario2/Model_based_Infinite.ipynb", "4_Causal_Policy_Learning/Scenario2/Optimization.md", "4_Causal_Policy_Learning/Scenario2/Spatial_temporal_DR.ipynb", "4_Causal_Policy_Learning/Scenario2/preliminary_MDP.ipynb", "4_Causal_Policy_Learning/Scenario2/preliminary_MDP-potential-outcome.ipynb", "4_Causal_Policy_Learning/Scenario3/A-learning_Multiple.ipynb", "4_Causal_Policy_Learning/Scenario3/Multi Stage.md", "4_Causal_Policy_Learning/Scenario3/Q-learning_Multiple.ipynb", "4_Causal_Policy_Learning/Scenario4/Bandits.md", "4_Causal_Policy_Learning/Scenario4/Contextual_Bandits/Contextual_Bandits.ipynb", "4_Causal_Policy_Learning/Scenario4/Contextual_Bandits/LinTS.ipynb", "4_Causal_Policy_Learning/Scenario4/Contextual_Bandits/LinUCB.ipynb", "4_Causal_Policy_Learning/Scenario4/MAB/Epsilon_Greedy.ipynb", "4_Causal_Policy_Learning/Scenario4/MAB/MAB.ipynb", "4_Causal_Policy_Learning/Scenario4/MAB/TS.ipynb", "4_Causal_Policy_Learning/Scenario4/MAB/UCB.ipynb", "4_Causal_Policy_Learning/Scenario4/Meta_Bandits/MTTS.ipynb", "4_Causal_Policy_Learning/Scenario4/Meta_Bandits/Meta_Bandits.ipynb", "4_Causal_Policy_Learning/Scenario4/Meta_Bandits/Meta_TS.ipynb", "4_Causal_Policy_Learning/Scenario4/OnlineEval/Direct Online Policy Evaluator.ipynb", "4_Causal_Policy_Learning/Scenario4/OnlineEval/Doubly Robust Online Policy Evaluator.ipynb", "4_Causal_Policy_Learning/Scenario4/OnlineEval/Inverse Probability Weighted Online Policy Evaluator.ipynb", "4_Causal_Policy_Learning/Scenario4/OnlineEval/Online Policy Evaluation.md", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/CascadeLinTS.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/Learning to rank.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/MTSS_Cascade.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/TS_Cascade.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/CombLinTS.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/CombTS.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/Combinatorial Optimization.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/MTSS_Comb.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/Assortment Optimization.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/MTSS_MNL.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/TS_Contextual_MNL.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/TS_MNL_Beta.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/UCB-MNL.ipynb", "4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Structured_Bandit.ipynb", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single-Item Recommendation.ipynb", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/Epsilon Greedy.ipynb", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/LinTS.ipynb", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/LinUCB.md", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/Multi-Task.md", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/MultiTask/MTTS.md", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/MultiTask/Meta-TS.md", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/TS.ipynb", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Single/UCB1.ipynb", "4_Causal_Policy_Learning/Scenario4/_old_docs(to delete)/Slate Recommendation.ipynb", "4_Causal_Policy_Learning/Scenario5/OnlineRL.md", "4_Causal_Policy_Learning/Scenario6/OnlineRL_non_Markov.ipynb", "5_Case_Study/MIMIC3/Case_Study_1.md", "5_Case_Study/MIMIC3/MIMIC3-Demo.ipynb", "5_Case_Study/MovieLens/Case_Study_2.md", "Overview.md", "README.md", "_old files(to delete)/Map.md"], "titles": ["Learner Name (Single/Multiple Stages/Infinite Horizon)", "<em>Causal Effect Learning (CEL)</em>", "<em>Causal Policy Learning (CPL)</em>", "<em>Causal Structure Learning (CSL)</em>", "Causal Inference 101", "Causal Inference 101", "Causal Inference Preliminary", "Policy Evaluation and Optimization", "Preliminary", "Causal Discovery", "Causal Mediation Analysis with Causal Discovery", "Functional-based Learner", "Preliminaries of Causal Graphs", "Score-based Learner", "Testing-based Learner", "ATE Estimation", "<strong>5. DR-learner</strong>", "<strong>8. Dragon Net</strong>", "<strong>7. Generalized Random Forest</strong>", "HTE Estimation", "<strong>6. Lp-R-learner</strong>", "<strong>Meta Learners</strong>", "<strong>Other Approaches</strong>", "<strong>4. R learner</strong>", "<strong>R-Learner, DR-Learner, and Lp-R-Learner</strong>", "<strong>1. S-learner</strong>", "<strong>Single Stage</strong>", "<strong>2. T-learner</strong>", "<strong>3. X-learner</strong>", "ATE", "HTE", "Markov Decision Processes", "Multiple Stage\u2013Finite Horizon", "Miscellaneous", "A-Learning (Single Stage)", "Reduction to Classification Problems", "Entropy learning", "Outcome Weighted Learning", "Continuous Action Space", "Deep Jump Learner for Continuous Actions", "Kernel-Based Learner", "Outcome Learning", "Discrete Action Space", "Adaptively Collected Data", "Concordance-assisted learning", "Policy Search", "Time-to-Event Data", "Plan To Do", "Q-Learning (Single Stage)", "<strong>Quantile Optimal Treatment Regime</strong>", "Single Stage (DTR)", "Test A-Learning Single", "Doubly Robust Estimator for Policy Evaluation (Infinite Horizon)", "Deeply-Debiased Off-Policy Evaluation", "Policy Evaluation", "Fitted-Q Evaluation", "Fitted-Q Iteration", "Importance Sampling for Policy Evaluation (Infinite Horizon)", "Confidence Interval in OPE", "Q-Learning (Infinite Horizon)", "Policy Optimization", "Infinite Horizon Importance Sampling for Policy Evaluation", "Preliminary: Off-policy Evaluation and Optimization in Markov Decision Processes", "Preliminary: Off-policy Evaluation and Optimization in Markov Decision Processes", "A-Learning (Multiple Stages)", "Multiple Stages (DTR)", "Q-Learning (Multiple Stages)", "Overview: Bandits ALgorithm", "Contextual Bandits", "LinTS", "LinUCB", "<span class=\"math notranslate nohighlight\">\\(\\epsilon\\)</span>-Greedy", "Multi-Armed Bandits (MAB)", "TS", "UCB", "Multi-Task Thompson Sampling (MTTS)", "Meta Bandits", "Meta Thompson Sampling", "Direct Online Policy Evaluator", "Doubly Robust Online Policy Evaluator", "Inverse Probability Weighted Online Policy Evaluator", "Online Policy Evaluation", "CascadeLinTS", "Online Learning to Rank (Cascading Bandit)", "MTSS_Cascade", "TS_Cascade", "CombLinTS", "CombTS", "Online Combinatorial Optimization (Combinatorial Semi-Bandit)", "MTSS_Comb", "Dynamic Assortment Optimization (Multinomial Logit Bandit)", "MTSS_MNL", "TS_Contextual_MNL", "TS_MNL", "UCB_MNL", "Structured Bandit (Slate Recommendation)", "Single-Item Recommendation", "Epsilon_Greedy", "LinTS", "LinUCB", "Multi-Task", "MTTS", "Meta-TS", "TS", "UCB1", "Slate Recommendation", "Online RL", "Ooline Policy Learning in Non-Markov Environments", "MIMIC III", "Mimic3 Demo", "MovieLens", "Overview", "Content of every notebook", "&lt;no title&gt;"], "terms": {"an": [0, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 24, 27, 28, 34, 37, 39, 48, 49, 50, 53, 55, 56, 57, 58, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 103, 104, 105, 107, 111, 112], "overview": [0, 10, 11, 12, 14], "includ": [0, 2, 5, 9, 26, 48, 50, 63, 64, 65, 66, 67, 68, 72, 73, 76, 78, 79, 80, 82, 84, 86, 87, 88, 89, 91, 92, 93, 95, 96, 97, 98, 103, 104, 105, 109, 111], "brief": [0, 111], "introduct": [0, 5, 62, 63, 68, 71, 72, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94, 96, 97, 107], "evolut": 0, "i": [0, 2, 4, 6, 9, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 24, 25, 34, 39, 48, 49, 50, 52, 53, 55, 56, 57, 58, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98, 103, 104, 105], "e": [0, 2, 4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 34, 37, 39, 48, 49, 50, 52, 53, 55, 56, 57, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 73, 75, 76, 77, 78, 79, 80, 82, 84, 85, 86, 87, 89, 90, 91, 92, 93, 96, 98, 103, 104, 111], "when": [0, 2, 4, 5, 6, 10, 12, 13, 14, 15, 19, 21, 27, 39, 49, 52, 53, 55, 57, 61, 62, 63, 69, 73, 75, 77, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 98, 103, 105, 111], "first": [0, 5, 9, 10, 14, 15, 18, 19, 20, 21, 22, 24, 25, 27, 37, 48, 49, 52, 53, 55, 61, 68, 74, 75, 79, 80, 82, 84, 85, 93, 104, 111, 112], "develop": [0, 2, 9, 14, 18, 22, 37, 39, 76, 87, 92, 93], "ani": [0, 4, 5, 6, 9, 11, 13, 15, 16, 18, 19, 21, 22, 25, 27, 28, 39, 49, 52, 53, 57, 61, 62, 63, 65, 67, 68, 74, 76, 82, 83, 84, 85, 95, 105, 111], "altern": [0, 15, 34, 64, 90], "extens": [0, 5, 19, 20, 24, 34, 48, 52, 53, 61, 64, 66, 68, 72, 96], "applic": [0, 2, 3, 9, 10, 12, 37, 39, 52, 55, 57, 62, 63, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96, 105], "situat": [0, 11, 13, 14, 39, 52, 55, 57, 68, 69, 70, 71, 73, 74, 75, 77, 78, 79, 80, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94], "describ": [0, 6, 26, 95, 109, 112], "data": [0, 2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 34, 37, 39, 48, 52, 53, 57, 61, 62, 63, 64, 66, 69, 70, 71, 73, 74, 75, 77, 78, 79, 80, 94, 109], "structur": [0, 2, 5, 10, 12, 15, 19, 34, 37, 48, 53, 64, 65, 66, 67, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93], "can": [0, 2, 4, 5, 6, 9, 10, 11, 13, 15, 18, 19, 20, 21, 22, 24, 25, 27, 28, 34, 37, 39, 48, 49, 50, 52, 53, 55, 56, 57, 58, 59, 61, 63, 64, 66, 67, 69, 71, 73, 75, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 103, 104, 105, 111, 112], "analyz": 0, "make": [0, 4, 6, 9, 10, 11, 13, 14, 15, 39, 48, 49, 66, 67, 68, 71, 78, 79, 80, 111, 112], "connect": [0, 12, 63, 107], "between": [0, 2, 4, 6, 14, 15, 19, 21, 28, 34, 39, 48, 51, 57, 61, 63, 64, 70, 73, 75, 79, 80, 84, 85, 91, 92, 93, 96, 111], "real": [0, 2, 3, 9, 12, 18, 19, 20, 22, 24, 34, 39, 48, 64, 66, 67, 78, 79, 80, 82, 87, 94], "mention": [0, 61, 111], "motiv": [0, 2, 4, 15, 48, 52, 53, 55, 56, 61, 62, 66, 68, 72, 76, 82, 83, 88, 90], "exampl": [0, 2, 4, 5, 6, 9, 14, 18, 19, 21, 22, 34, 48, 49, 52, 53, 61, 64, 66, 67, 68, 69, 71, 72, 73, 74, 76, 83, 84, 88, 89, 90, 91, 98, 103, 111], "we": [0, 2, 3, 4, 6, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 25, 26, 34, 37, 39, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 103, 104, 105, 107, 109, 111, 112], "us": [0, 2, 4, 6, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 34, 39, 48, 49, 50, 51, 53, 56, 57, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 89, 91, 92, 93, 94, 95, 96, 97, 98, 103, 104, 105, 107, 109, 111, 112], "advantag": [0, 11, 13, 14, 34, 39, 49, 52, 53, 55, 57, 58, 64, 69, 70, 71, 73, 74, 75, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 96, 111, 112], "descript": [0, 83, 88, 90, 105], "clear": 0, "definit": [0, 10, 26, 34, 49, 53, 55, 62, 63, 64, 83, 109], "concept": [0, 19, 63, 83, 107], "abstract": 0, "pseudo": [0, 16, 24, 49, 64, 66, 112], "In": [0, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 23, 24, 26, 27, 34, 37, 39, 48, 49, 52, 53, 57, 58, 61, 62, 63, 64, 66, 67, 68, 69, 70, 72, 73, 76, 77, 78, 79, 80, 82, 83, 85, 86, 87, 88, 89, 90, 91, 93, 94, 95, 96, 98, 103, 105, 107, 109, 111], "follow": [0, 2, 3, 4, 5, 9, 10, 11, 13, 14, 15, 19, 21, 23, 24, 26, 34, 37, 39, 48, 49, 50, 52, 53, 55, 56, 57, 58, 61, 62, 63, 64, 65, 66, 67, 68, 72, 78, 79, 80, 84, 85, 89, 91, 94, 95, 96, 105, 109, 111], "exhibit": [0, 34, 39, 48, 64, 66, 78, 79, 80, 94], "how": [0, 2, 3, 9, 10, 12, 21, 34, 37, 39, 48, 49, 50, 51, 52, 61, 64, 66, 67, 68, 76, 78, 79, 80, 94, 95, 105], "appli": [0, 10, 11, 16, 19, 20, 23, 24, 34, 39, 48, 49, 52, 53, 57, 61, 64, 66, 72, 75, 77, 78, 79, 80, 94, 96, 111], "do": [0, 5, 10, 12, 15, 23, 24, 34, 37, 39, 48, 49, 64, 66, 70, 74, 85, 87, 93, 104, 111], "respect": [0, 4, 6, 9, 13, 34, 39, 48, 49, 52, 55, 57, 61, 62, 63, 64, 66, 78, 79, 80], "import": [0, 2, 3, 10, 11, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 34, 37, 39, 48, 49, 50, 51, 52, 53, 55, 56, 58, 59, 63, 64, 66, 94, 97, 98, 103, 104, 109], "from": [0, 2, 3, 4, 6, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 34, 37, 39, 48, 49, 50, 51, 52, 53, 57, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 103, 104, 105, 107, 111], "causaldm": [0, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 34, 37, 48, 50, 51, 52, 53, 55, 56, 57, 58, 59, 61, 64, 66, 69, 70, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94, 97, 98, 103, 104, 112], "alearn": [0, 34, 51, 64], "test": [0, 9, 10, 11, 12, 13, 16, 20, 23, 24, 26, 34, 37, 48, 64, 66, 109, 111], "shared_simul": [0, 37, 51, 64, 66], "numpi": [0, 10, 11, 13, 14, 16, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 34, 37, 49, 51, 64, 66, 69, 70, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94, 97, 98, 103, 104, 109], "np": [0, 10, 11, 13, 14, 16, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 34, 37, 39, 49, 51, 64, 66, 69, 70, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94, 97, 98, 103, 104, 109], "modulenotfounderror": [0, 10, 11, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 34, 39, 48, 51, 64, 66], "traceback": [0, 10, 11, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 34, 37, 39, 48, 49, 51, 52, 53, 55, 56, 57, 58, 59, 61, 64, 66, 69, 70, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94, 97, 98, 103, 104, 109], "most": [0, 2, 5, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 34, 37, 39, 48, 49, 51, 52, 53, 55, 56, 57, 58, 59, 61, 62, 63, 64, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 103, 104, 105, 109, 111], "recent": [0, 2, 3, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 34, 37, 39, 48, 49, 51, 52, 53, 55, 56, 57, 58, 59, 61, 64, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94, 96, 97, 98, 103, 104, 109, 112], "call": [0, 4, 5, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 34, 37, 39, 48, 49, 51, 52, 53, 55, 56, 57, 58, 59, 61, 64, 66, 69, 70, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94, 97, 98, 103, 104, 109, 112], "last": [0, 9, 10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 34, 37, 39, 48, 49, 50, 51, 52, 53, 55, 56, 57, 58, 59, 61, 62, 64, 66, 69, 70, 71, 73, 74, 75, 77, 79, 80, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94, 97, 98, 103, 104, 109, 111], "var": [0, 10, 11, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 34, 37, 39, 48, 49, 51, 52, 53, 55, 56, 57, 58, 59, 61, 64, 66, 69, 70, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94, 97, 98, 103, 104, 109], "folder": [0, 10, 11, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 34, 37, 39, 48, 49, 51, 52, 53, 55, 56, 57, 58, 59, 61, 64, 66, 69, 70, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94, 97, 98, 103, 104, 109, 112], "9j": [0, 10, 11, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 34, 37, 39, 48, 49, 51, 52, 53, 55, 56, 57, 58, 59, 61, 64, 66, 69, 70, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94, 97, 98, 103, 104, 109], "vb5nb4rd5bx0gr1q5ytx9q600000gn": [0, 10, 11, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 34, 37, 39, 48, 49, 51, 52, 53, 55, 56, 57, 58, 59, 61, 64, 66, 69, 70, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94, 97, 98, 103, 104, 109], "t": [0, 2, 4, 5, 6, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 28, 34, 37, 39, 48, 49, 51, 52, 53, 55, 56, 57, 58, 59, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 103, 104, 105, 109, 111], "ipykernel_20767": 0, "261550316": 0, "py": [0, 9, 10, 11, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 34, 37, 39, 48, 49, 51, 52, 53, 55, 56, 57, 58, 59, 61, 64, 66, 69, 70, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94, 97, 98, 103, 104, 109], "modul": [0, 10, 11, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 34, 37, 39, 48, 49, 51, 52, 53, 55, 56, 57, 58, 59, 61, 64, 66, 69, 70, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94, 97, 98, 103, 104, 109], "3": [0, 10, 16, 17, 18, 20, 22, 23, 24, 25, 26, 27, 34, 37, 39, 48, 49, 51, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 103, 104, 105, 109], "4": [0, 3, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 25, 26, 27, 28, 34, 37, 39, 48, 49, 51, 53, 61, 64, 66, 67, 68, 69, 70, 71, 72, 73, 75, 76, 77, 78, 79, 80, 83, 84, 88, 89, 90, 91, 94, 95, 96, 97, 98, 103, 104, 105, 109], "No": [0, 4, 6, 9, 10, 11, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 34, 37, 39, 48, 49, 51, 52, 53, 55, 56, 57, 58, 59, 61, 64, 66, 69, 70, 71, 73, 74, 75, 76, 77, 82, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 97, 98, 103, 104, 111], "find": [0, 2, 4, 6, 9, 14, 15, 34, 39, 48, 49, 64, 66, 67, 68, 72, 73, 76, 78, 79, 80, 83, 86, 87, 88, 89, 90, 95, 96, 98, 103, 112], "optim": [0, 2, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 23, 24, 34, 37, 39, 48, 51, 52, 53, 55, 56, 57, 61, 64, 66, 67, 68, 72, 73, 76, 78, 79, 80, 83, 84, 86, 87, 89, 91, 93, 94, 95, 96, 97, 98, 103, 104, 105, 111, 112], "regim": [0, 2, 15, 19, 34, 39, 48, 51, 64, 66, 97, 98, 103, 104, 111], "appropri": [0, 11, 49, 52, 55, 57, 61, 75, 84, 87, 91, 112], "interpret": [0, 3, 10, 13, 34, 39, 48, 69, 70, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93, 97, 98, 103, 104], "A": [0, 2, 3, 6, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 28, 37, 39, 48, 49, 50, 52, 53, 61, 62, 63, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 103, 104, 105, 109], "sentenc": [0, 97, 98, 103, 104], "analysi": [0, 3, 9, 11, 13, 14, 26, 39, 71, 74, 84, 90, 95, 96, 97, 98, 103, 104, 105, 109, 111], "result": [0, 2, 4, 5, 10, 15, 18, 19, 20, 21, 22, 24, 26, 34, 39, 48, 51, 52, 53, 55, 57, 61, 64, 66, 82, 84, 85, 88, 97, 98, 103, 104, 109, 111], "estim": [0, 2, 5, 6, 9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 34, 37, 39, 48, 49, 51, 53, 55, 56, 57, 58, 61, 62, 63, 64, 66, 70, 71, 74, 78, 79, 80, 84, 85, 87, 94, 96, 97, 98, 103, 104, 109, 111], "fix": [0, 34, 48, 49, 55, 56, 64, 66, 68, 71, 78, 79, 80, 97], "valu": [0, 2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 18, 20, 21, 22, 23, 24, 26, 27, 34, 37, 39, 48, 49, 50, 51, 52, 53, 55, 56, 57, 61, 63, 64, 66, 68, 71, 72, 76, 78, 79, 80, 83, 96, 97, 109], "user": [2, 4, 6, 16, 17, 18, 20, 23, 25, 26, 27, 28, 34, 37, 48, 64, 66, 68, 69, 70, 71, 72, 75, 76, 77, 83, 86, 87, 89, 90, 91, 92, 93, 95, 96, 97, 105], "growth": 2, "engag": 2, "ar": [2, 3, 4, 6, 9, 11, 12, 13, 14, 15, 16, 18, 19, 21, 22, 24, 27, 28, 34, 37, 48, 49, 50, 52, 53, 55, 57, 61, 62, 63, 64, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 95, 96, 97, 98, 103, 104, 105, 107, 111, 112], "critic": [2, 26, 52, 61, 63, 109], "fast": [2, 9, 10, 11, 12, 13, 14, 52, 111], "chang": [2, 21, 26, 39, 57, 64, 86, 109, 112], "market": 2, "campaign": [2, 50], "internet": 2, "compani": [2, 19], "offer": [2, 53, 71, 90, 91, 92, 93, 94, 95, 105], "quantifi": [2, 3, 10, 74, 79, 80, 83, 109], "encourag": [2, 37], "new": [2, 4, 6, 34, 49, 50, 64, 66, 68, 75, 76, 77, 88, 95, 96, 105, 111], "product": [2, 90, 95, 105], "The": [2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 34, 37, 39, 48, 49, 50, 52, 53, 55, 56, 57, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 103, 104, 105, 109, 111, 112], "treatment": [2, 4, 9, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 34, 37, 39, 48, 50, 53, 63, 64, 66, 67, 76, 96, 109, 111], "ha": [2, 3, 5, 9, 10, 13, 18, 19, 22, 37, 39, 49, 52, 53, 57, 58, 61, 65, 69, 72, 73, 74, 75, 76, 84, 87, 88, 90, 91, 95, 96, 98, 103, 104], "posit": [2, 4, 6, 11, 13, 14, 15, 21, 25, 34, 48, 64, 66, 76, 95, 105], "effect": [2, 3, 9, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 37, 50, 53, 66, 90, 95, 105], "desir": [2, 3, 49], "busi": 2, "also": [2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 19, 21, 23, 24, 25, 34, 48, 49, 51, 52, 55, 56, 57, 61, 63, 64, 66, 73, 75, 76, 84, 85, 86, 87, 88, 89, 90, 91, 93, 96, 98, 103, 111], "lead": [2, 19, 53], "surplu": 2, "oper": [2, 10, 12, 15, 53, 90, 93, 94], "cost": [2, 20, 24, 37, 93], "increas": [2, 39, 53, 67, 71, 78, 79, 80, 96, 109], "impel": 2, "carri": 2, "out": [2, 10, 19, 48, 63, 107], "more": [2, 3, 4, 5, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 21, 22, 24, 28, 34, 37, 39, 49, 50, 52, 53, 55, 56, 57, 58, 59, 61, 63, 64, 68, 70, 71, 77, 86, 87, 89, 92, 93, 94, 96, 97, 98, 103, 104, 107, 112], "refin": 2, "strategi": 2, "acquisit": 2, "retent": 2, "etc": [2, 19, 34, 48, 68, 88, 95, 105], "specif": [2, 3, 4, 5, 6, 10, 15, 18, 19, 21, 22, 25, 26, 34, 48, 49, 52, 53, 56, 57, 58, 61, 62, 63, 66, 67, 69, 71, 73, 75, 76, 77, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 95, 96, 97, 98, 103, 105, 111], "associ": [2, 4, 5, 6, 9, 11, 13, 37, 39, 49, 63, 67, 78, 79, 80, 109, 111], "massiv": [2, 19], "scale": [2, 9, 20, 24, 25, 39, 55, 67, 82, 83, 84, 86, 88, 89, 91, 92, 96, 111], "promot": 2, "must": [2, 5], "balanc": [2, 62, 73, 96], "increment": 2, "sustain": 2, "return": [2, 34, 39, 48, 49, 51, 64, 66, 109], "invest": [2, 34, 48, 64, 66], "roi": [2, 73, 95, 96, 103, 104, 105], "requir": [2, 9, 11, 14, 16, 17, 18, 20, 22, 23, 34, 37, 39, 49, 52, 53, 61, 63, 64, 66, 76, 111], "predict": [2, 18, 21, 22, 25, 27, 28, 39, 48, 66, 109], "each": [2, 3, 4, 6, 9, 10, 11, 13, 14, 18, 19, 20, 21, 22, 24, 27, 34, 39, 48, 50, 57, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 103, 104, 105, 111], "caus": [2, 4, 6, 9, 11, 12, 13, 14, 19, 37, 49], "differ": [2, 3, 4, 5, 6, 12, 15, 21, 25, 27, 34, 48, 49, 50, 51, 57, 61, 62, 63, 64, 66, 68, 69, 72, 73, 75, 76, 77, 79, 80, 84, 85, 87, 88, 89, 91, 92, 95, 96, 98, 103, 107, 111], "action": [2, 4, 6, 19, 26, 34, 37, 48, 49, 50, 51, 52, 53, 55, 56, 57, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 103, 104, 105, 109, 111], "order": [2, 9, 10, 11, 12, 13, 14, 18, 20, 22, 24, 49, 53, 75, 76, 77, 82, 83, 84, 85, 86, 87, 89, 91, 92, 93, 95, 105], "maxim": [2, 37, 39, 48, 49, 66, 67, 68, 72, 76, 83, 95, 96], "thi": [2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 15, 18, 19, 21, 22, 23, 24, 25, 27, 37, 39, 49, 50, 52, 53, 55, 56, 57, 58, 59, 61, 62, 63, 67, 68, 71, 72, 74, 76, 83, 88, 89, 90, 91, 94, 95, 96, 97, 98, 103, 104, 105, 107, 111, 112], "problem": [2, 3, 10, 18, 19, 22, 23, 24, 37, 48, 49, 52, 53, 55, 56, 57, 61, 66, 67, 71, 73, 74, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94, 97, 104, 111, 112], "known": [2, 3, 9, 12, 15, 21, 25, 34, 57, 61, 62, 63, 64, 67, 72, 73, 75, 76, 77, 78, 79, 80, 83, 84, 88, 89, 90, 91, 96, 98, 103, 111], "uplift": [2, 16, 17, 18, 20, 23, 49, 50], "model": [2, 6, 10, 12, 15, 21, 23, 24, 25, 27, 28, 34, 39, 48, 49, 51, 52, 53, 55, 61, 62, 63, 64, 66, 67, 69, 70, 75, 76, 78, 79, 80, 82, 83, 84, 86, 89, 90, 91, 92, 93, 95, 96, 98, 105, 111], "heterogen": [2, 9, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 75, 83, 84, 88, 89, 90, 91, 111], "which": [2, 3, 4, 5, 6, 10, 12, 15, 18, 19, 21, 22, 23, 24, 26, 27, 28, 34, 37, 39, 48, 49, 52, 56, 57, 61, 62, 63, 64, 66, 67, 68, 69, 72, 73, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 103, 105, 107, 109, 111], "receiv": [2, 4, 6, 15, 48, 50, 62, 63, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 91, 92, 93, 94, 95, 96, 97, 98, 103, 104, 105, 111], "attent": [2, 3, 9, 11, 12, 13, 14, 39, 67, 78, 79, 80, 96, 111], "infer": [2, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 48, 49, 53, 63, 78, 79, 80, 90, 93, 107, 111], "literatur": [2, 9, 15, 19, 39, 52, 58, 61, 63, 76, 93, 107, 111, 112], "book": [2, 5, 48, 66, 111, 112], "provid": [2, 12, 14, 19, 34, 48, 51, 53, 61, 63, 64, 66, 71, 75, 78, 79, 80, 92, 97, 107, 112], "sampl": [2, 4, 6, 16, 17, 18, 20, 21, 22, 23, 24, 34, 37, 39, 48, 49, 52, 53, 58, 62, 68, 69, 71, 72, 73, 76, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 97, 98, 103, 104, 105, 111], "code": [2, 9, 10, 17, 18, 22, 37, 51, 105, 112], "answer": 2, "question": [2, 52, 61], "relat": [2, 9, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 34, 57, 62, 63, 64, 67, 68, 76, 96, 107, 109, 111], "under": [2, 3, 4, 5, 6, 9, 10, 15, 16, 19, 20, 21, 24, 25, 27, 28, 34, 37, 39, 48, 52, 53, 55, 57, 61, 68, 75, 77, 84, 89, 90, 91, 92, 93, 96, 107, 111, 112], "set": [2, 3, 9, 10, 11, 12, 13, 14, 18, 22, 26, 39, 51, 53, 57, 61, 62, 63, 66, 71, 77, 78, 79, 80, 82, 84, 85, 86, 87, 89, 91, 92, 93, 97, 109, 111, 112], "point": [2, 18, 22, 37, 39, 48, 50, 55, 56, 57, 58, 62, 63, 64, 66, 72, 76], "exposur": [2, 3, 10, 19, 111], "method": [2, 10, 12, 13, 19, 21, 25, 27, 28, 34, 39, 48, 49, 52, 53, 55, 56, 57, 58, 61, 64, 66, 77, 78, 79, 80, 111, 112], "interest": [2, 3, 4, 6, 10, 12, 18, 19, 22, 34, 39, 48, 49, 50, 61, 64, 66, 82, 83, 84, 85, 111], "dataset": [2, 3, 10, 19, 25, 26, 34, 39, 48, 50, 62, 63, 65, 66, 68, 72, 76, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 105, 109], "space": [2, 9, 26, 34, 39, 48, 50, 52, 57, 61, 62, 63, 64, 66, 69, 70, 71, 73, 74, 76, 77, 78, 79, 80, 86, 87, 89, 95, 97, 98, 103, 104, 105], "should": [2, 10, 12, 64, 66, 69, 82, 84, 85, 86, 87, 89, 91, 92, 112], "variou": [2, 3, 11, 13, 48, 52, 61, 66, 77, 86, 95, 111], "email": [2, 34, 48, 49], "sent": 2, "custom": [2, 19, 49, 50, 75, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93], "total": [2, 10, 12, 19, 39, 49, 50, 64, 68, 71, 72, 74, 75, 82, 84, 85, 86, 87, 89, 91, 92, 93, 95, 96, 97, 104, 105, 109, 111], "amount": [2, 83], "spent": [2, 39, 50], "after": [2, 3, 11, 13, 14, 23, 24, 26, 37, 50, 52, 53, 55, 56, 57, 58, 59, 61, 62, 66, 69, 71, 73, 74, 85, 94, 97, 98, 103, 104, 109], "fetch_hillstrom": [2, 49, 50], "discret": [2, 4, 5, 6, 26, 39, 49, 62, 63, 69, 70, 71, 73, 74, 109, 111], "q": [2, 5, 9, 34, 39, 49, 51, 52, 53, 61, 62, 63, 64, 67, 71, 73, 75, 77, 84, 89, 91, 93, 96, 97, 111], "much": [2, 3, 19], "spend": [2, 34, 48, 49, 50], "averag": [2, 9, 12, 15, 16, 19, 20, 21, 23, 24, 28, 34, 48, 53, 57, 58, 64, 66, 71, 74, 97, 104, 111], "add": [2, 5, 34, 48, 49, 75, 83, 88, 90, 112], "quantil": [2, 58, 111], "outcom": [2, 3, 10, 12, 15, 16, 19, 20, 21, 23, 24, 27, 28, 34, 39, 48, 49, 50, 64, 66, 67, 75, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 107, 111], "continu": [2, 4, 6, 9, 10, 11, 12, 13, 14, 34, 48, 49, 57, 61, 62, 64, 66, 71, 73, 74, 75, 77, 86, 87, 88, 89, 109, 111, 112], "owl": [2, 111], "john": [2, 5, 62, 63], "wanamak": 2, "onc": [2, 5, 75, 77, 83], "phrase": 2, "half": 2, "monei": [2, 50], "advertis": [2, 19, 86, 87, 88, 89], "wast": 2, "troubl": 2, "don": [2, 49, 91, 92, 93], "know": [2, 19, 49], "It": [2, 4, 5, 19, 20, 23, 24, 55, 56, 57, 61, 63, 69, 70, 71, 73, 74, 75, 82, 84, 85, 86, 87, 88, 89, 91, 92, 96, 98, 103], "indic": [2, 4, 6, 11, 13, 14, 15, 26, 39, 71, 79, 80, 83, 90, 91, 92, 93, 95], "our": [2, 4, 6, 15, 18, 22, 39, 49, 53, 57, 58, 61, 63, 66, 76, 78, 79, 80], "high": [2, 3, 4, 9, 10, 11, 12, 13, 14, 15, 34, 64], "intent": 2, "convert": [2, 4, 6, 11, 13, 14, 49], "natur": [2, 10, 12, 23, 24, 37, 49, 109], "todai": 2, "s": [2, 3, 5, 6, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 22, 23, 24, 26, 27, 28, 34, 48, 50, 52, 53, 55, 56, 57, 61, 62, 63, 64, 66, 68, 69, 70, 71, 75, 76, 77, 82, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 107, 111], "digit": 2, "techniqu": [2, 52, 61, 111], "enabl": [2, 9, 10, 12, 84, 89, 91], "convers": [2, 19], "lift": 2, "via": [2, 3, 4, 9, 10, 11, 12, 13, 14, 15, 52, 53, 55, 61, 62, 75, 78, 79, 80, 84, 89, 90, 91], "random": [2, 4, 6, 9, 11, 12, 13, 14, 15, 17, 19, 49, 51, 58, 62, 63, 68, 69, 70, 71, 72, 73, 75, 76, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93, 96, 97, 98, 107, 109], "control": [2, 3, 4, 6, 9, 12, 15, 16, 19, 20, 21, 23, 24, 27, 28, 34, 64, 111], "studi": [2, 3, 4, 5, 6, 9, 13, 15, 19, 50, 52, 55, 61, 68, 72, 76, 95, 96, 111], "randomli": [2, 4, 6, 71, 97], "select": [2, 10, 25, 27, 28, 37, 39, 50, 62, 67, 68, 69, 70, 71, 72, 73, 74, 76, 82, 84, 85, 86, 87, 89, 90, 91, 93, 94, 96, 97, 98, 103, 104, 109, 111], "form": [2, 11, 15, 52, 56, 61, 62, 69, 73, 75, 77, 84, 91], "two": [2, 3, 4, 5, 6, 10, 14, 15, 16, 21, 24, 27, 28, 49, 50, 52, 53, 57, 61, 63, 67, 68, 72, 73, 76, 78, 79, 80, 84, 89, 91, 96, 103, 111, 112], "group": [2, 4, 6, 15, 19, 21, 27, 28, 34, 49, 64, 72, 88, 96, 111], "one": [2, 4, 5, 6, 15, 19, 21, 25, 34, 37, 49, 52, 53, 55, 57, 61, 63, 64, 68, 72, 73, 76, 82, 83, 84, 85, 90, 91, 92, 93, 95, 96, 98, 103], "interven": [2, 4, 6, 9, 12], "other": [2, 3, 4, 6, 9, 13, 15, 19, 20, 21, 23, 24, 27, 34, 39, 48, 53, 61, 62, 63, 64, 66, 67, 68, 69, 72, 76, 82, 85, 86, 87, 88, 89, 92, 93, 95, 96, 105, 109, 111], "cannot": [2, 4, 6, 11, 14, 15, 53, 63], "base": [2, 4, 5, 9, 10, 12, 15, 18, 19, 21, 22, 25, 34, 37, 39, 48, 52, 53, 55, 56, 57, 61, 63, 64, 66, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 82, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 96, 97, 98, 103, 104, 107, 109, 111], "collect": [2, 3, 4, 6, 16, 18, 19, 22, 26, 49, 62, 63, 68, 72, 76, 90, 95, 96, 109], "intervent": [2, 4, 6, 10, 12, 15, 26], "converion": 2, "even": [2, 111], "win": 2, "impress": [2, 19], "those": [2, 5, 37, 63, 69, 70, 71, 73, 74, 75, 77], "With": [2, 34, 37, 57, 84, 91, 95], "wearabl": 2, "devic": 2, "easili": [2, 21, 27, 69, 73, 78, 84, 85, 87, 91, 92, 98, 103], "keep": [2, 6, 10, 12, 90, 93], "track": [2, 9], "own": [2, 76, 111], "meanwhil": [2, 62], "util": [2, 10, 11, 13, 14, 48, 52, 53, 57, 58, 61, 66, 68, 69, 70, 75, 76, 82, 84, 90, 91, 92, 93, 95, 109], "improv": [2, 19, 49, 82, 109], "manag": [2, 112], "increasingli": 2, "hot": 2, "topic": 2, "among": [2, 4, 9, 10, 11, 12, 13, 14, 49, 55, 61, 67, 68, 72, 75, 76, 84, 89, 91, 96, 111], "them": [2, 6, 10, 21, 27, 49, 61, 72, 83, 90, 92, 96], "decid": [2, 18, 22, 82, 84, 85, 86, 87, 88, 89], "biggest": 2, "challeng": [2, 3, 10, 53, 58], "For": [2, 3, 4, 5, 6, 19, 20, 21, 24, 26, 28, 34, 48, 49, 50, 52, 57, 61, 63, 64, 65, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 103, 104, 109, 111], "mai": [2, 3, 4, 6, 10, 15, 18, 19, 22, 37, 49, 63, 68, 69, 76, 98, 112], "given": [2, 4, 6, 11, 13, 14, 15, 16, 21, 23, 24, 26, 28, 34, 39, 48, 49, 52, 53, 55, 58, 61, 62, 63, 64, 66, 67, 69, 70, 78, 79, 80, 84, 89, 91, 111], "activ": 2, "suggest": [2, 4, 34, 55, 67, 74, 95, 96, 104], "help": [2, 66, 68, 72, 76, 95, 96], "regul": [2, 3, 10, 12], "psycholog": 2, "howev": [2, 4, 6, 9, 12, 15, 18, 19, 20, 21, 22, 24, 27, 34, 52, 53, 57, 58, 61, 64, 66, 73, 96, 98, 103], "send": [2, 34, 48, 86, 87, 89], "written": [2, 5, 9, 14, 15, 19, 20, 24], "intuit": [2, 37, 68, 71, 96, 97], "asleep": 2, "intens": [2, 19], "workout": 2, "who": [2, 4, 6, 15, 26, 50, 69, 70, 75, 76, 109], "rare": [2, 58], "exercis": 2, "would": [2, 4, 19, 21, 25, 34, 37, 48, 49, 50, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 76, 77, 78, 79, 80, 83, 88, 90, 95, 96, 98, 103, 105, 111], "decreas": [2, 3, 53, 71, 96, 97], "To": [2, 13, 15, 18, 21, 22, 39, 49, 52, 53, 57, 61, 62, 71, 77, 83, 84, 91, 106, 112], "address": [2, 19, 39, 71, 75, 111], "number": [2, 4, 9, 11, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 34, 37, 39, 49, 57, 64, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 104, 105, 111], "research": [2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 52, 56, 61, 87, 90, 93, 94, 111], "formal": [2, 3, 4, 15, 23, 24, 61, 63, 83, 88, 107], "reinforc": [2, 5, 9, 10, 11, 12, 13, 14, 48, 55, 56, 57, 61, 62, 63, 66, 71, 96, 97, 107], "mdp": [2, 52, 57, 61, 62, 63], "patient": [2, 25, 26, 39, 49, 76, 109], "seri": [2, 5, 18, 22, 34, 57, 61, 64], "stage": [2, 16, 24, 111], "final": [2, 19, 20, 21, 24, 27, 28, 48, 49, 52, 53, 55, 56, 61, 62, 64, 66, 68, 69, 70, 73, 84, 91, 92, 93, 98, 103, 111], "condit": [2, 4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 23, 24, 34, 39, 49, 52, 53, 63, 64, 75, 78, 79, 80, 84, 89, 91, 95], "affect": [2, 3, 4, 6, 12, 15, 37, 111], "onli": [2, 4, 5, 6, 12, 15, 49, 50, 52, 53, 57, 58, 61, 62, 63, 67, 77, 82, 83, 84, 85, 90, 91, 92, 93, 111, 112], "previou": [2, 19, 63, 68, 74, 76, 78, 79, 80, 84, 89, 91, 95, 96, 105, 111], "exist": [2, 4, 5, 6, 9, 10, 11, 12, 13, 19, 34, 39, 48, 52, 63, 83, 90, 95, 105, 111], "delai": [2, 66], "current": [2, 3, 49, 62, 63, 67, 78, 79, 80, 111], "decis": [2, 5, 9, 10, 11, 13, 14, 15, 34, 39, 48, 49, 50, 64, 66, 67, 76, 78, 79, 80, 90, 107, 111, 112], "subsequ": [2, 4, 6, 95], "regard": [2, 19, 53, 55, 57, 61, 68, 111], "cumul": [2, 57, 62, 63, 67, 68, 72, 76, 84, 89, 91, 95, 96], "sequenc": [2, 65, 67, 76, 95, 105], "longitudin": 2, "subject": [2, 4, 6, 15, 19, 21, 27, 34, 48, 64, 66], "experienc": 2, "entir": [2, 5, 84, 89, 91], "wide": [2, 9, 15, 19, 52, 57, 61, 67, 68, 71, 72, 76, 82, 84, 88, 89, 91, 95, 96, 97, 111], "formul": [2, 9, 13, 63, 89, 107, 111], "illustr": [2, 18, 22, 26, 49, 53, 67, 72, 78, 79, 80, 96, 109, 111], "context": [2, 39, 67, 68, 78, 79, 80, 111], "what": [2, 64, 66, 67, 90], "assign": [2, 4, 6, 12, 15, 19, 37, 48, 63, 66], "hiv": 2, "infect": [2, 3], "time": [2, 5, 9, 10, 11, 13, 14, 19, 20, 24, 34, 39, 49, 53, 57, 61, 62, 63, 64, 68, 71, 72, 74, 75, 76, 78, 79, 80, 95, 96, 97, 104, 109, 111], "datamdp": [2, 64, 65, 66], "cd4": 2, "count": [2, 71, 74, 97, 104], "wa": [2, 4, 9, 13, 15, 23, 24, 26, 37, 48, 49, 50, 64, 66], "all": [2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 19, 20, 23, 24, 26, 34, 37, 48, 49, 53, 61, 63, 64, 65, 66, 68, 75, 76, 78, 79, 80, 83, 86, 87, 88, 89, 92, 94, 95, 96, 105, 111], "interact": [2, 20, 24, 76, 95, 105], "same": [2, 4, 5, 6, 15, 18, 19, 21, 22, 28, 34, 37, 48, 53, 63, 64, 66, 77, 86, 87, 90, 91, 92, 93, 95], "possibl": [2, 4, 6, 9, 13, 21, 28, 53, 86, 87, 89, 111], "style": [2, 14, 94], "mani": [2, 3, 5, 9, 10, 12, 37, 55, 61, 62, 63, 78, 79, 80, 84, 89, 91, 95, 105], "through": [2, 9, 10, 11, 12, 14, 15, 63, 68, 72, 75, 76, 83, 90, 93, 95, 96, 105, 109], "channel": [2, 49], "allow": [2, 4, 5, 6, 37, 39, 48, 49, 53, 63, 66], "distribut": [2, 4, 6, 9, 14, 16, 17, 18, 20, 21, 22, 23, 24, 37, 49, 50, 53, 61, 62, 63, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 98, 103, 111], "credit": 2, "correspond": [2, 4, 6, 10, 12, 34, 37, 39, 48, 49, 52, 53, 57, 58, 61, 63, 64, 66, 68, 71, 72, 73, 74, 75, 76, 77, 83, 84, 87, 90, 91, 92, 93, 95, 96, 97, 98, 103, 104, 105], "contribut": [2, 3, 10], "becom": [2, 23, 24, 53, 57], "rule": [2, 37, 39, 87], "simpl": [2, 18, 22, 55, 56, 57, 67, 71, 76, 89, 96, 97, 111], "have": [2, 3, 4, 6, 10, 12, 15, 26, 37, 49, 50, 52, 57, 61, 62, 63, 65, 67, 68, 75, 76, 77, 82, 92, 95, 96, 105, 109, 111, 112], "been": [2, 4, 6, 9, 13, 15, 18, 22, 26, 39, 49, 52, 57, 58, 61, 67, 72, 73, 75, 76, 87, 92, 96, 98, 103, 109], "practic": [2, 39, 48, 53, 66, 68, 69, 71, 72, 73, 75, 78, 79, 80, 82, 84, 85, 86, 87, 89, 91, 92, 93, 96, 97, 98, 103], "long": [2, 52, 57, 61, 90, 111], "ever": 2, "enhanc": 2, "capabl": 2, "driven": 2, "attempt": 2, "popular": [2, 39, 56, 83, 84, 90, 93, 95, 96, 105], "framework": [2, 4, 6, 15, 68, 69, 75, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 105, 107], "classic": [2, 4, 6, 9, 14, 21, 23, 24, 39, 48, 55, 66, 68, 72, 73, 96, 103, 111, 112], "bandit": [2, 78, 79, 80, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94, 97, 98, 104, 105], "aim": [2, 6, 11, 13, 14, 15, 18, 19, 21, 22, 27, 34, 48, 50, 55, 56, 63, 64, 66, 68, 72, 76, 83, 88, 90, 95, 105, 107, 111], "prefer": [2, 19, 21, 27], "item": [2, 67, 68, 69, 71, 72, 73, 74, 75, 76, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 97, 98, 104, 105, 111], "click": [2, 19, 83, 91, 92, 93, 95], "rate": [2, 10, 11, 13, 14, 15, 19, 20, 24, 39, 52, 53, 61, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 83, 95, 96, 97, 109], "overal": [2, 16, 18, 19, 20, 21, 22, 23, 24, 27, 34, 48, 49, 64, 66, 68, 72, 83, 84, 88, 89, 90, 91, 96, 111], "profit": [2, 90, 95, 105], "repres": [2, 4, 6, 9, 11, 12, 13, 14, 15, 26, 39, 109, 111], "movi": [2, 68, 71, 72, 76, 91, 92, 93, 95, 96, 105], "youtub": 2, "netflix": 2, "where": [2, 4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 21, 22, 23, 24, 25, 26, 27, 28, 34, 37, 39, 48, 49, 50, 52, 53, 55, 57, 58, 61, 62, 63, 64, 66, 67, 68, 69, 71, 72, 73, 75, 76, 77, 78, 79, 80, 83, 84, 86, 88, 89, 90, 91, 95, 96, 97, 105, 109, 111, 112], "agent": [2, 49, 62, 63, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 98, 103, 105], "list": [2, 11, 13, 14, 51, 64, 77, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 95, 105, 111], "video": [2, 49], "thei": [2, 4, 5, 6, 57, 61, 63, 68, 72, 76, 95, 96], "visit": [2, 39, 53, 57, 68, 72, 76, 83, 90, 95, 96], "site": [2, 10, 11, 16, 17, 18, 20, 23], "either": [2, 4, 6, 15, 26, 34, 48, 50, 52, 55, 56, 61, 64, 66, 68, 71, 73, 74, 75, 77, 79, 82, 84, 85, 86, 87, 89, 90, 91, 92, 93, 95, 96, 97, 104, 111], "leav": [2, 3, 72, 76, 83, 95, 111], "typic": [2, 52, 57, 58, 61, 67, 68, 72, 88, 89], "larg": [2, 19, 26, 37, 51, 52, 53, 55, 57, 61, 63, 67, 71, 73, 74, 75, 76, 77, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 96, 104, 107, 109], "avail": [2, 4, 6, 9, 10, 13, 14, 17, 50, 63, 68, 72, 76, 82, 83, 89, 90, 95, 96, 105, 109], "therefor": [2, 34, 48, 53, 55, 56, 57, 68, 72, 73, 76, 77, 83, 86, 87, 89, 96, 98, 103, 111], "explor": [2, 21, 25, 37, 49, 52, 53, 55, 56, 57, 58, 59, 61, 66, 68, 69, 70, 71, 72, 73, 74, 75, 77, 78, 82, 85, 94, 96, 97, 98, 103, 104], "exploit": [2, 19, 71, 72, 73, 74, 78, 79, 80, 85, 96, 97, 98, 103, 104], "inform": [2, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 19, 21, 25, 26, 28, 34, 39, 50, 57, 61, 64, 65, 67, 68, 69, 70, 73, 75, 76, 77, 79, 80, 82, 83, 84, 86, 87, 89, 90, 91, 92, 95, 96, 98, 103, 105, 111, 112], "about": [2, 4, 5, 6, 15, 18, 20, 21, 22, 24, 28, 50, 68, 73, 76, 77], "so": [2, 4, 5, 9, 11, 13, 15, 23, 24, 49, 62, 63, 66, 71, 74, 96, 97, 104], "far": [2, 71, 74, 96, 97], "approach": [2, 3, 4, 6, 15, 16, 18, 20, 21, 23, 24, 25, 34, 37, 48, 52, 53, 55, 56, 57, 58, 61, 64, 66, 67, 68, 90, 92, 93, 94, 96, 111], "As": [2, 15, 20, 21, 24, 28, 52, 53, 55, 61, 62, 63, 67, 69, 70, 74, 75, 77, 82, 84, 85, 96, 98, 104, 111], "chapter": [2, 50, 63, 68, 72, 76, 82, 84, 85, 86, 87, 89, 91, 92, 93, 95, 96, 105, 107, 111], "genr": [2, 68, 72, 76, 95, 96], "five": [2, 91, 92, 93, 95], "whose": [2, 3, 63, 111], "unknown": [2, 9, 12, 13, 57, 61, 67, 68, 72, 73, 75, 77, 78, 79, 80, 84, 89, 91, 96, 98, 103, 111], "over": [2, 3, 21, 25, 39, 52, 53, 57, 61, 77, 78, 79, 80, 93, 96, 111], "goal": [2, 3, 37, 49, 53, 62, 63, 68, 72, 76, 78, 79, 80, 88, 90, 95, 96, 111, 112], "satisfact": [2, 68, 72, 76, 95, 96], "movielen": [2, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 90, 91, 92, 93, 95, 96, 105], "arm": [2, 67, 68, 69, 70, 71, 73, 74, 75, 76, 77, 87, 88, 95, 96, 97, 104, 105, 111], "contextu": [2, 67, 69, 70, 72, 78, 79, 80, 90, 91, 92, 96, 98, 111], "meta": [2, 19, 28, 67, 75, 83, 84, 88, 89, 90, 91, 95, 111], "multipl": [2, 9, 10, 11, 12, 13, 14, 34, 37, 49, 51, 67, 77, 111], "million": [2, 3, 9, 10, 11, 12, 13, 14], "try": [2, 16, 24, 26, 96, 109, 112], "whenev": [2, 68, 72, 83, 90], "assort": [2, 91, 93, 94, 95, 105, 111], "rank": [2, 82, 84, 85, 95, 105, 111], "top": [2, 9, 10, 11, 12, 13, 14, 63, 68, 72, 76, 82, 83, 84, 85, 93, 95, 96], "restaur": [2, 82, 83, 84, 85], "true": [2, 3, 10, 11, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 27, 34, 37, 48, 49, 50, 51, 53, 55, 64, 66, 69, 70, 71, 73, 75, 77, 79, 91, 93, 94, 95, 96, 97, 98, 103, 104, 109], "expect": [2, 16, 17, 18, 20, 21, 22, 23, 24, 34, 37, 39, 48, 52, 57, 61, 62, 63, 64, 66, 68, 69, 70, 73, 75, 76, 77, 79, 80, 85, 87, 96, 109], "yelp": [2, 82, 83, 84, 85], "discuss": [2, 9, 57, 61, 62, 63, 77, 107, 111, 112], "offlin": [2, 39, 49, 79, 111], "prevent": 2, "unnecessari": 2, "essenti": [2, 3, 61, 75], "variant": [2, 3, 57, 71, 96, 97], "frequent": 2, "commerci": 2, "websit": [2, 19, 65, 68, 72, 76, 95, 96, 112], "googl": 2, "displai": [2, 5, 82, 83, 84, 85], "twitter": 2, "usual": [2, 15, 49, 57, 61], "view": [2, 3, 61, 79, 80, 109], "bipartit": 2, "match": [2, 52, 57, 79, 80, 88, 91, 92, 93, 95, 105, 111], "need": [2, 20, 24, 34, 39, 49, 57, 64, 68, 72, 73, 74, 76, 77, 83, 88, 90, 95, 96, 98, 103, 105, 112], "show": [2, 4, 10, 15, 19, 49, 52, 61, 63, 71, 79, 82, 84, 85, 88, 90, 96, 97], "potenti": [2, 15, 19, 21, 27, 28, 34, 48, 49, 50, 53, 55, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 76, 77, 78, 79, 80, 83, 85, 86, 87, 88, 89, 90, 95, 107], "like": [2, 5, 19, 21, 25, 27, 34, 37, 48, 49, 53, 66, 68, 72, 76, 95, 96], "attract": [2, 3, 4, 9, 11, 12, 13, 14, 15, 21, 49, 78, 79, 80, 83, 84, 85, 86, 87, 88, 89, 95], "while": [2, 6, 10, 12, 21, 27, 34, 37, 49, 64, 67, 68, 77, 84, 89, 91, 92, 111], "adher": 2, "budget": 2, "constraint": [2, 5, 9, 10, 13, 55, 86, 87, 88, 89, 95, 105], "feedback": [2, 67, 68, 69, 72, 76, 78, 79, 80, 84, 88, 89, 91, 95, 96, 98, 103, 105], "achiev": [2, 19, 20, 24, 37, 52, 53, 61, 73, 77], "whom": 2, "its": [2, 5, 9, 11, 13, 19, 20, 21, 24, 37, 39, 52, 53, 56, 57, 61, 62, 63, 68, 73, 75, 76, 79, 82, 96, 98, 103, 111, 112], "chanc": 2, "accept": [2, 5], "adult": [2, 86, 87, 88, 89], "combinatori": [2, 84, 86, 87, 89, 91, 94, 95, 105, 111], "world": [2, 67, 68, 72, 76, 82, 87, 96], "across": [2, 25, 75, 76, 86], "retail": 2, "adjust": [2, 10, 77], "accord": [2, 4, 6, 12, 26, 53, 55, 57, 63, 73, 75, 93, 96, 98, 103, 111], "dure": [2, 3, 50], "period": [2, 11, 111], "rideshar": 2, "servic": [2, 83], "sever": [2, 16, 19, 23, 24, 26, 95, 109, 111], "weather": 2, "occur": [2, 63], "outsid": [2, 3, 10], "airlin": 2, "rais": 2, "ticket": 2, "farewel": 2, "date": [2, 75, 77], "rise": [2, 15], "low": [2, 52, 57, 61, 93, 95], "purchas": [2, 50, 90, 91, 92, 93, 94], "evalut": 2, "section": [2, 4, 6, 15, 19, 20, 21, 24, 57, 58, 61, 63, 107, 109, 111, 112], "harper": 2, "f": [2, 10, 11, 13, 14, 52, 61, 77, 83, 84, 89, 91, 95, 105, 112], "m": [2, 5, 10, 12, 15, 16, 17, 18, 19, 20, 23, 24, 34, 39, 48, 49, 52, 53, 55, 62, 64, 66, 68, 69, 75, 76, 77, 78, 79, 80, 82, 83, 87, 90, 91, 92, 96, 98, 111], "konstan": 2, "j": [2, 9, 11, 13, 14, 15, 16, 19, 20, 21, 23, 24, 25, 27, 28, 34, 49, 53, 61, 63, 64, 67, 68, 75, 76, 77, 78, 79, 80, 84, 90, 91, 92, 93, 94, 96, 103, 104], "histori": [2, 34, 48, 49, 50, 63, 71, 78, 79, 80, 96, 97, 111], "acm": [2, 39], "transact": 2, "intellig": [2, 19, 39, 67, 68, 69, 70, 76, 82, 83, 85, 96, 98], "tii": 2, "19": [2, 5, 10, 34, 51, 52, 109], "2015": [2, 5, 37, 48, 57, 61, 66, 67, 83, 86, 88, 96], "asghar": 2, "n": [2, 4, 6, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 34, 37, 39, 48, 49, 50, 51, 52, 53, 55, 56, 57, 61, 62, 63, 64, 65, 66, 68, 69, 71, 72, 73, 74, 75, 76, 77, 82, 83, 84, 86, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 104, 105, 111, 112], "review": [2, 9, 12, 19, 34, 39, 57, 58, 61, 64, 72, 84, 89, 91, 95, 96, 112], "arxiv": [2, 5, 9, 10, 11, 12, 13, 14, 16, 19, 20, 23, 24, 39, 52, 55, 68, 72, 73, 78, 79, 80, 82, 83, 84, 88, 89, 90, 91, 92, 95, 96, 105], "preprint": [2, 5, 9, 10, 11, 12, 13, 14, 16, 19, 20, 23, 24, 39, 52, 55, 68, 72, 73, 78, 79, 80, 82, 83, 84, 88, 89, 90, 91, 92, 95, 96, 105], "1605": 2, "05362": 2, "2016": [2, 5, 52, 57, 61, 82, 83, 84, 88, 91], "asuncion": 2, "newman": 2, "d": [2, 5, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 23, 24, 34, 39, 48, 49, 53, 57, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 95, 96, 103, 104, 105], "uci": 2, "machin": [2, 5, 9, 10, 11, 12, 13, 14, 15, 19, 21, 25, 27, 28, 52, 53, 56, 57, 58, 61, 67, 68, 69, 71, 74, 76, 77, 83, 86, 87, 88, 93, 95, 96, 97, 98, 103, 104, 105], "repositori": [2, 9, 10, 11, 13, 112], "2007": [2, 9, 10, 11, 12, 13, 14, 68], "tsiati": [2, 15, 34, 64, 111], "davidian": [2, 15, 34, 64, 111], "hollowai": [2, 111], "laber": [2, 15, 34, 64, 111], "b": [2, 9, 10, 11, 13, 14, 15, 16, 18, 19, 20, 21, 22, 24, 25, 27, 28, 34, 37, 39, 48, 49, 52, 57, 61, 62, 63, 64, 66, 67, 68, 69, 73, 75, 76, 77, 82, 83, 86, 88, 89, 95, 96, 98, 103, 104, 105], "2019": [2, 3, 5, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 52, 55, 68, 72, 83, 85, 90, 91, 92, 93, 94, 96, 111], "statist": [2, 4, 6, 9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 22, 23, 24, 34, 37, 39, 49, 52, 53, 57, 58, 61, 64, 68, 69, 70, 76, 78, 79, 80, 82, 83, 85, 87, 96, 98, 111], "precis": [2, 19, 69, 73, 75, 77, 84, 91, 111], "medicin": [2, 19, 37, 78, 79, 80, 111], "chapman": [2, 111], "hall": [2, 111], "crc": [2, 111], "era": [3, 10], "revolut": [3, 10], "identifi": [3, 9, 10, 11, 13, 14, 15, 18, 21, 22, 25], "area": [3, 10, 37, 72, 78, 79, 80, 96], "gener": [3, 4, 6, 10, 17, 19, 21, 37, 39, 48, 52, 55, 57, 58, 61, 62, 63, 66, 67, 68, 72, 76, 78, 79, 80, 88, 95, 96, 98, 104, 105, 111, 112], "graph": [3, 10, 111], "direct": [3, 9, 10, 11, 12, 13, 14, 49, 53, 55, 56, 61, 67, 90, 93, 109], "indirect": [3, 10, 12, 109], "mediat": [3, 9, 11, 13, 14, 63], "intermedi": 3, "variabl": [3, 4, 6, 9, 10, 11, 12, 13, 14, 16, 19, 20, 23, 24, 25, 26, 37, 48, 49, 58, 63, 65, 66, 68, 72, 76, 83, 96, 111], "instanc": [3, 37, 51, 77, 84, 91], "outbreak": 3, "coronaviru": [3, 10], "diseas": 3, "chines": [3, 10], "govern": 3, "taken": [3, 50, 53, 65, 76, 79, 80, 111], "extrem": [3, 21, 27], "measur": [3, 4, 6, 9, 10, 11, 12, 13, 14, 15, 19, 53, 57, 63, 111], "stop": [3, 78, 79, 80, 83, 95], "viru": 3, "lock": 3, "wuhan": 3, "down": 3, "jan": [3, 9, 10, 11, 12, 13, 14], "23rd": 3, "2020": [3, 9, 11, 12, 13, 14, 16, 17, 18, 19, 20, 23, 24, 39, 68, 69, 73, 82, 87, 89, 92, 93, 96, 98], "12": [3, 9, 10, 11, 12, 13, 14, 18, 22, 25, 26, 27, 28, 34, 48, 49, 51, 68, 96], "citi": [3, 10], "hubei": [3, 10], "lockdown": [3, 10], "directli": [3, 5, 12, 34, 37, 48, 49, 52, 53, 55, 56, 57, 58, 59, 61, 62, 63, 64, 85, 89, 93, 94, 97, 98, 103, 104], "block": [3, 5], "peopl": 3, "stimul": [3, 49], "quarantin": 3, "further": [3, 10, 12, 20, 24, 49, 50, 53, 84, 86, 87, 89, 91, 95, 105], "migrat": 3, "countrywid": 3, "china": [3, 10], "thu": [3, 9, 12, 15, 18, 20, 22, 24, 39, 49, 63, 76, 78, 79, 80], "indirectli": 3, "reduc": [3, 10, 12, 49, 53], "great": [3, 19, 83], "crisi": 3, "mechan": [3, 10, 63], "individu": [3, 4, 6, 10, 15, 21, 28, 34, 37, 39, 48, 50, 53, 64, 65, 66, 90, 95, 105], "veri": [3, 5, 19, 21, 25, 27, 49, 111], "decad": 3, "discoveri": [3, 12, 39], "disentangl": [3, 9, 11, 12, 13, 14], "complex": [3, 5, 9, 11, 12, 13, 14, 21, 27, 39, 53, 86, 87, 89, 93, 111], "relationship": [3, 4, 6, 9, 10, 11, 12, 13, 14, 37, 48, 57, 69, 84, 91, 93, 98, 111], "field": [3, 34, 64, 67], "compar": [3, 15, 16, 18, 20, 21, 22, 24, 27, 52, 61, 71, 77], "5": [3, 9, 10, 11, 12, 13, 14, 17, 18, 20, 21, 22, 23, 25, 26, 27, 28, 34, 37, 39, 48, 49, 51, 52, 53, 55, 56, 57, 58, 59, 61, 64, 66, 68, 72, 73, 76, 77, 83, 88, 90, 91, 92, 93, 94, 96, 97, 98, 103, 104, 109], "singl": [3, 21, 25, 27, 39, 52, 61, 64, 66, 97, 98, 103, 104, 109, 111], "nucleotid": 3, "polymorph": 3, "snp": 3, "person": [3, 9, 34, 39, 48, 64, 66, 68, 96, 112], "genom": 3, "fewer": 3, "non": [3, 9, 10, 12, 13, 14, 19, 26, 34, 37, 48, 49, 64, 66, 79, 80], "spuriou": 3, "protein": 3, "systemat": [3, 112], "phenotyp": 3, "focu": [3, 4, 6, 12, 19, 25, 34, 55, 64, 67, 68, 72, 76, 78, 79, 80, 89, 90, 91, 96, 111], "brem": 3, "kruglyak": 3, "2005": [3, 5, 48, 56, 66], "discov": [3, 95], "featur": [3, 4, 6, 12, 15, 26, 37, 39, 50, 68, 69, 70, 75, 76, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 98, 105, 109, 111], "explain": 3, "104": [3, 10, 72], "segreg": 3, "simul": [3, 6, 10, 12, 68, 72, 76, 95], "genet": 3, "divers": [3, 48, 66, 111], "strain": 3, "by4716": 3, "rm11": 3, "1a": [3, 20, 24], "contain": [3, 4, 6, 9, 11, 12, 13, 14, 15, 19, 39, 50, 65, 77, 78, 79, 80, 83, 95, 105, 111, 112], "thousand": 3, "genotyp": 3, "rich": 3, "primari": [3, 50, 67, 111], "influenc": [3, 10, 12, 53, 111], "target": [3, 10, 16, 17, 18, 20, 21, 22, 23, 24, 39, 48, 49, 52, 55, 57, 61, 62, 63, 66, 79, 88, 111], "herit": 3, "due": [3, 14, 25, 52, 53, 55, 56, 57, 58, 93, 109, 111], "dimension": [3, 4, 9, 10, 11, 12, 13, 14, 15, 18, 22, 34, 53, 64, 76, 95, 105, 111], "name": [3, 5, 9, 10, 11, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 34, 39, 48, 49, 51, 52, 55, 61, 64, 66, 67, 72, 74, 76, 88, 96, 104, 109], "quantit": 3, "loci": 3, "qtl": 3, "involv": [3, 67], "parsimoni": 3, "reveal": 3, "necessari": [3, 4, 6, 69, 84, 85, 86, 87, 91, 92], "depend": [3, 5, 39, 53, 57, 61, 63, 67, 68, 78, 79, 80, 88, 89, 90, 93, 95, 105, 111], "present": [3, 53, 62, 82, 84, 85, 86, 87, 89, 91, 92, 93, 111], "toward": [3, 53, 83, 84, 88, 89, 90, 91, 95], "level": [3, 4, 6, 19, 49, 111], "yer124c": 3, "daughter": 3, "cell": [3, 5, 37, 52, 53, 55, 56, 57, 58, 59, 61, 94, 97, 98, 103, 104], "particip": 3, "pathwai": 3, "wall": 3, "metabol": 3, "delet": [3, 11, 13, 14], "separ": [3, 19, 21, 27, 28, 52, 61, 88], "divis": 3, "sensit": [3, 34, 37, 64], "drug": 3, "against": [3, 53], "consid": [4, 6, 9, 11, 12, 13, 14, 19, 34, 48, 49, 50, 52, 53, 55, 56, 57, 61, 62, 63, 64, 66, 68, 69, 72, 73, 75, 76, 77, 82, 83, 84, 86, 87, 89, 90, 91, 92, 95, 98, 103, 105, 111], "popul": [4, 6, 15], "scientif": [4, 6], "often": [4, 6, 21, 27, 49], "doe": [4, 6, 9, 11, 12, 13, 14, 68, 82, 84, 85, 111], "y": [4, 6, 10, 12, 15, 16, 19, 20, 23, 24, 37, 39, 48, 49, 51, 64, 66, 67, 68, 78, 79, 80, 83, 84, 87, 88, 89, 90, 91, 93, 95, 96, 105], "establish": [4, 6, 14, 48, 53, 66], "respons": [4, 6, 15, 21, 25, 27, 90, 91, 92, 93], "advoc": [4, 6], "neyman": [4, 6], "rubin": [4, 6], "robin": [4, 6, 15, 34, 64], "denot": [4, 6, 9, 11, 13, 19, 20, 21, 24, 26, 27, 39, 49, 50, 52, 53, 55, 56, 57, 61, 62, 63, 67, 68, 72, 75, 76, 78, 79, 80, 83, 88, 90, 95, 96, 105, 109, 111], "vector": [4, 6, 9, 11, 12, 13, 14, 20, 24, 63, 68, 69, 73, 76, 83, 84, 89, 90, 91, 95, 98, 103, 105, 111], "simplic": [4, 6, 21, 25, 57, 86, 87, 89, 111], "simplest": [4, 5, 6, 49], "case": [4, 6, 9, 11, 13, 14, 15, 19, 21, 23, 24, 27, 34, 37, 48, 49, 64, 66, 74, 103, 105, 111, 112], "binari": [4, 6, 10, 26, 34, 37, 48, 50, 64, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 82, 83, 84, 85, 88, 90, 91, 92, 93, 96, 109, 111], "0": [4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 34, 37, 39, 48, 49, 50, 51, 52, 53, 55, 56, 57, 61, 62, 63, 64, 66, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 103, 104, 109, 111], "1": [4, 6, 10, 16, 17, 18, 19, 20, 22, 23, 24, 26, 27, 28, 37, 49, 50, 51, 52, 53, 55, 56, 57, 58, 61, 62, 63, 65, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 103, 104, 105, 109], "sai": [4, 6, 9, 11, 13, 14], "ad": [4, 6, 19, 34, 64, 78, 79, 80, 88, 95, 105, 106], "versu": [4, 6, 109, 111], "acquir": [4, 6], "app": [4, 6], "download": [4, 6, 16, 18, 22, 49], "experi": [4, 6, 15, 19, 37, 63, 68, 72, 76, 78, 79, 80, 95, 96], "baselin": [4, 6, 11, 13, 14, 15, 21, 26, 57, 61, 68, 75, 76, 96], "observ": [4, 6, 9, 11, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 37, 39, 48, 50, 52, 53, 55, 57, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 74, 75, 76, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 91, 94, 95, 96, 97, 104, 105, 111], "summar": [4, 6, 9, 10, 19, 21, 25, 27, 49, 72, 111], "z_i": [4, 6, 9, 11, 12, 13, 14, 20, 24], "x_i": [4, 15, 37, 39, 49], "t_i": [4, 15, 62, 63], "y_i": [4, 15, 37, 39, 49], "cdot": [4, 6, 9, 10, 11, 12, 13, 14, 15, 18, 20, 22, 23, 24, 34, 39, 50, 52, 53, 55, 56, 57, 61, 62, 63, 64, 65, 66, 67, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 82, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 97, 98, 103, 104, 111], "th": [4, 6, 15, 18, 22, 53, 57, 58, 62, 63, 76, 83], "covari": [4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 24, 75, 77, 86, 87, 89], "prior": [4, 6, 11, 67, 68, 69, 73, 75, 76, 77, 84, 85, 86, 87, 89, 91, 92, 93, 96, 98, 103], "assum": [4, 6, 9, 11, 13, 23, 24, 34, 37, 48, 57, 62, 63, 64, 66, 67, 68, 69, 70, 72, 73, 75, 76, 77, 82, 84, 85, 86, 87, 89, 90, 91, 92, 93, 95, 96, 98, 103, 105, 111], "chosen": [4, 6, 19, 55, 63, 68, 79, 80, 83, 84, 88, 90, 91, 92, 93], "henc": [4, 6, 10, 15, 37, 52, 57, 61, 68, 72, 76, 84, 91, 96], "sometim": [4, 6], "refer": [4, 5, 6, 49, 112], "counterfactu": [4, 6, 63], "becaus": [4, 6], "realiti": [4, 6], "both": [4, 5, 6, 11, 13, 14, 15, 21, 27, 39, 49, 52, 53, 57, 61, 63, 71, 75, 77, 84, 89, 91, 97, 103, 111], "hypothet": [4, 6], "contrari": [4, 6], "fact": [4, 6, 52, 53, 55, 56, 61, 62, 68], "actual": [4, 6, 15], "than": [4, 6, 10, 19, 20, 21, 23, 24, 28, 39, 52, 53, 57, 58, 61, 63, 68, 70, 72, 76, 96], "notion": [4, 6], "defin": [4, 5, 6, 10, 12, 15, 16, 18, 19, 20, 21, 22, 23, 24, 27, 34, 39, 48, 49, 52, 53, 57, 58, 61, 62, 63, 64, 66, 71, 78, 79, 80, 83, 88, 95, 96, 97, 105, 109, 111], "now": [4, 6, 21, 27, 49, 95], "deduc": [4, 6], "x": [4, 6, 15, 18, 19, 22, 23, 24, 34, 37, 39, 49, 51, 67, 69, 70, 75, 77, 78, 79, 80, 82, 84, 85, 86, 89, 91, 92, 96, 98, 105], "sutva": [4, 6, 15, 63], "stabl": [4, 6, 10, 15, 109], "unit": [4, 6, 15, 111], "begin": [4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 34, 37, 39, 48, 49, 52, 53, 55, 56, 57, 58, 61, 62, 63, 64, 65, 66, 69, 70, 71, 73, 74, 75, 77, 78, 79, 80, 82, 83, 84, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 104, 105, 111], "align": [4, 6, 15, 23, 24, 34, 37, 48, 52, 53, 57, 61, 62, 64, 65, 66, 69, 70, 71, 73, 74, 93, 97, 98, 104], "end": [4, 6, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 34, 37, 39, 48, 49, 52, 53, 55, 56, 57, 58, 61, 62, 63, 64, 65, 66, 69, 70, 71, 73, 74, 75, 77, 78, 79, 80, 82, 83, 84, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 103, 104, 105, 111], "That": [4, 6, 15, 19, 23, 24, 49], "regardless": [4, 6, 15], "experiment": [4, 6, 15, 111], "interfer": [4, 6, 15], "unmeasur": [4, 6, 9, 11, 13, 14, 15, 21, 25, 63], "confound": [4, 6, 9, 11, 12, 13, 14, 15, 21, 25, 63], "strong": [4, 6, 14, 15, 18, 22, 57, 61], "ignor": [4, 6, 15, 57, 61, 78, 79, 80, 112], "perp": [4, 6, 15, 63], "confirm": [4, 6, 15], "refut": [4, 6, 15], "believ": [4, 6, 15], "relev": [4, 6, 15, 57], "reason": [4, 6, 9, 12, 14, 15, 19], "abov": [4, 6, 9, 10, 11, 15, 16, 18, 19, 21, 22, 24, 25, 28, 39, 90, 112], "p": [4, 6, 9, 10, 11, 12, 13, 14, 15, 19, 20, 21, 24, 25, 27, 28, 34, 37, 39, 51, 61, 62, 63, 64, 68, 69, 70, 71, 74, 75, 77, 82, 84, 86, 87, 88, 89, 91, 92, 94, 96, 97, 98, 103, 104, 111, 112], "ensur": [4, 6, 15, 63], "abl": [4, 6, 15, 19, 73, 75], "similar": [4, 5, 6, 15, 37, 52, 53, 56, 57, 61, 63, 64, 67, 69, 70, 71, 73, 74, 75, 76, 77, 82, 83, 98, 111], "vice": [4, 6, 15], "versa": [4, 6, 15], "text": [4, 5, 6, 12, 15, 16, 19, 21, 24, 25, 27, 28, 37, 48, 50, 52, 55, 56, 62, 66, 74, 75, 77, 84, 89, 91, 92], "ATE": [4, 6, 12, 19], "There": [4, 5, 6, 19, 49, 50, 74], "deriv": [4, 6, 18, 21, 22, 28, 34, 39, 53, 58, 66, 89], "confoun": 4, "come": [4, 86, 87, 111], "consider": 4, "e_x": [4, 15], "quad": [4, 15, 18, 21, 22, 28, 34, 64, 75, 77, 78, 79, 80, 84, 89, 91], "similarli": [4, 10, 15, 34, 52, 53, 61, 62, 63, 64, 75, 77, 88, 89, 95], "mu": [4, 15, 16, 21, 24, 25, 69, 73, 75, 76, 77, 78, 79, 80, 82, 84, 89, 91], "gamma": [4, 15, 20, 24, 34, 52, 53, 55, 56, 57, 61, 62, 63, 64, 69, 70, 75, 77, 82, 84, 86, 89, 91, 92, 98], "paramet": [4, 9, 11, 15, 18, 20, 22, 24, 39, 69, 71, 74, 75, 77, 84, 89, 90, 91, 93, 96, 97, 98], "mle": 4, "least": [4, 15, 20, 21, 24, 68, 72, 76, 90, 95, 96], "squar": [4, 15, 20, 24], "Then": [4, 9, 10, 11, 12, 13, 14, 15, 18, 22, 58, 64, 66, 68, 72, 74, 76, 78, 79, 80, 84, 89, 91, 95, 96, 104, 105, 112], "hat": [4, 15, 16, 18, 20, 21, 22, 23, 24, 25, 27, 28, 34, 48, 49, 52, 55, 57, 61, 62, 63, 64, 66, 70, 71, 75, 82, 86, 94], "sum_": [4, 15, 18, 22, 34, 39, 48, 49, 52, 53, 55, 56, 57, 58, 61, 62, 63, 64, 68, 72, 74, 76, 78, 79, 80, 82, 83, 84, 88, 89, 90, 91, 92, 93, 94, 96, 104], "anoth": [4, 5, 9, 19, 49, 57, 58, 61], "class": [4, 9, 23, 24, 39, 49, 52, 53, 55, 61, 67, 68, 74, 76, 84, 89, 91, 95, 96, 104, 105, 111], "pi": [4, 15, 16, 20, 24, 37, 48, 49, 52, 53, 55, 56, 57, 58, 61, 62, 63, 66, 78, 79, 80], "get": [4, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 34, 48, 49, 50, 51, 64, 66, 69, 70, 71, 72, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93, 105], "function": [4, 5, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 34, 37, 39, 48, 49, 52, 53, 55, 56, 57, 61, 63, 64, 68, 70, 71, 75, 78, 79, 80, 84, 86, 87, 89, 90, 91, 92, 95, 96, 97, 105, 111], "One": [4, 15, 52, 61, 112], "difficult": [4, 15, 71], "build": [4, 5, 61, 68, 111, 112], "simpli": [4, 49, 76, 86], "stratifi": 4, "choos": [4, 52, 53, 61, 67, 68, 72, 74, 76, 78, 79, 80, 84, 88, 89, 90, 91, 95, 96, 104, 105], "cutoff": 4, "c_0": 4, "c_1": 4, "c_k": 4, "belong": [4, 55], "k": [4, 9, 10, 11, 12, 13, 14, 20, 24, 39, 49, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 103, 104, 105], "c_": [4, 34, 64, 71, 74, 97, 104], "le": [4, 5, 39, 52, 53, 55, 56, 62, 63, 83], "bar": [4, 18, 22, 57, 63, 65, 66], "_": [4, 9, 11, 13, 14, 15, 16, 18, 19, 21, 22, 24, 25, 27, 28, 34, 37, 39, 48, 49, 50, 52, 53, 55, 56, 57, 58, 61, 62, 63, 64, 66, 69, 73, 75, 76, 77, 78, 79, 80, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94, 95, 96, 98, 103, 104, 105, 111], "1k": 4, "0k": 4, "n_k": 4, "theoret": [4, 19, 53, 63, 77, 90, 95, 105, 107, 112], "justif": 4, "semiparametr": [4, 16, 19, 20, 23, 24, 52, 53, 61], "theori": [4, 19, 20, 24, 34, 37, 53, 64, 68, 90, 91, 93], "augment": [4, 15, 37, 53], "ipw": [4, 15, 49], "sinc": [4, 10, 15, 50, 53, 57, 67, 68, 72, 78, 79, 80, 90, 96, 103, 111], "probabl": [4, 15, 37, 39, 49, 52, 53, 57, 61, 62, 71, 72, 77, 90, 95, 96, 97], "everi": [4, 15, 52, 57, 61, 68, 72, 75, 76, 77, 82, 84, 89, 91, 92, 96], "themselv": [4, 15], "did": [4, 15, 64, 66, 111], "frac": [4, 15, 16, 18, 20, 22, 24, 34, 37, 39, 48, 49, 52, 53, 57, 61, 64, 71, 74, 90, 91, 92, 93, 94, 96, 97, 104], "ty": 4, "unbias": [4, 15, 57], "left": [4, 15, 18, 20, 22, 23, 24, 39, 49, 52, 61, 64, 78, 79, 80, 111], "right": [4, 9, 12, 15, 18, 20, 22, 23, 24, 39, 49, 52, 55, 56, 61, 64, 78, 79, 80, 111], "consequ": [4, 15, 39, 52, 61], "t_iy_i": [4, 15], "combin": [4, 15, 20, 21, 24, 25, 27, 28, 49, 52, 53, 61, 74, 76], "obtain": [4, 9, 11, 13, 18, 20, 21, 22, 23, 24, 27, 28, 49, 53, 57, 66, 87, 88, 111], "whether": [5, 79, 80, 91, 92, 93], "you": [5, 10, 34, 37, 48, 49, 66, 85, 112], "write": [5, 15, 18, 22], "content": [5, 20, 24, 111], "jupyt": [5, 112], "notebook": 5, "ipynb": [5, 9, 14], "regular": [5, 39, 61, 75], "md": 5, "ll": 5, "flavor": 5, "stand": [5, 34, 64, 90], "markedli": 5, "slight": 5, "variat": [5, 9], "commonmark": 5, "small": [5, 37, 111], "syntax": 5, "sphinx": 5, "ecosystem": 5, "power": [5, 20, 24, 112], "tool": [5, 15], "kind": [5, 58], "markup": 5, "languag": [5, 67], "serv": [5, 15, 63], "purpos": [5, 15, 26, 109], "line": [5, 19, 52, 61, 112], "wherea": [5, 63], "span": 5, "input": [5, 26, 109, 111], "being": [5, 71, 74, 76, 77, 83, 84, 89, 90, 91, 93, 95, 97, 104, 109], "At": [5, 62, 64, 66, 68, 69, 71, 73, 74, 83, 84, 86, 89, 91, 96, 97, 98, 103, 104], "insert": 5, "mydirectivenam": 5, "my": [5, 19], "work": [5, 9, 13, 34, 49, 53, 64, 66], "alreadi": [5, 16, 17, 18, 20, 22, 23, 48, 49, 66], "doesn": [5, 111], "pre": [5, 11, 63, 71, 95, 96, 97, 111], "note": [5, 10, 11, 13, 14, 19, 21, 28, 34, 37, 48, 49, 50, 62, 63, 64, 66, 69, 71, 73, 74, 75, 76, 77, 82, 84, 85, 86, 87, 89, 90, 91, 92, 95, 98, 103, 105], "box": 5, "here": [5, 9, 10, 11, 12, 13, 14, 18, 19, 22, 34, 37, 39, 53, 62, 64, 66, 69, 70, 71, 73, 74, 75, 76, 77, 79, 80, 82, 84, 85, 86, 87, 89, 91, 92, 93, 95, 96, 97, 103, 105], "built": [5, 37, 61], "see": [5, 9, 10, 11, 13, 14, 20, 21, 23, 24, 53, 61, 68, 72, 77, 95, 96, 109, 111], "document": [5, 10, 11, 13, 14, 109, 112], "less": [5, 19, 34, 39, 64], "pattern": 5, "some": [5, 15, 16, 19, 21, 24, 25, 27, 34, 39, 49, 52, 53, 61, 63, 64, 77, 78, 79, 80, 84, 95, 105, 107, 111], "rolenam": 5, "again": [5, 66], "valid": [5, 53, 58, 63], "doc": [5, 10, 109], "page": [5, 16, 19, 20, 23, 24, 57, 67, 88, 95, 96, 105, 112], "rel": [5, 21, 27, 57, 61, 76, 111], "path": [5, 10], "intro": 5, "cite": [5, 61], "store": [5, 79], "bibtex": 5, "holdgraf_evidence_2014": 5, "render": 5, "moreov": [5, 15, 19, 52, 53, 61], "bibliographi": 5, "properli": [5, 9], "bib": 5, "look": [5, 18, 19, 22, 53], "egw05": [5, 56], "damien": [5, 56], "ernst": [5, 56], "pierr": [5, 56], "geurt": [5, 56], "loui": [5, 56], "wehenkel": [5, 56], "tree": [5, 18, 19, 22, 49, 56], "batch": [5, 55, 56, 84, 89, 91], "mode": [5, 56, 84, 89, 91], "learn": [5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 49, 53, 55, 56, 57, 58, 61, 62, 63, 67, 68, 69, 71, 72, 74, 75, 76, 77, 78, 79, 80, 82, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 103, 104, 105, 112], "journal": [5, 9, 10, 11, 12, 13, 14, 16, 19, 20, 23, 24, 34, 37, 49, 56, 63, 64, 68, 78, 79, 80, 90, 107], "jl16": [5, 52, 57], "nan": [5, 10, 52, 55, 57], "jiang": [5, 52, 55, 57, 61, 67, 96], "lihong": [5, 52, 57], "li": [5, 15, 39, 52, 57, 61, 68, 69, 70, 78, 79, 80, 82, 90, 92, 93, 96, 98], "doubli": [5, 6, 16, 19, 20, 23, 24, 34, 39, 49, 53, 57, 61, 64, 78, 80], "robust": [5, 16, 19, 20, 23, 24, 34, 39, 49, 53, 57, 61, 64, 75, 78, 80, 83, 84, 88, 89, 90, 91, 95, 111], "off": [5, 39, 52, 55, 57, 58, 61, 72, 78, 79, 80, 85, 96, 112], "polici": [5, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 37, 51, 55, 56, 58, 68, 71, 112], "evalu": [5, 11, 13, 14, 15, 18, 21, 22, 26, 56, 58, 68, 96, 111], "intern": [5, 9, 10, 11, 12, 13, 14, 16, 19, 20, 23, 24, 39, 52, 53, 57, 58, 61, 67, 68, 69, 70, 76, 77, 82, 83, 85, 86, 87, 88, 93, 95, 96, 98, 105, 112], "confer": [5, 9, 10, 11, 12, 13, 14, 19, 39, 52, 53, 57, 58, 61, 67, 68, 69, 70, 76, 77, 82, 83, 85, 86, 87, 88, 90, 91, 93, 95, 96, 98, 105], "652": [5, 52, 57, 61], "661": [5, 52, 57, 61, 68, 96], "pmlr": [5, 19, 39, 52, 53, 57, 58, 61, 67, 68, 69, 76, 77, 82, 83, 85, 86, 87, 88, 90, 91, 93, 95, 96, 98, 105], "ku19": [5, 52], "nathan": [5, 52], "kallu": [5, 39, 52], "masatoshi": [5, 52], "uehara": [5, 52], "effici": [5, 15, 16, 19, 21, 24, 28, 37, 52, 53, 55, 56, 57, 58, 59, 61, 70, 75, 76, 77, 82, 84, 86, 87, 88, 89, 90, 91, 93, 94, 97, 98, 103, 104], "break": [5, 52, 61], "curs": [5, 18, 22, 52, 53, 61], "horizon": [5, 53, 62, 63, 86, 87, 89, 111], "doubl": [5, 15, 20, 24, 61, 79], "1909": [5, 52], "05850": [5, 52], "lvy19": [5, 55], "hoang": [5, 52, 55], "cameron": [5, 52, 55], "voloshin": [5, 52, 55], "yisong": [5, 52, 55], "yue": [5, 9, 10, 11, 12, 13, 14, 52, 55], "1903": [5, 55], "08738": [5, 55], "lltz18": [5, 57], "qiang": [5, 52, 57], "liu": [5, 37, 52, 57, 61], "ziyang": [5, 52, 57], "tang": [5, 52, 57, 61], "dengyong": [5, 52, 57], "zhou": [5, 39, 49, 52, 57, 67, 93, 96], "infinit": [5, 53, 62, 63, 68, 111], "advanc": [5, 9, 10, 11, 12, 13, 14, 19, 21, 25, 39, 57, 61, 75, 76, 77, 87, 90, 91, 92, 112], "neural": [5, 9, 10, 11, 12, 13, 14, 19, 39, 57, 61, 67, 75, 76, 77, 87, 90, 91, 92, 96], "process": [5, 9, 10, 11, 12, 13, 14, 19, 39, 52, 57, 61, 67, 75, 76, 77, 86, 87, 89, 90, 91, 92, 95, 96, 107, 111], "system": [5, 9, 10, 11, 12, 13, 14, 19, 39, 57, 61, 62, 67, 68, 72, 75, 76, 77, 83, 84, 87, 89, 90, 91, 92, 95, 96], "5356": [5, 57], "5366": [5, 57], "2018": [5, 9, 10, 11, 12, 14, 15, 34, 37, 39, 49, 57, 61, 62, 63, 64, 67, 71, 88, 90, 92, 96, 97, 103, 104, 107], "pre00": [5, 57], "doina": [5, 57], "precup": [5, 57, 61], "elig": [5, 57, 61], "trace": [5, 57, 61], "comput": [5, 9, 13, 19, 57, 61, 68, 75, 84, 90, 91, 92, 93], "scienc": [5, 9, 10, 11, 12, 13, 14, 19, 21, 25, 27, 28, 34, 57, 61, 64, 84, 91, 111], "depart": [5, 57, 61], "faculti": [5, 57, 61], "public": [5, 18, 22, 25, 26, 27, 28, 57, 61], "80": [5, 34, 49, 51, 57, 61, 64], "2000": [5, 9, 10, 11, 12, 13, 14, 48, 57, 61, 66, 89, 97, 98, 103, 104], "put14": [5, 63], "martin": [5, 63], "l": [5, 23, 24, 39, 52, 61, 62, 63, 67, 68, 69, 70, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 98], "puterman": [5, 62, 63], "markov": [5, 9, 11, 13, 14, 57, 83, 111], "stochast": [5, 52, 61, 62, 63, 67, 68, 72, 76, 78, 79, 80, 95, 96, 105], "dynam": [5, 15, 34, 37, 39, 48, 62, 63, 64, 66, 91, 93, 94, 95, 105, 111], "program": [5, 62, 63, 84, 90, 91, 93], "wilei": [5, 62, 63], "son": [5, 62, 63], "2014": [5, 9, 10, 11, 12, 13, 14, 34, 49, 62, 63, 64], "swcs21": [5, 53], "chengchun": [5, 53], "shi": [5, 19, 34, 39, 53, 58, 63, 64, 107], "runzh": [5, 53], "wan": [5, 53, 58, 75, 76, 83, 84, 88, 89, 90, 91, 95], "victor": [5, 19, 53], "chernozhukov": [5, 15, 53, 58], "rui": [5, 9, 10, 11, 12, 13, 14, 37, 49, 53], "song": [5, 9, 10, 11, 12, 13, 14, 34, 37, 39, 48, 49, 53, 64, 66, 75, 76, 78, 79, 80, 83, 84, 88, 89, 90, 91, 95], "deepli": [5, 58], "debias": [5, 15, 58], "interv": [5, 18, 22, 39, 48, 49, 53, 62, 63, 78, 79, 80], "9580": [5, 53, 58], "9591": [5, 53, 58], "2021": [5, 9, 13, 16, 19, 20, 23, 24, 39, 49, 53, 58, 75, 76, 77, 78, 79, 80], "swl": [5, 63, 107], "20": [5, 9, 10, 14, 16, 17, 18, 20, 22, 23, 34, 39, 48, 49, 51, 63, 89, 91, 92, 107, 109], "miss": [5, 63, 107], "shi2020reinforc": [5, 63, 107], "sb18": [5, 63, 107], "richard": [5, 9, 10, 11, 12, 13, 14, 63, 107], "sutton": [5, 62, 63, 71, 96, 97, 107], "andrew": [5, 63, 107], "g": [5, 9, 10, 11, 12, 13, 14, 21, 26, 28, 34, 49, 52, 53, 55, 57, 61, 62, 63, 67, 71, 75, 77, 84, 89, 90, 91, 92, 96, 97, 107, 111], "barto": [5, 62, 63, 71, 96, 97, 107], "mit": [5, 62, 63, 71, 96, 97, 107], "press": [5, 62, 63, 71, 73, 96, 97, 107], "tfl": [5, 52], "yihao": [5, 52], "feng": [5, 52], "bia": [5, 15, 16, 18, 20, 21, 22, 23, 24, 37, 39, 49, 52, 53, 55, 57, 61], "reduct": [5, 52], "represent": [5, 9, 10, 11, 12, 13, 14, 37, 52], "tb16": [5, 52], "philip": [5, 52, 57], "thoma": [5, 52, 57, 61], "emma": [5, 52], "brunskil": [5, 52], "2139": [5, 52], "2148": [5, 52], "tho15": [5, 57], "safe": [5, 57, 61], "doctor": [5, 12, 57], "dissert": [5, 57], "univers": [5, 57, 73, 96], "massachusett": [5, 57], "amherst": [5, 57], "uhj19": [5, 52], "jiawei": [5, 52], "huang": [5, 52], "minimax": [5, 52, 53], "weight": [5, 9, 10, 11, 12, 13, 14, 15, 18, 20, 21, 22, 24, 28, 52, 53, 57, 61, 88, 95, 105, 111], "1910": [5, 52], "12809": [5, 52], "vljy19": [5, 52, 55], "empir": [5, 52, 55, 57, 63, 68, 72, 96], "1911": [5, 52, 55], "06854": [5, 52, 55], "If": [5, 48, 64, 66, 75, 76, 82, 86, 89, 95, 105, 112], "insid": 5, "jupytext": 5, "metadata": [5, 18, 22, 75, 76], "run": [5, 10, 14], "command": [5, 112], "init": 5, "print": [5, 11, 13, 14, 16, 18, 20, 21, 22, 23, 24, 25, 27, 28, 34, 48, 51, 64, 66, 109], "default": [5, 9, 11, 48, 49, 75, 77, 82, 112], "kernel": [5, 18, 19, 20, 22, 24, 37, 39, 52, 61, 62, 63, 111], "output": [5, 11, 39], "rest": [5, 6, 10, 12, 78, 79, 80], "nb": 5, "r": [6, 10, 12, 15, 16, 17, 18, 19, 21, 22, 25, 27, 28, 34, 39, 48, 49, 50, 52, 57, 58, 61, 62, 63, 64, 65, 66, 68, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 103, 104, 105, 109, 111], "s_i": [6, 15, 18, 19, 20, 21, 22, 23, 24, 28, 34, 111], "a_i": [6, 15, 18, 19, 20, 22, 23, 24, 37, 39, 49, 50, 78, 79, 80, 111], "r_i": [6, 15, 18, 19, 20, 21, 22, 23, 24, 28, 34, 50, 64, 65, 78, 79, 80, 111], "equival": [6, 9, 10, 11, 12, 13, 14, 37, 53, 67, 72, 96], "pearl": [6, 9, 10, 11, 12, 13, 14], "spirt": [6, 9, 10, 11, 12, 13, 14], "mathemat": [6, 10, 12, 34, 64, 88, 95, 105], "physic": [6, 10, 12, 111], "hold": [6, 10, 12, 57, 61, 62, 63], "constant": [6, 10, 12, 21, 27, 37], "unchang": [6, 10, 12], "three": [6, 9, 11, 13, 14, 15, 16, 20, 21, 24, 25, 49, 67, 68, 69, 70, 71, 73, 74, 77, 78, 79, 80, 82, 84, 85, 86, 89, 91, 92, 93, 95, 96, 105, 111], "regress": [6, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 23, 24, 25, 27, 28, 34, 48, 49, 55, 57, 61, 64, 66, 84], "propens": [6, 12, 15, 16, 20, 21, 23, 24, 28, 34, 39, 49, 57, 61, 64], "score": [6, 9, 12, 15, 16, 20, 21, 23, 24, 26, 28, 34, 39, 49, 57, 61, 64, 109, 111], "roust": 6, "procedur": [6, 11, 16, 19, 24, 53, 58], "introduc": [6, 15, 18, 19, 20, 21, 22, 24, 25, 28, 34, 52, 53, 57, 58, 61, 62, 63, 64, 66, 67, 68, 74, 75, 77, 78, 79, 80, 83, 90, 93, 96, 104, 107, 111, 112], "cel": 6, "detail": [6, 10, 12, 15, 16, 19, 20, 21, 24, 28, 50, 53, 72, 96, 111, 112], "hte": [6, 16, 18, 20, 21, 22, 23, 24, 25, 27, 28, 109], "captur": [6, 18, 21, 22, 27, 39, 79, 80], "heterogenieti": 6, "state": [6, 11, 13, 14, 19, 21, 25, 26, 27, 49, 52, 53, 55, 56, 57, 61, 62, 63], "quit": [6, 19, 21, 27, 57, 61, 111], "few": [6, 19, 52, 61, 63, 68, 72, 76, 88, 96, 107, 111], "deal": [6, 84, 85, 89, 91, 94, 111], "methodolog": [9, 12, 34, 64], "reli": [9, 12, 13, 52, 61], "locat": [9, 12], "reward": [9, 12, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 37, 48, 49, 50, 57, 62, 63, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 103, 104, 105, 111], "conveni": [9, 12], "violat": [9, 12, 53], "emerg": [9, 12], "basic": [9, 15, 16, 21, 24, 25, 28, 34, 86, 87, 89, 111], "wai": [9, 21, 23, 24, 28, 37, 49, 52, 53, 55, 56, 57, 58, 59, 61, 66, 94, 97, 98, 103, 104], "mathcal": [9, 10, 11, 12, 13, 14, 34, 39, 52, 53, 57, 61, 62, 63, 64, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 103, 104, 105, 111], "mathbf": [9, 10, 11, 12, 13, 14, 50], "z": [9, 10, 11, 12, 13, 14, 16, 19, 24, 61, 73, 82, 83, 85, 86, 88, 95, 96, 103, 104, 105], "node": [9, 11, 12, 13, 14, 111], "edg": [9, 10, 11, 12, 13, 14], "said": [9, 11, 12, 13, 14], "parent": [9, 11, 12, 13, 14, 112], "z_j": [9, 11, 12, 13, 14], "let": [9, 10, 11, 12, 13, 14, 15, 19, 20, 21, 24, 25, 27, 28, 39, 48, 50, 52, 53, 57, 61, 62, 63, 65, 68, 72, 76, 83, 88, 90, 95, 96, 105], "pa_": [9, 11, 12, 13, 14], "cycl": [9, 11, 12, 13, 14], "acycl": [9, 10, 11, 12, 13, 14], "dag": [9, 10, 11, 12, 13, 14, 109], "suppos": [9, 10, 11, 12, 13, 14, 19, 34, 50, 64, 65, 68, 69, 70, 71, 72, 73, 74, 83, 88, 90, 97, 98, 103, 104], "character": [9, 10, 11, 12, 13, 14, 56, 62, 79, 80, 82, 84, 90, 95, 105], "z_1": [9, 11, 12, 13, 14], "z_2": [9, 11, 12, 13, 14], "z_d": [9, 11, 12, 13, 14], "rightarrow": [9, 11, 12, 13, 14, 20, 24], "mean": [9, 11, 12, 13, 14, 19, 39, 49, 51, 52, 57, 61, 63, 64, 66, 69, 71, 73, 74, 75, 77, 78, 79, 80, 84, 86, 87, 88, 89, 91, 92, 96, 97, 98, 103, 104, 109, 111], "propos": [9, 10, 13, 14, 37, 39, 52, 53, 57, 58, 61, 64, 78, 79, 80, 82, 111], "plusibl": 9, "up": [9, 13, 18, 20, 22, 24, 63, 67, 75, 77, 111], "markovian": 9, "unless": [9, 14], "certain": [9, 49, 63], "assumpt": [9, 11, 13, 14, 16, 19, 21, 24, 25, 37, 53, 57, 61, 63, 67, 68, 79, 83, 84, 89, 91, 107, 111], "satisfi": [9, 15, 16, 17, 18, 20, 22, 23, 24, 49, 52, 53, 57, 61, 68, 72, 76, 86, 87, 88, 89, 95, 96, 105], "specifi": [9, 10, 11, 15, 18, 22, 23, 24, 34, 37, 48, 50, 53, 63, 64, 66, 79, 96, 97, 98, 103], "type": [9, 15, 50, 52, 53, 55, 56, 57, 58, 61, 68, 72, 73, 76, 78, 79, 90, 91, 92, 93, 94, 96, 111, 112], "focus": [9, 19, 49, 57, 72, 83, 95, 96, 105, 111], "local": [9, 14, 18, 19, 20, 22, 24, 49, 112], "independ": [9, 10, 11, 12, 13, 14, 15, 20, 24, 49, 50, 63, 86], "skeleton": [9, 111], "determin": [9, 12, 14, 71, 75, 84, 89, 90, 91, 92, 93, 95, 105], "orient": [9, 10, 14], "well": [9, 11, 13, 19, 21, 37, 49, 55, 57, 61, 62, 63, 71, 72, 82, 86, 88, 89, 96, 97, 107, 111], "pc": [9, 10, 11, 12, 13, 111], "algorithm": [9, 10, 12, 19, 20, 21, 24, 25, 27, 28, 37, 52, 56, 62, 63, 68, 69, 72, 75, 76, 77, 78, 79, 80, 82, 85, 86, 87, 92, 93, 111, 112], "et": [9, 11, 12, 14, 15, 16, 24, 37, 49, 52, 53, 57, 58, 61, 63, 71, 74, 78, 79, 80, 82, 86, 96, 97, 104, 107], "al": [9, 11, 12, 14, 15, 16, 24, 37, 49, 52, 53, 57, 58, 61, 63, 71, 74, 78, 79, 80, 82, 86, 96, 97, 104, 107], "kalisch": [9, 10, 11, 12, 13, 14], "b\u00fchlmann": [9, 10, 11, 12, 13, 14], "easi": [9, 14, 19, 21, 23, 24, 25, 48, 55, 57, 66, 71, 90], "shah": [9, 10, 11, 12, 13, 14], "peter": [9, 10, 11, 12, 13, 14, 16, 19, 20, 23, 24], "second": [9, 15, 21, 27, 34, 39, 53, 64, 82, 84, 85, 111], "ica": [9, 13, 14], "lingam": [9, 13, 14, 111], "shimizu": [9, 10, 11, 12, 13, 14], "2006": [9, 10, 11, 12, 13, 14, 16, 19, 20, 23, 24, 85], "cam": [9, 10, 11, 12, 13, 14], "greedi": [9, 10, 11, 12, 13, 14, 72, 78, 79, 80, 97, 111], "search": [9, 10, 11, 12, 13, 14, 83], "ge": [9, 52, 53, 57, 61, 62, 63, 75, 76, 83, 84, 88, 89, 90, 91, 95], "chicker": [9, 10, 11, 12, 13, 14], "2002": [9, 10, 11, 12, 13, 14, 68, 71, 74, 96, 97, 104], "fge": 9, "ramsei": [9, 10, 11, 12, 13, 14], "2017": [9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 22, 23, 24, 49, 67, 73, 90, 91, 93, 95, 96, 105], "bayesian": [9, 10, 11, 12, 13, 14, 75, 76, 84, 85, 87, 89, 91], "zheng": [9, 10, 11, 12, 14], "open": [9, 10, 26, 109, 112], "construct": [9, 10, 11, 12, 13, 14, 16, 20, 21, 24, 25, 52, 53, 55, 57, 58, 61, 75], "notear": [9, 11, 14, 109, 111], "vae": [9, 13], "parameter": [9, 13, 75, 77, 84, 89, 91], "network": [9, 10, 11, 12, 13, 14, 19, 39, 49], "yu": [9, 10, 11, 12, 13, 14, 19, 21, 25, 27, 28, 37, 49], "friendli": [9, 13], "gnn": [9, 10, 11, 12, 13, 14], "zhu": [9, 10, 11, 12, 13, 14, 39, 90, 92], "chen": [9, 10, 11, 12, 13, 14, 78, 79, 80, 87, 88, 95, 105], "cai": [9, 11, 12, 13, 14, 39, 78, 79, 80], "cut": [9, 13], "support": [9, 20, 24, 63, 68, 73, 74, 77, 111], "train": [9, 10, 16, 18, 19, 20, 22, 23, 24, 34, 37, 48, 51, 64, 66, 69, 70, 82, 111], "free": [9, 55, 111], "gaussian": [9, 10, 12, 13, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 86, 87, 89, 98, 103, 111], "o": [9, 10, 11, 12, 13, 14, 15, 111], "ye": [9, 111], "max": [9, 39, 48, 49, 52, 61, 66, 111], "adjac": [9, 10, 11, 13, 14, 111], "b_": [9, 11, 13, 14], "leq": [9, 11, 13, 14, 78, 79, 80, 88, 90, 111], "matrix": [9, 10, 11, 13, 14, 69, 73, 75, 84, 86, 87, 89, 91, 92, 95, 109], "otherwis": [9, 11, 13, 14, 48, 50, 66, 71, 77, 83, 97, 112], "nest": [9, 11, 13, 14, 34, 64], "faith": [9, 11, 13, 14], "suffici": [9, 11, 13, 14, 52, 57], "pair": [9, 11, 13, 14, 52, 53, 57, 61, 63, 69, 73, 84, 85, 87, 91, 92, 93, 98, 103], "epsilon": [9, 11, 13, 14, 23, 24, 49, 72, 78, 79, 80, 97, 111], "label": [9, 10, 11, 13, 14, 37, 39, 52, 53, 55, 57, 58, 61, 62, 63, 75, 78, 79, 80, 83, 84, 89, 90, 91, 95, 105], "lsem_x": [9, 11, 13, 14], "jointli": [9, 11, 13, 14, 34, 64], "error": [9, 11, 13, 14, 19, 34, 48, 64, 66], "plu": [9, 11, 13], "n_i": [9, 11, 13], "anm": [9, 11, 13], "f_i": [9, 11, 13], "special": [9, 11, 13, 111], "handl": [9, 11, 13, 14, 19, 21, 39, 57, 61, 96, 109, 111], "version": [9, 11, 13, 18, 22, 52, 53, 57, 61, 68, 71, 72, 90, 96, 97], "f_2": [9, 13], "f_1": [9, 13], "perform": [9, 13, 18, 19, 20, 21, 22, 24, 27, 37, 49, 52, 55, 56, 57, 61, 68, 69, 70, 71, 73, 74, 75, 77, 78, 79, 80, 96, 97], "nonlinear": [9, 13, 21, 27], "transform": [9, 13, 34], "fisher": [9, 14], "implement": [9, 11, 13, 14, 18, 19, 21, 22, 25, 37, 39, 48, 49, 55, 57, 66, 75, 77, 78, 79, 80, 111, 112], "packag": [9, 10, 11, 14, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 37, 49, 50, 51, 64, 84, 91, 109, 112], "http": [9, 10, 11, 13, 14, 17, 18, 22, 26, 50, 109, 112], "github": [9, 10, 11, 13, 14, 17, 69, 70, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93, 112], "com": [9, 10, 11, 13, 14, 17, 26, 50, 112], "bd2kccd": [9, 14], "highli": [9, 14], "java": [9, 14], "blob": [9, 14], "20pc": [9, 14], "20in": [9, 14], "20action": [9, 14], "recov": [9, 11], "hyper": [9, 11, 74], "cdt15": [9, 11], "xunzheng": [9, 13], "incorpor": [9, 10, 19, 71, 73, 96, 97], "auto": 9, "encod": 9, "modifi": [9, 12, 69, 73, 84, 85, 86, 87, 89, 91, 92, 98, 103], "smooth": [9, 39], "evid": 9, "lower": [9, 11, 13, 14, 49, 52, 57, 61, 79, 86], "bound": [9, 19, 20, 24, 52, 53, 61, 62, 63, 70, 72, 74, 77, 78, 79, 80, 86, 94, 104], "loss": [9, 10, 19, 62, 63, 111], "fishmoon1234": 9, "pytorch": [9, 10], "paszk": 9, "anoc": [9, 11, 12, 13, 14], "cvae": 9, "constrain": [9, 10, 11, 12, 13, 14], "novel": [9, 10, 61], "identif": [9, 10, 11, 12, 13, 14, 111, 112], "tempor": [9, 10, 57, 61], "publicli": [9, 10, 109], "anonym": [9, 10, 26, 109], "judea": [9, 10, 11, 12, 13, 14], "survei": [9, 10, 11, 12, 13, 14, 68, 72, 88, 90, 96, 112], "96": [9, 10, 11, 12, 13, 14, 48, 51, 103, 104, 109], "146": [9, 10, 11, 12, 13, 14, 72], "2009": [9, 10, 11, 12, 13, 14], "pater": [9, 10, 11, 12, 13, 14], "clark": [9, 10, 11, 12, 13, 14], "glymour": [9, 10, 11, 12, 13, 14], "schein": [9, 10, 11, 12, 13, 14], "stuart": [9, 10, 11, 12, 13, 14], "kauffman": [9, 10, 11, 12, 13, 14], "valerio": [9, 10, 11, 12, 13, 14], "aimal": [9, 10, 11, 12, 13, 14], "frank": [9, 10, 11, 12, 13, 14], "wimberli": [9, 10, 11, 12, 13, 14], "gene": [9, 10, 11, 12, 13, 14], "express": [9, 10, 11, 12, 13, 14, 18, 21, 22, 25, 52, 61, 67, 73], "microarrai": [9, 10, 11, 12, 13, 14], "marku": [9, 10, 11, 12, 13, 14], "8": [9, 10, 11, 12, 13, 14, 16, 18, 19, 20, 21, 23, 24, 25, 27, 28, 49, 51, 53, 57, 58, 61, 66, 68, 96, 98, 103, 109], "mar": [9, 10, 11, 12, 13, 14], "613": [9, 10, 11, 12, 13, 14], "636": [9, 10, 11, 12, 13, 14], "rajen": [9, 10, 11, 12, 13, 14], "jona": [9, 10, 11, 12, 13, 14], "hard": [9, 10, 11, 12, 13, 14], "generalis": [9, 10, 11, 12, 13, 14], "1804": [9, 10, 11, 12, 13, 14], "07203": [9, 10, 11, 12, 13, 14], "shohei": [9, 10, 11, 12, 13, 14], "patrik": [9, 10, 11, 12, 13, 14], "hoyer": [9, 10, 11, 12, 13, 14], "aapo": [9, 10, 11, 12, 13, 14], "hyv\u00e4rinen": [9, 10, 11, 12, 13, 14], "antti": [9, 10, 11, 12, 13, 14], "kerminen": [9, 10, 11, 12, 13, 14], "7": [9, 10, 11, 12, 13, 14, 16, 17, 19, 20, 21, 23, 24, 25, 26, 27, 28, 37, 39, 48, 49, 51, 52, 53, 55, 56, 57, 58, 59, 61, 68, 83, 90, 94, 96, 97, 98, 103, 104, 109], "oct": [9, 10, 11, 12, 13, 14], "2003": [9, 10, 11, 12, 13, 14, 34, 64], "2030": [9, 10, 11, 12, 13, 14], "6": [9, 10, 11, 12, 13, 14, 16, 17, 18, 21, 22, 23, 25, 26, 27, 28, 34, 37, 39, 49, 51, 52, 53, 55, 56, 57, 58, 59, 61, 68, 90, 94, 95, 96, 97, 98, 103, 104, 109], "ernest": [9, 10, 11, 12, 13, 14], "penal": [9, 10, 11, 12, 13, 14, 19, 37, 48, 66], "annal": [9, 10, 11, 12, 13, 14, 17, 18, 19, 22, 34, 64], "42": [9, 10, 11, 12, 13, 14, 16, 49, 51, 69, 70, 71, 73, 74, 75, 77, 97, 98, 103, 104], "2526": [9, 10, 11, 12, 13, 14], "2556": [9, 10, 11, 12, 13, 14], "david": [9, 10, 11, 12, 13, 14, 19, 111], "maxwel": [9, 10, 11, 12, 13, 14], "nov": [9, 10, 11, 12, 13, 14], "507": [9, 10, 11, 12, 13, 14, 85], "554": [9, 10, 11, 12, 13, 14], "joseph": [9, 10, 11, 12, 13, 14], "madelyn": [9, 10, 11, 12, 13, 14], "ruben": [9, 10, 11, 12, 13, 14], "sanchez": [9, 10, 11, 12, 13, 14], "romero": [9, 10, 11, 12, 13, 14], "magnet": [9, 10, 11, 12, 13, 14], "reson": [9, 10, 11, 12, 13, 14], "imag": [9, 10, 11, 12, 13, 14], "analyt": [9, 10, 11, 12, 13, 14, 50], "121": [9, 10, 11, 12, 13, 14, 26], "129": [9, 10, 11, 12, 13, 14, 109], "9": [9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 22, 23, 49, 51, 61, 64, 96, 98, 103, 109], "xun": [9, 10, 11, 12, 13, 14], "bryon": [9, 10, 11, 12, 13, 14], "aragam": [9, 10, 11, 12, 13, 14], "pradeep": [9, 10, 11, 12, 13, 14], "ravikumar": [9, 10, 11, 12, 13, 14], "eric": [9, 10, 11, 12, 13, 14], "xing": [9, 10, 11, 12, 13, 14], "tear": [9, 10, 11, 12, 13, 14], "pp": [9, 10, 11, 12, 13, 14, 34, 39, 64, 67, 68, 69, 70, 76, 77, 82, 83, 85, 86, 87, 88, 90, 91, 93, 98], "9472": [9, 10, 11, 12, 13, 14], "9483": [9, 10, 11, 12, 13, 14], "10": [9, 10, 11, 12, 13, 14, 16, 17, 18, 19, 20, 21, 22, 23, 24, 26, 34, 37, 39, 48, 49, 51, 70, 84, 86, 87, 89, 91, 96, 109], "jie": [9, 10, 11, 12, 13, 14], "tian": [9, 10, 11, 12, 13, 14], "gao": [9, 10, 11, 12, 13, 14], "mo": [9, 10, 11, 12, 13, 14], "1904": [9, 10, 11, 12, 13, 14, 68, 72, 96], "10098": [9, 10, 11, 12, 13, 14], "11": [9, 10, 11, 12, 13, 14, 16, 17, 18, 20, 23, 25, 26, 27, 28, 34, 48, 49, 51, 61, 96, 103, 104], "shengyu": [9, 10, 11, 12, 13, 14], "zhitang": [9, 10, 11, 12, 13, 14], "1906": [9, 10, 11, 12, 13, 14], "04477": [9, 10, 11, 12, 13, 14], "hengrui": [9, 10, 11, 12, 13, 14], "wenbin": [9, 10, 11, 12, 13, 14], "lu": [9, 10, 11, 12, 13, 14, 34, 39, 64, 78, 79, 80, 96], "demand": 10, "understand": [10, 19, 48, 66, 71], "kei": [10, 37, 39, 57, 83, 112], "factor": [10, 57, 62, 63, 83, 84, 85, 86, 87, 89, 90, 95], "guid": [10, 70, 73, 75, 77, 96, 98, 103], "downstream": 10, "task": [10, 53, 55, 57, 61, 63, 67, 72, 76, 77, 96], "m_1": [10, 12], "m_2": [10, 12], "m_p": [10, 12], "dimens": [10, 12], "2": [10, 16, 17, 18, 19, 20, 22, 23, 24, 25, 26, 28, 37, 49, 50, 51, 52, 53, 55, 56, 57, 58, 61, 62, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 103, 104, 105, 109], "next": [10, 19, 21, 28, 49, 57, 61, 62, 63, 79, 80, 109, 112], "give": [10, 18, 22, 62, 68, 72, 76, 96], "te": [10, 12], "de": [10, 12, 53, 67, 96], "ie": [10, 12], "equat": [10, 12, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 39, 49, 52, 53, 55, 56, 57, 58, 61, 62, 64, 74, 75, 77, 78, 79, 80, 82, 83, 84, 86, 88, 89, 90, 91, 92, 93, 94, 95, 96, 104, 105], "split": [10, 12, 15, 18, 22, 52, 53, 61, 82, 83, 84, 88, 89, 91, 95, 105], "partial": [10, 12, 23, 24, 26, 34, 64, 86, 87, 89, 109], "remov": [10, 11, 12, 37], "replac": [10, 12, 34, 39, 49, 53, 57, 61], "citet": [10, 58, 61], "pearl2009caus": 10, "dm": [10, 15, 52, 55, 61], "dm_i": 10, "big": [10, 15, 16, 18, 20, 22, 24, 34, 37, 39, 52, 53, 55, 56, 57, 61, 62, 64, 75, 79, 82, 91], "m_i": 10, "_i": [10, 21, 28, 49, 50, 69, 78, 79, 80, 84, 89, 91, 95, 98, 105], "omega_i": 10, "setminu": 10, "except": [10, 64], "im": 10, "def_im": 10, "im_i": 10, "firstli": [10, 74, 96, 104], "sourc": [10, 112], "degre": [10, 11, 13, 14, 19, 20, 24, 82], "freedom": 10, "smaller": [10, 20, 21, 23, 24, 109], "decompos": [10, 53, 84, 89, 91], "compon": [10, 11, 48, 52, 61, 62, 111], "row": [10, 21, 25, 26, 27, 28, 49, 67], "compos": 10, "investig": [10, 68], "spread": 10, "major": [10, 48, 68, 73, 84, 89, 91, 96, 98, 103], "panda": [10, 11, 16, 17, 18, 20, 22, 23, 25, 26, 27, 28, 49, 51, 64, 66, 109], "pd": [10, 14, 25, 26, 27, 28, 34, 48, 49, 51, 64, 66, 109], "os": [10, 11, 13, 14, 37, 52, 53, 55, 56, 57, 58, 59, 61, 69, 70, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94, 97, 98, 103, 104, 109], "pickl": [10, 39, 109], "ipykernel_20803": 10, "372426792": 10, "cdm": [10, 11, 13, 14], "2_causal_structure_learn": [10, 11, 13, 14], "torch": [10, 11, 13, 14], "tensordataset": [10, 11, 13, 14], "dataload": [10, 11, 13, 14], "nn": [10, 11, 13, 14], "data_typ": 10, "realdata": 10, "real_data_fil": 10, "covid19": 10, "pkl": 10, "epoch": [10, 90, 91, 92, 93, 94], "100": [10, 15, 25, 34, 39, 49, 51, 64, 75, 91, 92, 96, 109], "node_numb": 10, "32": [10, 16, 19, 20, 23, 24, 51, 68, 90, 91, 92, 109], "sample_s": 10, "38": [10, 18, 22, 34, 49, 51, 109], "batch_siz": 10, "rep_numb": 10, "namespac": 10, "a_typ": [10, 11, 13, 14], "graph_degre": 10, "k_max_it": 10, "original_lr": 10, "003": [10, 34], "seed": [10, 11, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 37, 39, 49, 51, 69, 70, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94, 96, 97, 98, 103, 104, 109], "2333": [10, 39], "simu_g_fil": 10, "s1_trueg": 10, "opt": [10, 11, 16, 17, 18, 20, 23, 34, 48, 51, 64, 66], "anaconda3": [10, 11, 16, 17, 18, 20, 23], "lib": [10, 11, 16, 17, 18, 20, 22, 23, 49], "python3": [10, 11, 16, 17, 18, 20, 22, 23, 49], "lr_schedul": 10, "userwarn": 10, "detect": [10, 25, 39], "step": [10, 16, 20, 21, 23, 24, 25, 27, 28, 37, 49, 51, 52, 53, 57, 61, 65, 78, 79, 80], "befor": [10, 11, 15, 16, 24, 77], "later": [10, 34, 37, 52, 53, 55, 56, 57, 58, 59, 61, 64, 94, 97, 98, 103, 104], "opposit": [10, 37], "failur": [10, 26, 109], "skip": 10, "schedul": [10, 75, 77, 91, 94], "org": [10, 18, 22, 109], "html": [10, 50, 109, 112], "warn": [10, 34, 48, 49, 51, 64, 66], "best": [10, 39, 48, 66, 68, 95], "elbo": 10, "22061661439340574": 10, "nll": 10, "0005989748265559731": 10, "mse": 10, "743592665974832e": 10, "05": [10, 18, 22, 49], "seaborn": 10, "sn": 10, "matplotlib": [10, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 49, 109], "pyplot": [10, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 109], "plt": [10, 16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 49, 109], "load": [10, 26], "join": [10, 49], "anoce_result": 10, "rb": 10, "calcul": [10, 19, 49, 52, 55, 61, 64, 66, 69, 70, 71, 74, 75, 77, 91, 93, 96, 97, 98, 104], "calculate_effect": [10, 109], "plot": [10, 11, 13, 14, 109], "covid": 10, "matshow": 10, "cmap": 10, "bwr": 10, "vmin": 10, "vmax": 10, "fig1": 10, "gcf": 10, "colorbar": 10, "df": [10, 11, 13, 14], "datafram": [10, 14, 34, 48, 49, 51, 64, 66, 109], "arrai": [10, 25, 26, 27, 28, 34, 37, 39, 49, 51, 64, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94, 97, 98, 103, 104, 109, 111], "read_csv": [10, 25, 26, 27, 28, 64, 66, 109], "csv": [10, 25, 26, 27, 28, 109], "column": [10, 14, 21, 25, 26, 27, 28, 34, 49, 51, 82, 84, 86, 89, 91, 92, 109], "31": [10, 11, 13, 48, 51, 61], "round": [10, 11, 13, 14, 34, 48, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 103, 104, 105], "reshap": [10, 11, 13, 14, 21, 25, 39], "shenzhen": 10, "212": 10, "026": 10, "guangzhou": 10, "107": [10, 37], "068": 10, "beij": 10, "039": 10, "043": 10, "chengdu": 10, "084": 10, "018": 10, "shanghai": 10, "072": 10, "dongguan": 10, "027": 10, "suzhou": 10, "113": [10, 26, 49, 109], "xian": 10, "055": 10, "045": [10, 72], "hangzhou": 10, "097": 10, "zhengzhou": 10, "070": 10, "chongq": 10, "132": [10, 34, 48], "029": 10, "changsha": 10, "079": 10, "nanj": 10, "101": [10, 11, 13, 14, 49], "047": 10, "13": [10, 11, 13, 14, 18, 22, 26, 51, 96], "kunm": 10, "006": [10, 51], "046": 10, "14": [10, 11, 13, 14, 18, 22, 26, 51, 109], "tianjin": 10, "081": [10, 72], "058": 10, "15": [10, 18, 22, 48, 49, 51], "hefei": 10, "024": 10, "076": [10, 72], "16": [10, 16, 17, 18, 20, 23, 49, 51], "009": 10, "056": 10, "17": [10, 16, 17, 18, 20, 23, 49, 51], "wenzhou": 10, "319": [10, 16, 19, 20, 23, 24], "033": [10, 39, 93], "18": [10, 49, 51, 68, 76, 96], "nanchang": 10, "052": 10, "001": 10, "zhoukou": 10, "014": 10, "fuyang": 10, "021": 10, "21": [10, 16, 17, 18, 20, 22, 23, 26, 34, 48, 49, 51, 84], "shangqiu": 10, "008": 10, "023": 10, "22": [10, 16, 17, 18, 20, 22, 23, 34, 48, 51], "yueyang": 10, "002": [10, 91], "23": [10, 18, 22, 34, 48, 49, 51], "zhumadian": 10, "24": [10, 16, 17, 18, 20, 23, 48, 49, 51, 109], "changd": 10, "25": [10, 11, 13, 14, 16, 17, 18, 20, 22, 23, 48, 49, 51, 66, 69, 70, 75], "nanyang": 10, "025": 10, "26": [10, 16, 17, 18, 20, 23, 37, 49, 51], "yichun": 10, "032": 10, "27": [10, 16, 17, 18, 20, 23, 51], "xinyang": 10, "034": 10, "28": [10, 16, 17, 18, 20, 23, 49, 51, 87], "anq": 10, "010": 10, "005": [10, 34], "29": [10, 34, 49, 51, 64], "jiujiang": 10, "042": 10, "020": 10, "mt_data": 10, "zero": [10, 11, 13, 14, 21, 25, 26, 34, 39, 49, 52, 61, 64, 69, 75, 82, 84, 85, 86, 87, 89, 94, 97, 98, 103, 104], "30": [10, 26, 51, 109], "fig": [10, 111], "figur": [10, 111], "figsiz": 10, "ax": 10, "add_subplot": 10, "cax": 10, "shrink": 10, "horizont": 10, "cities_nam": 10, "set_xtick": 10, "arang": 10, "len": [10, 11, 13, 14, 21, 28, 34, 37, 39, 48, 49, 64, 66, 68, 72, 76, 77, 95, 96, 109], "set_ytick": 10, "set_xticklabel": 10, "rotat": 10, "90": [10, 49, 51], "set_yticklabel": 10, "linear": [10, 12, 19, 23, 24, 37, 68, 69, 70, 78, 79, 80, 82, 86, 89, 90, 91, 92, 93, 96, 98], "addit": [10, 12, 14, 21, 52, 53, 57, 58, 61, 62, 63, 77, 111], "graphic": [10, 12], "art": [11, 13, 14, 19, 52, 61, 111], "uniqu": [11, 13, 14, 39, 55, 56, 62, 63, 107], "invari": [11, 13, 14, 111], "trasform": [11, 13, 14], "disadvantag": [11, 13, 14, 69, 70, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93], "knowledg": [11, 39, 68, 69, 73, 76, 77, 98, 103], "realiz": [11, 13, 14, 57, 73], "underli": [11, 13, 14, 19, 62, 63, 78], "lsem": [11, 14], "g_j": [11, 13], "differenti": [11, 13], "argument": [11, 13, 53], "corollari": [11, 13], "threshold": 11, "synthetic_dataset": [11, 13, 14], "1234": [11, 13, 14], "300": [11, 13, 14, 39, 72], "ground_truth_g": [11, 13, 14], "simulate_random_dag": [11, 13, 14], "graph_typ": [11, 13, 14], "erdo": [11, 13, 14], "renyi": [11, 13, 14], "w_rang": [11, 13, 14], "c": [11, 13, 14, 15, 18, 22, 25, 26, 27, 28, 34, 37, 39, 48, 49, 58, 61, 64, 66, 67, 68, 69, 71, 73, 74, 75, 76, 77, 82, 83, 84, 85, 91, 92, 93, 94, 95, 96, 97, 98, 104, 105], "ones": [11, 13, 14, 21, 25, 34, 37, 49, 51, 64, 73, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93, 103], "simulate_lsem": [11, 13, 14], "plot_net": [11, 13, 14, 109], "nx": [11, 13, 14, 49], "to_numpy_arrai": [11, 13, 14], "labels_nam": [11, 13, 14, 109], "rang": [11, 13, 14, 39, 51, 64, 88, 111], "ipykernel_20869": 11, "2370726509": [11, 13, 14], "pip": [11, 14, 16, 17, 18, 20, 22, 23, 49, 112], "instal": [11, 14, 16, 17, 18, 20, 22, 23, 49, 112], "igraph": 11, "factor_analyz": 11, "directlingam": 11, "fit": [11, 15, 18, 20, 21, 22, 24, 25, 27, 28, 34, 48, 49, 51, 64, 66, 109], "adjacency_matrix_": 11, "ica_r": 11, "ab": [11, 13, 14], "fdr": [11, 13, 14], "tpr": [11, 13, 14], "shd": [11, 13, 14], "count_accuraci": [11, 13, 14], "digraph": [11, 13, 14], "statsmodel": [11, 18, 22], "tsa": 11, "tsa_model": 11, "futurewarn": 11, "int64index": 11, "deprec": 11, "futur": [11, 62, 63], "index": [11, 14, 18, 22, 39, 48, 57, 66, 76, 83, 109, 112], "dtype": [11, 34, 48, 49, 51, 66, 109], "instead": [11, 18, 21, 22, 27, 48, 52, 57, 61, 64, 66, 68, 75, 84, 89, 91, 109, 112], "to_datetim": 11, "datetimeindex": 11, "float64index": 11, "67": [11, 13, 14, 51, 67, 90, 93, 94, 96], "prune": [11, 13, 14], "metric": [11, 13, 14, 37], "fals": [11, 13, 14, 18, 22, 34, 48, 69, 70, 75, 77, 91, 92, 93, 94, 97, 109], "ham": [11, 13, 14], "distanc": [11, 13, 14], "smallest": [11, 13, 14, 21, 39], "revers": [11, 13, 14], "take": [11, 13, 14, 21, 27, 28, 37, 49, 53, 62, 66, 68, 71, 72, 73, 75, 76, 77, 82, 84, 86, 87, 88, 89, 91, 92, 93, 94, 96, 97, 111], "account": [11, 13, 14, 66, 73, 75, 83, 84, 88, 89, 90, 91, 111], "neg": [11, 13, 14, 34, 37, 48, 64, 66], "better": [11, 13, 14, 18, 21, 22, 25, 27, 28, 34, 48, 50, 52, 64, 66, 71, 74, 109], "00": [11, 13, 14, 16, 18, 22, 34, 48, 49, 51, 64], "50": [11, 13, 14, 26, 39, 48, 51], "62": [11, 13, 14, 25, 26, 27, 28, 51, 64], "daggnn": [11, 13, 14], "equal": [11, 13, 14, 39, 52, 53, 57, 61, 62, 83, 86, 87, 89, 90], "varianc": [11, 13, 14, 16, 18, 20, 21, 22, 23, 24, 39, 52, 53, 57, 58, 61, 69, 73, 98, 103], "biometrika": [11, 13, 14, 15, 16, 19, 20, 23, 24], "219": [11, 13, 14], "228": [11, 13, 14], "2013": [11, 13, 14, 15, 21, 68, 69, 87, 88, 95, 96, 98, 105], "mooij": [11, 13, 14], "janz": [11, 13, 14], "sch\u00f6lkopf": [11, 13, 14], "cma": 12, "dissect": 12, "transmit": 12, "comprehens": [12, 26, 109], "cate": [12, 19], "moder": 13, "sem": 13, "good": [13, 21, 27, 55, 56, 63, 73, 96], "analysis": 13, "contrain": 13, "ipykernel_20883": 13, "notears_linear": [13, 109], "lambda1": [13, 109], "loss_typ": [13, 109], "l2": [13, 109], "notears_r": 13, "author": 14, "nois": [14, 75, 86, 87, 111], "normal": [14, 16, 17, 18, 20, 23, 49, 51, 52, 57, 58, 61, 75, 79, 87, 88], "sparsiti": [14, 37, 68], "teat": 14, "leverag": [14, 18, 20, 22, 24, 39, 77], "ipykernel_20889": 14, "pydot": 14, "git": [14, 112], "pycaus": 14, "start_vm": 14, "tetrad": 14, "tetradrunn": 14, "new_df": 14, "map": [14, 55, 56, 63, 67, 78, 79, 80, 111, 112], "02": [14, 34, 48, 51, 64, 109], "format": [14, 64], "algoid": 14, "testid": 14, "gettetradgraph": 14, "getnod": 14, "dot_str": 14, "tetradgraphtodot": 14, "graph_from_dot_data": 14, "node_a": 14, "fill": 14, "fillcolor": 14, "red": 14, "add_nod": 14, "nx_pydot": 14, "from_pydot": 14, "pc_re": 14, "medic": 15, "trial": [15, 67, 96], "ve": [15, 19, 111], "preliminari": 15, "notat": [15, 63, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94, 107, 112], "rl": [15, 53, 62, 63, 107], "main": [15, 20, 23, 24, 111, 112], "common": [15, 19, 21, 25, 86, 88, 111], "causal": [15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 107, 112], "consist": [15, 16, 19, 20, 21, 23, 24, 25, 26, 37, 49, 52, 55, 57, 58, 61, 62, 63, 79, 88, 95, 105, 109], "These": [15, 19, 21, 52, 53, 61, 63], "nuc": [15, 21, 25], "remark": [15, 71, 75, 77, 97], "commonli": [15, 19, 55, 56, 57, 58, 61, 62, 68, 69, 78, 79, 80, 98], "impos": [15, 55, 63, 107], "automat": [15, 57, 61, 63, 77], "behavior": [15, 16, 17, 18, 20, 21, 22, 23, 24, 49, 57, 62, 63, 79, 83, 90, 95, 105], "strictli": [15, 57, 61], "re": [15, 76, 111], "shown": [15, 73, 75, 83, 96, 98, 103], "below": [15, 16, 21, 23, 24, 25, 27, 64, 66, 68, 72, 76, 96, 111], "rh": 15, "rid": 15, "pure": 15, "categori": [15, 52, 55, 61, 96, 111], "IS": [15, 52, 57, 61], "dr": [15, 19, 20, 39, 52, 57, 61], "widehat": [15, 16, 24, 39, 52, 53, 55, 56, 58, 61, 78, 79, 80], "invers": [15, 49, 57, 61], "aipw": [15, 49], "proce": [15, 63, 107], "bigg": 15, "flip": 15, "role": [15, 78, 79, 80], "third": [15, 52, 61, 82, 84, 85], "misspecif": [15, 34, 53, 64, 69, 82, 86, 92], "term": [15, 20, 24, 52, 53, 57, 61, 66, 68, 75, 79, 80], "correct": 15, "correctli": [15, 53, 79], "prove": [15, 16, 20, 24, 37, 52, 53, 58], "mild": [15, 16, 19, 24, 52], "entropi": 15, "semi": [15, 86, 87, 89, 94, 95, 105], "parametr": [15, 61], "converg": [15, 19, 20, 24, 39, 52, 53, 55, 56, 61, 111], "found": [15, 34, 50, 64, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94, 111, 112], "zhang": [15, 67, 93, 96], "sequenti": [15, 34, 49, 63, 64, 67, 72, 75, 77, 78, 79, 80, 88, 96, 107], "681": 15, "694": 15, "v": [15, 16, 18, 19, 20, 22, 23, 24, 37, 39, 48, 52, 58, 61, 62, 63, 70, 78, 79, 80, 83, 84, 85, 87, 90, 91, 92, 93, 94], "chetverikov": 15, "demir": 15, "duflo": 15, "hansen": 15, "w": [15, 21, 27, 34, 39, 48, 63, 64, 65, 66, 67, 68, 70, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 105, 111], "newei": 15, "kennedi": [16, 19, 20, 23, 24], "extend": [16, 24, 37, 57, 61], "oracl": [16, 19, 20, 23, 24], "theorem": [16, 24, 61, 89], "nuisanc": [16, 18, 20, 22, 24, 52, 53, 57, 61], "i_": [16, 20, 24, 53], "mu_a": [16, 24], "mathbb": [16, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 34, 37, 39, 49, 52, 53, 55, 56, 57, 61, 62, 63, 64, 78, 79, 80, 111], "phi": [16, 24, 34, 69, 73, 75, 77, 82, 84, 86, 89, 91, 92, 98], "_a": [16, 20, 24, 70], "_1": [16, 24, 49, 53], "_0": [16, 24, 49], "i_2": [16, 20, 24, 53], "yield": [16, 21, 24, 27, 39, 49, 52, 53, 57, 61], "tau": [16, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 49, 53], "_n": [16, 20, 23, 24, 49], "sy": [16, 17, 18, 20, 23], "execut": [16, 17, 18, 19, 20, 23, 68, 76, 96], "scikit": [16, 17, 18, 20, 22, 23, 49, 50], "scikit_uplift": [16, 49], "py3": [16, 18, 22, 49], "none": [16, 18, 22, 49, 51, 71, 75, 83, 97, 103], "whl": [16, 18, 22, 49], "kb": [16, 18, 22, 49], "25l": 16, "90m": [16, 18, 22], "0m": [16, 18, 22], "32m0": 16, "31m": 16, "eta": [16, 18, 20, 22, 23, 24, 49, 52, 53, 55, 57, 58, 61, 62, 63, 84, 89, 90, 91, 95, 105], "36m": 16, "2k": [16, 18, 22], "91m": 16, "32m41": 16, "31m1": 16, "mb": [16, 18, 22], "36m0": [16, 18, 22], "01": [16, 34, 48, 49, 51, 64, 109], "32m42": 16, "31m601": 16, "25h": 16, "alinaxu": [16, 17, 18, 20, 23], "tqdm": [16, 17, 18, 20, 22, 23, 49, 109], "64": [16, 17, 18, 20, 22, 23, 51], "request": [16, 17, 18, 20, 23, 49], "joblib": [16, 17, 18, 20, 22, 23, 49], "threadpoolctl": [16, 17, 18, 20, 22, 23, 49], "scipi": [16, 17, 18, 20, 22, 23, 49], "python": [16, 17, 18, 20, 22, 23, 49, 84, 91, 112], "dateutil": [16, 17, 18, 20, 22, 23, 49], "kiwisolv": [16, 17, 18, 20, 23, 49], "fonttool": [16, 17, 18, 20, 23], "cycler": [16, 17, 18, 20, 23, 49], "pillow": [16, 17, 18, 20, 23], "pypars": [16, 17, 18, 20, 23, 49], "pytz": [16, 17, 18, 20, 22, 23, 49], "2022": [16, 17, 18, 20, 22, 23, 76, 83, 84, 88, 89, 90, 91, 95], "charset": [16, 17, 18, 20, 23], "idna": [16, 17, 18, 20, 23, 49], "certifi": [16, 17, 18, 20, 23, 49], "urllib3": [16, 17, 18, 20, 23, 49], "six": [16, 17, 18, 20, 22, 23, 49, 111], "successfulli": [16, 18, 22, 27, 49], "lightgbm": [16, 18, 20, 22, 23, 24, 25, 26, 27, 28, 109], "lgbmregressor": [16, 20, 21, 23, 24, 25, 26, 27, 28, 109], "sklearn": [16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 37, 109], "linear_model": [16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 109], "linearregress": [16, 20, 21, 22, 23, 24, 25, 26, 27, 28, 109], "logisticregress": [16, 20, 21, 22, 23, 24, 28, 109], "_util_causaldm": [16, 17, 18, 20, 21, 22, 23, 24, 34, 48, 50], "causal_effect_learn": [16, 20, 23, 24], "single_stag": [16, 20, 23, 24], "drlearner": [16, 24], "ipykernel_20899": 16, "3726533159": 16, "size": [16, 17, 18, 20, 21, 22, 23, 24, 34, 39, 48, 49, 51, 86, 87, 88, 89, 111], "n0": [16, 17, 18, 20, 21, 22, 23, 24, 49], "mc": [16, 17, 18, 20, 21, 22, 23, 24, 49], "223": [16, 17, 18, 20, 21, 22, 23, 24, 49], "data_behavior": [16, 17, 18, 20, 21, 22, 23, 24], "get_data_simul": [16, 17, 18, 20, 21, 22, 23, 24], "data_target": [16, 17, 18, 20, 21, 22, 23, 24], "hte_tru": [16, 17, 18, 20, 21, 22, 23, 24], "s1": [16, 20, 21, 23, 24, 51], "s2": [16, 20, 21, 23, 24, 51], "n_fold": [16, 20, 23, 24], "y_model": [16, 20, 23, 24], "max_depth": [16, 18, 20, 21, 22, 23, 24, 25, 27, 28, 109], "ps_model": [16, 23, 24], "rlearner_model": [16, 23, 24], "hte_dr_learn": [16, 24], "to_numpi": [16, 18, 20, 21, 22, 23, 24, 25], "fold": [16, 23, 24, 49], "r2": [16, 23, 24], "baselearn": [16, 24], "980": [16, 24, 49], "pslearner": [16, 24], "943": [16, 23, 24, 87], "978": [16, 24], "947": [16, 24], "975": [16, 24], "942": [16, 23, 24], "946": [16, 24], "940": [16, 24], "2566": [16, 24], "0408": [16, 24], "8131": [16, 24], "0906": [16, 24], "5665": [16, 24], "7341": [16, 24], "6459": [16, 24], "272": [16, 24], "2961": [16, 18, 20, 21, 22, 23, 24], "4475": [16, 18, 20, 21, 22, 23, 24], "731": [16, 18, 20, 21, 22, 23, 24], "2863": [16, 18, 20, 21, 22, 23, 24], "4471": [16, 18, 20, 21, 22, 23, 24], "1839": [16, 18, 20, 21, 22, 23, 24], "3869": [16, 18, 20, 21, 22, 23, 24], "238": [16, 18, 20, 21, 22, 23, 24], "bias_dr_learn": [16, 24], "sum": [16, 18, 20, 21, 22, 23, 24, 49, 51, 53, 74, 95, 96, 104, 109], "variance_dr_learn": [16, 24], "29436318987432813": [16, 24], "011818461500106": [16, 24], "xinkun": [16, 19, 20, 23, 24], "nie": [16, 19, 20, 23, 24], "stefan": [16, 17, 18, 19, 20, 22, 23, 24, 111], "wager": [16, 17, 18, 19, 20, 22, 23, 24, 111], "quasi": [16, 19, 20, 23, 24], "108": [16, 19, 20, 23, 24, 25, 26, 27, 28], "299": [16, 19, 20, 23, 24], "robinson": [16, 19, 20, 23, 24], "root": [16, 19, 20, 23, 24], "econometrica": [16, 19, 20, 23, 24], "econometr": [16, 19, 20, 23, 24], "societi": [16, 19, 20, 23, 24, 34, 64], "931": [16, 19, 20, 23, 24], "954": [16, 19, 20, 23, 24], "1988": [16, 19, 20, 23, 24, 84], "edward": [16, 19, 20, 23, 24], "h": [16, 19, 20, 23, 24, 34, 39, 66, 67, 75, 76, 77, 78, 79, 80, 82, 83, 84, 86, 89, 90, 91, 92, 95, 96, 104, 105], "2004": [16, 19, 20, 23, 24, 34, 64], "14497": [16, 19, 20, 23, 24], "van": [16, 19, 20, 23, 24, 73, 89, 95, 96, 103, 104, 105], "der": [16, 19, 20, 23, 24], "laan": [16, 19, 20, 23, 24], "biostatist": [16, 19, 20, 23, 24, 34, 64], "lee": [16, 19, 20, 23, 24], "okui": [16, 19, 20, 23, 24], "whang": [16, 19, 20, 23, 24], "uniform": [16, 19, 20, 23, 24, 49], "confid": [16, 19, 20, 23, 24, 48, 70, 72, 74, 78, 79, 80, 94, 104], "band": [16, 19, 20, 23, 24], "1207": [16, 19, 20, 23, 24], "1225": [16, 19, 20, 23, 24], "foster": [16, 19, 20, 23, 24], "syrgkani": [16, 19, 20, 23, 24], "orthogon": [16, 19, 20, 23, 24, 67, 96], "1901": [16, 19, 20, 23, 24], "09036": [16, 19, 20, 23, 24], "claudiashi57": 17, "dragonnet": [17, 19], "ipykernel_20929": 17, "3985528005": [17, 18], "susan": [17, 18, 19, 22, 111], "athei": [17, 18, 19, 22, 111], "juli": [17, 18, 19, 22, 76, 77, 88], "tibshirani": [17, 18, 19, 22], "forest": [17, 19], "47": [17, 18, 19, 22, 26, 51, 71, 74, 96, 97, 104, 109], "1148": [17, 18, 19, 22], "1178": [17, 18, 19, 22], "solut": [18, 22, 37, 39, 55, 56, 62, 112], "moment": [18, 22], "psi_": [18, 22, 34, 52, 53, 58, 61, 64], "nu": [18, 22], "o_i": [18, 22, 39], "care": [18, 22, 26, 109], "option": [18, 20, 22, 24, 34, 39, 48, 51, 64, 66, 68, 69, 70, 71, 73, 74, 97, 98, 103, 104], "xi": [18, 22, 52, 61], "beta": [18, 22, 23, 24, 34, 48, 49, 66, 69, 73, 75, 77, 84, 85, 91, 93, 103, 111], "induc": [18, 22], "solv": [18, 22, 23, 24, 34, 37, 39, 48, 52, 53, 55, 56, 57, 61, 62, 63, 64, 73, 87, 90, 95, 96, 98, 103, 105], "alpha_i": [18, 22], "alpha": [18, 22, 49, 53, 58, 62, 63, 69, 70, 75, 77, 82, 85, 93, 98], "otim": [18, 22], "vv": [18, 22], "notic": [18, 22, 69, 85, 86, 93, 98], "formula": [18, 22, 48, 112], "just": [18, 20, 21, 22, 24, 27], "learner": [18, 19, 22, 34, 37, 48, 49, 51, 64, 66, 94, 97, 98, 103, 104, 109, 111], "ordinari": [18, 22], "prone": [18, 22], "grf": [18, 19, 22], "adapt": [18, 19, 20, 22, 24, 37, 39, 48, 63, 66, 67, 71, 84, 85, 87, 89, 91, 92, 94, 96, 97], "design": [18, 19, 22, 52, 53, 61, 84, 89, 91], "quantiti": [18, 22], "grow": [18, 22, 61], "dot": [18, 22, 34, 49, 52, 57, 61, 64, 68, 72, 76, 83, 90, 95, 96, 105, 111], "l_b": [18, 22], "fall": [18, 22], "leaf": [18, 22], "frequenc": [18, 22, 69, 70, 82, 84, 89, 91, 92], "alpha_": [18, 22, 77], "bi": [18, 22], "boldsymbol": [18, 22, 69, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 95, 97, 98, 104, 105], "x_0": [18, 22], "flexibl": [18, 22, 39, 53, 78, 79, 80, 111], "ipykernel_20939": 18, "econml": [18, 22], "pypi": [18, 22], "pkg": [18, 22], "dev": [18, 22], "colab": [18, 22], "wheel": [18, 22], "cp38": [18, 22], "manylinux_2_17_x86_64": [18, 22], "manylinux2014_x86_64": [18, 22], "32m3": [18, 22], "31m96": [18, 22], "25hrequir": [18, 22], "usr": [18, 22, 49], "dist": [18, 22, 49], "spars": [18, 22], "py2": [18, 22], "77": [18, 22, 49, 51, 68], "32m77": [18, 22], "31m12": [18, 22], "shap": [18, 22], "41": [18, 22, 48, 51], "40": [18, 22, 49, 51, 109], "manylinux2010_x86_64": [18, 22], "571": [18, 22], "32m571": [18, 22], "31m58": [18, 22], "numba": [18, 22], "56": [18, 22, 39, 51, 68, 76, 96, 109], "cloudpickl": [18, 22], "slicer": [18, 22], "patsi": [18, 22], "importlib": [18, 22], "llvmlite": [18, 22], "39": [18, 22, 34, 49, 51], "0dev0": [18, 22], "setuptool": [18, 22], "57": [18, 22, 26, 49, 51], "zipp": [18, 22], "demo": [18, 22, 51, 112], "causalforest": [18, 22], "causalivforest": [18, 22], "regressionforest": [18, 22], "dml": [18, 22], "causalforestdml": [18, 22], "est": [18, 22], "criterion": [18, 22], "het": [18, 22], "n_estim": [18, 22], "400": [18, 22, 26, 51], "min_samples_leaf": [18, 22], "min_var_fraction_leaf": [18, 22], "min_var_leaf_on_v": [18, 22], "min_impurity_decreas": [18, 22], "max_sampl": [18, 22], "45": [18, 22, 49, 51, 109], "min_balancedness_tol": [18, 22], "warm_start": [18, 22], "fit_intercept": [18, 22, 37], "subforest_s": [18, 22], "honest": [18, 22], "verbos": [18, 22], "n_job": [18, 22, 37], "random_st": [18, 22], "1235": [18, 22], "iloc": [18, 21, 22, 25, 26, 27, 28, 39, 109], "hte_grf": [18, 22], "flatten": [18, 22], "2344": [18, 22], "612": [18, 22], "7801": [18, 22], "6886": [18, 22], "6297": [18, 22], "2293": [18, 22], "4417": [18, 22], "819": [18, 22], "okai": [18, 22], "bias_grf": [18, 22], "variance_grf": [18, 22], "706857912147952": [18, 22], "198946462195667": [18, 22], "setup": [19, 23, 24, 37, 51, 52, 53, 90, 111], "triplet": [19, 62, 63, 111], "trajectori": [19, 57, 61, 62, 63, 111], "imagin": 19, "terminolog": 19, "lot": [19, 49, 62], "recommend": [19, 34, 37, 39, 48, 51, 64, 66, 67, 68, 72, 76, 83, 88, 90], "adversit": 19, "impact": 19, "annual": 19, "incom": [19, 90, 91, 92, 93], "expos": [19, 111], "statu": [19, 26, 49, 79, 80, 109], "pictur": [19, 49], "dress": 19, "shop": 19, "femal": [19, 68], "higher": [19, 53, 68, 72, 76, 96], "male": [19, 68, 69, 70, 75, 76, 96], "cloth": 19, "By": [19, 34, 48, 50, 53, 62, 63, 66, 71, 75, 95, 97, 107], "clearli": [19, 111], "granular": 19, "averg": 19, "characsterist": 19, "subsect": [19, 61], "briefli": [19, 67, 96], "lp": 19, "asid": [19, 49], "paper": [19, 20, 24], "pleas": [19, 20, 21, 24, 28], "easiest": [19, 21, 23, 24, 25, 49], "apporach": 19, "enough": [19, 53, 112], "complic": [19, 21, 27, 53], "worth": [19, 89], "sensibl": 19, "trend": [19, 21, 27, 68, 103, 104, 111], "cancel": 19, "tend": [19, 21, 25], "particularli": [19, 34, 48, 64, 66], "larger": [19, 34, 48, 50, 53, 61, 64, 66], "part": [19, 49, 53, 111, 112], "properti": [19, 93, 103], "minim": [19, 52, 53, 61, 62, 63, 67, 72, 84, 89, 91, 96], "deep": [19, 34, 64, 111], "boost": [19, 49], "acheiv": 19, "guarante": [19, 63, 112], "alwai": [19, 34, 48, 53, 68, 72, 73, 76, 85, 87, 93, 96, 98, 103], "faster": [19, 39, 53, 61], "might": [19, 51, 52], "computation": [19, 58, 84, 89, 91, 93], "polynomi": [19, 20, 24], "tradeoff": [19, 53], "nonparametr": [19, 61], "inherit": 19, "dragon": 19, "net": 19, "qualiti": 19, "outperform": [19, 69, 82, 85, 86, 87, 92, 93], "kunzel": [19, 21, 25, 27, 28], "sekhon": [19, 21, 25, 27, 28], "bickel": [19, 21, 25, 27, 28], "metalearn": [19, 21, 25, 27, 28], "proceed": [19, 21, 25, 27, 28, 34, 39, 64, 68, 70, 96], "nation": [19, 21, 25, 27, 28, 111], "academi": [19, 21, 25, 27, 28], "116": [19, 21, 25, 27, 28, 34, 48, 78, 79, 80], "4156": [19, 21, 25, 27, 28], "4165": [19, 21, 25, 27, 28], "claudia": 19, "blei": 19, "veitch": 19, "alicia": 19, "curth": 19, "mihaela": 19, "schaar": 19, "artifici": [19, 39, 67, 68, 69, 70, 76, 82, 83, 85, 96, 98], "1810": 19, "1818": 19, "idea": [20, 21, 23, 24, 25, 112], "residu": [20, 23, 24], "cross": [20, 24, 49], "relax": [20, 24, 53], "breviti": [20, 24], "1b": [20, 24], "basi": [20, 24, 52, 61, 75], "k_": [20, 24], "hs": [20, 24], "bandwidth": [20, 24, 39], "mu_1": [20, 21, 24, 27, 28], "mu_0": [20, 21, 24, 27, 28], "estimt": [20, 24], "_b": [20, 24], "_r": [20, 24], "theta": [20, 24, 69, 71, 73, 75, 82, 83, 84, 85, 86, 87, 89, 91, 92, 93, 95, 97, 98, 103, 105], "arg": [20, 23, 24, 34, 37, 48, 49, 52, 55, 56, 62, 63, 64, 66, 69, 70, 73, 74, 82, 84, 85, 86, 87, 89, 90, 91, 92, 93, 104], "min_": [20, 23, 24, 49, 52, 55, 56], "tb": [20, 24], "s_0": [20, 24, 53, 62, 63], "repeat": [20, 24, 66, 96], "twice": [20, 24], "n_": [20, 24], "samplem": [20, 24], "tradit": [20, 24, 57], "milder": [20, 24, 53], "lprlearner": [20, 24], "ipykernel_20950": 20, "1060362725": 20, "ps_model_a": [20, 24], "ps_model_b": [20, 24], "lprlearner_model": [20, 24], "hte_lp_r_learn": [20, 24], "lp_r": [20, 24], "0353": [20, 24], "2368": [20, 24], "0444": [20, 24], "0884": [20, 24], "6845": [20, 24], "6876": [20, 24], "6223": [20, 24], "85": [20, 24, 51], "bias_lp_r_learn": [20, 24], "variance_lp_r_learn": [20, 24], "2909913487561472": [20, 24], "1822936738050482": [20, 24], "conclus": [20, 21, 23, 24, 25, 27, 109], "incred": [20, 24], "without": [21, 62, 63, 80, 111], "foundament": [21, 25], "esitm": [21, 25], "plug": [21, 25, 39, 52, 53, 55, 61], "supervis": [21, 25, 27, 28], "ipykernel_20956": 21, "629983193": 21, "034775": [21, 49], "453145": [21, 49], "167637": 21, "084880": [21, 49], "234459": [21, 49], "553798": 21, "144626": [21, 49], "040543": [21, 49], "956732": 21, "148426": [21, 49], "021139": [21, 49], "095578": 21, "120852": [21, 49], "377594": [21, 49], "323133": 21, "995": [21, 49], "022440": [21, 49], "887551": [21, 49], "797542": 21, "996": [21, 49], "411179": [21, 49], "655833": [21, 49], "722846": 21, "997": [21, 49], "155706": [21, 49], "992197": [21, 49], "140100": 21, "998": [21, 49], "510241": [21, 49], "828438": [21, 49], "167118": 21, "999": [21, 49, 91, 93], "744187": [21, 49], "857147": [21, 49], "458481": 21, "1000": [21, 25, 37, 49, 51, 84, 91, 92, 94, 95], "sanda": [21, 25, 26, 27, 28], "s_learner": [21, 25], "hstack": [21, 25, 34, 49, 51, 64], "hte_s_learn": [21, 25], "1492": 21, "1687": 21, "589": 21, "0319": 21, "8354": 21, "5843": 21, "4577": 21, "0791": [21, 87], "bias_s_learn": 21, "variance_s_learn": 21, "2857192464627009": 21, "079505077680185": 21, "toi": 21, "although": [21, 25, 53, 58], "cover": [21, 25], "mu0": [21, 27, 28, 109], "mu1": [21, 27, 28, 51, 109], "hte_t_learn": [21, 27, 109], "glanc": [21, 27], "869": 21, "8733": 21, "6596": 21, "3087": 21, "2298": 21, "5598": 21, "2745": 21, "8211": 21, "bias_t_learn": 21, "variance_t_learn": 21, "29138198450323705": 21, "810391408711312": 21, "overfit": [21, 27], "provabl": [21, 28, 96], "imput": [21, 28], "tild": [21, 28, 53, 64, 66, 69, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93, 98, 103], "delta": [21, 28, 75, 77], "tau_1": [21, 28], "tau_0": [21, 28], "s_t0": [21, 28], "s_t1": [21, 28], "r_t0": [21, 28], "r_t1": [21, 28], "unobserv": [21, 28], "origin": [21, 26, 28, 34, 48, 49, 50, 77, 109], "n_t0": [21, 28], "n_t1": [21, 28], "delta0": [21, 28], "delta1": [21, 28], "tau0": [21, 28], "tau1": [21, 28], "hte_x_learn": [21, 28], "predict_proba": [21, 28, 109], "9341": 21, "9235": 21, "2944": 21, "4147": 21, "5626": 21, "214": [21, 64, 68, 70], "5443": 21, "roughli": [21, 52, 53, 111], "catch": 21, "synthet": [21, 111], "slightli": [21, 61, 63], "bias_x_learn": 21, "variance_x_learn": 21, "2827518068171628": 21, "7686646616779012": 21, "worst": 21, "ipykernel_21075": 22, "1878709796": 22, "came": [23, 24], "start": [23, 24, 62, 66, 69, 70, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93, 97, 98, 103, 104, 109], "g_0": [23, 24], "u": [23, 24, 53, 74, 104, 112], "m_0": [23, 24], "manipul": [23, 24], "l_0": [23, 24], "rlearner": [23, 24], "ipykernel_21083": 23, "1454775972": [23, 24], "hte_r_learn": [23, 24], "y_learner": [23, 24], "ps_learner": [23, 24], "958": [23, 24], "966": [23, 24], "951": [23, 24], "948": [23, 24], "957": [23, 24], "932": [23, 24], "950": [23, 24, 26], "944": [23, 24], "683": [23, 24], "584": [23, 24], "659": [23, 24], "705": [23, 24], "677": [23, 24], "536": [23, 24, 49], "667": [23, 24], "642": [23, 24], "669": [23, 24], "551": [23, 24], "5085": 23, "1427": 23, "1424": 23, "0139": 23, "1341": 23, "4466": 23, "5688": 23, "bias_r_learn": [23, 24], "variance_r_learn": [23, 24], "02930508052654023": 23, "1359997242638173": 23, "amaz": [23, 24], "significantli": [23, 24], "ipykernel_21089": 24, "4971": 24, "0231": 24, "0514": 24, "0037": 24, "0943": 24, "4128": 24, "1436": 24, "4714": 24, "010664510462813687": 24, "3201771635462656": 24, "ipykernel_21094": 25, "2327889422": [25, 27, 28], "5000": [25, 26, 27, 28], "glucos": [25, 26, 27, 28, 109], "pao2": [25, 26, 27, 28, 109], "pao2_fio2": [25, 26, 27, 28, 109], "iv_input": [25, 26, 27, 28, 109], "sofa": [25, 26, 27, 28], "data_cel_select": [25, 26, 27, 28, 109], "mimic3_cel_select": [25, 27, 28], "pop": [25, 27, 28], "000000": [25, 26, 27, 28, 109], "122": [25, 26, 27, 28], "59": [25, 26, 27, 28, 37, 51], "444444": [25, 26, 27, 28], "198": [25, 26, 27, 28, 64], "148148": [25, 26, 27, 28], "383136": [25, 26, 27, 28], "125": [25, 26, 27, 28], "192": [25, 26, 27, 28], "690": [25, 26, 27, 28], "647482": [25, 26, 27, 28], "976040": [25, 26, 27, 28], "4995": [25, 26, 27, 28], "4996": [25, 26, 27, 28], "333333": [25, 26, 27, 28], "143": [25, 26, 27, 28, 72], "846153": [25, 26, 27, 28], "025000": [25, 26, 27, 28], "4997": [25, 26, 27, 28], "106": [25, 26, 27, 28, 109], "258": [25, 26, 27, 28], "500000": [25, 26, 27, 28], "923": [25, 26, 27, 28], "214286": [25, 26, 27, 28], "402531": [25, 26, 27, 28], "4998": [25, 26, 27, 28], "4999": [25, 26, 27, 28], "userinfo_index": [25, 26, 27, 28, 109], "sanda_all1": 25, "copi": [25, 49, 109], "sanda_all0": 25, "200": [25, 34, 48, 49, 51, 64, 66], "15234589": 25, "01825633": 25, "fail": [25, 112], "www": 26, "kaggl": [26, 109], "asjad99": 26, "mimiciii": 26, "access": [26, 109, 112], "center": [26, 109], "databas": [26, 109], "clinic": [26, 67, 96, 109], "61": [26, 48, 49, 51, 109], "532": [26, 109], "admiss": [26, 109], "2001": [26, 109], "2012": [26, 37, 67, 90, 95, 105, 109], "boston": [26, 109], "teach": [26, 109], "hospit": [26, 109], "demograph": [26, 109], "vital": [26, 78, 79, 80, 109], "lab": [26, 109], "cohort": [26, 109], "sepsi": [26, 109], "meet": [26, 109], "criteria": [26, 109], "conduct": [26, 49], "ventil": 26, "particular": [26, 49, 52, 61, 111], "characterist": [26, 111], "physiolog": 26, "whole": [26, 49], "mimic3_sepsis_data": 26, "ipykernel_21099": 26, "1741109578": 26, "mimic3_data": [26, 109], "bloc": 26, "icustayid": [26, 109], "charttim": 26, "gender": [26, 68, 76, 96], "ag": [26, 52, 53, 55, 56, 57, 58, 59, 61, 68, 76, 94, 96, 97, 98, 103, 104], "elixhaus": 26, "re_admiss": 26, "died_in_hosp": 26, "died_within_48h_of_out_tim": [26, 109], "mortality_90d": 26, "input_tot": 26, "input_4hourli": 26, "output_tot": 26, "output_4hourli": 26, "cumulated_bal": 26, "sir": 26, "vaso_input": 26, "7245486000": 26, "17639": 26, "826435": 26, "6527": 26, "000": [26, 109], "13617": 26, "520": 26, "7090": 26, "884898": 26, "6898241400": 26, "30766": 26, "069028": 26, "5805732000": 26, "12049": 26, "217303": 26, "4264269300": 26, "30946": 26, "970000": 26, "1300": 26, "340": 26, "160": [26, 72], "960": [26, 94], "125000": [26, 109], "5707825200": 26, "19793": 26, "588912": 26, "9552": 26, "6830": 26, "540": 26, "2722": 26, "457625": 26, "20950": 26, "99961": 26, "4379511600": 26, "18316": 26, "820324": 26, "7665": 26, "11314": 26, "3649": 26, "20951": 26, "99984": 26, "6807542400": 26, "28815": 26, "459329": 26, "9572": 26, "600": 26, "15517": 26, "605": 26, "5944": 26, "690146": 26, "20952": 26, "99988": 26, "6946088400": 26, "11978": 26, "343576": 26, "30918": 26, "650": 26, "19835": 26, "480": [26, 86], "11083": 26, "773188": 26, "20953": 26, "99992": 26, "4289137200": 26, "15191": 26, "885116": 26, "14948": 26, "442": 26, "91": [26, 49, 51, 109], "30256": 26, "15307": 26, "558": 26, "250000": 26, "20954": 26, "99995": 26, "4612773240": 26, "8538": 26, "739340": 26, "20955": 26, "mimic3_data_select": 26, "84": [26, 48, 49, 51], "168": 26, "110": 26, "727273": 26, "179": 26, "447": [26, 83, 85], "499993": 26, "187": 26, "347": 26, "222222": 26, "375000": 26, "136": [26, 109], "787683": 26, "206": [26, 109], "005547": 26, "965110": 26, "144": 26, "376": [26, 34], "752": 26, "172130": 26, "269": 26, "999996": 26, "record": [26, 50], "pressur": [26, 109], "oxygen": [26, 109], "fraction": [26, 109], "deliv": [26, 109], "fio2": [26, 109], "ratio": [26, 52, 53, 57, 61, 109], "organ": [26, 109], "assess": [26, 50, 109], "dysfunct": [26, 109], "iv": [26, 109], "volumn": [26, 109], "fluid": [26, 109], "administ": [26, 109], "addition": 26, "creat": 26, "aspect": 26, "ipykernel_21104": 27, "56653165": 27, "40760015": 27, "57383026": 27, "71361037": 27, "52345108": 27, "ipykernel_21109": 28, "56653142": 28, "52681314": 28, "97653794": 28, "70878901": 28, "46804044": 28, "contrast": [34, 51, 57, 64, 79, 80, 95, 111], "incent": [34, 48, 64, 66], "comparison": [34, 57, 64], "mainli": [34, 48, 55, 56, 64, 66, 68, 72, 76, 84, 89, 91, 96, 111], "complet": [34, 64, 75, 77], "regret": [34, 62, 63, 64, 67, 72, 75, 76, 77, 84, 86, 89, 91, 96], "convent": [34, 63, 64, 90, 107], "soon": [34, 57, 64], "word": [34, 48, 62, 63, 64, 66, 68, 72, 76, 95, 96, 105], "multinomi": [34, 48, 50, 64, 66, 91, 92, 93, 95, 105], "constrast": [34, 64], "furthermor": [34, 64, 68, 72, 75, 76, 84, 89, 91, 96], "omega": [34, 52, 53, 57, 61, 64], "c_j": 34, "blip": [34, 64], "max_": [34, 49, 56, 62, 63, 64, 66, 69, 70, 73, 74, 82, 84, 85, 86, 87, 89, 90, 91, 92, 93, 104], "psi": [34, 39, 64, 75], "hand": [34, 39, 48, 55, 56, 66], "logist": [34, 49, 57, 61, 69, 70, 75, 82, 84, 91, 92, 98], "substitut": [34, 90, 95, 105], "euqat": 34, "appendix": 34, "s_": [34, 48, 52, 53, 55, 56, 57, 61, 62, 63, 64, 65, 66, 94, 111], "bootstrap": [34, 48, 51, 58, 64, 66], "utilz": [34, 64], "boostrap": [34, 48, 64], "resampl": [34, 48, 64, 66], "standard": [34, 48, 51, 52, 53, 57, 58, 61, 64, 66, 69, 73, 75, 77, 79, 85, 86, 87, 90, 92, 93, 94, 98, 111], "ipykernel_21114": 34, "1249134311": 34, "get_data": [34, 48, 50], "target_col": [34, 48, 49, 50], "binary_trt": [34, 48, 50], "2d": 34, "intercept": [34, 48, 49, 51, 66, 82, 84, 86, 89, 91, 92], "newaxi": [34, 51], "model_info": [34, 48, 51, 64, 66], "x_prop": [34, 51, 64], "recenc": [34, 48, 49, 50], "x_q0": [34, 51, 64], "x_c": [34, 51, 64], "action_spac": [34, 48, 51, 64, 66], "phi_": [34, 64], "exp": [34, 51, 75], "gamma_": 34, "j0": 34, "j1": 34, "j2": 34, "initi": [34, 37, 39, 48, 49, 51, 53, 55, 56, 57, 61, 62, 63, 66, 70, 71, 74, 94, 97, 104], "opt_d": [34, 48, 51, 64, 66], "recommend_act": [34, 37, 48, 64, 66], "value_count": [34, 48, 66], "v_hat": [34, 48, 51, 64, 66], "predict_valu": [34, 48, 64, 66], "fitted_model": [34, 48, 51, 64, 66], "3389e": 34, "0295e": 34, "3272e": 34, "03": [34, 50, 64, 109], "1025e": 34, "7135e": 34, "7582e": 34, "202": 34, "int64": [34, 48, 49, 51, 66], "126": [34, 48, 51], "18615811062617": 34, "71": [34, 51], "mail": [34, 48, 49, 50], "els": [34, 48], "women": [34, 48, 49, 50], "men": [34, 48, 49, 50], "deviaiton": [34, 48, 51, 64, 66], "amai": [34, 48, 51, 64, 66], "reliabl": [34, 48, 51, 64, 66], "n_b": [34, 48, 51, 64, 66], "fitted_param": [34, 48, 51, 64, 66], "fitted_valu": [34, 48, 51, 64, 66], "value_avg": [34, 48, 51, 64, 66], "value_std": [34, 48, 51, 64, 66], "param": [34, 48, 51, 64, 66], "predict_value_boot": [34, 48, 64, 66], "value_hat": [34, 48, 51, 64, 66], "3843662825924": 34, "989242109807423": 34, "replic": [34, 48], "99": [34, 49, 51], "37488160184647": 34, "37": [34, 37, 48, 49, 51], "std": [34, 48, 51, 64, 66], "37127842161804": 34, "2024261616976": 34, "placehold": [34, 64, 66], "schult": [34, 64], "institut": [34, 64], "640": [34, 64], "seattl": [34, 64], "symposium": [34, 64], "189": [34, 64], "326": [34, 64], "springer": [34, 64, 67, 68, 96], "york": [34, 64], "ny": [34, 49, 64], "murphi": [34, 48, 64, 66], "royal": [34, 64], "65": [34, 39, 49, 51, 64], "331": [34, 64, 67], "355": [34, 64], "liang": [34, 64, 67, 96], "88": [34, 49, 51, 64, 109], "fan": [34, 64], "46": [34, 51, 64, 89], "925": [34, 64], "a_": [34, 50, 52, 53, 55, 56, 57, 61, 62, 63, 64, 65, 66, 71, 74, 75, 76, 77, 82, 84, 86, 87, 89, 90, 95, 96, 97, 104, 105, 111], "publish": [37, 52, 53, 55, 56, 57, 58, 59, 61, 94, 97, 98, 103, 104], "todo": [37, 48, 51, 59, 66, 94, 97, 98, 103, 104, 105, 111], "hide": [37, 52, 53, 55, 56, 57, 58, 59, 61, 94, 97, 98, 103, 104], "getcwd": [37, 52, 53, 55, 56, 57, 58, 59, 61, 69, 70, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94, 97, 98, 103, 104], "chdir": [37, 52, 53, 55, 56, 57, 58, 59, 61, 69, 70, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94, 97, 98, 103, 104], "filenotfounderror": [37, 52, 53, 55, 56, 57, 58, 59, 61, 69, 70, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94, 97, 98, 103, 104], "ipykernel_21127": 37, "2987427551": 37, "errno": [37, 52, 53, 55, 56, 57, 58, 59, 61, 69, 70, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94, 97, 98, 103, 104], "file": [37, 52, 53, 55, 56, 57, 58, 59, 61, 69, 70, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94, 97, 98, 103, 104, 112], "directori": [37, 52, 53, 55, 56, 57, 58, 59, 61, 69, 70, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94, 97, 98, 103, 104], "stai": 37, "close": [37, 52, 57, 61, 73], "behaviour": [37, 57, 61, 90], "share": [37, 53, 57, 61, 75, 76, 84, 89, 91, 112], "foundat": [37, 62, 68, 103, 104], "min": [37, 39, 49, 71], "neq": 37, "object": [37, 49, 68, 72, 73, 83, 95, 96, 98, 103, 109], "classif": [37, 55, 57, 61], "classifi": [37, 50], "impli": [37, 52, 62, 63, 111], "why": 37, "w_i": 37, "shift": [37, 111], "though": 37, "finit": [37, 48, 53, 57, 61, 66, 71, 74, 77, 96, 97, 104], "instabl": 37, "svm": 37, "tbd": 37, "owl_simu": 37, "generate_test_cas": [37, 51], "case1": 37, "sigma": [37, 52, 53, 58, 61, 69, 73, 75, 77, 84, 86, 87, 89, 91, 98, 103, 104], "xai": [37, 51], "outcomeweightedlearn": 37, "linearsvc": 37, "svc": 37, "model_select": 37, "gridsearchcv": 37, "cross_val_scor": 37, "clf": 37, "cs": [37, 84, 91], "logspac": 37, "param_grid": 37, "dict": [37, 64], "assignment_prob": 37, "your": [37, 49, 112], "asymptot": [37, 52, 53, 61, 79], "notabl": [37, 68], "meantim": [37, 79], "zhao": 37, "yingqi": 37, "american": [37, 49, 78, 79, 80], "499": [37, 68], "1106": 37, "1118": 37, "ying": 37, "regimen": [37, 48, 66], "3776": 37, "3788": 37, "lou": 37, "zhilan": 37, "jun": 37, "shao": 37, "menggang": 37, "biometr": 37, "74": [37, 51, 109], "506": 37, "516": 37, "On": [37, 39], "stat": 37, "68": [37, 51], "sim": [37, 52, 53, 55, 57, 61, 62, 63, 69, 73, 75, 77, 78, 79, 80, 82, 83, 84, 86, 88, 89, 90, 91, 92, 93, 95, 105], "const": 37, "despit": 39, "paid": [39, 111], "domain": [39, 95, 105], "dose": 39, "price": [39, 90, 91, 92, 93], "contin": 39, "discontinu": 39, "i2dr": 39, "unlik": 39, "idr": 39, "newli": 39, "ingredi": 39, "multi": [39, 50, 64, 67, 68, 76, 77, 87, 88, 95, 96, 105, 111], "overcom": 39, "limit": [39, 49, 53, 57, 61, 74, 104], "bullet": [39, 53], "densiti": [39, 49, 52, 53, 57, 61, 62], "eqnarrai": [39, 52, 53, 55, 56, 61, 62, 63], "eqn": [39, 52, 53, 55, 57, 58, 61, 62, 63, 75, 83, 84, 89, 91, 95, 105], "almost": [39, 63], "sure": [39, 63], "naiv": 39, "concern": [39, 109], "psi_h": 39, "trade": [39, 57, 63, 72, 78, 79, 80, 85, 96], "decai": [39, 53], "yet": 39, "union": 39, "q_": [39, 49, 64, 66], "dnn": 39, "argmin_": [39, 61], "substack": [39, 55, 56], "gamma_n": 39, "argmax_": [39, 75, 77, 78, 79, 80, 90, 91, 92, 93, 94, 96, 98, 103, 104], "foral": [39, 62, 63, 78, 79, 80, 83, 84, 88, 89, 90, 91, 93], "argmax": 39, "value_djq": 39, "warfarin": 39, "djl_opt": 39, "data_gen": 39, "data_gener": 39, "realdatagener": 39, "file_nam": [39, 109], "real_envir": 39, "djl_partit": 39, "djl_agent": 39, "djlearn_opt": 39, "mlp_max_it": 39, "ipykernel_21132": 39, "2744164990": 39, "partit": 39, "067": 39, "133": 39, "167": [39, 66], "333": 39, "minut": 39, "opt_polici": 39, "train_data": 39, "xt": 39, "3333333333333333": 39, "0th": 39, "djl_eval": 39, "def": [39, 49, 51], "pi_evalu": 39, "act_list": 39, "linspac": 39, "x_max": 39, "org_data": 39, "x_min": 39, "val": 39, "act": 39, "append": [39, 51], "regr_mean": 39, "djlearn_ev": 39, "10022123966200729": 39, "4833333333333334": 39, "calibr": 39, "34": [39, 49, 51, 75, 76, 77], "2111": 39, "08885": 39, "kosorok": [39, 48, 66], "august": 39, "assist": 39, "26th": 39, "sigkdd": 39, "mine": 39, "march": 39, "1243": [39, 49], "1251": 39, "earli": [48, 66, 78, 79, 80], "kept": [48, 66], "evolv": [48, 66], "hope": [48, 66], "straightforward": [48, 53, 55, 66, 73, 103], "ol": 48, "r_": [48, 50, 52, 53, 55, 56, 57, 61, 62, 63, 64, 68, 70, 72, 74, 75, 76, 77, 82, 84, 86, 89, 95, 96, 104, 105, 111], "qlearn": [48, 51, 66], "ipykernel_21164": 48, "3479176628": 48, "want": [48, 49, 64, 66, 85, 112], "beta_": [48, 66, 77], "94": [48, 49, 51], "202956": 48, "239801": 48, "611375": 48, "526133": 48, "152892": 48, "843148": 48, "000549": 48, "007584": 48, "000416": 48, "float64": [48, 66], "371": 48, "207": 48, "48792828230047": 48, "53": [48, 49, 51], "0005": 48, "0076": 48, "0004histori": 48, "49": [48, 49, 51], "31352423343282": 48, "37323834017361": 48, "shold": 48, "set_index": [48, 66], "40675465960642": 48, "115": [48, 83], "95548975939548": 48, "502988081748748": 48, "wang": [48, 49, 66, 67, 87, 88, 95, 96, 105], "zeng": [48, 66], "statistica": [48, 66, 84], "sinica": [48, 66], "901": [48, 66], "dtr": [48, 66, 111], "sandwich": 48, "project": 48, "ci": [48, 53, 62, 63], "extendour": 49, "satisfactori": 49, "prolong": 49, "watch": [49, 71], "platform": 49, "tail": 49, "preval": 49, "heavi": [49, 112], "unstabl": [49, 57], "skew": 49, "surviv": 49, "median": 49, "moodi": 49, "invert": 49, "cummul": 49, "qunatil": 49, "year": [49, 50, 69, 70, 75], "feasibl": [49, 51, 53, 66, 88, 92], "misspecifi": 49, "pretain": 49, "c_i": 49, "rho_": 49, "beta_1": 49, "fine": 49, "grid": 49, "beta_0": 49, "u_": [49, 74, 96, 104], "1n": 49, "0n": 49, "1i": [49, 64, 65, 66], "0i": 49, "proper": 49, "nelder": 49, "mead": 49, "x1": 49, "x2": 49, "shape": [49, 51, 64], "x_1": 49, "loc": [49, 109], "x_2": 49, "nameerror": [49, 109], "ipykernel_21176": 49, "478063769": 49, "quantile_otr": 49, "quantileotr": 49, "mocondquant_0": 49, "mocondquant_1": 49, "coeffici": [49, 69], "coef_original_scal": 49, "q_est": [49, 51], "dr_qopt": 49, "mopropen": 49, "notbinaryrandom": 49, "termin": [49, 78, 79, 80, 112], "129150": 49, "iter": [49, 53, 55, 64, 66, 75, 84, 89, 91], "gradient": [49, 52, 61, 78, 79, 80], "final_simplex": 49, "0401e": 49, "04": [49, 109], "0062e": 49, "3241e": 49, "9385e": 49, "9699e": 49, "9649e": 49, "9516e": 49, "0098e": 49, "7645e": 49, "9178e": 49, "9988e": 49, "6791e": 49, "1197": 49, "fun": 49, "119701027689532": 49, "messag": 49, "nfev": 49, "nit": 49, "success": 49, "0000e": 49, "3468e": 49, "7854e": 49, "06": [49, 87], "63": [49, 51], "chardet": 49, "sklift": 49, "return_x_y_t": 49, "history_seg": 49, "zip_cod": [49, 50], "newbi": [49, 50], "142": 49, "44": [49, 51], "surburban": 49, "phone": [49, 50], "350": [49, 72], "329": 49, "08": 49, "rural": [49, 50], "web": [49, 50, 68, 83, 95, 96, 105], "180": 49, "500": [49, 72, 76, 86, 87, 89, 94], "750": 49, "675": 49, "83": [49, 51], "urban": [49, 50], "63995": 49, "105": 49, "54": [49, 51], "63996": 49, "63997": 49, "63998": 49, "552": 49, "multichannel": [49, 50], "63999": 49, "472": 49, "82": [49, 51, 67, 96], "64000": 49, "578": [49, 50], "inplac": 49, "217": 49, "267": 49, "332": 49, "451": [49, 72], "459": 49, "63466": 49, "63552": 49, "63743": 49, "63876": 49, "63883": 49, "segment": 49, "length": [49, 62, 63, 83, 86, 87, 89, 90], "concat": 49, "get_dummi": 49, "prefix": 49, "axi": [49, 51], "drop": [49, 66], "countri": 49, "anymor": 49, "zip_code_rur": 49, "channel_multichannel": 49, "categor": [49, 77, 111], "integ": [49, 76, 95, 105], "subset": [49, 63, 83, 86, 87, 88, 89, 90, 95, 105, 109], "ntreatment": 49, "na": [49, 94, 97, 98, 103, 104], "zip_code_surburban": [49, 50], "zip_code_urban": [49, 50], "channel_phon": [49, 50], "channel_web": [49, 50], "297": 49, "264": 49, "66": [49, 51], "149": 49, "265": 49, "117": 49, "210": 49, "215": 49, "239": 49, "70": [49, 51], "154": 49, "maximum": [49, 64, 66, 70, 71, 74, 75, 88, 95, 97, 104, 105], "exceed": 49, "502953": 49, "35": [49, 51], "1895e": 49, "7227e": 49, "4110e": 49, "8883e": 49, "3248e": 49, "6189e": 49, "4630e": 49, "8951e": 49, "8789e": 49, "1688e": 49, "1876e": 49, "7185e": 49, "4111e": 49, "9113e": 49, "3260e": 49, "6160e": 49, "5493e": 49, "8964e": 49, "8975e": 49, "1777e": 49, "1816e": 49, "7171e": 49, "4095e": 49, "8872e": 49, "3259e": 49, "6174e": 49, "7327e": 49, "8731e": 49, "9187e": 49, "1762e": 49, "1882e": 49, "7222e": 49, "4113e": 49, "8993e": 49, "3252e": 49, "6171e": 49, "6759e": 49, "9012e": 49, "9038e": 49, "1803e": 49, "1924e": 49, "7234e": 49, "4088e": 49, "8863e": 49, "3250e": 49, "6158e": 49, "4646e": 49, "9095e": 49, "8690e": 49, "2013e": 49, "1900e": 49, "7211e": 49, "4096e": 49, "8999e": 49, "3246e": 49, "6178e": 49, "3607e": 49, "9148e": 49, "9045e": 49, "1516e": 49, "1880e": 49, "9149e": 49, "6187e": 49, "4407e": 49, "9451e": 49, "8686e": 49, "1759e": 49, "1875e": 49, "7196e": 49, "4083e": 49, "9025e": 49, "6157e": 49, "5918e": 49, "9206e": 49, "8949e": 49, "1680e": 49, "1872e": 49, "7252e": 49, "4081e": 49, "8846e": 49, "3243e": 49, "6168e": 49, "4315e": 49, "8960e": 49, "8996e": 49, "1701e": 49, "1925e": 49, "7192e": 49, "4085e": 49, "8711e": 49, "3264e": 49, "6172e": 49, "5903e": 49, "9406e": 49, "8946e": 49, "1745e": 49, "1889e": 49, "7195e": 49, "4101e": 49, "8838e": 49, "3258e": 49, "6177e": 49, "4543e": 49, "9190e": 49, "8917e": 49, "75": [49, 51], "181": 49, "5661e": 49, "6834e": 49, "bin": 49, "patch": 49, "hist": [49, 109], "facecolor": 49, "blue": 49, "xlabel": 49, "r1": 49, "ylabel": 49, "titl": 49, "histogram": 49, "xlim": 49, "ylim": 49, "face": 49, "_c": 49, "rho": [49, 52, 57, 61], "_j": [49, 53, 75, 76, 77], "qdr_qope": 49, "mixtur": 49, "mdn": 49, "gbdt": 49, "futher": 49, "quanatil": 49, "025941": 49, "121537": 49, "806875": 49, "637488": 49, "363393": 49, "641093": 49, "525509": 49, "381373": 49, "342528": 49, "780761": 49, "quantileop": 49, "qope_est": 49, "927600463556344": 49, "5961404868027": 49, "lan": 49, "ben": 49, "sherwood": 49, "523": 49, "1254": 49, "treat": [50, 95, 109, 111], "week": 50, "merchandis": 50, "compris": [50, 111], "nine": 50, "month": 50, "dollar": 50, "past": [50, 63, 71], "suburban": 50, "ident": [50, 69, 73, 75, 84, 86, 89, 91, 92, 94, 97, 98, 103, 104], "flase": 50, "blog": 50, "minethatdata": 50, "2008": [50, 90], "phi1": 51, "phi2": 51, "psi1": 51, "psi2": 51, "random_binari": 51, "450": [51, 66], "150": 51, "a1": [51, 64, 66], "binomi": [51, 84], "60": 51, "a2": [51, 64, 66], "astyp": 51, "int": 51, "mu2": 51, "y_opt": 51, "opt_tru": 51, "optimal_a": 51, "optimal_v": 51, "004": 51, "250": 51, "720": 51, "95": [51, 91], "1108": 51, "575955081366": 51, "someth": 51, "wrong": 51, "estimate_value_boot": 51, "estimated_contrast": [51, 64], "estimated_prop": 51, "prop": 51, "head": [51, 64, 109], "estimate_valu": 51, "ipykernel_21191": 51, "1171830641": 51, "153": [51, 72], "a0": 51, "232": 51, "8969": 51, "9788": 51, "s1a1": 51, "del": 51, "1102": 51, "524126394967": 51, "554474056899934": 51, "379": 51, "334892": 51, "318229": 51, "628596": 51, "027810": 51, "313279": 51, "716134": 51, "729627": 51, "050612": 51, "335": 51, "294202": 51, "253088": 51, "460437": 51, "091607": 51, "664498": 51, "409741": 51, "410791": 51, "090007": 51, "200070": 51, "071281": 51, "474": 51, "508450": 51, "48": [51, 68, 109], "375403": 51, "517774": 51, "092061": 51, "114": [51, 72], "33": [51, 87, 109], "a_est": 51, "c0": 51, "c1": 51, "vhat": 51, "q0": [51, 66], "q1": [51, 66], "opt_v": 51, "rep": 51, "36": [51, 86], "43": 51, "51": 51, "52": [51, 109], "55": [51, 84, 91, 109], "58": [51, 109], "69": 51, "72": 51, "73": 51, "76": [51, 90, 91, 93], "78": [51, 90, 91, 93], "79": 51, "81": 51, "86": 51, "87": 51, "89": 51, "92": 51, "93": 51, "97": [51, 92], "98": 51, "248": 51, "2674": 51, "9966": 51, "718": 51, "432": 51, "9964": 51, "1119": 51, "7158350462053": 51, "366": [51, 94], "5116": 51, "157": 51, "1218": 51, "7812": 51, "0755e": 51, "4913e": 51, "3333e": 51, "8864e": 51, "1197e": 51, "0288e": 51, "5741e": 51, "1112": [51, 66], "2353635304949": 51, "1120": 51, "4987706735005": 51, "10000": [51, 73], "decent": 52, "short": [52, 57], "signific": [52, 109], "op": [52, 55, 57, 61, 62, 63, 111], "fqe": [52, 55, 56, 61], "integr": [52, 61], "bellman": [52, 55, 56, 61, 62], "bellman_q": [52, 55, 61, 62], "r_t": [52, 55, 56, 61, 62, 67, 68, 69, 71, 72, 73, 74, 76, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 104, 105, 111], "a_t": [52, 53, 55, 56, 61, 62, 63, 64, 67, 68, 69, 70, 71, 72, 73, 74, 76, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 93, 95, 96, 97, 98, 103, 104, 105, 111], "s_t": [52, 53, 55, 56, 57, 61, 62, 63, 68, 111], "wise": [52, 57, 61], "stepi": [52, 57, 61], "stepdr": [52, 61], "i_t": [52, 57, 61, 83], "self": [52, 57, 61], "besid": [52, 55, 56, 57, 61], "recurs": [52, 61, 62], "debia": [52, 53, 61], "reflect": [52, 57, 61, 63, 68, 72, 76, 96], "mi": [52, 53, 61], "sens": [52, 53, 61], "per": [52, 61, 69, 70, 75], "suffer": [52, 61], "huge": [52, 61], "avoid": [52, 53, 57, 61], "widetild": [52, 57, 61], "equiv": [52, 53, 61, 75, 78, 79, 80, 83], "drl": [52, 53, 61], "margin": [52, 53, 57, 61], "infti": [52, 53, 55, 56, 57, 61, 62], "p_t": [52, 53, 57, 61], "p_b": [52, 57, 61], "recal": [52, 53, 57, 58, 61], "manner": [52, 61], "tini": [52, 53, 61], "textrm": [52, 53, 58, 61], "nt": [52, 53, 58, 61], "sqrt": [52, 61, 70, 74, 94, 104], "weakli": [52, 57, 61], "lower_bound": [52, 58, 61], "tupl": [52, 53, 61, 62, 67, 76, 95, 105], "proven": [52, 61], "speak": [52, 53, 61], "pack": [52, 53, 55, 56, 57, 58, 59, 61, 94, 97, 98, 103, 104], "ipykernel_21196": 52, "2982377520": [52, 55, 56, 59], "eqn_omega": [52, 61], "mini": [52, 61], "solvel": [52, 61], "sup_": [52, 61], "simplifi": [52, 61, 62, 78, 79, 80], "reproduc": [52, 61], "hilbert": [52, 61], "rkh": [52, 61], "outer": [52, 61], "descent": [52, 61, 78, 79, 80], "approxim": [52, 57, 61, 75, 77, 82, 84, 86, 91, 92], "still": [53, 57, 61, 75], "stationari": [53, 61, 62, 63, 67], "slow": 53, "wald": [53, 58, 78, 79], "nomin": 53, "coverag": 53, "weaker": 53, "deeper": 53, "new_drl_term": 53, "a_0": [53, 63], "dirac": 53, "p_": [53, 61, 78, 79, 80], "event": 53, "numer": [53, 55, 56, 68, 72, 76, 95, 96, 105], "discount": [53, 61, 62, 63], "debiasterm": 53, "protect": [53, 79], "tr": 53, "tripli": 53, "ci_tr": 53, "z_": [53, 58], "nuisans": 53, "i_1": 53, "t_1": [53, 62, 63, 111], "t_": 53, "disjoint": 53, "t_2": 53, "counterpart": [53, 57], "arbitrari": 53, "ipykernel_21201": 53, "3779975037": [53, 57, 58, 61], "breakthrough": 53, "spirit": 53, "uncorrel": 53, "hoeffd": 53, "decomposit": 53, "degener": 53, "environ": [55, 67, 68, 72, 76, 78, 79, 80, 95, 96, 105, 109], "conceptu": [55, 57], "side": [55, 56], "contract": [55, 56], "ell": [55, 56], "until": [55, 56, 57, 75, 77, 90, 91, 92, 93, 94], "ipykernel_21206": 55, "fqi": 56, "ipykernel_21212": 56, "vanilla": 57, "reweight": 57, "prod_": 57, "transit": [57, 62, 63], "immedi": [57, 62, 63], "_t": [57, 63, 64, 65, 66, 78, 79, 80, 83, 84, 89, 90, 91, 95, 105], "bias": 57, "exponenti": 57, "issu": [57, 71], "made": [57, 67], "forward": 57, "stationar": [57, 62], "sa": [57, 61], "rather": [57, 63], "understood": 57, "trick": [57, 64], "omit": 57, "save": [57, 75, 112], "ipykernel_21217": 57, "principl": [57, 61], "truncat": [57, 61], "estimand": [57, 61], "neglig": [57, 61], "harri": [57, 61], "ergod": [57, 61], "chain": [57, 61], "eventu": [57, 61], "mix": [57, 61, 89], "ref": [58, 61], "sec": [58, 61], "adopt": [58, 84], "tighter": 58, "concentr": [58, 88], "inequ": 58, "curse_horizon": [58, 61], "explicitli": [58, 79, 80, 84, 89, 91], "kallus2019effici": [58, 61], "eqref": [58, 61], "ci_drl": 58, "upper": [58, 70, 72, 74, 78, 79, 80, 94, 104], "ipykernel_21222": 58, "ipykernel_21228": 59, "ipykernel_21235": 61, "textit": 61, "citep": 61, "jiang2016doubl": 61, "farajtabar2018mor": 61, "uehara2019minimax": 61, "rotnitzky1995semiparametr": 61, "carefulli": [61, 74], "thomas2016data": 61, "our_method": 61, "superior": [61, 75], "gain": 61, "tang2019doubl": 61, "upon": [61, 68, 111], "vspace": 61, "1cm": 61, "worthi": 61, "denomin": 61, "modif": 61, "throw": 61, "awai": [61, 80], "geometr": [61, 84, 90, 91, 93], "2cm": 61, "mean_": 61, "proof": 61, "cramer": 61, "rao": 61, "bickel1993effici": 61, "van2000asymptot": 61, "liu2018break": 61, "ineffici": [61, 73, 74, 77], "mass": 62, "enter": 62, "throughout": 62, "report": [62, 111], "move": 62, "readi": 62, "t_n": [62, 63], "uniformli": [62, 63], "def_valu": [62, 63], "benefit": [62, 63], "_l": [62, 63], "_u": [62, 63], "opo": [62, 63], "repeatedli": [63, 76, 107], "perspectii": [63, 107], "implicitli": [63, 107], "writ": [63, 107], "ground": [63, 107], "literautr": [63, 107], "a_1": 63, "y_t": 63, "had": 63, "w_t": [63, 65, 82, 84, 85], "y_0": 63, "s_1": 63, "cup_": 63, "determinist": [63, 75, 78, 79, 80, 84, 89, 90, 91, 95, 105], "homogen": 63, "central": [63, 67, 72, 96], "ma": 63, "subseteq": [63, 88, 90], "cmia": 63, "w_": [63, 83, 84], "statioanri": 63, "ii": [63, 96], "shall": 63, "wors": 63, "ca": 63, "sra": 63, "s_j": 63, "a_j": 63, "y_j": 63, "onlin": [63, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94, 95, 96, 97, 98, 103, 104, 105, 111, 112], "markovobserv": 63, "robserv": 63, "interchang": 63, "m_t": 64, "tj": 64, "h_": [64, 65, 66, 111], "ti": [64, 65, 66], "till": [64, 65, 66], "q_t": 64, "h_t": 64, "v_": [64, 90, 91, 94], "t0": 64, "omega_": 64, "d_t": 64, "backward": [64, 66], "previous": [64, 69, 70, 71, 73, 74, 75, 77], "phi_t": 64, "gamma_t": 64, "eqaut": 64, "accordingli": [64, 69, 73, 74, 85, 87, 93, 98, 103, 104], "m_k": 64, "h_ti": 64, "ipykernel_21255": 64, "3431659105": 64, "datamdp_feas": [64, 66], "txt": [64, 66], "sep": [64, 66], "cd4_0": [64, 66], "cd4_6": [64, 66], "cd4_12": [64, 66], "a3": [64, 66], "5872e": 64, "0493e": 64, "9347e": 64, "2010e": 64, "568": 64, "1057": 64, "8412e": 64, "2479e": 64, "1162": 64, "4662578531918": 64, "3156513295758": 64, "559003921896037": 64, "120": 64, "245571": 64, "595014": 64, "143433": 64, "440232": 64, "3966192806022": 64, "626837283714682": 64, "omega_t": 64, "w_1": 65, "w_2": 65, "multistag": 66, "pi_": 66, "d_": 66, "ipykernel_21262": 66, "2551514490": 66, "prepar": [66, 95], "reset": 66, "reset_index": [66, 109], "q2": 66, "898024": 66, "102009": 66, "116478": 66, "002859": 66, "171": 66, "676661": 66, "454044": 66, "288382": 66, "921595": 66, "015938": 66, "158": 66, "553900": 66, "477566": 66, "551396": 66, "334465": 66, "182": 66, "312429": 66, "703112": 66, "550": 66, "1113": [66, 86, 88], "3004201781748": 66, "9663576650953": 66, "6050454629164577": 66, "BE": 66, "THE": 66, "AS": 66, "THAT": 66, "OF": 66, "979": 66, "4518636939481": 66, "0772776227565": 66, "2034780374001155": 66, "accuraci": 66, "financ": [67, 72, 96, 111], "slot": 67, "casino": 67, "gambler": 67, "plai": [67, 68, 72, 74, 76, 78, 79, 80, 88], "earn": 67, "payout": 67, "element": [67, 83], "produc": 67, "divid": [67, 111], "adversari": 67, "pacakg": 67, "four": [67, 75, 84, 87, 89, 91], "distinct": 67, "along": 67, "laern": 67, "durand": [67, 96], "achilleo": [67, 96], "iacovid": [67, 96], "strati": [67, 96], "mitsi": [67, 96], "pineau": [67, 96], "mous": [67, 96], "novo": [67, 96], "carcinogenesi": [67, 96], "healthcar": [67, 72, 76, 96], "shen": [67, 78, 79, 80, 96], "zha": [67, 96], "portfolio": [67, 96], "choic": [67, 83, 84, 90, 95, 96, 105], "twenti": [67, 96], "fourth": [67, 96], "joint": [67, 96], "xu": [67, 96], "811": [67, 96], "821": [67, 96], "bouneffouf": [67, 68, 72, 96], "bouzeghoub": 67, "gan\u00e7arski": 67, "novemb": [67, 93], "mobil": 67, "awar": 67, "324": 67, "berlin": [67, 68], "heidelberg": [67, 68], "primarili": 68, "profil": 68, "occup": [68, 76, 96], "season": 68, "temperatur": 68, "aid": 68, "mab": [68, 71, 73, 74, 76, 96], "tast": 68, "film": 68, "ultim": [68, 72, 76, 83, 88, 90, 95, 96], "lipschitz": 68, "linucb": [68, 96, 111], "lint": [68, 96, 111], "vari": 68, "static": [68, 75, 84, 89, 112], "nonstationari": 68, "1m": [68, 72, 76, 95, 96], "fulli": [68, 72, 75, 76, 96], "highest": [68, 71, 72, 73, 74, 76, 83, 84, 85, 86, 87, 89, 95, 96, 97, 98, 103, 104], "comedi": [68, 69, 71, 72, 74, 75, 76, 95, 96], "drama": [68, 72, 76, 77, 95, 96], "thriller": [68, 70, 71, 72, 73, 75, 76, 77, 95, 96], "sci": [68, 69, 70, 72, 73, 76, 96], "fi": [68, 69, 70, 72, 73, 76, 96], "colleg": [68, 69, 70, 75, 76, 96], "grad": [68, 69, 70, 75, 76, 96], "student": [68, 69, 70, 75, 76, 96], "manageri": [68, 76, 96], "academ": [68, 76, 96], "educ": [68, 76, 96], "technician": [68, 76, 96], "engin": [68, 76, 96], "writer": [68, 76, 96], "bernoulli": [68, 72, 76, 83, 84, 85, 88, 89, 98, 103], "chu": [68, 70, 96], "reyzin": [68, 70], "schapir": [68, 70, 96], "2011": [68, 70, 78, 79, 80, 92], "june": [68, 69, 70, 82, 83, 86, 88, 90, 91, 93, 98], "payoff": [68, 69, 70, 96, 98], "fourteenth": [68, 70], "208": [68, 70], "jmlr": [68, 70], "workshop": [68, 70], "agraw": [68, 69, 90, 91, 92, 93, 94, 96, 98], "goyal": [68, 69, 90, 91, 93, 94, 96, 98], "thompson": [68, 69, 72, 73, 76, 78, 79, 80, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 95, 98, 103, 104, 105, 111], "127": [68, 69, 96, 98, 109], "135": [68, 69, 72, 96, 98], "kveton": [68, 69, 75, 76, 77, 82, 83, 86, 88, 95, 96, 98, 105], "zaheer": [68, 69, 75, 76, 77, 82, 96, 98], "szepesvari": [68, 69, 76, 77, 82, 83, 95, 96, 98, 105], "ghavamzadeh": [68, 69, 76, 82, 96, 98], "boutili": [68, 69, 76, 77, 82, 96, 98], "2066": [68, 69, 82, 96, 98], "2076": [68, 69, 82, 96, 98], "rish": [68, 72, 96], "10040": [68, 72, 96], "slivkin": [68, 72, 96], "286": 68, "hazan": 68, "megiddo": 68, "513": 68, "langford": [68, 78, 79, 80, 96], "2010": [68, 96], "april": [68, 83, 85], "articl": [68, 96], "19th": [68, 96], "670": [68, 96], "auer": [68, 71, 74, 96, 97, 104], "cesa": [68, 71, 74, 96, 97, 104], "bianchi": [68, 71, 74, 96, 97, 104], "freund": 68, "nonstochast": 68, "multiarm": [68, 71, 74, 96, 97, 104], "siam": 68, "scalabl": [69, 70, 75, 77, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 111], "ucb": [69, 70, 72, 82, 85, 86, 87, 92, 93, 94, 96, 104], "suscept": [69, 82, 86, 92], "avial": [69, 95, 98, 105], "consdier": [69, 98], "ts": [69, 70, 72, 75, 76, 77, 84, 85, 87, 89, 91, 92, 93, 96, 98, 111], "domian": [69, 73, 98, 103], "thecorrespond": [69, 98], "posterior": [69, 70, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93, 96, 98, 103], "greatest": [69, 73, 85, 98, 103], "updat": [69, 70, 71, 73, 74, 75, 77, 79, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94, 97, 98, 103, 104, 111, 112], "distirbut": [69, 73, 85, 87, 93, 98, 103], "rewad": [69, 73, 85, 87, 93, 98, 103], "ipykernel_21274": 69, "836241344": [69, 70, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93], "cmab": [69, 70], "imit": [69, 70, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93], "_env_realcmab": [69, 70], "_env": [69, 70, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93], "env": [69, 70, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94, 97, 98, 103, 104], "single_contextual_env": [69, 70], "deviat": [69, 73, 75, 77, 86, 87], "prior_theta_u": [69, 98], "prior_theta_cov": [69, 98], "covarainc": [69, 73], "lints_gaussian_ag": [69, 77, 98], "lints_gaussian": [69, 98], "get_phi": [69, 70, 75], "take_act": [69, 70, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94, 97, 98, 103, 104], "get_reward": [69, 70, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94, 97, 98, 103, 104], "receive_reward": [69, 70, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94, 97, 98, 103, 104], "feature_info": [69, 70, 75], "encount": [69, 70], "old": [69, 70, 75], "retrain_freq": [69, 70, 82, 98], "glm": [69, 70, 96, 111], "lints_glm_ag": 69, "lints_glm": 69, "specifci": 70, "gaussain": 70, "theta_a": [70, 71, 73, 97], "u_a": [70, 74, 104], "theta_": [70, 71, 73, 82, 83, 84, 85, 86, 88, 90, 93, 97, 98, 103], "ipykernel_21279": 70, "exploration_t": 70, "linucb_gaussian_ag": 70, "linucb_gaussian": 70, "linucb_glm_ag": 70, "linucb_glm": 70, "ideal": 71, "domin": 71, "eploit": 71, "epsilon_t": [71, 97], "epsilon_": [71, 75, 77, 96, 97], "pull": [71, 74, 75, 97, 104], "c_a": [71, 74, 97, 104], "decrease_ep": [71, 97], "specfi": [71, 97], "ipykernel_21284": 71, "epsilon_greedi": 71, "_env_realmab": [71, 73, 74], "single_gaussian_env": [71, 73, 74, 97, 98, 103, 104], "emploi": [71, 90, 95], "greedy_ag": [71, 97], "single_bernoulli_env": [71, 73, 74, 98, 103], "fischer": [71, 74, 96, 97, 104], "235": [71, 74, 96, 97, 104], "256": [71, 74, 96, 97, 104], "satisf": [72, 83], "tackl": [72, 96], "preprocess": [72, 76], "175": [72, 76, 109], "tabl": 72, "311": 72, "309": [72, 90], "288": 72, "204": 72, "096": 72, "170": 72, "312": 72, "287": 72, "313": 72, "305": 72, "176": 72, "278": 72, "455": 72, "553": 72, "421": [72, 91, 92], "420": 72, "07272": [72, 96], "Be": 73, "especi": [73, 75, 90, 95, 105, 111], "uncertainti": [73, 74], "dilemma": [73, 96, 98, 103], "greedili": [73, 74, 84, 89, 91, 96, 98, 103, 104], "nearli": [73, 96, 98, 103], "manual": [73, 103, 112], "r_0": 73, "ipykernel_21295": 73, "reward_typ": [73, 103], "u_prior_mean": [73, 87, 103], "u_prior_cov": [73, 103], "ts_gaussian_ag": [73, 103], "prior_phi_beta": [73, 103], "ts_bernoulli_ag": [73, 103], "russo": [73, 95, 96, 103, 104, 105], "kazerouni": [73, 95, 96, 103, 104, 105], "osband": [73, 95, 96, 103, 104, 105], "wen": [73, 82, 83, 86, 88, 95, 96, 103, 104, 105], "tutori": [73, 83, 88, 89, 90, 91, 95, 96, 103, 104, 105, 112], "1707": [73, 95, 96, 105], "0203": [73, 96], "lattimor": [73, 96], "szepesv": [73, 96], "ari": [73, 96], "cambridg": [73, 96], "radiu": [74, 96, 104], "2log": 74, "ucb1": [74, 96, 111], "log": [74, 104], "ipykernel_21300": 74, "ucb_ag": [74, 94, 104], "hierarch": [75, 76, 84, 89, 91], "alignedat": [75, 77, 84, 89, 91], "inter": [75, 83, 84, 88, 89, 90, 91, 111], "intra": 75, "y_": [75, 77, 83, 84, 87, 88, 89, 90, 91, 93], "mu_": [75, 76, 77], "hierachical_model": 75, "explicit": [75, 77, 84, 91], "pymc3": [75, 77, 84, 91, 92], "mathmet": 75, "simultan": [75, 84, 89, 91], "ipykernel_21305": 75, "meta_bandit": [75, 77], "mtts_gaussian": 75, "_env_realmultitask": [75, 77], "multitask_env": [75, 77], "episod": [75, 77], "preced": [75, 77], "concurr": 75, "theta_prior_mean": 75, "theta_prior_cov": 75, "delta_cov": 75, "delta_j": 75, "xs": [75, 84, 89, 91, 92], "approximate_solut": 75, "finish": [75, 77], "update_freq": [75, 77, 84, 89, 91, 92, 94], "mtts_gaussian_ag": 75, "mtts_agent": 75, "posterior_u": [75, 77, 103], "posterior_cov_diag": [75, 77], "mtts_binari": 75, "phi_beta": [75, 77, 84, 91, 94, 97, 98, 103], "mtts_binary_ag": 75, "posterior_alpha": [75, 77, 103], "posterior_beta": [75, 77, 103], "29655": [75, 76], "29668": [75, 76], "basu": [75, 76, 77], "szepesv\u00e1ri": [75, 76, 77], "28029": [75, 76, 77], "28041": [75, 76, 77], "acceler": 76, "perspect": [76, 85, 87], "arbitrati": 76, "decsion": 76, "lack": [76, 111], "a_k": 76, "r_k": 76, "konobeev": [76, 77], "hsu": [76, 77], "mladenov": [76, 77], "5884": [76, 77], "5893": [76, 77], "hong": 76, "7724": 76, "7741": 76, "maintain": 77, "demonstr": 77, "accommod": [77, 86], "ipykernel_21315": 77, "meta_ts_gaussian": 77, "sigma_0": 77, "sigma_q": 77, "meta_ts_gaussian_ag": 77, "meta_ts_ag": 77, "episode_finish": 77, "meta_post": 77, "candid": [77, 82, 84, 85, 86, 87, 89, 91, 92, 93], "candi_mean": 77, "entri": [77, 83], "meta_ts_binari": 77, "meta_ts_binary_ag": 77, "ongo": [78, 79, 80], "econom": [78, 79, 80, 111], "crucial": [78, 79, 80], "instruct": [78, 79, 80], "exposit": [78, 79, 80], "link": [78, 79, 80, 112], "dud\u00edk": [78, 79, 80], "suvta": [78, 79, 80], "dr_est": [78, 79, 80], "2110": [78, 79, 80], "15501": [78, 79, 80], "533": [78, 79, 80], "240": [78, 79, 80], "255": [78, 79, 80], "534": [78, 79, 80], "708": [78, 79, 80], "719": [78, 79, 80], "1103": [78, 79, 80], "4601": [78, 79, 80], "dream": 79, "architectur": 79, "tripl": 79, "x_t": 79, "buffer": 79, "pi_b": 79, "pi_t": 79, "histor": [79, 80], "kappa_t": [79, 80], "pr": [79, 80], "kappa": [79, 80], "overlap": 80, "zong": [82, 83], "laplac": 82, "mid": [82, 84, 85, 86, 87, 89, 90, 91, 92, 93, 96, 104], "inroduct": [82, 84, 85, 86, 87, 89, 91, 92, 93], "cascad": [82, 84, 85, 95, 105, 111], "ipykernel_21339": 82, "structured_bandit": [82, 84, 85, 86, 87, 89, 91, 92, 93], "_env_realcascad": [82, 84, 85], "cascading_env": [82, 84, 85], "itm": [82, 84, 85, 86, 87, 89, 91, 92, 93], "considerd": [82, 86, 89], "lints_ag": [82, 86, 92], "fisrt": [82, 86, 89], "restatur": [82, 84, 85, 86, 87, 89, 91, 92, 93], "1301": 82, "2087": 82, "1123": 82, "unfortun": [82, 84, 85], "ni": [82, 83], "sung": [82, 83], "ke": [82, 83], "1603": [82, 83], "05359": [82, 83], "sort": 83, "slate": [83, 88, 90, 93, 94], "f_r": [83, 84, 89, 91, 95, 105], "examin": [83, 111], "bottom": [83, 95], "she": 83, "latent": 83, "e_": [83, 84], "visibl": 83, "theta_i": [83, 84, 85, 87, 88, 89, 90, 91, 92, 93], "probabilist": [83, 84, 91], "mathmat": 83, "model_cascad": [83, 84], "permut": 83, "ts_cascad": 83, "cascadelint": [83, 111], "mtss_cascad": 83, "chuklin": 83, "rijk": 83, "synthesi": 83, "lectur": 83, "retriev": [83, 95], "2202": [83, 84, 88, 89, 90, 91, 95], "13227": [83, 84, 88, 89, 90, 91, 95], "ashkan": [83, 86, 88, 95, 105], "767": [83, 95, 105], "776": [83, 93, 95, 105], "cheung": [83, 85], "tan": [83, 85], "zhong": [83, 85], "22nd": [83, 85], "438": [83, 85], "mtss": [84, 89, 91, 111], "general_hierach": [84, 89, 91], "mtt": [84, 89, 91], "subsum": [84, 89, 91, 95, 105], "full": [84, 89, 111], "enjoi": [84, 91], "conjug": [84, 85, 91, 93, 103], "facilit": [84, 89, 91], "deploy": [84, 89, 91], "ipykernel_21350": 84, "gamma_prior_mean": [84, 89, 91, 92], "gamma_prior_cov": [84, 89, 91, 92], "coverainc": [84, 91, 92], "n_init": [84, 91, 92, 94], "draw": [84, 91, 92], "mtss_agent": [84, 89, 91], "2189": 84, "1610": 84, "1206": 84, "forcina": 84, "franconi": 84, "rivista": 84, "di": [84, 109], "applicata": 84, "salvati": [84, 91], "wiecki": [84, 91], "fonnesbeck": [84, 91], "peerj": [84, 91], "e55": [84, 91], "doi": [84, 91], "7717": [84, 91], "ipykernel_21355": 85, "u_prior_alpha": [85, 93], "u_prior_beta": [85, 93], "ts_agent": [85, 87, 93], "2690": 85, "reach": 86, "kalman": 86, "filter": 86, "exact": 86, "Of": [86, 87, 89], "cours": [86, 87, 89], "welcom": [86, 87, 89], "ipykernel_21360": 86, "combinatorial_semi": [86, 87, 89], "_env_realcomb": [86, 87, 89], "combsemi_env": [86, 87, 89], "prior_gamma_mu": 86, "prior_gamma_cov": [86, 89], "lints_semi": 86, "tot_r": [86, 87, 89], "1895": 86, "1700": 86, "2219": 86, "2807": 86, "1593": 86, "2784": 86, "172": 86, "2831": 86, "1523": [86, 89], "8214": 86, "2055": 86, "408": 86, "0487": 86, "8551": 86, "1778": 86, "595": 86, "9068": 86, "6194": 86, "9444": [86, 89], "3574891974648375": 86, "1122": [86, 88], "began": 87, "famili": 87, "sub": 87, "bay": [87, 89], "ipykernel_21366": 87, "u_prior_cov_diag": 87, "diagon": 87, "ts_semi": 87, "1054": 87, "2060": 87, "494": 87, "1488": 87, "1351": 87, "1816": 87, "898": 87, "1587": 87, "1114": [87, 89], "321": 87, "8094": 87, "8462": 87, "8306": 87, "6929": 87, "6706": 87, "6444": 87, "5902": 87, "5764": [87, 89], "0607550383245": 87, "yuan": [87, 88, 95, 105], "februari": 87, "151": [87, 88, 95, 105], "159": [87, 88, 95, 105], "perrault": 87, "boursier": 87, "valko": 87, "perchet": 87, "5429": 87, "5440": 87, "alloc": [88, 95, 105], "scenario": 88, "pali": 88, "sigma_2": [88, 89], "combt": [88, 111], "comblint": [88, 111], "mtss_comb": 88, "sankararaman": 88, "5114": 88, "5122": 88, "lmm": 89, "sigma_1": 89, "ipykernel_21376": 89, "prior_gamma_mean": 89, "mtss_semi": 89, "686": 89, "2132": 89, "689": 89, "1645": 89, "1733": 89, "2671": 89, "1611": 89, "2099": 89, "1668": 89, "9462": 89, "4307": 89, "9867": 89, "846": 89, "504": 89, "3613": 89, "6928": 89, "45535406270607": 89, "pari": 89, "golrezaei": 89, "ssrn": 89, "3651397": 89, "mnl": [90, 91, 92, 93, 94, 111], "arguabl": 90, "eta_0": 90, "eta_1": 90, "eta_": [90, 91, 92, 93, 94], "eta_k": 90, "revenu": [90, 91, 92, 93], "convention": 90, "v_i": 90, "mnldist": 90, "cup": 90, "v_0": 90, "intract": [90, 93], "appear": [90, 91, 92, 93, 94], "matter": 90, "ts_mnl": 90, "ts_contextual_mnl": 90, "mtss_mnl": 90, "pentico": 90, "european": 90, "190": 90, "295": 90, "luce": [90, 95, 105], "courier": [90, 95, 105], "corpor": [90, 95, 105], "avadhanula": [90, 91, 92, 93, 94], "zeevi": [90, 91, 93, 94], "oh": [90, 91, 92], "iyengar": [90, 91, 92], "1453": [90, 93, 94], "1485": [90, 93, 94], "ou": [90, 92], "jin": [90, 92], "1805": [90, 92], "02971": [90, 92], "bui": [91, 92, 93], "concret": 91, "eqn1": 91, "logit": [91, 92, 93, 95, 105], "ipykernel_21386": 91, "_env_realmnl": [91, 92, 93], "mnl_env": [91, 92, 93, 94], "same_reward": [91, 92, 93, 94], "clip": [91, 93], "275": 91, "448": [91, 92], "836": [91, 92], "9493188224156814": 91, "id": [91, 92, 93], "framwork": 92, "realtionship": 92, "ipykernel_21391": 92, "mnl_ts_contextu": 92, "298": 92, "9729194890231303": 92, "tulabandhula": 92, "tractabl": [92, 93], "14033": 92, "multinomila": 93, "nice": [93, 103], "ipykernel_21396": 93, "ts_mnl_beta": 93, "mnl_t": 93, "864": 93, "394": [93, 109], "911": 93, "430": [93, 109], "03330462654669619": 93, "dong": 93, "switch": [93, 112], "2607": 93, "2615": 93, "48log": 94, "longleaf": [94, 97, 98, 103, 104], "home": [94, 97, 98, 103, 104], "lge": [94, 97, 98, 103, 104], "ipykernel_21401": 94, "3636065689": [94, 97, 98, 103, 104], "_env_mnl": 94, "20000": 94, "update_freq_linear": 94, "with_intercept": [94, 97, 98, 103, 104], "x_mu": [94, 97, 98, 103, 104], "x_sigma": [94, 97, 98, 103, 104], "sigma_gamma": [94, 97, 98, 103, 104], "mu_gamma": 94, "exp_r": 94, "109": 94, "519": 94, "906": 94, "main_raw_model": [95, 105], "cardin": [95, 105], "exclud": [95, 105], "appeal": 95, "brows": 95, "02038": [95, 105], "2015a": [95, 105], "strike": 96, "unfamiliar": 96, "iii": 96, "guaasian": [96, 111], "glmt": 96, "guassian": [96, 111], "2071": 96, "2080": 96, "ipykernel_21419": 97, "sigma_theta": [97, 98, 103, 104], "mu_theta": [97, 98, 103, 104], "specifii": 97, "cnt": [97, 98], "rewrit": 98, "ipykernel_21424": 98, "lints_bernoulli_ag": 98, "lints_bernoulli": 98, "breward": 103, "ipykernel_21429": 103, "4375": 103, "ipykernel_21434": 104, "rs": 104, "1249": 104, "cook": 105, "privaci": 109, "he": 109, "mortal": 109, "hour": 109, "diagram": 109, "load_ext": 109, "autoreload": 109, "math": 109, "datetim": 109, "multiprocess": 109, "pool": 109, "functool": 109, "omp_num_thread": 109, "5_case_studi": [], "subset_mimic3_sepsis_data": [], "ipykernel_21449": [], "2998256519": [], "_decor": [], "wrapper": [], "kwarg": [], "stacklevel": [], "310": [], "func": [], "io": 112, "parser": [], "reader": [], "filepath_or_buff": [], "delimit": [], "header": 109, "index_col": [], "usecol": [], "squeez": [], "mangle_dupe_col": [], "true_valu": [], "false_valu": [], "skipinitialspac": [], "skiprow": [], "skipfoot": [], "nrow": [], "na_valu": [], "keep_default_na": [], "na_filt": [], "skip_blank_lin": [], "parse_d": [], "infer_datetime_format": [], "keep_date_col": [], "date_pars": [], "dayfirst": [], "cache_d": [], "chunksiz": [], "compress": [], "decim": [], "linetermin": [], "quotechar": [], "quot": [], "doublequot": [], "escapechar": [], "comment": [], "encoding_error": [], "dialect": [], "error_bad_lin": [], "warn_bad_lin": [], "on_bad_lin": [], "delim_whitespac": [], "low_memori": [], "memory_map": [], "float_precis": [], "storage_opt": [], "676": [], "kwd": [], "kwds_default": [], "678": [], "_read": [], "679": [], "680": [], "573": [], "574": [], "575": [], "textfileread": [], "576": [], "577": [], "__init__": [], "930": [], "iohandl": [], "_engin": [], "_make_engin": [], "933": [], "934": [], "1214": [], "str": [], "pathlik": [], "readcsvbuff": [], "byte": [], "1215": [], "bool": [], "1216": [], "get_handl": [], "overload": [], "1217": [], "path_or_buf": [], "is_text": [], "784": [], "ioarg": [], "785": [], "786": [], "787": [], "788": [], "causal_discovery_learn": [], "case_studi": [], "randn": 109, "rseed": 109, "npseed": 109, "delay_end_of_record_and_discharge_or_death": [], "weight_kg": [], "gc": [], "hr": [], "sysbp": [], "meanbp": [], "diabp": [], "rr": [], "spo2": [], "temp_c": [], "fio2_1": [], "potassium": [], "sodium": [], "chlorid": [], "bun": [], "creatinin": [], "magnesium": [], "calcium": [], "ionised_ca": [], "co2_meql": [], "sgot": [], "sgpt": [], "total_bili": [], "albumin": [], "hb": [], "wbc_count": [], "platelets_count": [], "ptt": [], "pt": [], "inr": [], "arterial_ph": [], "paco2": [], "arterial_b": [], "arterial_lact": [], "hco3": [], "mechvent": [], "shock_index": [], "median_dose_vaso": [], "max_dose_vaso": [], "obspi": [], "beachbal": [], "plot_mt": 109, "mimic3_data_fin": [], "sample_demo": 109, "est_mt": 109, "w_threshold": 109, "demo_res_mt": 109, "4497709639893197": [], "2259495770059539": [], "demo_res_net": 109, "2764": [], "968979885058": [], "961": [], "0344827586207": [], "3726": [], "0034626436773": [], "in_input": [], "died_within_48hour": [], "core": [], "1817": [], "settingwithcopywarn": 109, "slice": 109, "row_index": 109, "col_index": 109, "caveat": 109, "pydata": 109, "user_guid": 109, "_setitem_single_column": [], "103": 109, "193": [], "166": [], "123": 109, "200000": 109, "266": [], "282": [], "229": [], "304": [], "761905": [], "162": [], "750000": [], "161": [], "766": [], "666667": [], "510": [], "714286": [], "230": [], "285714": [], "491": [], "163": [], "142857": [], "418": [], "367347": [], "169": [], "501": [], "587302": [], "131": [], "353": [], "346": [], "857120": [], "196": [], "111111": [], "571429": [], "489796": [], "542": [], "857143": [], "833333": [], "384": [], "772727": [], "769": [], "545455": [], "292": [], "600000": 109, "260": [], "213": [], "333325": [], "186": [], "249": [], "499996": [], "111": [], "400000": [], "314": [], "102": [], "262": [], "873": [], "333299": [], "317": [], "531914": [], "344": [], "145": 109, "467": [], "714290": [], "933333": [], "298246": [], "340426": [], "134": [], "155": [], "496": [], "166667": [], "226": [], "565": [], "194": [], "148": 109, "181818": [], "454545": [], "357569": [], "224": [], "324322": [], "555556": [], "985": [], "277763": [], "733333": [], "423077": [], "141": [], "201": [], "251": [], "ensembl": 109, "gradientboostingclassifi": 109, "35193837": [], "15100322": [], "37937706": [], "21685053": [], "00572692": [], "35366461": [], "10757065": [], "05879746": [], "30753862": [], "27232834": [], "08068463": [], "45049988": [], "0060788": [], "07484116": [], "13040501": [], "19635191": [], "1242306": [], "66716023": [], "32382886": [], "04121226": [], "26585647": [], "33936103": [], "04903773": [], "02095465": [], "00546565": [], "06986865": [], "00787551": [], "34063497": [], "11724709": [], "07787983": [], "31888453": [], "13037105": [], "04135072": [], "90892501": [], "16500385": [], "1283525": [], "14416355": [], "08225486": [], "42131848": [], "00556242": [], "10858594": [], "01104204": [], "75754023": [], "03973348": [], "12670468": [], "03626968": [], "12951083": [], "05274683": [], "3620197": [], "0364981": [], "32033171": [], "35990093": [], "07887963": [], "11768663": [], "14273112": [], "02035232": [], "7821337": [], "04273572": [], "13181626090930249": [], "death": 109, "within": [109, 112], "34214908": [], "15483742": [], "33360699": [], "21308046": [], "00311157": [], "359681": [], "11028062": [], "06525265": [], "32251312": [], "26930135": [], "08273835": [], "47329251": [], "00722481": [], "07548401": [], "13385522": [], "1992917": [], "12232846": [], "67345188": [], "30241027": [], "03958685": [], "26278474": [], "32718327": [], "04868508": [], "0261224": [], "00102555": [], "07001004": [], "01674666": [], "33343453": [], "11249884": [], "05936183": [], "33902806": [], "13446026": [], "04408134": [], "90951684": [], "18122974": [], "12890962": [], "14675372": [], "09387125": [], "40208288": [], "00692851": [], "1096049": [], "02037488": [], "76030491": [], "04719836": [], "15350811": [], "03047809": [], "13395765": [], "05205824": [], "35508516": [], "03555667": [], "30540774": [], "36072918": [], "07001589": [], "11951063": [], "13380248": [], "01573469": [], "80052499": [], "04350663": [], "1311544427995885": [], "271": [], "21870224": [], "40566972": [], "66622106": [], "1879345": [], "1901635": [], "85648741": [], "9401981": [], "30275857": [], "67184641": [], "36721931": [], "59254365": [], "12774396": [], "4649726": [], "60819096": [], "0017973": [], "11530562": [], "7907991": [], "77513013": [], "27653223": [], "27977167": [], "33523561": [], "63267806": [], "5328774": [], "40388746": [], "41585275": [], "87905889": [], "65355666": [], "46495149": [], "06793454": [], "14837157": [], "57664137": [], "12229885": [], "81609308": [], "53073325": [], "7307595": [], "19831203": [], "84101367": [], "84671498": [], "66528849": [], "26055158": [], "70986044": [], "20867846": [], "64290819": [], "90753136": [], "05010359": [], "06274677": [], "00564529": [], "82901546": [], "2423345": [], "84998288": [], "6205014": [], "75504146": [], "38889206": [], "89695554": [], "82694905": [], "84062773": [], "17027401": [], "71774599": [], "89250861": [], "12039556": [], "99682994": [], "8115788": [], "67692267": [], "49726147": [], "14091275": [], "81277854": [], "99234011": [], "26287652": [], "6201452": [], "55478225": [], "51406748": [], "94066256": [], "81857514": [], "32446681": [], "65200423": [], "52600314": [], "65274637": [], "43326703": [], "1311298": [], "98514328": [], "84965923": [], "59685668": [], "19285778": [], "39099085": [], "64473278": [], "94732209": [], "59949607": [], "57939714": [], "97767451": [], "74199621": [], "4573362": [], "7692076": [], "68035161": [], "4551159": [], "18658372": [], "57316288": [], "24437089": [], "12308573": [], "07157904": [], "54553513": [], "51033153": [], "72059844": [], "73863371": [], "3825371": [], "24976983": [], "92079241": [], "3779517": [], "690975": [], "17710764": [], "03307371": [], "65368796": [], "74642474": [], "78890149": [], "73139714": [], "76941559": [], "67403198": [], "67380637": [], "28527416": [], "33060888": [], "6236443": [], "48675916": [], "35922594": [], "20071466": [], "51001997": [], "3204937": [], "63009583": [], "02760156": [], "57296171": [], "95090512": [], "3324716": [], "81677784": [], "20916119": [], "86120512": [], "249127": [], "37621414": [], "15349536": [], "79589419": [], "35246522": [], "31678183": [], "19296922": [], "77700503": [], "51193196": [], "99117612": [], "4823706": [], "53156153": [], "43102557": [], "40103314": [], "61969736": [], "64124312": [], "76152565": [], "94959211": [], "65342793": [], "34557005": [], "27355209": [], "4209176": [], "13746585": [], "36171859": [], "33685667": [], "13257665": [], "81306708": [], "68853012": [], "31979033": [], "24412454": [], "09177695": [], "86438281": [], "84099211": [], "44339376": [], "27803224": [], "26479591": [], "8494692": [], "96195243": [], "89076941": [], "40085841": [], "95628598": [], "9584967152996288": [], "smaple_demo": [], "3098": [], "1902": [], "55370395": [], "4298809412995734": [], "workflow": 111, "depict": 111, "summari": 111, "merit": 111, "downsid": 111, "miscellan": 111, "subtract": 111, "wish": 111, "social": 111, "epidemiolog": 111, "t_0": 111, "ccc": 111, "hline": 111, "vdot": 111, "hdashlin": 111, "substanti": 111, "willing": 111, "parallel": 111, "adequ": 111, "sc": 111, "seek": 111, "compens": 111, "correpond": 111, "conjunct": 111, "bowl": 111, "quatil": 111, "otr": 111, "jump": 111, "comb": 111, "dmitri": 111, "arkhangelski": 111, "hirshberg": 111, "guido": 111, "imben": 111, "technic": 111, "bureau": 111, "practition": 112, "handbook": 112, "complement": 112, "unifi": 112, "api": 112, "desktop": 112, "branch": 112, "go": 112, "visiabl": 112, "_build": 112, "commit": 112, "push": 112, "cd": 112, "password": 112, "gh": 112, "reinstal": 112, "credenti": 112, "token": 112, "cname": 112, "subset_rl_data_final_cont": 109, "mimic3_bas": 109, "48h": 109, "1006": 109, "173913": 109, "625": 109, "428571": 109, "758782": 109, "mimic3_multi_stag": 109, "wb": 109, "dump": 109, "mimic_fin": 109, "to_csv": 109, "ipykernel_30529": 109, "758319251": 109, "lag": 109, "lag_k": 109, "new_sofa": 109, "mimic3_sampl": 109, "groupbi": 109, "ipykernel_28731": 109, "3793710715": 109, "mimic3_single_stag": 109, "152": 109, "137": 109, "081590": 109, "800000": 109, "1204": 109, "138": 109, "794872": 109, "782051": 109, "668956": 109, "153846": 109, "4132": 109, "364286": 109, "956461": 109, "252": 109, "883864": 109, "4201": 109, "580087": 109, "118": 109, "083333": 109, "539": 109, "065657": 109, "363636": 109, "818182": 109, "5170": 109, "174": 109, "525000": 109, "147": 109, "350198": 109, "616727": 109, "437500": 109, "6504": 109, "081169": 109, "836364": 109, "423": 109, "030303": 109, "090909": 109, "fste": 109, "5769399": 109, "5085273": 109, "58722237": 109, "46061915": 109, "75731054": 109, "fsde": 109, "48898334": 109, "59767349": 109, "30945388": 109, "69109301": 109, "fsie": 109, "06592324": 109, "08914619": 109, "27776849": 109, "06621753": 109, "35384615": 109, "70769231": 109, "06153846": 109, "41538462": 109, "76923077": 109, "12307692": 109, "47692308": 109, "83076923": 109, "18461538": 109, "53846154": 109, "barcontain": 109, "artist": 109, "12968636e": 109, "19898149e": 109, "24396566e": 109, "43603356e": 109, "31089138e": 109, "21971678e": 109, "06065978e": 109, "82908445e": 109, "29373902e": 109, "57378496e": 109, "80665075e": 109, "19204846e": 109, "87878672e": 109, "64194759e": 109, "74329403e": 109, "99208870e": 109, "05536722e": 109, "93997356e": 109, "37658583e": 109, "30516698e": 109, "69053614e": 109, "25454412e": 109, "90354918e": 109, "84492112e": 109, "74707375e": 109, "99243862e": 109, "32124499e": 109, "76639796e": 109, "81722590e": 109, "36737950e": 109, "48175640e": 109, "16482878e": 109, "83113927e": 109, "46330508e": 109, "02204099e": 109, "14829020e": 109, "10124807e": 109, "05696535e": 109, "95670546e": 109, "12886177e": 109, "77514502e": 109, "98200718e": 109, "50224457e": 109, "93376762e": 109, "25920083e": 109, "61056677e": 109, "69004260e": 109, "71707357e": 109, "38961340e": 109, "80770800e": 109, "64875651e": 109, "62006664e": 109, "24956862e": 109, "45699450e": 109, "50326753e": 109, "76415804e": 109, "13658304e": 109, "19737465540314486": 109, "42850795": 109, "04122985": 109, "37054069": 109, "0055272": 109, "10384686": 109, "01457029": 109, "16909439": 109, "28221447": 109, "05764574": 109, "008193": 109, "30211856": 109, "0551675": 109, "01006845": 109, "09689565": 109, "10600407": 109, "18238777": 109, "44978522": 109, "19716563": 109, "289073": 109, "03827421": 109, "22619666": 109, "1875545": 109, "23778146": 109, "20841167": 109, "73958005": 109, "11909299": 109, "09661241": 109, "15624675": 109, "3466977": 109, "42682439": 109, "353852": 109, "12244475": 109, "53581201": 109, "38763738": 109, "00624024": 109, "02708992": 109, "08227609": 109, "09644005": 109, "19550407": 109, "30207966": 109, "03525717": 109, "34339108": 109, "30668368": 109, "11740263": 109, "23538089": 109, "41147115": 109, "46029296": 109, "10346963": 109, "51161134": 109, "04498817": 109, "18302802": 109, "21907476": 109, "54002382": 109, "23518752": 109, "06635588": 109, "83090637": 109, "3999141": 109, "20399937380848096": 109, "20534783": 109, "60799131": 109, "03101525": 109, "30487613": 109, "73901719": 109, "50869865": 109, "93409258": 109, "06268418": 109, "62814712": 109, "33088885": 109, "06805273": 109, "85343431": 109, "3891968": 109, "77059072": 109, "85723926": 109, "90852121": 109, "16255577": 109, "73226175": 109, "0713091": 109, "61008793": 109, "84837405": 109, "73072933": 109, "96310458": 109, "69542996": 109, "06679508": 109, "80242966": 109, "75052079": 109, "89086905": 109, "0049731": 109, "05624172": 109, "05820508": 109, "80224073": 109, "08963454": 109, "0349788": 109, "01483998": 109, "63905221": 109, "74432509": 109, "78090422": 109, "99109928": 109, "95093155": 109, "67313649": 109, "06334448": 109, "05130982": 109, "86413964": 109, "79011822": 109, "13613724": 109, "05677335": 109, "77466503": 109, "82624963": 109, "71759965": 109, "87293765": 109, "95941413": 109, "81655015": 109, "00536321": 109, "70841914": 109, "24891247": 109, "12551622": 109, "6953789": 109, "10741154": 109, "82186952": 109, "6414173": 109, "97879022": 109, "42927105": 109, "27864757": 109, "42377512": 109, "42966655": 109, "75082494": 109, "1816504": 109, "08880529": 109, "57819536": 109, "1209202": 109, "22000112": 109, "85809935": 109, "42621801": 109, "72353439": 109, "40045611": 109, "09534446": 109, "43170283": 109, "18914595": 109, "24989338": 109, "43053592": 109, "14426689": 109, "28013788": 109, "13285216": 109, "31529729": 109, "05722861": 109, "50437684": 109, "35486627": 109, "44263627": 109, "88826623": 109, "26089302": 109, "8225689": 109, "52442018": 109, "10365132": 109, "07635828": 109, "85447013": 109, "99921777": 109, "06040788": 109, "05859007": 109, "99065991": 109, "50620091": 109, "03579105": 109, "93077781": 109, "68668211": 109, "42035374": 109, "03808058": 109, "48700577": 109, "19118358": 109, "2131336": 109, "70773032": 109, "83005235": 109, "77993266": 109, "07031865": 109, "13590299": 109, "49003107": 109, "50057977": 109, "20914573": 109, "66345884": 109, "23977303": 109, "0794276": 109, "34455499": 109, "36109094": 109, "19848057": 109, "58006391": 109, "11359767": 109, "23537098": 109, "18899855": 109, "64967052": 109, "63723815": 109, "05042186": 109, "26366224": 109, "00872736": 109, "32914701": 109, "51474347": 109, "41667122": 109, "54158338": 109, "71321121": 109, "26489405": 109, "0774718": 109, "52229178": 109, "61766863": 109, "57557176": 109, "94774448": 109, "55186488": 109, "29666119": 109, "35960446": 109, "20136832": 109, "77408578": 109, "19227108": 109, "11463203": 109, "35932623": 109, "29545405": 109, "86337085": 109, "95171379": 109, "61272862": 109, "00475441": 109, "06064992": 109, "64206127": 109, "75432718": 109, "20535944": 109, "37009124": 109, "35431129": 109, "78816905": 109, "76940612": 109, "68175408": 109, "74628053": 109, "10881984": 109, "17531085": 109, "07151351": 109, "82140618": 109, "01038676": 109, "08642818615808806": 109, "086": 109}, "objects": {}, "objtypes": {}, "objnames": {}, "titleterms": {"learner": [0, 9, 10, 11, 13, 14, 16, 20, 21, 23, 24, 25, 27, 28, 39, 40, 69, 70, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93], "name": [0, 111], "singl": [0, 19, 26, 34, 48, 49, 50, 51, 96], "multipl": [0, 32, 64, 65, 66], "stage": [0, 19, 26, 32, 34, 48, 49, 50, 64, 65, 66], "infinit": [0, 52, 57, 59, 61], "horizon": [0, 32, 52, 57, 59, 61], "main": [0, 11, 14, 19, 34, 37, 39, 48, 49, 52, 53, 55, 56, 57, 58, 59, 61, 64, 66, 69, 70, 71, 73, 74, 75, 77, 78, 79, 80, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94, 97, 98, 103, 104], "idea": [0, 11, 14, 19, 34, 37, 39, 48, 49, 52, 53, 55, 56, 57, 58, 59, 61, 64, 66, 69, 70, 71, 73, 74, 75, 77, 78, 79, 80, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94, 97, 98, 103, 104], "algorithm": [0, 11, 13, 14, 34, 48, 49, 64, 66, 67, 71, 73, 74, 83, 84, 88, 89, 90, 91, 94, 96, 97, 98, 103, 104], "detail": [0, 9, 11, 13, 14, 34, 39, 48, 64, 66, 71, 73, 74, 84, 89, 91, 94, 97, 98, 103, 104], "kei": [0, 34, 48, 64, 66, 69, 70, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94, 97, 98, 103, 104], "step": [0, 34, 48, 64, 66, 69, 70, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94, 97, 98, 103, 104, 112], "demo": [0, 11, 13, 14, 34, 37, 39, 48, 49, 52, 53, 55, 56, 57, 58, 61, 64, 66, 69, 70, 71, 73, 74, 75, 77, 78, 79, 80, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94, 97, 98, 103, 104, 109], "code": [0, 5, 11, 13, 14, 34, 39, 48, 64, 66, 69, 70, 71, 73, 74, 75, 77, 78, 79, 80, 82, 84, 85, 86, 87, 89, 91, 92, 93, 94, 97, 98, 103, 104], "1": [0, 2, 9, 11, 12, 13, 14, 15, 21, 25, 34, 39, 48, 59, 64, 66, 78, 79, 80, 96, 111, 112], "polici": [0, 2, 7, 34, 39, 45, 48, 49, 52, 53, 54, 57, 59, 60, 61, 62, 63, 64, 66, 78, 79, 80, 81, 107, 111], "learn": [0, 1, 2, 3, 26, 34, 36, 37, 39, 41, 44, 48, 51, 52, 59, 64, 66, 83, 107, 109, 111], "2": [0, 2, 9, 11, 12, 13, 14, 15, 21, 27, 34, 39, 48, 59, 64, 66, 78, 79, 80, 111, 112], "evalu": [0, 7, 34, 39, 48, 49, 52, 53, 54, 55, 57, 59, 61, 62, 63, 64, 66, 78, 79, 80, 81], "refer": [0, 2, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 34, 37, 39, 48, 52, 53, 55, 56, 57, 58, 61, 62, 63, 64, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 103, 104, 105, 107, 111], "causal": [1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 26, 63, 109, 111], "effect": [1, 4, 6, 10, 12, 26, 109, 111], "cel": [1, 26, 111], "cpl": [2, 111], "scenario": 2, "fix": [2, 111], "independ": [2, 111], "state": [2, 111], "person": [2, 12], "incent": 2, "ad": [2, 5], "target": 2, "bid": 2, "markovian": [2, 111], "transit": [2, 111], "mobil": 2, "health": 2, "3": [2, 9, 11, 12, 13, 14, 15, 21, 28, 78, 79, 80, 111], "non": [2, 11, 107, 111], "healthcar": 2, "clinic": 2, "trail": 2, "multi": [2, 72, 75, 100], "touch": 2, "attribut": 2, "4": [2, 23, 24, 111], "adapt": [2, 43, 111], "recommend": [2, 69, 70, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93, 95, 96, 105], "system": 2, "onlin": [2, 78, 79, 80, 81, 83, 88, 106], "dynam": [2, 90], "price": 2, "5": [2, 16, 24, 111], "6": [2, 20, 24, 111], "structur": [3, 9, 11, 13, 14, 68, 72, 95, 111], "csl": [3, 111], "spread": 3, "covid": 3, "19": 3, "gene": 3, "express": 3, "trait": 3, "yeast": 3, "infer": [4, 5, 6], "101": [4, 5], "potenti": [4, 6, 63, 112], "outcom": [4, 6, 37, 41, 63, 109], "assumpt": [4, 6, 15], "averag": [4, 6], "regress": 4, "model": [4, 9, 11, 13, 14], "propens": 4, "score": [4, 13], "stratif": 4, "invers": [4, 80], "weight": [4, 37, 80], "doubli": [4, 15, 52, 79], "robust": [4, 15, 52, 79], "estim": [4, 15, 19, 52], "what": [5, 111], "myst": 5, "ar": 5, "role": 5, "direct": [5, 15, 78], "us": [5, 37], "citat": 5, "execut": 5, "your": 5, "markdown": 5, "file": 5, "preliminari": [6, 8, 12, 62, 63], "do": [6, 47], "oper": 6, "treatment": [6, 10, 12, 49], "heterogen": [6, 12], "optim": [7, 49, 59, 60, 62, 63, 88, 90], "discoveri": [9, 10, 11, 13, 14, 109], "gener": [9, 11, 12, 13, 14, 18, 22, 49, 69, 70, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93], "graph": [9, 11, 12, 13, 14], "terminolog": [9, 11, 12, 13, 14], "overview": [9, 13, 39, 67, 69, 70, 71, 73, 74, 75, 77, 79, 82, 84, 85, 86, 87, 89, 91, 92, 93, 111], "popular": 9, "graphic": [9, 11, 13, 14, 68, 72], "linear": [9, 11, 13, 14], "equat": [9, 11, 13, 14], "addit": [9, 11, 13], "nois": [9, 11, 13], "lsem": [9, 13], "method": [9, 15, 96], "To": [9, 47], "Be": 9, "mediat": [10, 12], "analysi": [10, 12], "from": [10, 109], "tabl": 10, "anoc": 10, "cvae": 10, "cai": 10, "et": [10, 13], "al": [10, 13], "2020": 10, "function": [11, 62], "base": [11, 13, 14, 40, 58], "goal": [11, 13, 14], "applic": [11, 13, 14], "gaussian": [11, 14, 96], "gaussain": 11, "synthet": [11, 13, 14], "dataset": [11, 13, 14, 49], "ica": 11, "lingam": 11, "summari": [11, 13, 14], "result": [11, 13, 14], "under": [11, 13, 14, 63, 78, 79, 80], "differ": [11, 13, 14, 19], "toi": 12, "exampl": 12, "decis": [12, 31, 59, 62, 63], "make": 12, "remark": 12, "notear": 13, "zheng": 13, "2018": 13, "test": [14, 51], "pc": 14, "ATE": [15, 29], "identif": 15, "import": [15, 57, 61, 69, 70, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93, 112], "sampl": [15, 57, 61, 75, 77, 96], "dr": [16, 24], "8": [17, 22], "dragon": [17, 22], "net": [17, 22], "7": [18, 22], "random": [18, 22], "forest": [18, 22], "hte": [19, 30], "approach": [19, 22], "The": 19, "advantag": 19, "lp": [20, 24], "r": [20, 23, 24], "meta": [21, 76, 77, 102], "s": [21, 25], "t": [21, 27], "x": [21, 28], "other": 22, "mimic3": [25, 26, 27, 28, 109], "data": [25, 26, 27, 28, 43, 46, 49, 50, 65, 68, 72, 76, 83, 88, 90, 95, 96, 105, 111], "real": [26, 49, 50, 65, 68, 72, 76, 83, 88, 90, 95, 96, 105], "pre": [26, 49], "process": [26, 31, 49, 62, 63], "final": 26, "select": 26, "markov": [31, 62, 63, 107], "finit": 32, "miscellan": 33, "A": [34, 51, 64, 111], "reduct": 35, "classif": 35, "problem": [35, 50, 65, 68, 72, 76, 83, 88, 90, 95, 96, 105], "entropi": 36, "when": [37, 112], "should": 37, "i": [37, 111], "owl": 37, "spars": 37, "a1": 37, "deriv": 37, "continu": [38, 39], "action": [38, 39, 42], "space": [38, 42], "deep": 39, "jump": 39, "difficulti": 39, "kernel": 40, "discret": 42, "collect": 43, "concord": 44, "assist": 44, "search": 45, "time": 46, "event": 46, "plan": 47, "q": [48, 55, 56, 59, 66], "quantil": 49, "regim": 49, "motiv": 49, "set": [49, 50, 65, 68, 72, 76, 83, 88, 90, 95, 96, 105], "simul": [49, 96], "off": [49, 53, 62, 63], "qope": 49, "dtr": [50, 65], "doubl": 52, "reinforc": 52, "stationari": [52, 57], "distribut": [52, 57, 58], "todo": [52, 53, 55, 56, 57, 58, 61], "note": [52, 53, 57, 58, 61], "deepli": 53, "debias": 53, "fit": [55, 56], "iter": 56, "break": 57, "curs": 57, "confid": [58, 96], "interv": 58, "op": 58, "asymptot": 58, "ci": 58, "drl": 58, "valu": 62, "framework": [63, 78, 79, 80], "identifi": 63, "bandit": [67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 83, 88, 90, 95, 96, 111], "contextu": 68, "lint": [69, 98], "environ": [69, 70, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93, 107], "specifi": [69, 70, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93], "hyperparamet": [69, 70, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93], "interact": [69, 70, 71, 73, 74, 75, 77, 82, 84, 85, 86, 87, 89, 91, 92, 93], "bernoulli": [69, 70, 71, 73, 74, 75, 77, 96], "linucb": [70, 99], "epsilon": [71, 96], "greedi": [71, 96], "arm": 72, "mab": 72, "ts": [73, 78, 79, 80, 102, 103], "ucb": [74, 78, 79, 80], "task": [75, 100], "thompson": [75, 77, 96], "mtt": [75, 101], "eg": [78, 79, 80], "probabl": [79, 80], "explor": [79, 80], "cascadelint": 82, "rank": 83, "cascad": 83, "support": [83, 88, 90, 96], "mtss_cascad": 84, "ts_cascad": 85, "comblint": 86, "combt": 87, "combinatori": 88, "semi": 88, "mtss_comb": 89, "assort": 90, "multinomi": 90, "logit": 90, "mtss_mnl": 91, "ts_contextual_mnl": 92, "ts_mnl": 93, "ucb_mnl": 94, "slate": [95, 105], "item": 96, "claasic": 96, "upper": 96, "bound": 96, "epsilon_greedi": 97, "ucb1": 104, "rl": 106, "oolin": 107, "mimic": 108, "iii": 108, "exclud": 109, "sofa": 109, "covari": 109, "list": 109, "regard": 109, "variabl": 109, "2023": [], "02": [], "11": [], "chang": [], "anoth": [], "movielen": 110, "introduct": 111, "expect": 111, "sl": 111, "ml": 111, "case1": 111, "paradigm": 111, "d": 111, "panel": 111, "pl": 111, "case2": 111, "case3": 111, "case4": 111, "case5": 111, "case6": 111, "appendix": 111, "singeldtr": 111, "mdp": 111, "b": 111, "multidtr": 111, "c": 111, "content": 112, "everi": 112, "notebook": 112, "how": 112, "contribut": 112, "compil": 112, "new": 112, "version": 112, "option": 112, "publish": 112, "error": 112, "messag": 112, "run": 112, "ghp": 112}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinxcontrib.bibtex": 9, "sphinx": 56}})