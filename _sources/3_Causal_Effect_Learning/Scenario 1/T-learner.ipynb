{"cells":[{"cell_type":"markdown","source":["\n","### **2. T-learner**\n","The second learner is called T-learner, which denotes ``two learners\". Instead of fitting a single model to estimate the potential outcomes under both treatment and control groups, T-learner aims to learn different models for $\\mathbb{E}[R(1)|S]$ and $\\mathbb{E}[R(0)|S]$ separately, and finally combines them to obtain a final HTE estimator.\n","\n","Define the control response function as $\\mu_0(s)=\\mathbb{E}[R(0)|S=s]$, and the treatment response function as $\\mu_1(s)=\\mathbb{E}[R(1)|S=s]$. The algorithm of T-learner is summarized below:\n","\n","**Step 1:**  Estimate $\\mu_0(s)$ and $\\mu_1(s)$ separately with any regression algorithms or supervised machine learning methods;\n","\n","**Step 2:**  Estimate HTE by \n","\\begin{equation*}\n","\\hat{\\tau}_{\\text{T-learner}}(s)=\\hat\\mu_1(s)-\\hat\\mu_0(s).\n","\\end{equation*}\n","\n"],"metadata":{"id":"cMny8Ri7RvqC"},"id":"cMny8Ri7RvqC"},{"cell_type":"code","source":["import sys\n","!{sys.executable} -m pip install scikit-uplift"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676133349545,"user_tz":300,"elapsed":7237,"user":{"displayName":"Yang Xu","userId":"12270366590264264299"}},"outputId":"1e2df84c-2e8e-44d2-a736-4df7bcfa321a","id":"VaEnsqKmVCbT"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting scikit-uplift\n","  Downloading scikit_uplift-0.5.1-py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 KB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from scikit-uplift) (2.25.1)\n","Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.8/dist-packages (from scikit-uplift) (1.0.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from scikit-uplift) (4.64.1)\n","Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.8/dist-packages (from scikit-uplift) (1.21.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from scikit-uplift) (1.3.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from scikit-uplift) (3.2.2)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.0->scikit-uplift) (1.2.0)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.0->scikit-uplift) (3.1.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.0->scikit-uplift) (1.7.3)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->scikit-uplift) (1.4.4)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->scikit-uplift) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->scikit-uplift) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->scikit-uplift) (0.11.0)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->scikit-uplift) (2022.7.1)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->scikit-uplift) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->scikit-uplift) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->scikit-uplift) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->scikit-uplift) (2022.12.7)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib->scikit-uplift) (1.15.0)\n","Installing collected packages: scikit-uplift\n","Successfully installed scikit-uplift-0.5.1\n"]}],"id":"VaEnsqKmVCbT"},{"cell_type":"code","source":["# import related packages\n","from matplotlib import pyplot as plt;\n","from lightgbm import LGBMRegressor;\n","from sklearn.linear_model import LinearRegression\n","from causaldm._util_causaldm import *;"],"metadata":{"id":"LmVuim4vVCbY"},"execution_count":null,"outputs":[],"id":"LmVuim4vVCbY"},{"cell_type":"code","source":["n = 10**3  # sample size in observed data\n","n0 = 10**5 # the number of samples used to estimate the true reward distribution by MC\n","seed=223"],"metadata":{"id":"AfK6i0A_VCbZ"},"execution_count":null,"outputs":[],"id":"AfK6i0A_VCbZ"},{"cell_type":"code","source":["# Get data\n","data_behavior = get_data_simulation(n, seed, policy=\"behavior\")\n","#data_target = get_data_simulation(n0, seed, policy=\"target\")\n","\n","# The true expected heterogeneous treatment effect\n","HTE_true = get_data_simulation(n, seed, policy=\"1\")['R']-get_data_simulation(n, seed, policy=\"0\")['R']\n","\n"],"metadata":{"id":"7JCIkg1dVCba"},"execution_count":null,"outputs":[],"id":"7JCIkg1dVCba"},{"cell_type":"code","source":["mu0 = LGBMRegressor(max_depth=3)\n","mu1 = LGBMRegressor(max_depth=3)\n","\n","mu0.fit(data_behavior.iloc[np.where(data_behavior['A']==0)[0],0:2],data_behavior.iloc[np.where(data_behavior['A']==0)[0],3] )\n","mu1.fit(data_behavior.iloc[np.where(data_behavior['A']==1)[0],0:2],data_behavior.iloc[np.where(data_behavior['A']==1)[0],3] )\n","\n","\n","# estimate the HTE by T-learner\n","HTE_T_learner = mu1.predict(data_behavior.iloc[:,0:2]) - mu0.predict(data_behavior.iloc[:,0:2])\n"],"metadata":{"id":"X1VmlNjstdsN"},"execution_count":null,"outputs":[],"id":"X1VmlNjstdsN"},{"cell_type":"markdown","source":["Now let's take a glance at the performance of T-learner by comparing it with the true value for the first 10 subjects:"],"metadata":{"id":"CUv_0SuBTi3e"},"id":"CUv_0SuBTi3e"},{"cell_type":"code","source":["print(\"T-learner:  \",HTE_T_learner[0:8])\n","print(\"true value: \",HTE_true[0:8].to_numpy())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5OHVneDpTgMp","executionInfo":{"status":"ok","timestamp":1676133432547,"user_tz":300,"elapsed":279,"user":{"displayName":"Yang Xu","userId":"12270366590264264299"}},"outputId":"b52dcdb0-7c95-4610-de67-be469620b196"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["T-learner:   [ 1.869   1.8733  0.6596  0.3087 -0.2298 -0.5598 -2.2745 -1.8211]\n","true value:  [ 1.2961 -0.4475  0.731   0.2863  0.4471 -0.1839 -3.3869 -1.238 ]\n"]}],"id":"5OHVneDpTgMp"},{"cell_type":"markdown","source":["This is quite good! T-learner captures the overall trend of the treatment effect w.r.t. the heterogeneity of different subjects."],"metadata":{"id":"Ux89PwJagR5_"},"id":"Ux89PwJagR5_"},{"cell_type":"code","source":["Bias_T_learner = np.sum(HTE_T_learner-HTE_true)/n\n","Variance_T_learner = np.sum((HTE_T_learner-HTE_true)**2)/n\n","print(\"The overall estimation bias of T-learner is :     \", Bias_T_learner, \", \\n\", \"The overall estimation variance of T-learner is :\",Variance_T_learner,\". \\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SW8ONIdFPpvM","executionInfo":{"status":"ok","timestamp":1676133434389,"user_tz":300,"elapsed":280,"user":{"displayName":"Yang Xu","userId":"12270366590264264299"}},"outputId":"2d305edf-3657-43eb-a70b-eb6e990634e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The overall estimation bias of T-learner is :      0.29138198450323705 , \n"," The overall estimation variance of T-learner is : 1.810391408711312 . \n","\n"]}],"id":"SW8ONIdFPpvM"},{"cell_type":"markdown","source":["**Conclusion:** In this toy example, the overall estimation variance of T-learner is smaller than that of S-learner. In some cases when the treatment effect is relatively complex, it's likely to yield better performance by fitting two models separately. \n","\n","However, in an extreme case when both $\\mu_0(s)$ and $\\mu_1(s)$ are nonlinear complicated function of state $s$ while their difference is just a constant, T-learner will overfit each model very easily, yielding a nonlinear treatment effect estimator. In this case, other estimators are often preferred."],"metadata":{"id":"vOsw-rfxU415"},"id":"vOsw-rfxU415"},{"cell_type":"markdown","source":["## References\n","1. Kunzel, S. R., Sekhon, J. S., Bickel, P. J., and Yu, B. (2019). Metalearners for estimating heterogeneous treatment effects using machine learning. Proceedings of the national academy of sciences 116, 4156–4165.\n"],"metadata":{"id":"nyirbjS5JdGh"},"id":"nyirbjS5JdGh"}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}