{"cells":[{"cell_type":"markdown","source":["### **4. R learner**\n","The idea of classical R-learner came from Robinson 1988 [3] and was formalized by Nie and Wager in 2020 [2]. The main idea of R learner starts from the partially linear model setup, in which we assume that\n","\\begin{equation}\n","  \\begin{aligned}\n","    R&=A\\tau(S)+g_0(S)+U,\\\\\n","    A&=m_0(S)+V,\n","  \\end{aligned}\n","\\end{equation}\n","where $U$ and $V$ satisfies $\\mathbb{E}[U|D,X]=0$, $\\mathbb{E}[V|X]=0$.\n","\n","After several manipulations, it’s easy to get\n","\\begin{equation}\n","\tR-\\mathbb{E}[R|S]=\\tau(S)\\cdot(A-\\mathbb{E}[A|S])+\\epsilon.\n","\\end{equation}\n","Define $m_0(X)=\\mathbb{E}[A|S]$ and $l_0(X)=\\mathbb{E}[R|S]$. A natural way to estimate $\\tau(X)$ is given below, which is also the main idea of R-learner:\n","\n","**Step 1**: Regress $R$ on $S$ to obtain model $\\hat{\\eta}(S)=\\hat{\\mathbb{E}}[R|S]$; and regress $A$ on $S$ to obtain model $\\hat{m}(S)=\\hat{\\mathbb{E}}[A|S]$.\n","\n","**Step 2**: Regress outcome residual $R-\\hat{l}(S)$ on propensity score residual $A-\\hat{m}(S)$.\n","\n","That is,\n","\\begin{equation}\n","\t\\hat{\\tau}(S)=\\arg\\min_{\\tau}\\left\\{\\mathbb{E}_n\\left[\\left(\\{R_i-\\hat{\\eta}(S_i)\\}-\\{A_i-\\hat{m}(S_i)\\}\\cdot\\tau(S_i)\\right)^2\\right]\\right\\}\t\n","\\end{equation}\n","\n","The easiest way to do so is to specify $\\hat{\\tau}(S)$ to the linear function class. In this case, $\\tau(S)=S\\beta$, and the problem becomes to estimate $\\beta$ by solving the following linear regression:\n","\\begin{equation}\n","\t\\hat{\\beta}=\\arg\\min_{\\beta}\\left\\{\\mathbb{E}_n\\left[\\left(\\{R_i-\\hat{\\eta}(S_i)\\}-\\{A_i-\\hat{m}(S_i)\\} S_i\\cdot \\beta\\right)^2\\right]\\right\\}.\n","\\end{equation}\n","\n"],"metadata":{"id":"32szzPY4RyWO"},"id":"32szzPY4RyWO"},{"cell_type":"code","source":["import sys\n","!{sys.executable} -m pip install scikit-uplift"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oJd6A5hgXmGZ","executionInfo":{"status":"ok","timestamp":1676134075357,"user_tz":300,"elapsed":4287,"user":{"displayName":"Yang Xu","userId":"12270366590264264299"}},"outputId":"9e32343f-1b89-4ab6-eca3-8a02680d80af"},"id":"oJd6A5hgXmGZ","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting scikit-uplift\n","  Downloading scikit_uplift-0.5.1-py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 KB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.8/dist-packages (from scikit-uplift) (1.21.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from scikit-uplift) (1.3.5)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from scikit-uplift) (3.2.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from scikit-uplift) (2.25.1)\n","Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.8/dist-packages (from scikit-uplift) (1.0.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from scikit-uplift) (4.64.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.0->scikit-uplift) (3.1.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.0->scikit-uplift) (1.2.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.21.0->scikit-uplift) (1.7.3)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->scikit-uplift) (3.0.9)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->scikit-uplift) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->scikit-uplift) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->scikit-uplift) (1.4.4)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->scikit-uplift) (2022.7.1)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->scikit-uplift) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->scikit-uplift) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->scikit-uplift) (2022.12.7)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->scikit-uplift) (2.10)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib->scikit-uplift) (1.15.0)\n","Installing collected packages: scikit-uplift\n","Successfully installed scikit-uplift-0.5.1\n"]}]},{"cell_type":"code","source":["# import related packages\n","from matplotlib import pyplot as plt\n","from lightgbm import LGBMRegressor\n","from sklearn.linear_model import LinearRegression\n","from sklearn.linear_model import LogisticRegression \n","from causaldm._util_causaldm import *\n","from causaldm.learners.Causal_Effect_Learning.Single_Stage.Rlearner import Rlearner"],"metadata":{"id":"eRpP5k9MBtzO"},"execution_count":null,"outputs":[],"id":"eRpP5k9MBtzO"},{"cell_type":"code","source":["n = 10**3  # sample size in observed data\n","n0 = 10**5 # the number of samples used to estimate the true reward distribution by MC\n","seed=223"],"metadata":{"id":"lovM_twTxuOj"},"execution_count":null,"outputs":[],"id":"lovM_twTxuOj"},{"cell_type":"code","source":["# Get data\n","data_behavior = get_data_simulation(n, seed, policy=\"behavior\")\n","#data_target = get_data_simulation(n0, seed, policy=\"target\")\n","\n","# The true expected heterogeneous treatment effect\n","HTE_true = get_data_simulation(n, seed, policy=\"1\")['R']-get_data_simulation(n, seed, policy=\"0\")['R']\n","\n"],"metadata":{"id":"AnRQO0viX3D1"},"id":"AnRQO0viX3D1","execution_count":null,"outputs":[]},{"cell_type":"code","source":["# R-learner for HTE estimation\n","outcome = 'R'\n","treatment = 'A'\n","controls = ['S1','S2']\n","n_folds = 5\n","y_model = LGBMRegressor(max_depth=2)\n","ps_model = LogisticRegression()\n","Rlearner_model = LGBMRegressor(max_depth=2)\n","\n","HTE_R_learner = Rlearner(data_behavior, outcome, treatment, controls, n_folds, y_model, ps_model, Rlearner_model)\n","HTE_R_learner = HTE_R_learner.to_numpy()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jYIe491FKQAs","executionInfo":{"status":"ok","timestamp":1676134159221,"user_tz":300,"elapsed":687,"user":{"displayName":"Yang Xu","userId":"12270366590264264299"}},"outputId":"26de837c-daa2-4402-d668-c71439246014"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["estimate with R-learner\n","fold 1,testing r2 y_learner: 0.942, ps_learner: 0.943\n","fold 2,testing r2 y_learner: 0.958, ps_learner: 0.966\n","fold 3,testing r2 y_learner: 0.951, ps_learner: 0.948\n","fold 4,testing r2 y_learner: 0.957, ps_learner: 0.932\n","fold 5,testing r2 y_learner: 0.950, ps_learner: 0.944\n","fold 1, training r2 R-learner: 0.683, testing r2 R-learner: 0.584\n","fold 2, training r2 R-learner: 0.659, testing r2 R-learner: 0.705\n","fold 3, training r2 R-learner: 0.677, testing r2 R-learner: 0.536\n","fold 4, training r2 R-learner: 0.667, testing r2 R-learner: 0.642\n","fold 5, training r2 R-learner: 0.669, testing r2 R-learner: 0.551\n"]}],"id":"jYIe491FKQAs"},{"cell_type":"code","source":["print(\"R-learner:  \",HTE_R_learner[0:8])\n","print(\"true value: \",HTE_true[0:8].to_numpy())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676134159939,"user_tz":300,"elapsed":176,"user":{"displayName":"Yang Xu","userId":"12270366590264264299"}},"outputId":"d1c29b6e-2994-44d5-f2d9-07331faa6f5f","id":"D_B2JzoeEVkM"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["R-learner:   [-0.5085 -0.1427 -1.1424 -0.0139 -1.1341 -1.1424 -1.4466 -1.5688]\n","true value:  [ 1.2961 -0.4475  0.731   0.2863  0.4471 -0.1839 -3.3869 -1.238 ]\n"]}],"id":"D_B2JzoeEVkM"},{"cell_type":"code","source":["Bias_R_learner = np.sum(HTE_R_learner-HTE_true)/n\n","Variance_R_learner = np.sum((HTE_R_learner-HTE_true)**2)/n\n","print(\"The overall estimation bias of R-learner is :     \", Bias_R_learner, \", \\n\", \"The overall estimation variance of R-learner is :\",Variance_R_learner,\". \\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676134160896,"user_tz":300,"elapsed":142,"user":{"displayName":"Yang Xu","userId":"12270366590264264299"}},"outputId":"bd4d43cf-5fd2-4263-aeb8-449ac7ad7d37","id":"2FvnH_FtEVkj"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["The overall estimation bias of R-learner is :      -0.02930508052654023 , \n"," The overall estimation variance of R-learner is : 3.1359997242638173 . \n","\n"]}],"id":"2FvnH_FtEVkj"},{"cell_type":"markdown","source":["**Conclusion:** It's amazing to see that the bias of R-learner is significantly smaller than all other approaches."],"metadata":{"id":"EWhausRhExr5"},"id":"EWhausRhExr5"},{"cell_type":"markdown","metadata":{"id":"1098b550"},"source":["## References\n","\n","2. Xinkun Nie and Stefan Wager. Quasi-oracle estimation of heterogeneous treatment effects. Biometrika, 108(2):299–319, 2021.\n","\n","3. Peter M Robinson. Root-n-consistent semiparametric regression. Econometrica: Journal of the Econometric Society, pages 931–954, 1988.\n","\n","4. Edward H Kennedy. Optimal doubly robust estimation of heterogeneous causal effects. arXiv preprint arXiv:2004.14497, 2020\n","\n","5. M. J. van der Laan. Statistical inference for variable importance. The International Journal of Biostatistics, 2(1), 2006.\n","\n","6. S. Lee, R. Okui, and Y.-J. Whang. Doubly robust uniform confidence band for the conditional average treatment effect function. Journal of Applied Econometrics, 32(7):1207–1225, 2017.\n","\n","7. D. J. Foster and V. Syrgkanis. Orthogonal statistical learning. arXiv preprint arXiv:1901.09036, 2019."],"id":"1098b550"}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"colab":{"provenance":[],"collapsed_sections":["1098b550"]}},"nbformat":4,"nbformat_minor":5}